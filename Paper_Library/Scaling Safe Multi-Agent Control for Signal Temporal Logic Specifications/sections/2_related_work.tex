\subsection{Related Work}
\label{sec:related}

Symbolic methods have been part of a recent resurgence as neuro-symbolic algorithms \citep{Chaudhuri2021,Xu2018} which aspire to combine the generalizability of neural 
methods with the ability of most symbolic systems to be interpretable and modifiable by human users.
Notably, there have been efforts to integrate temporal logic constraints within learning-enabled controllers.
In the field of Reinforcement Learning (RL), some examples of this are TLTL \citep{li2017reinforcement}, which defines a reward function from a logic specification 
and reward shaping mechanisms, \citep{Icarte2022, Jothimurugan2019} which create automata modeling a similar specification and augment RL-based algorithms used for control.
This has been extended to the Multi-agent domain, which had recent work \citep{Neary2021, Eappen2022} showing possibilities of coordinating multiple agents 
with diverging objectives, as well as the benefits of distributing specifications among agents in terms of scalability.

% A key aspect of scaling control to higher-dimension environments and robots involves efficiently incorporating a high-level planner into the approach. 
% The planner and the low-level controller focus on two often significantly differing features of the underlying task. \SJ{Say what these different features are}
A key aspect of scaling control to higher-dimensional environments and robots involves efficiently incorporating a high-level planner. This involves decomposing complex logic planning from control tasks, allowing each component to focus on its specific role. The high-level planner focuses on logic-level planning, ensuring that the robot's actions adhere to complex specifications, such as those defined by STL. In contrast, the low-level controller acts as a tracker, executing the high-level plan accurately.
Modern control methods have demonstrated this benefit as well from the burgeoning progress in Hierarchical RL \citep{yang2020hierarchical,Nachum2018, Haworth2020, Vezhnevets2020, Icarte2022} methods as 
well as the successful integration of classical planners with advanced control schemes, including RL controllers \citep{Xiong2022}.

Symbolic techniques have appeared in robot motion planning as well with the use of Signal Temporal Logic (STL) to specify objectives for multi-robot systems, which can then be solved by MILP solvers \citep{Sun2022}, graph-based algorithms \citep{Buyukkocak2021}  or sampling-based methods \citep{Kantaros2020,Vasile2020}. 
Collision avoidance in these multi-robot systems is a challenging problem since one must also achieve the underlying objectives as well and a myriad of techniques \citep{chen2021scalable,qin2021learning,zhang_neural_2023,zhang_gcbf_2024,yu2022learning} have attempted to handle this for general robot motion planning tasks. 
These existing methods, however, have not considered the generality of symbolic methods in specifying these objectives or quickly fail to scale as the specification dimension, robot complexity and number of agents increases.


% \ab{THE RELATED WORK SECTION SEEMS A BIT SHORT; KEEP IN MIND YOUR BROADER AREA THAT YOU DEFINED IN THE ABSTRACT IS " safe multi-agent control via rich specification" ARE YOU COVERING ALL THE SUBCLASSES OF THAT? ALSO, YOU MENTIONED, "These existing methods, however, have not considered the generality of symbolic methods in specifying these objectives or quickly fail to scale as the specification dimension, robot complexity, and/or the number of agents increases." YOU MIGHT WANT TO END THAT BY MENTIONING THAT YOUR APPROACH ALLEVIATES THOSE ISSUES BECAUSE XYZ...AND THEN THAT'S A NATURAL PROGRESSION TO SECTION 3}