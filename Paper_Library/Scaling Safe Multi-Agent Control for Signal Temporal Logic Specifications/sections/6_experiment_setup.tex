\section{Experiment Setup}
\label{sec:exp-setup}

Our experiments aim to validate the following two questions:
\begin{itemize}
	\item How scalable is a neural STL planner over competing methods in terms of the number of agents and specification complexity? 
 % \zk{Or say how much better than baseline, or how scalable is neural STL planner? Necessary sounds like something people have to choose, it is a bit too strong. }
 % \item Is ``co-learning" the safety and objective policies necessary in multi-agent systems?
	\item How do the distinct components of our planner (GNN and ODE) help with scalability?
 % Is ``co-learning" the safety and objective policies necessary in multi-agent systems? \zk{Co-learning is not mentioned in intro and abstract. Although it appeared in the approach, but I feel that it is not the main focus of our work. } \zk{We should ask questions about GNN and ODE, and why they can scale things up. }
\end{itemize}

To demonstrate the robustness of our method to various specifications and agent models we execute our experiments on the following robot benchmarks: 
2D single integrator dynamics (App. \ref{app:ss-single-addnl-experiments}), 
2D non-linear Dubins Car model (Table \ref{tab:dubins-spec-v-n-results}), 
2D Double Integrator dynamics (App. \ref{app:ss-double-addnl-experiments}) 
and a real-world 3D drone quadcopter setup moving in a fixed 2D plane (App. \ref{app:real-world-expts}).

Our framework\footnote{Code: \href{https://github.com/jeappen/mastl-gcbf}{https://github.com/jeappen/mastl-gcbf}} was built using JAX \citep{jax2018github} based off \gcbfp~ \citep{zhang_gcbf_2024} (Sec. \ref{sec:app-gcbf+}) with all comparisons using this underlying collision avoidance controller. 
To demonstrate the effectiveness of our method, we compare it against a state-of-the-art MILP-based planner (STLPY \citep{kurtz2022mixed}, Table \ref{tab:dubins-spec-v-n-results}) and an ablation of our planner without  the GNN component (labeled ODE, Table \ref{tab:dubins-ode-ablation}).

We evaluate the planner on a range of specifications: \seq,~\cover, ~\loopspec~ and ~\branch. 
These STL specifications can be drawn to parallels in the real-world. A \seq~task is akin to a set of drones that need to visit a series of locations in a specific order at given time intervals for logging time-sensitive information. 
The \cover~task depicts a scenario where each drone measures a different sensor reading but must all cover the same locations within a time interval to consolidate information. 
The \loopspec~task captures a set of surveillance drones patrolling the same areas. 
Lastly, consider a scenario where drones are grouped into two separate rooms with two goals present in each. Here a \branch~task could represent a common specification applied to each agent that they must visit the goals of a particular room. 
For a more formal description of the specifications, refer to Appendix \ref{app:stl-specs}.

%To emphasize the challenge of satisfying these individual temporal objectives while ensuring global constraints such as safety \SJ{What does safety mean here - collision avoidance or goal satisfaction}, we perform a related ablation study (Table \ref{tab:safety-performance}) showcasing how our approach balances liveness (or performance) and safety. 
%For each specification, we consider the case of an algorithm prioritizing safety above all else while sacrificing objective satisfaction (i.e. by remaining stationary rather than risking collisions) vs. an algorithm that can satisfy the temporal specifications nearly always yet allows collisions between agents by simply following the nominal controller.
%% \joe{explain nominal controller as part of gcbf}

We sampled 30 random initial seeds for each experiment and
 report the mean planning time (in seconds), the percentage of runs in which the specification was satisfied (Finish Rate), the percentage of runs where the agent was safe (i.e. did not collide),
 the percentage of successful runs for each specification where the STL specification was satisfied and no collisions occurred, and time-to-reach (TtR) in number of steps (i.e. how long it took for the successful runs to complete the task).