\section{Experiments} \label{sec:experiments}

%We evaluate  MILPs and heuristics on Ethereum mainnet transaction traces from the last two weeks of January 2025. Read/write sets are extracted from these traces, and the conflicts are derived from those read/write sets. 
As described, we study two validator-side tasks: (i) OBS: scheduling a fixed ordered block on $p$ cores to minimize makespan and (ii) PBC: selecting and scheduling mempool transactions to maximize reward under a runtime budget $B$. We evaluate our MILP formulations and conflict-aware greedy heuristics on transaction traces extracted from the Ethereum mainnet for blocks 21,631,019 - 21,635,079, spanning 15 - 16 January 2025. %during \LK{[TODO: precise date range, e.g., blocks XX -- XX (on January XX 2025)]}.  
Each transaction trace records the execution outcome, including the read and write sets, gas used, and internal call tree produced by the Ethereum Virtual Machine (EVM).  
From these traces, we extract per-transaction \texttt{gasUsed}, \texttt{to}/\texttt{from} addresses, storage keys accessed, and all contract calls.  
Conflicts are then derived exactly from overlapping read/write sets (as described in \Cref{subsubsec:conflicts}). In addition to comparing our heuristics against the MILP baselines, for OBS, we include a baseline inspired by Solana’s declared-access execution model (Sealevel), where transactions expose read/write account sets up front and the runtime schedules only non-conflicting transactions to run concurrently~\cite{solanaSealevel,yakovenko2017solana}. We denote this baseline by \textbf{Sol}. On our Ethereum-derived instances (using the access sets extracted from traces), we implement Sol as a deterministic, event-driven scheduler that scans transactions in block order and dispatches each transaction as soon as a core becomes available and it does not conflict with currently running transactions. For PBC, we instead compare against a simple \textbf{reward-greedy} baseline (\textbf{RG}) that uses the same non-conflicting dispatch rule but selects candidates purely by reward-based priority (i.e., favoring higher-fee transactions, breaking ties by arrival order), yielding a lightweight selection-and-scheduling baseline under the conflict constraints.

\subsection{Hardware and Software}

All experiments were run on a Dell PowerEdge R7615 equipped with a single AMD EPYC 9654P (96 cores/ 192 threads) and $\approx$1.5TiB RAM, running Ubuntu 24.04.3 LTS. We use MATLAB R2025b for the heuristics and invoke HiGHS 1.7.1 through MATLAB’s \texttt{intlinprog} for MILPs. We do not limit the number of threads: MATLAB and HiGHS may use all available cores. Unless otherwise specified, solver tolerances follow MATLAB defaults. We set a maximum running time of $\mathit{MaxTime}:=6000$ s.~for the solver. All heuristics are deterministic; repeated runs on the same workload yield identical schedules.

\subsection{Workload Construction}
Our experiments use real Ethereum transactions to synthesize controlled workloads for both problems.  
To control workload size across configurations $(R \text{ or } B, p, X)$, we build synthetic workloads by taking consecutive mainnet transactions in their original order and re-aggregating them, rather than relying on variable on-chain block boundaries.


\noindent\textbf{Trace filtering.}  We parse transactions and separate them into two categories:
\begin{itemize}
  \item \textbf{Homogeneous} transactions: pure ETH transfers that do not invoke any smart contract, and therefore use the default gas amount of $21,000$ units.
  \item \textbf{Heterogeneous} transactions: the full set of observed transactions, including contract calls with varying performed computations.
\end{itemize}
Each transaction’s gas used $\gasused{\tau}$ is taken directly from its execution trace, and its execution time $\executiontime{\tau}$ is normalized proportionally to gas use.

\noindent\textbf{OBS workloads.}  
For each experiment, we collect a sequence of transactions (Homogeneous or Heterogeneous) in their original blockchain order, ignoring actual block boundaries.  
We then aggregate this sequence into blocks of size determined by either
%\begin{itemize}
  %\item 
  (a) the number of rounds $R$ for homogeneous cases, each round able to process up to $p$ transactions; or
  %\item 
  (b) the gas budget $B$ for heterogeneous cases, stopping once $\sum_{\tau} \gasused{\tau} \approx B$.
%\end{itemize}
For each configuration $(R\text{ or }B,p)$, we construct five consecutive, non-overlapping workloads.
%In practice, t
This corresponds to simple transactions extracted from 219 blocks ($9,600$ transactions) of mainnet data for the homogeneous case, and 14 blocks ($2,460$ transactions) of mainnet data for the heterogeneous.% case.
%\LK{[TODO: maybe specify how many blocks’ worth of transactions were needed to reach these sizes]}


\noindent\textbf{PBC workloads.}  
To emulate a validator’s mempool, we use a sliding window of transactions.  
Given configuration $(R,p,X)$ or $(B,p,X)$, where $X$ is the \emph{pool factor}, we select a candidate pool containing approximately $X$ times the transactions (or total gas) that fit in one block:
\begin{itemize}
  \item 
  Homogeneous case: $R \cdot p \cdot X$ transactions;
  \item 
  Heterogeneous case: $B \cdot p \cdot X$, where $\sum_{\tau}\gasused{\tau} \approx B$.
\end{itemize}
The corresponding MILP and heuristic then select and schedule a feasible subset for inclusion.  
For each configuration, we again construct five independent workloads.  
In practice, this corresponds to simple transactions extracted from $2,989$ blocks ($137,200$ transactions) of mainnet data for the homogeneous case, and 24 blocks ($4,280$ transactions) of mainnet data for the heterogeneous case.
%\LK{[TODO: again, include total number of unique transactions analyzed and approximate number of source blocks.]}


\noindent\textbf{Experiment parameters.}  
For homogeneous transactions, experiment duration is discretized into equal-length rounds, so progress is naturally parameterized by the number of rounds \(R\), with per-round capacity \(p\). For heterogeneous transactions, we parameterize the experiment duration by a continuous runtime limit \(B\), which directly captures feasibility under varying processing times. For homogeneous cases, we evaluate each configuration with rounds \(R\in\{10,30,100\}\), cores \(p\in\{2,4,8\}\), and (when applicable) pool factor \(X\). For mempool experiments we use \(X\in\{2,4,8\}\) in the homogeneous case and \(X\in\{2,4\}\) in the heterogeneous case. For heterogeneous cases, we set the runtime limit to \(B\in\{210\text{K},630\text{K},2100\text{K}\}\). For every R \text{ or }B,p,X configuration, we run five %consecutive, 
non-overlapping workloads and report the mean. 

%\begin{itemize}
 %   \item \textbf{Problem~\ref{prb:block}:} Each workload contains exactly \(R\times p\) consecutive transactions (at most \(p\) per round) for simple (homogeneous) cases. For mixed (heterogeneous) cases, each workload is gas-bounded. We take consecutive transactions until the cumulative \(\sum_{\tau}\gasused{\tau} \approx B\).
%    \item \textbf{Problem~\ref{prb:mpool}:} For simple cases, given \((R,p,X)\), the candidate pool contains the next \(R\cdot p\cdot X\) transactions.  For mixed cases, given \((B,p,X)\), the candidate pool consists of consecutive transactions whose total gas-used satisfies \(\sum_{\tau}\gasused{\tau} \approx B\cdot p\cdot X\).
%\end{itemize}

\subsection{Hypotheses} \label{subsec:hypotheses}

We evaluate the following hypotheses:

%\begin{enumerate}
  %\item 
  \noindent
  \textbf{H1 (MILP scaling):} MILP runtime grows steeply with problem size and heterogeneity.

  %\item 
  \noindent
  \textbf{H2 (Heuristic speed):} The conflict-aware greedy heuristics runs orders of magnitude faster than MILPs across all settings.

  %\item \textbf{H3 (Practical quality):} Even without optimality guarantees, the heuristic yields high-quality parallel schedules that make parallel execution practically attractive compared to sequential execution.
  %\item 
  \noindent
  \textbf{H3 (Heuristic quality):} 
  %Despite lacking optimality guarantees, 
  The heuristics yield parallel schedules that approach the performance of MILP solutions.

  %\item 
  \noindent
  \textbf{H4 (Practical speedup):} The heuristics yield parallel schedules with significant speedup with respect to sequential executions.

%\end{enumerate}
