\begin{abstract}


Tensor decomposition is a fundamental tool for analyzing multi-dimensional data by learning low-rank factors to represent high-order interactions. While recent works on temporal tensor decomposition have made significant progress by incorporating continuous timestamps in latent factors, they still struggle with general tensor data with continuous indexes not only in the temporal mode but also in other modes, such as spatial coordinates in climate data.  Moreover, the challenge of self-adapting model complexity is largely unexplored in functional temporal tensor models, with existing methods being inapplicable in this setting.  To address these limitations, we propose functional \underline{C}omplexity-\underline{A}daptive \underline{T}emporal \underline{T}ensor d\underline{E}composition (\textsc{Catte}). 
 Our approach encodes continuous spatial indexes as learnable Fourier features and employs neural ODEs in latent space to learn the temporal trajectories of factors. To enable automatic adaptation of model complexity, we introduce a sparsity-inducing prior over the factor trajectories. 
 We develop an efficient variational inference scheme with an analytical evidence lower bound, enabling sampling-free optimization. Through extensive experiments on both synthetic and real-world datasets, we demonstrate that \textsc{Catte} not only reveals the underlying ranks of functional temporal tensors but also significantly outperforms existing methods in prediction performance and robustness against noise. The code is available at \url{https://github.com/OceanSTARLab/CATTE}.


    
    % Temporal tensor decomposition, which often incorporates continuous timestamps, is a powerful tool for handling multiway temporal data. Existing methods primarily focus on enc\MODEL  g these timestamps into the low-rank representations of tensors, which are associated with finite objects in each mode,  corresponding to discrete indexes. While effective for certain cases, these approaches overlook the intrinsic property of real-world dynamic tensor data like spatiotemporal tensors, where entries are characterized by both continuous mode indexes and timestamps.
    % %Although several methods based on functional tensors have been proposed recently to model continuous-indexed data, these approaches do not explicitly model temporal dynamics. 
    % To address the limitation, we propose  Ode-aided Deep varIational decompositioN for Continuous-indexed Temporal Tensor (\MODEL  ).
    % We treat the continuous-indexed temporal data as the interaction between  a group of latent functions,  under a sparse Bayesian framework with automatic rank (i.e., model complexity) determination.
    % We  model the posterior mean of the latent functions  with  the continuous-indexed latent ODE, which is efficient and scalable for large tensor data. Furthermore, we derive an analytical variational lower bound for the marginal data likelihood, allowing for efficient optimization via gradient descent without relying on reparameterization tricks.
    % Our method facilitates the learning of off-grid relationships and complex temporal dynamics while allowing for self-adaptation of model complexity.
    %  Extensive experiments on synthetic and real-world datasets demonstrate the superior performance of the proposed approach. 
    \end{abstract}
    