\section{Additional Background on Blockchain}

\subsection*{\textbf EVM} The Ethereum Virtual Machine (EVM) is a distributed Turing complete system that allows us to build Smart Contracts written in Solidity or Vyper, and execute them using the Ethereum Blockchain.

A temporary Ethereum address generated to sign transactions and to communicate with the AP-DL Smart Contract. This ensures that the Smart Contract does not use the same Ethereum address to refer to the device only once.

\subsection*{\textbf Zero-Knowledge Proof}  A Zero-Knowledge Proof is a method by which one participant in the network \textit{(prover)} can prove to another participant \textit{(verifier)} that they know a value x, without revealing the value of x. There are two types of ZKPs — interactive and non-interactive. An interactive proof involves a series of questions from the \textit{verifier} to the \textit{prover} to prove their knowledge whereas a non-interactive proof relies on the \textit{verifier} picking a random challenge for the \textit{prover} to solve. Multiple interactions between the \textit{prover} and \textit{verifier} become unnecessary as the proof exists in a single message sent from the \textit{prover} to the \textit{verifier}. We utilize a non-interactive ZK proof also known as ZK-STARK.
The Zero Knowledge proof allows the progress made by the agent to be verified without revealing any data. By storing the proof on-chain agents can verify the validity of the progress of any other agent without requiring any interaction. Secondly, as anyone who has the private key to the signing account of the ZKP can prove that this progress was indeed done by them, they can be rewarded or penalized depending on the update they sent. So in an incentivized system, agents would be motivated to publish good updates.

\subsection*{\textbf Blockchain Operations} Connecting to the blockchain and sending transactions to it requires access to an Ethereum Node. There are two ways of accessing one. First, running a node locally on a system that directly connects to the network, downloading it's entire state. Secondly, by using a Remote RPC Endpoint which is essentially a node running on a remote machine that handles running the node and relays our transaction data. The transaction data cannot be manipulated as it is signed by a private key. This allows IoT Devices to data centers to interact with blockchains. Permissionless Blockchains like Ethereum allow anyone to create decentralized applications using Smart Contracts. These smart contracts are written in programming languages like Solidity and Vyper. All this combined creates a decentralized and turing complete atomic computation environment.

\section{Incentivization}
One of abilities of blockchain is to support decentralized finance. This allows us to incentivize the training process rewarding and penalizing agents relative to their contribution towards improving the accuracy of the global model. After an agent completes its training process it creates a ZKP of its progress. It internally uses a Commit Reveal Scheme. The agent will locally generate a random number(the reveal) with a salt and then hash it and send it on-chain (the commit). Finally, we’ll hash their random number (that the miner shouldn't know about) with the block-hash on the commit block (that the player couldn't know about). This final hash is a pretty good source of randomness on-chain because it gives the player an assurance that the miner didn’t manipulate it. This process is used to hide the identity of the agent if they choose to redeem their rewards using the reveal to a new address with no transaction history. If the model update from this agent is accepted, then the ZKP is stored on the chain with the users address and can be redeemed by any address as long as the have the reveal to value of the commit. The ZKP also allows another agent to validate the progress of an other agent using the ZKP without requiring to interact with the agent. These measuring help in incentivizing the users to push good updates and make agents accountable to the other agents in a privacy-preserving manner.


\section{Software and Models Settings}

\smallskip\noindent\textbf{Computing Infrastructure} 
All experiments were performed on a cluster equipped with Intel(R) 
Xeon(R) Platinum 8260 CPU @ 2.40GHz and 8GB of RAM.

\smallskip\noindent\textbf{Software and Libraries}  
All models and experiments were written in Python 3.7. 
All models in the paper were implemented in Pytorch 1.5.0. The Tensorflow Privacy library \href{https://github.com/tensorflow/privacy} is utilized for privacy computation. 

\smallskip\noindent\textbf{Architectures}  The network architecture for MNIST/FMNIST dataset is reported in Table \ref{table-struct}. For COVID dataset, the RESNET18 model was utilized due to its superior performance in classifying  normal and COVID-19 pneumonia classes, \cite{Chowdhury_2020}. To speed up the training progress, all layers except the last fully connected one were frozen. Hence, the parameter learning takes place only at this last layer. 

\begin{table}[!tbh]
\centering
%\resizebox{0.8\linewidth}{!}
{%
\begin{tabular}{l l l l} 
 \toprule
 Layer (type) & Output Shape & Param \# & Tr.~Param \# \\
 \midrule
 Conv2d-1 & $ [1, 32, 26, 26] $ & $ 320$ & $ 320$  \\ 
 Conv2d-2 &  $ [1, 64, 24, 24]$ & $ 18,496$ & $ 18,496$ \\
 Dropout2d-3 & $ [1, 64, 12, 12] $ & $ 0$ & $ 0$ \\ 
 Linear-4 & $ [1, 128]$ & $ 1,179,776 $ & $ 1,179,776 $  \\
 Dropout2d-5 & $ [1, 128] $ & $ 0 $ & $ 0 $ \\
 Linear-6 & $ [1, 10]$ & $ 1,290$ & $ 1,290$ \\
 \bottomrule
\end{tabular}
}
\caption{Model Structure}
\label{table-struct}
\end{table}
 

\smallskip\noindent\textbf{Code} 
The implementation of all models and the relevant experiments  will be released upon publication. 


\smallskip\noindent\textbf{Algorithms' Setting} 
The parameters settings for all models across datasets are given in Table  \ref{tab:parameter_setting_1}.  The settings for private extension of these models are summarized in Table  \ref{tab:parameter_setting_2}.

\begin{itemize}
    \item Inner epochs: the number of local epochs each agent performs on its own data in a single round.  
    \item ACRs: the total number of asynchronous communication rounds(ACRs, see Definition 2) that each agent perform during the course of model's training. This parameter depends strongly on model, the number of agents $K$ and the total number of training sample $n$ in case of Fed-Avg. Given a fixed number of rounds $N$,  with $K$ agents, the number of ACRs for chain, tree, star topology respectively is: $N K $, $N \log_2 K $ and $N$. 
\end{itemize}


\begin{table}[htb]
\centering
\resizebox{0.86\linewidth}{!}{%
\begin{tabular}{r r r r r r}
\toprule
 Model &  Data &  Batch size & \# Rounds & \# Inner epochs & \# ACRs \\
\midrule
 SGD &MNIST/FMNIST & 64 & NA &30  & NA \\
 $\textrm{PA-DL}_C$ & MNIST/FMNIST & 64 &30  & 1 &  $30 \  K$  \\
  $\textrm{PA-DL}_T$ & MNIST/FMNIST&  64 &30  & 1 & $30\  \log_2 K $    \\
   $\textrm{PA-DL}_S$ & MNIST/FMNIST&  64 &30  & 1 &  30\\ 
   $\textrm{FedAvg}$ & MNIST/FMNIST&  64 &30  & NA & $\frac{30  n}{K 64 }$   \\
   \midrule
       SGD & COVID &  8& NA & 30 & NA \\
 $\textrm{PA-DL}_C$ & COVID & 8 &30  & 1 &  $30\  K$ \\
  $\textrm{PA-DL}_T$ & COVID&  8 &30  & 1 & $30\  \log_2 K $   \\
   $\textrm{PA-DL}_S$ &  COVID&  8 &30  & 1 &  30 \\
      $\textrm{FedAvg}$ & COVID&  8 &30  & NA & $\frac{30  n}{K 16 }$   \\
\bottomrule
\end{tabular}
}
\caption{Parameters settings for all \textbf{non-private} models presented in the paper, where $K$ is the number of agents, $n$ is the total number of training samples.  }
\label{tab:parameter_setting_1}
\end{table}

\begin{table}[htb]
\centering
\resizebox{0.85\linewidth}{!}{%
\begin{tabular}{r r r r r r}
\toprule
 Model &  Data &  Batch size & \# Rounds & \# Inner epochs & \# ACRs \\
\midrule
 $\textrm{PA-DL}_C$ & MNIST/FMNIST & 64 &20  & 1 &  $20 \  K$  \\
  $\textrm{PA-DL}_T$ & MNIST/FMNIST&  64 &20  & 1 & $20\  \log_2 K $    \\
   $\textrm{PA-DL}_S$ & MNIST/FMNIST&  64 &20  & 1 &  20\\ 
   $\textrm{DP-FedAvg}$ & MNIST/FMNIST&  64 &20  & NA & $\frac{20  n}{K 64 }$   \\
   \midrule
 $\textrm{PA-DL}_C$ & COVID & 16 &20  & 1 &  $20\  K$ \\
  $\textrm{PA-DL}_T$ & COVID&  16 &20  & 1 & $20\  \log_2 K $   \\
   $\textrm{PA-DL}_S$ &  COVID&  16 &20  & 1 &  20 \\
      $\textrm{DP-FedAvg}$ & COVID&  16 &20  & NA & $\frac{20  n}{K 16 }$   \\
\bottomrule
\end{tabular}
}
\caption{Parameters settings for private extensions of all models presented in the paper, where $K$ is the number of agents, $n$ is the total number of training samples.  }
\label{tab:parameter_setting_2}
\end{table}

\section{Extended Results}

The experiments reported below extend the analysis reported in Section 7.3 of the main paper, that focuses on the impact of the privacy constraints onto the accuracy of the different models. Figure \ref{fig:fig-dp-2} provides a comparison across all models on the unbiased versions of MNIST (left) and FMNIST (right) datasets, while Figure \ref{fig-biased-dp-2} illustrates the performance of all models on the biased counterparts of these datasets. The parameter settings for all models are summarized in Table  \ref{tab:parameter_setting_2}. The resulting final privacy losses for all algorithms are $\epsilon=0.5$ (for K=10), $1.1$ (for K=50), and $1.6$ (for K=100). The privacy loss increases (sub-linearly) with the number of agents as the dataset size $n_a$ each agent is given decreases while the mini-batch size $b$ is fixed.  

Notice that the reason why the algorithms stop to different ACR is because they are all ran for 20 rounds, and their total number of ACRs is reported in Table \ref{tab:parameter_setting_2}.

The results follow trends as those reported in the main paper. 
In particular, PA-DL produces private models that are significantly more accurate to those produced by DP-FedAvg, under the same privacy constraints. 

Similar observation are also made for the COVID dataset, illustrated in Figure \ref{fig-dp-COVID-19-2}. Since this is a very small dataset, the experiments use $K=5$ and $K=10$ agents, and the data samples are distributed uniformly across the $K$ agents.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{augmented_private_sigma_2-0_K_10_ACR.pdf} 
\includegraphics[width=0.85\textwidth]{augmented_private_sigma_2-0_K_50_ACR.pdf} 
\includegraphics[width=0.85\textwidth]{augmented_private_sigma_2-0_K_100_ACR.pdf} 
\caption{Accuracy vs ACRs on unbiased MNIST (left) and unbiased  FMNIST (right) datasets for $K=10$ (top), $K=50$ (middle), and $K=100$ (bottom) agents.  The final privacy loss of each model for $K=10$, $K=50$, and $K=50$ respectively are $0.5, 1.1$ and $1.6$.
\label{fig:fig-dp-2}}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{biased_private_sigma_2-0_K_10_ACR.pdf}
\includegraphics[width=0.85\textwidth]{biased_private_sigma_2-0_K_50_ACR.pdf}
\includegraphics[width=0.85\textwidth]{biased_private_sigma_2-0_K_100_ACR.pdf} 
\caption{Accuracy vs ACRs on \textbf{biased} MNIST (left) and \textbf{biased}  FMNIST (right) datasets for $K=10$ (top), $K=50$ (middle), and $K=100$ (bottom) agents. The final privacy loss of each model for $K=10$, $K=50$, and $K=50$ respectively are $0.5, 1.1$ and $1.6$. }
\label{fig-biased-dp-2}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=0.85\textwidth]{COVID_private_sigma_2-0_K_10_ACR.pdf} 
\caption{Accuracy vs ACRs on COVID-19 dataset for $K=5$ (left) and $K=10$(right). The final privacy loss of each model for $K=5$ and $K=10$ respectively are $2.4$ and $3.5$. }
\label{fig-dp-COVID-19-2}
\end{figure}
