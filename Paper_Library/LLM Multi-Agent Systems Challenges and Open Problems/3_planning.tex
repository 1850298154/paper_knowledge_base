
\section{Planning}\label{sec: planning}




% While existing works have demonstrated the remarkable capabilities of multi-agent systems, the potential for advanced multi-agent systems far exceeds the progress made to date. Existing works mainly focus on designing planning methods in one single agent by breaking down the tasks into small, manageable tasks~\cite{chen2022program,ziqi-lu-2023-tab,yao2023tree,long2023large,besta2023graph,wang2022rationale}. However, in multi-agent systems, agents with different specilizations collaborate on a common task, and careful planning for the interactions between different-role agents is not studied. Several important issues remain unclear, e.g., 1) optimizing task assignment based on the agents' capabilities and specilizations; 2) introducing loops by debating or discussion, to strengthen the quality of reasoning in the intermediate results; 3) handling and aligning complex context in a multi-agent setting, i.e., context of the overall task, the single agents, and some common senses. 


Planning in multi-agent systems involves understanding the overall tasks and design work flow among agents based on their roles and specializations, (\textit{i}.\textit{e}., global planning) and breaking down the tasks for each agent into small manageable tasks (\textit{i}.\textit{e}., local planning). Such process must account for functionalities of the agents, dynamic interactions among the agents, as well as a more complex context compared with single-agent systems. This complexity introduces unique challenges and opportunities in the multi-agent systems.

\subsection{Global Planning}\label{sec: global_planning}

Global planning refers to understanding the overall task and split the task into smaller ones and coordinate the sub-tasks to the agents. It requires careful consideration of task decomposition and agent coordination. Below we discuss the unique challenges in global planning in multi-agent systems.

\textbf{Designing effective work flow based on the
agents’ specializations. }
Partitioning responsibilities and designing effective work flows for agents is crucial for ensuring that the tasks for each agent are executable while meaningful and directly contributes to the overall objective in systems. The biggest challenge lies in the following perspectives: 1) the partition of work flow should maximize the utilization of each agent's unique capabilities, \textit{i}.\textit{e}., each agent can handle a part of the task that matches its capabilities and expertise; 2) each agent's tasks must  align with the overall goal; and 3) the design must understand and consider the context for the overall tasks as well as each agent. This requires a deep understanding of the task at hand and the specific strengths and limitations of each agent in the system.

\textbf{Introducing loops for a subset of agents to enhance intermediate results. }
Multi-agent systems can be integrated with loops inside one or multiple subsets of agents to improve the quality of the intermediate results, or, local optimal answers. In such loops, agents debate or discuss to achieve an optimal results that are accepted by the agents in the loop. 
The iterative process can refine the intermediate results, leading to a deeper exploration of the task. The agents in the loop can adjust their reasoning process and plans during the loop, thus have better capabilities in handling uncertainties of the task.


\textbf{Game Theory. }
Game theory provides a well-structured framework for understanding strategic interactions in multi-agent systems, particularly for systems that involve complex interactions among agents such as debates or discussions. 
A crucial concept in game theory is equilibrium, \textit{e}.\textit{g}., Nash Equilibrium~\cite{kreps1989nash} and Stackelberg Equilibrium~\citep{von2010market,conitzer2006computing}, that  describes a state where, given the strategies of others, no agent benefits from unilaterally changing their strategy. Game theory has been applied in multi-agent systems, especially Stackelberg equilibrium~\cite{gerstgrasser2023oracles,harris2023stackelberg}, as the structure of
Stackelberg equilibrium contains
is a leader agent and multiple follower agents, and such hierarchical architectures are wildely considered in multi-agent systems.
\citep{gerstgrasser2023oracles}
designs a general multi-agent framework to identify Stackelberg Equilibrium in Markov games, and \cite{harris2023stackelberg} extend the Stackelberg model to allow agents to consider external context information, such as traffic and weather, etc.
However, some problems are still challenging in multi-agent systems, such as defining an appropriate payoff structure for both the collective strategy and individual agents based on the context of the overall tasks, and efficiently achieving equilibrium states. These unresolved issues highlight the ongoing need for refinement in the application of game theory to complex multi-agent scenarios.









\subsection{Single-Agent Task Decomposition}\label{sec: single_agent_planning}

Task decomposition in a single agent involves generating a series of intermediate reasoning steps to complete a task or arrive at an answer. This process can be represented as transforming direct input-output ($\langle \text{input}\rightarrow \text{output}\rangle$) mappings into the $\langle \text{input}\rightarrow\text{rational}\rightarrow\text{output}\rangle$ mappings~\cite{wei2022chain,zhang2023igniting}. Task composition can be of different formats, as follows.

\textit{i) Chain of Thoughts (CoT)}~\cite{wei2022chain} that transforms big tasks into step-by-step manageable tasks to represent interpretation of the agents' reasoning (or thinking) process.

\textit{ii) Multiple CoTs}~\cite{wang2022self} that explores multiple independent CoT reasoning paths  and return the one with the best output. 


% However, it does not offer “local exploration” within a path, such as backtracking.

\textit{iii) Program-of-Thoughts (PoT)}~\cite{chen2022program} that uses language models to generate text and programming language statements, and finally an answer.

\textit{iv) Table-of-Thoughts (Tab-CoT)}~\cite{ziqi-lu-2023-tab}  that utilize a tabular-format for reasoning, enabling the complex reasoning process to be explicitly modelled in a highly structured manner.

\textit{v) Tree-of-Thoughts (ToT)}~\cite{yao2023tree,long2023large} that extends CoT by formulating a tree structure to explore multiple reasoning possibilities at each step. It enables generating new thoughts based on a given arbitrary thought and possibly backtracking from it. 

\textit{vi) Graph-of-Thoughts-Rationale (GoT-Rationale)}~\cite{besta2023graph} that explores an arbitrary graph to enable aggregating arbitrary thoughts into a new one and enhancing the thoughts using loops.

\textit{vii) Rationale-Augmented Ensembles}~\cite{wang2022rationale} that automatically aggregate across diverse rationales to overcome the brittleness of performance to sub-optimal rationales.


In multi-agent systems, task decomposition for a single agent becomes more intricate. Each agent must understand layered and sophisticated context, including 1) the overall tasks, 2) the specific context of the agent's individual tasks, and 3) the contextual information provided by other agents in the multi-agent system. 
Moreover, the agents must align these complex, multi-dimensional contexts into their decomposed tasks to ensure coherent and effective functioning within the overall task. 
We summarize the challenges for single agent planning as follows.


\textbf{Aligning Overall Context. }
Alignment of goals among different agents is crucial in multi-agent systems. Each LLM agent must have a clear understanding of its role and how it fits into the overall task, such that the agents can perform their functions effectively. Beyond individual roles, agents need to recognize how their tasks fit into the bigger picture, such that their outputs can harmonize with the outputs of other agents, and, further, ensuring all efforts are directed towards the common goal.


\textbf{Aligning Context Between Agents. }
Agents in multi-agent systems process tasks collectively, and each agent must understand and integrate the contextual information provided by other agents within the system to  ensure that the information provided by other agents is fully utilized.


\textbf{Aligning Context for Decomposed Tasks. }
When tasks of each agents are broken down into smaller, more manageable sub-tasks, aligning the complex context in multi-agent systems becomes challenging.  Each agent's decomposed task must fit their individual tasks and the overall goal while integrating with contexts of other agents. 
Agents must adapt and update their understanding of the task in response to context provided by other agents, and further, plan the decomposed tasks accordingly.


\textbf{Consistency in Objectives. }
In multi-agent systems, consistency in objectives is maintained across various levels, \textit{i}.\textit{e}., from overall goals down to individual agent tasks and their decomposed tasks. Each agent must understand and effectively utilize the layered contexts while ensuring its task and the decomposed sub-tasks to remain aligned with the overall goals. 
\cite{harris2023stackelberg} extends the Stackelberg model~\citep{von2010market,conitzer2006computing} to enable agents to incorporate external context information, such as context (or insights) provided by other agents. However, aligning the complex context with the decomposed tasks during reasoning remains unresolved.





