


\section{Empirical Evaluation}
\label{sec:empirical}


\subsection{Experimental Setup}
We use a total of five domains with varying configurations to evaluate our approach. All these five domains had  a mix of deterministic and stochastic actions. We use an implementation of LAO*~\cite{hansen2001lao} from the MDP-Lib~\cite{mdplib} repository for computing policies for SSPs. We use  OpenRAVE~\cite{diankov10_openrave} robot simulation system with its collision checkers to represent 3D environments and performing collision checking. We also CBiRRT's~\cite{bernson2009cbirrt} implementation from the PrPy~\cite{prpy} suite for computing motion plans. In practice, fixing the horizon $H$ for the SSP solver apriori is infeasible and renders some problems unsolvable. Instead, we implemented a variant that dynamically increases the horizon until the goal is reached with a probability $p > 0$. The source code of the framework along with the videos of our experiments can be found at \url{https://aair-lab.github.io/STAMP.html}




\citet{lagriffoul2018platform} propose several framework-independent benchmark domains for task and motion planning systems. While these benchmarks are proposed for deterministic TAMP systems, characteristics of the domains can still be used to evaluate STAMP systems. Fig. 
\ref{fig:char} shows the criteria fulfilled by every domain used to evaluate our approach. We include the average number of branches in the policy tree as an additional criterion to depict the complexity of stochastic problems. 

\begin{figure*}[t!]
\begin{subfigure}{1\columnwidth}
  \centering
  \includegraphics[width=0.3\columnwidth]{./kitchen_top_1.png}
  % \hspace{1em}
  \includegraphics[width=0.3\columnwidth]{./kitchen_top_2.png}

\end{subfigure}
\caption{Setting up a dining table: Fetch uses STAMP policy to set up a dining table. A tray is available to carry multiple items at a time but carrying more than two items on the tray may break the items. Left: The initial state. Right: The goal state.}
\label{fig:kitchen}

\end{figure*}


  



  %     

\paragraph{\textbf{Problem $\mathbf{1}$: Cluttered Table}}
In this problem, we have a table cluttered with cans, each having different probabilities of being crushed when grasped by the robot. Some cans are delicate and are highly likely to be crushed when the robot grabs them, incurring a high cost (probability for crushing was set to $0.1$, $0.5$ \& $0.9$ in different experiments in Fig. \ref{fig:anytime_result}(a)), while others are normal cans that cannot be crushed. The goal for the robot is to pick up a specified can. We used different numbers of cans ($15$, $20$, $25$) and different random configurations of cans to extensively evaluate the proposed framework. We also used this scenario to evaluate our approach in the real-world (Fig. \ref{fig:exp_1_2}) using the Fetch robot~\cite{wise16_fetch}.






% \begin{figure*}[t!]
%     \centering
% %    \includegraphics[width=\textwidth]{./anytime_results_new.eps}
%   % \includegraphics[width=\textwidth]{./anytime_results_new.png}
%   \includegraphics[width=\textwidth,height=7in]{./anytime_results_new_2.eps}
%     \caption{Anytime performance of ATM-MDP, showing the time in seconds (x-axis) vs. probability mass refined (y-axis).}
%     \label{fig:anytime_result}
%     % \vspace{-1em}
% \end{figure*}

\paragraph{\textbf{Problem $\mathbf{2}$: Aircraft Inspection}}
In this problem, an unmanned aerial vehicle (UAV) is employed to inspect possibly faulty parts of an aircraft in an airplane hangar.  The goal for the agent is to locate the fault and notify the human supervisor about it. Fig. \ref{fig:exp_3_6} shows the simulated environment. The UAV's sensors are inaccurate and may fail to locate the fault with some non-zero probability (failure probability was set to 0.05, 0.1, \& 0.15 for experiments in Fig. \ref{fig:anytime_result}(b)) while inspecting the location; it may also drift to another location while flying from one location to another or while inspecting the parts. The UAV has a limited amount of battery charge. A charging station is available for the UAV to dock and charge itself. All movements use some amount of battery charge depending on the length of the trajectory, but the high-level planner cannot determine whether the current level of charge is sufficient for the action or not as it lacks the details such as current battery level, length of previous and next trajectories, etc.  This makes it necessary to have an interleaved approach that searches for a high-level policy that has valid low-level refinements.


\begin{figure*}[t!]
  \footnotesize
  \begin{center}
  \begin{tabular}{|c|c|c|c|c|c|}
      \hline
      Criteria & Cluttered Table & \makecell{Aircraft \\ Inspection} &  \makecell{Building Keva \\ Structures} &  Kitchen & Find the can \\ \hline
      % Deterministic & \checkmark & ~ & \checkmark &  \checkmark  &  ~ & ~   \\ \hline
      % Stochastic & \checkmark & \checkmark & \checkmark & ~ & \checkmark & \checkmark \\ \hline    
      Infeasible Tasks & \checkmark & \checkmark & ~  &  ~ & ~  \\ \hline
      Large task spaces & \checkmark & \checkmark & \checkmark & \checkmark  & ~  \\ \hline
      Motion/task trade-off & \checkmark & \checkmark  & \checkmark & \checkmark & ~ \\ \hline
      Non-monotonicity & \checkmark & ~ & ~ & \checkmark &  \checkmark \\ \hline
      $\#$branches & $O(2d)$ & $O(4^h)$ & $O(2^n)$ &  $2$ & $2$  \\ \hline
  \end{tabular}
  \end{center}
  \caption{Critera defined by \cite{lagriffoul2018platform} evaluated in each of the test domains.}
  \label{fig:char}
  \end{figure*}







% \begin{figure}[t]
%   \centering 
%   \centering
% %   \footnotesize
%   \begin{tabular}{|l|c|c|}
%     \hline
%     Problem & \% Solved & Avg. Time (s)  \\ \hline 
%     Cluttered-15 &  100  & 367.89 $\pm$ 854.52  \\
%     Cluttered-20 &  97   & 654.1541 $\pm$ 1641.98   \\
%     Cluttered-25 & 86 & 990.93 $\pm$ 1011.07  \\ 
%     Aircraft Inspection & 100 & 278.94 $\pm$ 30.54 \\ 
%     $3\pi$ &  100 & 227.04 $\pm$ 38.11   \\
%     Twisted-Tower-12 &  100 &  805.31 $\pm$ 102.10  \\
%     Three-Tower-12 & 100  & 1367.27 $\pm$ 144.29  \\
%     Sort Clutter ($N=3$) & 100 & 687.65 $\pm$ 103.36 \\
%     Sort Clutter ($N=5$) & 52 & 2384.91 $\pm$ 540.65 \\
%     Sort Clutter ($N=8$) & 12 & 3687.65 $\pm$ 301.21 \\
%     \hline
%   \end{tabular}
%   \caption{Summary of times taken to solve the TAMP problems. Timeout: 4000 seconds}
%   \label{fig:time_result_deterministic}
% \end{figure}

% \begin{figure}[t]
%     \centering
% %   \footnotesize
%   \begin{tabular}{|l|c|c|}
%           \hline
%           Problem & \% Solved & Avg. Time (s)  \\ \hline
          
%           Cluttered-15 & 100 & 1120.21 $\pm$ 1014.54  \\
%           Cluttered-20 &  83 & 1244.32 $\pm$ 990.65  \\
%           Cluttered-25 & 75 & 1684.54  $\pm$ 890.78  \\
%           Aircraft Inspection & 100 & 2875.01 $\pm$ 103.65 \\
%           $3\pi$ &  100 & 1356.34 $\pm$ 75.8    \\
%           Tower-12 &  100 &  2232.36 $\pm$ 104.84  \\
%           Twisted-Tower-12 & 80 & 3249.92 $\pm$ 773.69   \\ 
%           Setting up a dining table & 100 & 1287.23 $\pm$ 321.32 \\
%           Find the can & 100 & 36.74 $\pm$ 0.13\\ 

%       \hline
%       \end{tabular}
%       \caption{Summary of times taken to solve the STAMP problems. Timeout: 4000 seconds.}
%       \label{fig:time_result_stochastic}
%       % \vspace{-2em}
%   \end{figure}





\paragraph{\textbf{Problem $\mathbf{3}$: Building Structures with Keva Planks}}
In this problem, the YuMi robot~\cite{yumi} is used to build different structures using Keva planks. Keva planks are laser-cut wooden planks with uniform geometry. Fig.\,\ref{fig:exp_1_2} and Fig.\,\ref{fig:domainFig} show the target structures.  Planks are placed one at a time by a user after each pickup and placement by the YuMi. Each new plank may be placed at one of a few predefined locations, which adds uncertainty in the planks' initial location. For our experiments, two predefined locations were used to place the planks with a probability of $0.8$ for the first location and a probability of $0.2$ for the second location. In this problem, handwritten goal conditions are used to specify the desired target structure. The YuMi needs a task and motion policy for successively picking up and placing planks to build the structure. There are infinitely many configurations in which one plank can be placed on another, but the abstract model blurs out different regions on the plank. The generator that samples put-down poses for planks on the table uses the target structure to concretize each plank's target put-down pose. The number of branches in a solution tree grows exponentially with the number of planks in the structure and can quickly become huge. For example, a solution tree for a structure with just $10$ planks would have a total of $1024$ branches. Due to the large state space, state-of-the-art SSP solver used for other domains failed to compute a high-level policy for these problems. Our observation shows that most SSP solvers fail to compute a high-level solution for structures that have greater than $6$ planks. However, these structure-building problems exhibit repeating substructure every 1-2 layers that reuse minor variants of the same abstract policy. We used this observation and used a generalized SSP solver \cite{karia2022preliminary} that computes generalized policies for SSPs with such repeating patterns. Other approaches for generalized planning~\cite{srivastava2008AAAI,bonet2009,hu2011,srivastava11_aij} can also be used to automatically extract and utilize such patterns in other problems with repeating structures.

% \paragraph{Problem $4$: Sort cluttered table} ~ \vspace{0.3em}\\
% In this problem, as shown in Fig. \ref{fig:sort}, the \emph{Fetch} robot is used to sort objects placed on a table. The goal is to have all $N$ blue blocks on the left table and all $N$ green blocks on the right table while $2N$ red blocks act as obstacles. The cluttered configuration of objects on the table renders some actions infeasible that makes ordering of the actions critical. The interleaved framework proposed by \emph{HPlan} algorithm searches for an abstraction that is sufficient to compute a valid order of the cans to be moved to solve the problem. For our experiments, we use $N = 3$, $5$, and $8$ (total number of objects 12,
%  20, and 32 respectively). 

\paragraph{\textbf{Problem $\mathbf{4}$: Setting Up a Dining Table}}
In this problem, the Fetch robot arranges a dining table with two plates and two glasses (Fig. \ref{fig:kitchen}). A tray is available for the robot to use for carrying multiple items at once. If the robot tries to carry more than two objects on a tray at once, the objects can fall from the tray with a probability $0.2$ and that would break the objects. While using the tray can reduce the number of trips between tables, breaking the objects would render the problem unsolvable. As our approach considers all possible outcomes of stochastic actions, it successfully computes a policy that prevents any object from breaking compared to determinization-based approaches that only consider the most likely outcome for stochastic actions that may fail to solve such problems as most-likely scenarios might fail to capture dead ends in the domain.   


\begin{figure*}[t!]
  \centering
%    \includegraphics[width=\textwidth]{./anytime_results_new.eps}
% \includegraphics[width=\textwidth]{./anytime_results_new.png}
\includegraphics[width=\textwidth,height=6in]{./anytime_results_new_3.png}
 \caption{Anytime performance of ATM-MDP, showing the time in seconds (x-axis) vs. probability mass refined (y-axis).}
  \label{fig:anytime_result}
  % \vspace{-1em}
\end{figure*}


\paragraph{\textbf{Problem $\mathbf{5}$: Find the Can}} In this problem, the \emph{Fetch} robot searches for a can that may be present in one of the drawers. Fig. \ref{fig:exp_3_6} shows the simulated environment for the problem. The can is placed in one of the drawers with a given prior distribution. The robot does not have access to the can's location apriori and has to open the drawer to check whether the can is present in the drawer or not. In our experiments, the can is placed in the upper drawer with a probability $0.6$ and in the bottom drawer with a probability $0.4$. 

\subsection{Analysis of the results}




% \begin{figure}[t]
%   \centering 
%   \centering
% %   \footnotesize
%   \begin{tabular}{|l|c|c|}
%     \hline
%     Problem & \% Solved & Avg. Time (s)  \\ \hline 
%     Cluttered-15 &  100  & 367.89 $\pm$ 854.52  \\
%     Cluttered-20 &  97   & 654.1541 $\pm$ 1641.98   \\
%     Cluttered-25 & 86 & 990.93 $\pm$ 1011.07  \\ 
%     Aircraft Inspection & 100 & 278.94 $\pm$ 30.54 \\ 
%     $3\pi$ &  100 & 227.04 $\pm$ 38.11   \\
%     Twisted-Tower-12 &  100 &  805.31 $\pm$ 102.10  \\
%     Three-Tower-12 & 100  & 1367.27 $\pm$ 144.29  \\
%     Sort Clutter ($N=3$) & 100 & 687.65 $\pm$ 103.36 \\
%     Sort Clutter ($N=5$) & 52 & 2384.91 $\pm$ 540.65 \\
%     Sort Clutter ($N=8$) & 12 & 3687.65 $\pm$ 301.21 \\
%     \hline
%   \end{tabular}
%   \caption{Summary of times taken to solve the TAMP problems. Timeout: 4000 seconds}
%   \label{fig:time_result_deterministic}
% \end{figure}

\begin{figure}[t]
    \centering
  \footnotesize
  \begin{tabular}{|l|c|c|}
          \hline
          Problem & \% Solved & Avg. Time (s)  \\ \hline
          
          Cluttered-15 & 100 & 1120.21 $\pm$ 1014.54  \\
          Cluttered-20 &  83 & 1244.32 $\pm$ 990.65  \\
          Cluttered-25 & 75 & 1684.54  $\pm$ 890.78  \\
          Aircraft Inspection & 100 & 2875.01 $\pm$ 103.65 \\
          $3\pi$ &  100 & 1356.34 $\pm$ 75.8    \\
          Tower-12 &  100 &  2232.36 $\pm$ 104.84  \\
          Twisted-Tower-12 & 80 & 3249.92 $\pm$ 773.69   \\ 
          Setting up a dining table & 100 & 1287.23 $\pm$ 321.32 \\
          Find the can & 100 & 36.74 $\pm$ 0.13\\ 

      \hline
      \end{tabular}
      \caption{Summary of times taken to solve the STAMP problems. Timeout: 4000 seconds.}
      \label{fig:time_result_stochastic}
      % \vspace{-2em}
  \end{figure}

% policies that consider all possible contingencies
% nature of solutions 
\paragraph{\textbf{Nature of the Solutions }}
The most distinct characteristic of the solutions generated through our framework is that they capture all possible contingencies that may arise while executing the policy. E.g., solutions generated for setting up the dinner table (problem 4) avoid placing more than two items on the tray to completely eliminate the possibility of incurring higher expected cost, and solutions for picking up a can from the cluttered table (problem 1) avoid picking up a delicate can for similar reasons. 

\paragraph{\textbf{Quality of the Solutions Over Time}} 
While our approach computes refinements for every action in the policy, the anytime property allows the agent to start executing the actions before all the actions are refined. Our approach computes anytime policies with respect to the possible outcomes handled by a policy at any point in time. Fig. \ref{fig:anytime_result} shows the anytime property of our approach in stochastic test domains. The y-axis shows the probability with which the policy available at any point of time during the algorithm's computation will be able to handle all possible outcomes, and the x-axis shows the time (in seconds) required to compute task and motion policies that handle these outcomes. The results show that with time, the likelihood with which the solution would be able to handle any scenario increases. The agent can use this observation to decide a threshold at which it can start executing the actions. For our experiments, we use a threshold of $60\%$ of all possible outcomes to start the execution of the policy. Our experiments show that in most cases, the problem was solved significantly faster compared to starting execution after refining the entire policy tree (Fig.~\ref{fig:time_result_stochastic}).

% \begin{figure}[t]
%   \centering 
%   \centering
% %   \footnotesize
%   \begin{tabular}{|l|c|c|}
%     \hline
%     Problem & \% Solved & Avg. Time (s)  \\ \hline 
%     Cluttered-15 &  100  & 367.89 $\pm$ 854.52  \\
%     Cluttered-20 &  97   & 654.1541 $\pm$ 1641.98   \\
%     Cluttered-25 & 86 & 990.93 $\pm$ 1011.07  \\ 
%     Aircraft Inspection & 100 & 278.94 $\pm$ 30.54 \\ 
%     $3\pi$ &  100 & 227.04 $\pm$ 38.11   \\
%     Twisted-Tower-12 &  100 &  805.31 $\pm$ 102.10  \\
%     Three-Tower-12 & 100  & 1367.27 $\pm$ 144.29  \\
%     Sort Clutter ($N=3$) & 100 & 687.65 $\pm$ 103.36 \\
%     Sort Clutter ($N=5$) & 52 & 2384.91 $\pm$ 540.65 \\
%     Sort Clutter ($N=8$) & 12 & 3687.65 $\pm$ 301.21 \\
%     \hline
%   \end{tabular}
%   \caption{Summary of times taken to solve the TAMP problems. Timeout: 4000 seconds}
%   \label{fig:time_result_deterministic}
% \end{figure}

% \begin{figure}[t]
%     \centering
% %   \footnotesize
%   \begin{tabular}{|l|c|c|}
%           \hline
%           Problem & \% Solved & Avg. Time (s)  \\ \hline
          
%           Cluttered-15 & 100 & 1120.21 $\pm$ 1014.54  \\
%           Cluttered-20 &  83 & 1244.32 $\pm$ 990.65  \\
%           Cluttered-25 & 75 & 1684.54  $\pm$ 890.78  \\
%           Aircraft Inspection & 100 & 2875.01 $\pm$ 103.65 \\
%           $3\pi$ &  100 & 1356.34 $\pm$ 75.8    \\
%           Tower-12 &  100 &  2232.36 $\pm$ 104.84  \\
%           Twisted-Tower-12 & 80 & 3249.92 $\pm$ 773.69   \\ 
%           Setting up a dining table & 100 & 1287.23 $\pm$ 321.32 \\
%           Find the can & 100 & 36.74 $\pm$ 0.13\\ 

%       \hline
%       \end{tabular}
%       \caption{Summary of times taken to solve the STAMP problems. Timeout: 4000 seconds.}
%       \label{fig:time_result_stochastic}
%       % \vspace{-2em}
%   \end{figure}

% impact of prioritized solutions
\paragraph{\textbf{Impact of Prioritized \emph{RTL} Path Selection}} 
The results presented in Fig. \ref{fig:anytime_result} indicate that when \emph{RTL} paths are selected using the $p/c$ ration (blue line), the framework can quickly handle outcomes with most likely outcomes, compared to a randomized selection of \emph{RTL} paths for refinements (red line). In most cases, $80\%$ of probable executions are covered within about $30\%$ of the total computation time. This characteristic is most evident in the \emph{aircraft inspection} problem due to a large number of possible outcomes and differences in the probability of different outcomes. Such a prioritization does not make a significant impact if all the outcomes are equally probable. E.g., such impact is the least evident in the \emph{cluttered table} problem with the probability of crushing the objects set to $0.5$ given each outcome becomes equally probable and the sequence in which they are handled does not make any difference. 

\paragraph{\textbf{Scalability of the Framework}}
Fig.~\ref{fig:time_result_stochastic} shows the time taken by our approach to compute  complete STAMP solutions by concretizing every action in the entire policy for the given test problems respectively. We combine results for different variants of the test problem as variations in the probabilities of outcomes do not affect the time required to concretize all actions in the entire policy. Values in Fig.~\ref{fig:time_result_stochastic} are averages of $50$ runs with standard deviation. Our empirical evaluation shows that solving a STAMP problem requires significantly more time than  an equivalent TAMP problem. E.g., the stochastic variant of the aircraft inspection problem takes nearly $15$ times more time than the deterministic version as the stochastic variant had $780$ branches in the solution tree compared to a single branch in the deterministic variant. These results reinforce our hypothesis that an anytime approach that prioritizes high-probability scenarios over low-probability situations but still considers all possible outcomes suits better than an approach that does not consider all possible outcomes while showing scalability of our approach to solve large problems. Results for larger problems such as \emph{Twisted-Tower-12} and \emph{Cluttered-25} show \emph{scalability} of our system. Even though our approach needs a significant time to compute solutions for such huge problems due to a large number of RTL paths in the policy trees, it was able to solve almost all problems in these problem settings.