\section{Formal Framework}
\label{sec:formal}


% \subsection{Stoachstic Task and Motion Planning Problem}
% \subsection{Problem Statement}

% The main contribution of the paper is a probabilistically complete approach that computes task and motion policies for stochastic task and motion planning problems. We define the stochastic task and motion planning problem (STAMPP) as follows: 
% \begin{definition}
%     A stochastic task and motion planning problem (STAMPP) is defined as triplet $\langle \M, \alpha, \abs{\M}   \rangle$ where $\M$ is a low-level continuous stochastic shortest path (SSP) problem, $\alpha$ is an abstraction function, and $\abs{\M}$ is an abstract stochastic shortest path problem computed by applying the abstraction function $\alpha$ on the low-level SSP problem $\M$. 
% \end{definition}


% A solution of stochastic task and motion planning problem is a policy with actions from the concrete low-level continuous $SSP$ $\M$. Now, we define each component in the STAMPP triplet.


\subsection{Stochastic Task and Motion Planning Problem}
\label{sec:definition}

The main contribution of the paper is a probabilistically complete approach that computes task and motion policies for stochastic task and motion planning problems. We define the stochastic task and motion planning (STAMP) problem  as follows: 
\begin{definition}
    A stochastic task and motion planning (STAMP) problem  is defined as triplet $\langle \M, \alpha, \abs{\M}   \rangle$ where $\M$ is a low-level continuous stochastic shortest path (SSP) problem with $|\Am_\text{mp}| > 0$, $\alpha$ is an abstraction function, and $\abs{\M}$ is an abstract stochastic shortest path problem computed by applying the abstraction function $\alpha$ on the low-level SSP problem $\M$. 
\end{definition}

A solution for a stochastic task and motion planning (STAMP) problem  is a policy with actions from the concrete model $\M$. In this work, we consider solutions in the form of  a policy tree where each node $u_p$ in the tree represents a  state $s_{u_p}$ and an edge $e_p$ represents an action  $a_{e_p}$. The child of a node-edge pair $(u_p,e_p)$ in the policy tree refers to a possible outcome of executing the action $a_{e_p}$ at the state $s_{u_p}$. In the case of all deterministic actions, the tree would have a single branch. Now, we define the specific  \emph{entity abstraction} that we use to define the STAMP problem.



\subsection{Entity Abstraction}
\label{sec:entity}
In this paper, we use entity abstraction to define a stochastic task and motion planning problem. We define entity abstraction by extending the notion of abstractions introduced in Sec.~\ref{subsec:abstraction} as follows: Let $\mathcal{U}_l\;(\mathcal{U}_h)$ be the universe of $V_l\;(V_h)$ such that $|\mathcal{U}_h| \leq |\mathcal{U}_l|$. Let $\rho \; : \; \mathcal{U}_h \rightarrow 2^{\mathcal{U}_l}$ be a collection function that maps elements in $\mathcal{U}_h$ to the collection of $\mathcal{U}_l$ elements that they represent, e.g., $\rho(Table) = \{ loc \; : \; \land_{i}\; loc \cdot BoundaryVector_i < 0 \}$. Here $\rho$ binds Table $\in \mathcal{U}_h$ to a set of locations in $\mathcal{U}_l$ that are bounded by some polygonal boundary. Here $\mathcal{U}_l$ and $\mathcal{V}_l$ are low-level concrete universe and vocabulary and $\mathcal{U}_h$ and $\mathcal{V}_h$ are their abstract counterparts.


We define \emph{entity abstraction} $\alpha_\rho$ using the collection function $\rho$ as $\llbracket r \rrbracket _{\alpha_\rho(V_l)}(\tilde{o_1},\dots,\tilde{o_n}) = True $ iff $\exists\,o_1,\dots,o_n$ such that $o_i \in \rho(\tilde{o_i})$ and $\llbracket \psi_{r}^{\alpha_{\rho}}(o_1,\dots,o_n) \rrbracket _{S_l} = True$. We omit the subscript $\rho$ when it is clear from the context. Entity abstractions define the truth values of predicates over abstracted entities as disjunction of the corresponding concrete predicate instantiations. E.g., an object is in the abstract region ``kitchen'' if it is at one of the any locations in that region and an object is on ``table'' if it is at any location on the table-top. Such abstractions have been used for efficient generalized planning~\cite{srivastava2008AAAI} as well as answer set programming~\cite{zeynep18_aspocp}. These type of abstractions introduce terms that may not be identifiable at high level which makes these abstractions lossy and high-level models obtained by these abstractions inaccurate. E.g., the exact location of the table, the trajectory used to reach a configuration from current configuration.

Now, we use entity abstraction to define an abstract hybrid predicate for each hybrid predicate in our vocabulary by replacing each continuous argument in the hybrid predicate with its symbolic reference. E.g., \emph{$\abs{at}$($o_1$,$\overline{loc}$)} is an abstract hybrid predicate corresponding to a hybrid predicate \emph{at($o_1$,{loc})} where, \emph{$\overline{loc} \in \mathcal{U}$} is a symbolic reference of type $\tau_O$ for the continuous vector \emph{loc}. 

To formally define an abstract hybrid predicate, let $\alpha$ be a composition of entity abstraction and function abstraction. The abstract version of a concrete predicate $p_h$ is denoted as $\abs{p_h}_{\alpha}$. We omit the subscript $\alpha$ when it is clear from the context. We define $\abs{p_h}$ as follows:  
\begin{definition}
    A predicate $\abs{p_h}_\alpha(y_1,\dots,y_k,\bar{\theta}_1,\dots,\bar{\theta}_m)$ is an \textbf{abstract hybrid predicate} corresponding to a concrete hybrid predicate $p_h(y_1,\dots,y_k,\theta_1,\dots,\theta_m)$ iff all of its arguments $y_1,\dots,y_k,\bar{\theta}_1,\dots,\bar{\theta}_m$ are variables of type $\tau_O$ and $\forall\,\bar{\theta}_i \in \emph{arg}(\abs{p_h}_{\alpha})\, \theta_i \in \rho(\overline{\theta_i})$. $\abs{\mathcal{P}_h}_{\alpha}$ is a set of all abstract hybrid predicates.  
\end{definition}


We also define an abstract hybrid action for each hybrid action in the model using the abstraction $\alpha$. The abstraction $\alpha$ replaces each action argument of type $\tau_R$ with its symbolic reference of type $\tau_O$ and each concrete hybrid predicate in its precondition and effect with its abstract counterpart. Finally, we use these concepts to define an abstract SSP as follows: 



\begin{definition}
    Given a concrete planning problem $\mathcal{M}$, an \textbf{abstract planning} problem $\abs{\mathcal{M}} = \langle \mathcal{O}, \abs{\mathcal{P}}, \abs{\mathcal{\Sm}}, \abs{\mathcal{A}}, T, C \abs{s_0}, \abs{S_g}, \gamma, H \rangle$, where, 

    \begin{itemize}
        \item $O$ is a set of names for the objects in the environment and symbolic references for entities in the environment, 
        \item $\abs{\mathcal{P}} = \mathcal{P}_{sym} \cup \abs{\mathcal{P}_h}$ is a set of abstract predicates,
        \item $\abs{\Sm}$ is a set of abstract states,
        \item $\abs{\mathcal{A}} = \mathcal{A}_{sym} \cup \abs{\mathcal{A}_{h}}$ is a set of abstract actions available to the robot, 
        \item $T: \abs{\Sm} \times \abs{\Am} \times \abs{\Sm} \rightarrow [0,1]$ is a transition function,
        \item $C: \abs{\Sm} \times \abs{\mathcal{A}} \rightarrow \mathbb{R}$ is a cost function,
        \item $\abs{s_0} \in \abs{\Sm}$ is the initial state,
        \item $\abs{S_g} \subset \abs{\Sm}$ is the set of goal states,
        \item $\gamma = 1$ is a discount factor (fixed),
        \item $H$ is a fixed horizon. 
    \end{itemize}

\end{definition}

A solution to an abstract planning problem is a valid sequence of actions $ \abs{\pi}_{\alpha} = \langle \abs{a_0},\dots, \abs{a_n} \rangle$ such that each action in $\abs{\pi}$, when applied sequentially from the initial state $\abs{s_0}$, the system reaches one of the goal states in $\abs{S_g}$.



\begin{figure}[t!]
  % \begin{small}
      \noindent \emph{Place($obj_1$, $config_1$, $config_2$, $target\_pose$, $traj_1$)} \\
      \begin{tabular}{rl}
          \emph{precon} & \emph{RobotAt($config_1$)} , \emph{holding($obj_1$)}, \\ 
                          & \emph{IsValidMP($traj_1$, $config_1$, $config_2$)}, \\
                          & \emph{IsCollisionFree($traj_1$)}, \\ 
                          & \emph{IsPlacementConfig($obj_1$,$config_2$,$target\_pose$)} \\ \\ 
          \emph{Concrete} & $\lnot$\emph{holding($obj_1$)}, \\
          \emph{effect}  & $\forall$ \emph{traj intersects(vol(obj, target\_pose))}, \\
                          & \emph{sweptVol(robot,traj)} $\rightarrow$ \emph{Collision($obj_1$,traj)}, \\
                          & \emph{RobotAt($config_2$)}, \emph{at($obj_1$,target\_pose)}  \\ \\ 
          \emph{Abstract} & $\lnot$ \emph{holding($obj_1$)}, \\
          \emph{effect}   & $\forall \; traj$ \? \emph{Collision($obj_1$,$traj_1$)}, \\
                          & $\lnot$\emph{RobotAt($config_1$)}, \emph{RobotAt($config_2$)}, \\
                          & \emph{at($obj_1$,target\_pose)} \\ 
      \end{tabular}
  % \end{small}
  \caption{Specification of concrete (above) and abstract(below) effects of a one-handed robot's action for placing an object}
  \label[fig]{abs_example1}
\end{figure}



Concretization operation is performed by replacing abstract symbolic references with concrete objects from their low-level domains. For instance, let $\Sm_h$ be the set of abstract states generated when an abstraction
$\alpha$ is applied on a set of concrete states $\Sm_l$. For any
$s_h \in \Sm_h$, the \emph{concretization function}
$\Gamma_\alpha(s_h) = \set{s_l \in \Sm_l: \alpha(s_l)=s_h}$ denotes the set of
concrete states represented by the abstract state $s$. Similarly, abstract hybrid actions are refined by grounding abstract entities using values from their low-level domains. But, generating the complete concretization of an
abstract state can be computationally intractable, especially in cases
where the concrete state space is continuous. In such situations, the
concretization operation can be implemented as a \emph{generator} that
incrementally samples elements from an abstract argument's concrete
domain. A generator can also be designed in way that it validates the generated values while generating them and only yield valid instantiations for the symbolic arguments.



\paragraph{\textbf{Example}}  Consider the specification of a robot's action of placing an item as a part of an SSP. In practice, low-level accurate models of such actions may be expressed as generative models or simulators. Fig. \ref{abs_example1} helps to identify the nature of abstract representations needed for expressing such actions. For readability, we use a convention where preconditions are comma-separated conjunctive lists and universal quantifiers represent conjunctions over the quantified variables. 

Fig. \ref{abs_example1} shows the specification of an action that places an object at the specified pose. Concrete description of the action requires action arguments representing object to be placed (\emph{obj}$_1$), the initial and final configuration of the robot (\emph{config}$_1$, \emph{config}$_2$), target pose for the object (\emph{target\_pose}), and the motion trajectory that takes the robot from its initial configuration to final configuration (\emph{traj}$_1$). Here \emph{obj$_1$} is an argument of type $\tau_O$ and \emph{config}$_1$, \emph{config}$_2$, \emph{target\_pose}, and \emph{traj}$_1$ are continuous 0arguments of type $\tau_R$. The abstract counterpart of this action is computed by replacing the continuous arguments of type $\tau_R$ in the concrete version with symbolic arguments representing abstract entities as mentioned earlier. E.g., \emph{target\_pose} in the abstract specification is a symbolic reference for all valid target poses for the object and \emph{traj}$_1$ is a reference for all valid motion trajectories that take the robot from \emph{config}$_1$ to \emph{config}$_2$. Values of these arguments can not be determined precisely in the abstracted space and thus a subset of preconditions and effects can not be evaluated while planning with abstract models.  E.g., it is not possible to determine whether a trajectory is collision-free as part of the precondition. Similarly, it is also not possible to determine what trajectories will be in a collision when an object is placed at a certain pose in the abstract model. Such predicates are annotated in the set of effects with the symbol \?. While computing abstractions in such a way loses important information, the abstract model is still sound~\cite{srivastava14_tmp,srivastava2016metaphysics}. 

\begin{figure}[t!]
  \begin{center}
    \includegraphics[width=0.5\columnwidth]{./new_prn.png}
  \end{center}
  \caption{Plan refinement graph (PRG) used to maintain
separate abstract models. Each plan refinement node (PRN) contains an abstract
model, partially refined policy, and current state of refinement. Each edge contains refinement for a partial policy ($\sigma_{ij}$) and a failure reason ($p_k$). }
  \label{fig:prg}
\end{figure}




\begin{algorithm}[t!]
  % \begin{small}
    \KwIn{model $\M$, abstraction function $\alpha$, concretization function $\gamma$,  abstract model $\abs{\M}_{\alpha}$, symbolic planner $P$}
    \KwOut{anytime, contingent policy that is executable in $\M$ }
    Initialize PRG with a node with an abstract policy $\abs{\pi}$ for $\mathcal{G}$
    computed using \emph{P}\;
    \While{solution of desired quality not found}
    {
      $u$ $\gets$ GetPRNode()\;
      $\abs{\M}_u$ $\gets$ GetAbstractModel($u$)\;
      $\abs{\pi}_u$ $\gets$ GetAbstractPolicy($\abs{\M}_u$, $\mathcal{G}$, $P$, $u$)\;
      Choice $\gets$ NDChoice\{\emph{RefinePolicy}, \emph{RefineAbstraction}\}\;
      \If{Choice = \emph{RefinePolicy}}{
        \While{$\abs{\pi}_u$ has an unrefined RTL path and resource limit is not
          reached}{
            $path$ $\gets$ GetUnrefinedRTLPath($\abs{\pi}_u$)\;
          \If{explore\tcp{non-deterministic}}{
            replace a suffix of refined partial $path$ with a random action\;
          }
          Search for a feasible concretization of $path$\;
        }
      }
      \If{Choice = \emph{RefineAbstraction}}{
        $path$ $\gets$ GetUnrefinedRTLPath($\abs{\pi}_u$)\;
        $\sigma \gets$ ConcretizeFirstUnrefinedAction($path$)\;
        failure\_reason $\gets$ GetFailedPrecondition($\sigma$
        )\;
        $\abs{\M'}$ $\gets$ UpdateAbstraction($\abs{\M}$, failure\_reason) \;
        % random\_action $\gets$ choose\_random\_action(${\cal D}$)\;
        % next\_state $\gets$ apply\_action(random\_action)\;
        $\abs{\pi'}$ $\gets$ merge($\abs{\pi}$, GetAbstractPolicy($\abs{\M'}$, $\mathcal{G}$, solver))\;
        generate\_new\_pr\_node($\abs{\pi'}$, $\abs{\M'}$)\;
      }
      recompute  $p/c$ ratio for unrefined RTL paths\;
    }
  % \end{small}
\caption{\small HPlan Algorithm}
\label{alg:atam}
\end{algorithm}



Refining (instantiating) the abstract \emph{place} action sampling concrete values for each symbolic abstract entity in its arguments from their low-level domain. E.g., refining the symbolic entity \emph{target\_pose} would require using a generative model such as a simulator to sample a valid pose for the object being placed and computing a valid motion plan that takes the robot from its current configuration to a configuration that places the object at the sampled pose. This can be implemented using a backtracking search that tries to instantiate abstract entities in a sequential order while evaluating concrete preconditions for the instantiations. 



% \subsection{Stochastic Task and Motion Planning Problem}
% \label{sec:definition}


% The robot may require to change its pose as part of executing some actions which which indeed requires it to have an explicit motion plan. E.g., to execute the action \emph{Place(obj$_1$, pd\_pose, traj$_1$)}, the robot must have a valid trajectory that changes robot's pose to \emph{pd\_pose} in order to place the object \emph{obj}$_1$. We define such actions as \emph{motion planning actions}. Action arguments for such motion planning actions specify trajectories required to execute these actions and preconditions can be used to specify constraints on these motion planning trajectories. Values for these motion planning arguments can be \emph{``sampled''} using a motion planner. E.g, the action \emph{place} (Fig. \ref{abs_example1}) contains a motion planning argument \emph{traj}$_1$ and its precondition specifies a constraint that it should be a valid collision-free trajectory (\emph{IsCollisionFree(traj$_1$)}). We formally define motion planning actions as follows:
% \begin{definition}
% A \textbf{motion planning action} $a_{mp}(o_1,\dots,o_k,\theta_1,\dots,\theta_j,t_1,\dots,t_n)$ is a hybrid action where $o_1,\dots,o_k$ are of type $\tau_o$, $\theta_1,\dots,\theta_j$ are of type $\tau_R$, and $t_1,\dots,t_n$ are motion planning trajectories. \emph{pre(a$_{mp}$)} contains constraints on $t_1,\dots,t_n$ and \emph{eff(a$_{mp})$} represents the effective pose of the robot after executing action $a_{mp}$. $\mathcal{A}_{mp} \subset \mathcal{A}_h$ is the set of all motion planning actions.
% \end{definition}  

% We use these components to define concrete and abstract planning problems as follows:


% \begin{definition}
%     A \textbf{concrete planning} problem $P$ is defined as a $6$-tuple $ \mathcal{M} = \langle \mathcal{O}^\mathcal{M}, \mathcal{P}^{\mathcal{M}}, \mathcal{X}^\mathcal{M},  \mathcal{A}^\mathcal{M}, T^{\mathcal{M}}, C, x_0, X_g, \gamma, H \rangle$, where, 


% \begin{itemize}
%     \item $\mathcal{O}^\mathcal{M}$ is a set of names for the objects in the environment,
%     \item $\mathcal{P}^\mathcal{M} = \mathcal{P}_{sym} \cup \mathcal{P}_{h}$ is a set of predicates,
%     \item $\mathcal{X}^\mathcal{M}$ is a set of states defined using predicates in $\mathcal{P}^\mathcal{M}$,
%     \item $\mathcal{A}^\mathcal{M} = \mathcal{A}_{sym} \cup \mathcal{A}_{h}$ is a set of actions available to the robot, where $\mathcal{A}_{mp} \subset \mathcal{A}_{h}$ is a set of motion planning actions,
%     \item $T: \mathcal{X} \times \mathcal{A} \times \mathcal{X} \rightarrow [0,1]$ is a transition function,
%     \item $C: \mathcal{X} \times \mathcal{A} \rightarrow \mathbb{R}$ is a cost function,
%     \item $x_0 \in \mathcal{X}^\mathcal{M}$ is the initial state,
%     \item $X_g \subset \mathcal{X}^\mathcal{M}$ is the set of goal or terminal states,
%     \item $\gamma = 1$ is the discount factor,
%     \item $H$ is the horizon. 
% \end{itemize}
% \end{definition}

% For ease of reading, we omit the superscript when it is clear from the context. The solution to a concrete planning problem is a valid sequence of actions $\pi = \langle a_0,\dots,a_n \rangle$ such that every action when applied sequentially from the initial state $x_0$, the system reaches one of the goal states in $X_g$. 




% The main contribution of the paper is a probabilistically complete approach that computes task and motion policies for stochastic task and motion planning problems. We define the stochastic task and motion planning problem (STAMPP) as follows: 
% \begin{definition}
%     A stochastic task and motion planning problem (STAMPP) is defined as triplet $\langle \M, \alpha, \abs{\M}   \rangle$ where $\M$ is a low-level continuous stochastic shortest path (SSP) problem with $|\Am_\text{mp}| > 0$, $\alpha$ is an abstraction function, and $\abs{\M}$ is an abstract stochastic shortest path problem computed by applyting the abstraction function $\alpha$ on the low-level SSP problem $\M$. 
% \end{definition}


  




% With this, we define stochastic task and motion planning problems as follows: 
% \begin{definition}

%     A \textbf{stochastic task and motion planning problem}  (\emph{STAMPP}) can be defined as a $3$-tuple $\langle \M$, $\alpha$, $\abs{\M}_{\alpha} \rangle$, where $\M$ is a concrete \emph{SSP} with $|\mathcal{A}^{\M}_{mp}| > 0$, $\alpha$ is an abstraction function that is a composition of entity abstraction and function abstraction, and $\abs{\M}_{\alpha}$ is an abstract model computed by applying $\alpha$ on the concrete model $\M$.
% \end{definition}





% A solution for a stochastic task and motion planning problem (STAMPP) is a policy with actions from the concrete model $\M$. In this work, we consider solutions in the form of  a policy tree where each node $u_p$ in the tree represents a  state $s_{u_p}$ and an edge $e_p$ represents an action  $a_{e_p}$. The child of a node-edge pair $(u_p,e_p)$ in the policy tree refers to a possible outcome of executing the action $a_{e_p}$ at the state $s_{u_p}$. In the case of all deterministic actions (\emph{TAMPP}), the tree would have a single branch. 
