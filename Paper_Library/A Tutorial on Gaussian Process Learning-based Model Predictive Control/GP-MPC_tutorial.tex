%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.

% \documentclass[acmsmall,screen,review]{acmart}
\documentclass[acmsmall]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.

% \setcopyright{acmlicensed}
% \copyrightyear{2024}
% \acmYear{2024}
% \acmDOI{XXXXXXX.XXXXXXX}

% %% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}
% \acmISBN{978-1-4503-XXXX-X/18/06}

%%
%% These commands are for a JOURNAL article.
\acmJournal{CSUR}
% \acmVolume{37}
% \acmNumber{4}
% \acmArticle{111}
% \acmMonth{8}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{array}
% \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
% \usepackage[colorlinks,urlcolor=blue,linkcolor=blue,citecolor=blue]{hyperref}

\let\Bbbk\relax
\usepackage{amssymb}
% \usepackage{newtxtext,newtxmath}

\usepackage{amscd}
\usepackage{float}
\usepackage{subfig}
\usepackage{nccmath}
% For degree symbol
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{url}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{A Tutorial on Gaussian Process Learning-based Model Predictive Control}
% From Principles to Practice: Gaussian Process Learning in Model Predictive Control

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Jie Wang}
% \authornote{Both authors contributed equally to this research.}
\email{jwangjie@outlook.com}
\orcid{0000-0001-9970-1808}
% \authornotemark[1]
\authornote{Corresponding author.}
\affiliation{%
  \institution{Concordia University}
  \streetaddress{1455 Blvd. De Maisonneuve Ouest}
  \city{Montreal}
  \state{QC}
  \country{Canada}
  \postcode{H3G 1M8}
}

\author{Youmin Zhang}
\email{ymzhang@encs.concordia.ca}
\affiliation{%
  \institution{Concordia University}
  \streetaddress{1455 Blvd. De Maisonneuve Ouest}
  \city{Montreal}
  \state{QC}
  \country{Canada}
  \postcode{H3G 1M8}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{J. Wang et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    This tutorial provides a systematic introduction to Gaussian process learning-based model predictive control (GP-MPC), an advanced approach integrating Gaussian process (GP) with model predictive control (MPC) for enhanced control in complex systems. It begins with GP regression fundamentals, illustrating how it enriches MPC with enhanced predictive accuracy and robust handling of uncertainties. A central contribution of this tutorial is the first detailed, systematic mathematical formulation of GP-MPC in literature, focusing on deriving the approximation of means and variances propagation for GP multi-step predictions. Practical applications in robotics control, such as path-following for mobile robots in challenging terrains and mixed-vehicle platooning, are discussed to demonstrate the real-world effectiveness and adaptability of GP-MPC. This tutorial aims to make GP-MPC accessible to researchers and practitioners, enriching the learning-based control field with in-depth theoretical and practical insights and fostering further innovations in complex system control.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010520.10010553.10010554</concept_id>
       <concept_desc>Computer systems organization~Robotics</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257.10010293.10010075.10010296</concept_id>
       <concept_desc>Computing methodologies~Gaussian processes</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Robotics}
\ccsdesc[500]{Computing methodologies~Gaussian processes}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Gaussian process, model predictive control, learning-based control, mobile robotics, dynamic modeling}

% \received{20 March 2024}
% \received[revised]{12 March 2024}
% \received[accepted]{5 June 2024}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle


\section{Introduction}
\label{sec:intro}
The pursuit of sophisticated control strategies in robotics has been increasingly directed towards approaches that can effectively navigate the complexities and uncertainties inherent in real-world environments \cite{brunke2022safe}. Traditional control methods often struggle with these dynamic and unpredictable aspects. This has led to a growing interest in \textit{learning-based} control solutions, particularly Gaussian process (GP) learning-based model predictive control (GP-MPC) \cite{hewing2020learning}. This method synergizes the probabilistic modeling capabilities of Gaussian processes (GPs) with the forward-looking computing and optimization features of model predictive control (MPC). The integration of GP into MPC frameworks introduces a probabilistic layer that adeptly manages uncertainties and improves the precision of future state prediction, a critical advantage in complex, real-world applications such as autonomous navigation and advanced robotics \cite{wang2023learning}.

GP is the most widely used surrogate model in Bayesian machine learning, offering a probabilistic framework for approximating the true objective function to predict the behavior of systems \cite{wang2023recent}. Unlike deterministic models, GPs estimate a probability distribution over possible functions that fit the observed data, enabling them to predict future observations along with a measure of uncertainty (variance) \cite{wang2023intuitive}. This characteristic is particularly valuable in control systems, where the ability to quantify uncertainty in predictions can dramatically enhance the robustness and reliability of the control strategy \cite{he2022adaptive}.

MPC is an advanced forward-looking control strategy that uses a dynamic model of the system to predict and optimize the control action over a future time horizon \cite{khalid2023control}. By solving an optimization problem at each time step, MPC determines control inputs that optimize future system performance, subject to constraints on states, inputs, and outputs \cite{deshpande2021fault}. The predictive nature of MPC, combined with its constraint-handling capabilities, makes it highly effective for managing complex dynamic systems and constraints \cite{chevet2020decentralized}.

Integrating GP with MPC creates a new paradigm in control strategies. It enhances the accuracy of MPC's predictive model and incorporates model uncertainties directly into the control optimization process \cite{wang2024improving}. This leads to more informed, nuanced decisions considering the system's inherent dynamic uncertainties. The key challenge lies in the mathematical derivation and integration of the GP model within the MPC framework, which requires systematic techniques such as linearization for approximating non-Gaussian means and uncertainties in multi-step GP predictions.

Recent literature has provided high-quality reviews and tutorials on learning-based control, focusing on learning-based MPC \cite{hewing2020learning}, GP-based control \cite{liu2018gaussian}, and the intersection of control and reinforcement learning from a safety perspective \cite{brunke2022safe}. These works offer in-depth insights into the state-of-the-art in learning-based control but often assume a solid understanding of GP learning and control theories. However, there exists a gap in the comprehensive understanding of the mathematical principles underpinning the integration of GP into MPC frameworks, particularly among robotics and control communities.

This tutorial aims to fill this gap by providing an accessible introduction to GP-based MPC. Starting with an intuitive explanation of GP regression, the tutorial then delves into the mathematical foundations required for integrating GP into MPC, and finally explores advanced applications of GP-MPC in robotic and autonomous vehicle control. By providing a solid theoretical foundation coupled with practical application examples, this tutorial not only provides a comprehensive guide to understanding and implementing GP-MPC but also inspires further research and development in the field of GP-MPC. 

The subsequent sections of this paper are structured as follows. Sec. \ref{sec:gp} introduces Gaussian process regression fundamentals. Sec. \ref{sec:mean_var_approx} delves into the mathematical derivation for integrating GP predictions within MPC, particularly focusing on approximating GP means and uncertainties for multi-step forecasts. Sec. \ref{sec:gp_mpc} discusses employing GP means within MPC without considering uncertainties; Sec. \ref{sec:path_following} and \ref{sec:mixed_platoon} present practical applications of GP-MPC in robotic controls, with Sec. \ref{sec:path_following} on advanced path-following for wheeled robots and Sec. \ref{sec:mixed_platoon} on mixed-vehicle platooning controls, integrating both GP means and uncertainties. Finally, Sec. \ref{sec:conclusion} offers concluding remarks.

\section{Gaussian Processes}
\label{sec:gp}
Gaussian process regression (GPR) is a powerful machine learning method used for making predictions, especially useful when dealing with uncertainties and complex behaviors in systems. This section is designed to provide a solid understanding of the basics of GPR. We aim to explain GPR concepts in a way that is accessible to everyone, regardless of their prior knowledge in this area. It sets the foundation for combining GPR with MPC later on.

\subsection{Mathematical Basics}
This part introduces the essential mathematical concepts that GPR is built on, including the multivariate normal (MVN) distribution, kernels, and the non-parametric nature of GPR \cite{wang2023intuitive}.  

\subsubsection{Gaussian and Multivariate Normal Distributions}
Central to GPR are the Gaussian/normal distribution and its generalization to multiple dimensions, the MVN distribution. These distributions form the probabilistic cornerstone for modeling and making predictions in systems with inherent uncertainties. A Gaussian distribution, or univariate normal distribution, for a variable $X$ is defined by its probability density function (PDF):
%
\begin{ceqn}
    \begin{align}
       P_X(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp{\left(-\frac{(x - \mu)^2}{2 \sigma^2}\right)} \, , \tag{1} 
    \end{align}
\end{ceqn}
%
where $x$ represents the real argument of $X$. The behavior of $X$ is entirely determined by its mean $\mu$ and variance $\sigma^2$ as $P_X(x)\sim\mathcal{N}(\mu, \sigma^2)$. In Fig. \ref{figure:1D}, the PDF of a univariate normal distribution (one-dimensional) is visualized by plotting 1000 data points sampled from a normal distribution. 
%
\begin{figure}
    \centering
    \includegraphics[trim=0.4cm 0.1cm 1.4cm 0.6cm, width=0.55\columnwidth]{figures/1d_random.pdf}
    \caption{Visualization of a Gaussian distribution: 1000 data points sampled from a standard Gaussian distribution are represented as red vertical bars along the $X$-axis. The accompanying curve, a two-dimensional bell curve, illustrates the probability density function (PDF) of the distribution \cite{wang2023intuitive}.}
    \label{figure:1D}
\end{figure}
%

For systems characterized by multiple related variables $\mathbf{x} = [x_1, x_2, \ldots, x_M]^\top$, the Gaussian framework extends to MVN. This extension is essential for modeling their joint behavior. The PDF of an MVN for a vector $\mathbf{x}$ in an $M$-dimensional space, with a mean vector $\mu$ and a covariance matrix $\Sigma$, is expressed as \cite{wang2023intuitive}:
%
\begin{equation}
    \mathcal{N}(\mathbf{x} | \mu,\Sigma) = \frac{1}{(2\pi)^\frac{M}{2} |\Sigma|^\frac{1}{2}}\exp\left[-\frac{(\mathbf{x}-\mu)^\top \Sigma^{-1}(\mathbf{x}-\mu)}{2}\right] \, . \tag{2} 
\end{equation}
%
This formula captures the inter-variable correlations within vector $\mathbf{x}$. Here, $\Sigma$ is a symmetric matrix that defines the covariance, or the joint variability, between every pair of elements in $\mathbf{x}$. The matrix is pivotal in determining how changes in one variable affect others, encapsulating the essence of their interdependencies. The mean vector $\mu$ and the covariance matrix $\Sigma$ are crucial parameters that define this distribution. Specifically, $\mu = \mathbb{E}[\mathbf{x}] \in \mathbb{R}^M$ represents the expected value (or the average) of the vector $\mathbf{x}$, indicating the central tendency or the typical value each variable in $\mathbf{x}$ is expected to take. On the other hand, $\Sigma = \text{cov}[\mathbf{x}] \in \mathbb{R}^{M \times M}$, with each element $\Sigma_{ij}$, quantifies the covariance between the $i$-th and $j$-th elements of $\mathbf{x}$. Covariance measures how two variables fluctuate together; a positive covariance indicates that two variables tend to move in the same direction, whereas a negative covariance signifies that they move inversely. The diagonal elements of $\Sigma$, which represent the variance of each variable, show the extent to which each variable varies from its mean, providing insights into the spread or dispersion of the data. 

For intuitive understanding, a bivariate normal (BVN) distribution offers a simpler illustration of an MVN. In Fig. \ref{figure:2D}, a BVN distribution is visualized as a three-dimensional bell curve with the vertical axis (height) representing the probability density. 
%
\begin{figure}
    \centering
    \subfloat{{\includegraphics[trim=1.6cm 1.0cm 2.6cm 1.8cm, width=0.6\columnwidth]{figures/3d_gaussian_example.pdf} }}
    \qquad \qquad \qquad \qquad 
    \subfloat{{\includegraphics[trim=0.3cm 0.0cm 3.8cm 0.2cm, width=0.25\columnwidth]{figures/2d_gaussian_example.pdf} }}
    \caption{Visualization of a bivariate normal distribution: The upper image shows a 3-D bell curve for probability density, and the lower images display 2-D ellipse contours indicating the correlation between joint variables $x_1$ and $x_2$ \cite{wang2023intuitive}.}%
    \label{figure:2D}
\end{figure}
%
The correlation between two variables $x_1$ and $x_2$ is illustrated by the shape of two-dimensional ellipse contour projections. The function $P(x_1, x_2)$ denotes the joint probability density of $x_1$ and $x_2$. The BVN distribution is formulated as:
%
\begin{equation}
   \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} \sim \mathcal{N}(\mu, \Sigma) = \mathcal{N}\left(\begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix}, \begin{bmatrix} \sigma_{11} & \sigma_{12}  \\ \sigma_{21} & \sigma_{22} \end{bmatrix}\right)  \, , \tag{3}
\end{equation}
%
where $\mu$ is a two-dimensional vector with $\mu_1$ and $\mu_2$ represent means of $x_1$ and $x_2$, respectively. In the matrix $\Sigma$, the diagonal elements $\sigma_{11}$ and $\sigma_{22}$ are variances of $x_1$ and $x_2$, and the off-diagonal terms $\sigma_{12}$ and $\sigma_{21}$ describes their covariances. 

\subsubsection{Kernels}
Kernel functions are pivotal in GPR to enable effective modeling of relationships between data points across high-dimensional spaces. These functions are based on the principle that data points closer together in the input space should have similar outputs, which is essential for achieving accurate regression outcomes. By controlling the model's smoothness and flexibility, kernel functions enable GPR to adeptly handle complex data patterns and facilitate accurate interpolation of observed data for precise prediction \cite{wang2023intuitive}.

The choice of a kernel function can significantly affect the model's performance, with options ranging from the widely used radial basis function (RBF) to more specialized or custom kernels tailored to specific data properties like continuity, smoothness, periodicity, and expected trend in the data \cite{duvenaud2014automatic}. The RBF kernel, expressed as:
%
\begin{ceqn}
    \begin{align}
        k({x}_i,{x}_j) = \sigma_f^2 \exp \left[-\frac{1}{2}
         ({x}_i - {x}_j)^\top l^{-1}
         ({x}_i - {x}_j) \right]  \, , \tag{4}
    \end{align}
\end{ceqn}
%
is favored for its simplicity and efficacy, particularly in domains such as robotic control \cite{brunke2022safe,wang2023learning}. The hyperparameters $\sigma_f$ and $l$ influence the vertical scale and the smoothness of the regression model, respectively, which are crucial in shaping the model's behavior. For instance, adjusting the length scale parameter $l$ directly impacts the model's sensitivity to input data changes, as depicted in Fig. \ref{figure:hyperparameters_l}. A smaller $l$ value increases the model's responsiveness to minor variations, potentially leading to overfitting, while a larger $l$ enhances smoothness and generalization capabilities.

%
\begin{figure}
    \centering
    \vspace{0.1cm}
    \subfloat{{\includegraphics[trim=3.0cm 0.5cm 3.8cm 2cm, width=0.50\columnwidth]{figures/l_small.pdf} }}
    \qquad \qquad
    \subfloat{{\includegraphics[trim=3.8cm 0.5cm 2.8cm 0.2cm, width=0.43\columnwidth]{figures/l_medium.pdf} }}
    \qquad 
    \subfloat{{\includegraphics[trim=2.85cm 0.5cm 3.8cm 0.2cm, width=0.43\columnwidth]{figures/l_large.pdf} }}
    \caption{Impact of the length scale hyperparameter $l$ on model smoothness: smaller $l$ values lead to higher sensitivity to data variations (top), medium $l$ balances sensitivity and smoothness (lower left), and larger $l$ values favor smoothness over sensitivity to local changes (lower right) \cite{wang2023intuitive}.}
    \label{figure:hyperparameters_l}
\end{figure}
%

Hyperparameter optimization is crucial for customizing the GPR model to accurately reflect the underlying structure of the observed data. This process is conducted through the maximization of the log marginal likelihood \cite{rasmussen2006}:
%
\begin{equation}
    \boldsymbol{\theta^*} = \arg\max\limits_{\theta} \log p(\mathbf{y} \, \vert \, \mathbf{x}, \boldsymbol{\theta})  \, . \tag{5}
\end{equation}
%
The process of optimization in GPR seeks a delicate balance between fitting the observed data accurately and maintaining the model’s ability to generalize to new data. This equilibrium is crucial for avoiding overfitting, a scenario where the model is overly complex, mirroring the training data too closely at the expense of its predictive capability on unseen data (Fig. \ref{figure:hyperparameters_l}). Through meticulous adjustment of hyperparameters, the optimization process not only aligns the model with the observed data but also regulates its complexity. This regulation optimizes the predictive uncertainty $\boldsymbol{\Sigma}(\mathbf{x}_*)$, thereby boosting the model’s confidence and reliability across various inputs. As depicted in Fig. \ref{figure:optimized_gp}, optimizing hyperparameters significantly enhances the model’s accuracy and reliability compared to scenarios where parameters are not optimized (Fig. \ref{figure:hyperparameters_l}).

% %
% \begin{figure}
%     \centering
%     {{\includegraphics[trim=2.2cm 1.0cm 2.8cm 0.8cm, width=0.85\columnwidth]{figures/regression_gpflow.pdf}}}
%     \caption{GPR Visualization: Black crosses denote observed data points. From these, GPR considers all possible functions (illustrated by 20 samples in assorted colors) that align with the data. The solid red line represents the GP mean function, calculated from the distribution of these possible infinite numbers of functions. The surrounding blue-shaded region illustrates the prediction uncertainty, shown as 3 times the standard deviation from the mean. This analysis employs an RBF kernel with optimized hyperparameters ($\sigma_f = 0.0067$, $l = 0.0967$), demonstrating the model's improved predictive accuracy and reliability.}
%     \label{figure:optimized_gp}
% \end{figure}
% %
\subsubsection{Non-parametric Modeling}
Understanding the key difference between parametric and non-parametric models \cite{murphy2012machine} is essential for understanding the capabilities of GPR. Parametric models, characterized by a fixed set number of parameters, offer limited complexity and adaptability.
For example, a linear regression model, defined as $y = \theta_1 + \theta_2 x$, assumes a direct relationship between $x$ and $y$ through fixed parameters $\theta_1$ and $\theta_2$. While increases complexity by adding more terms, as in a polynomial model $y = \theta_1 + \theta_2 x + \theta_3 x^2$, the model is still confined to a predetermined structure, which potentially limits its ability to capture more intricate data patterns.

Typically, in regression tasks, we use a training dataset $D$ comprising $n$ observed points, denoted as $D=[(x_i,y_i)\, \vert \, i=1, \ldots, n]$, to establish a mapping from input values $x$ to output values $y$ through a set of basis functions $f(x)$. Parametric models simplify this process by summarizing the data with a finite set of parameters $\boldsymbol{\theta}$, allowing for predictions on new inputs $\mathbf{x}_*$ to be made without direct reference to the original dataset $D$ after the model has been trained. Mathematically, this concept is expressed as $P(f_* \, \vert \, \mathbf{x}_*, \boldsymbol{\theta}, D) = P(f_* \, \vert \, \mathbf{x}_*, \boldsymbol{\theta})$, where $f_*$ represents the model's predictions for new, unseen data points $\mathbf{x}_*$.

Non-parametric models like GPR, in contrast, do not confine their complexity to a predetermined number of parameters. They allow the model's complexity to grow with the observed dataset to enhance their flexibility and capacity to model complex relationships. By leveraging an infinite-dimensional feature space through kernels, GPR excels in tasks requiring precise predictions and uncertainty modeling. This adaptability is particularly valuable for tackling the diverse and intricate patterns found in real-world systems, where traditional parametric methods may fall short.

\subsection{Gaussian Process Regression}
GPR offers a unique methodology for modeling functions $\mathbf{f}$ from observed data $\mathcal{D}$, without the need for specifying a predefined function form. In general, the dataset $\mathcal{D}$ comprises input vectors $\mathbf{x} = [{x}_1, \cdots, {x}_n]^\top \in \mathbb{R}^{n_a \times n}$ and corresponding output values $\mathbf{f} = [{f}(x_1), \cdots, {f}(x_n)]^\top \in \mathbb{R}^{1 \times n}$, where $n$ denotes the total number of observations within $\mathcal{D}$. Unlike conventional regression methods that seek to identify a singular best-fit function, GPR models a distribution over possible functions that fit the observed data. This probabilistic approach is illustrated in Fig. \ref{figure:optimized_gp}, emphasizing GPR's capacity to accommodate the inherent uncertainties in modeling complex data relationships.
%
\begin{figure}
    \centering
    {{\includegraphics[trim=2.2cm 1.0cm 2.8cm 0.8cm, width=0.65\columnwidth]{figures/regression_gpflow.pdf}}}
    \caption{GPR visualization: Black crosses denote observed data points. From these, GPR considers all possible functions (illustrated by 20 samples in assorted colors) that align with the data. The solid red line represents the GP mean function, calculated from the distribution of these possible infinite numbers of functions. The surrounding blue-shaded region illustrates the prediction uncertainty, shown as 3 times the standard deviation from the mean. This analysis employs an RBF kernel with optimized hyperparameters ($\sigma_f = 0.0067$, $l = 0.0967$), demonstrating the model's improved predictive accuracy and reliability \cite{wang2023intuitive}.}
    \label{figure:optimized_gp}
\end{figure}
%

GPR constructs this model by assuming that the observed data can be described by an MVN, with the probability of any set of function values $\mathbf{f}$ given inputs $\mathbf{x}$ as:
%
\begin{equation}
       P(\mathbf{f} \, \lvert\, \mathbf{x}) = \mathcal{N}(\mathbf{f} \, \lvert \, \boldsymbol\mu, \mathbf{K}) \, , \tag{6}
\end{equation}
%
Here, the variable $\boldsymbol\mu = \left[ m({x}_1), \ldots, m({x}_n) \right]$ represents the mean function, and $\mathbf{K}$ is the covariance matrix computed using the chosen kernel function, composing of positive definite elements $K_{ij} = k({x}_i,{x}_j)$. With no observation, we default the mean function to $m(\mathbf{x}) = 0$, assuming the data is normalized to zero mean. 

The regression process with GP models is depicted in Fig. \ref{figure:gp_pred}, where observed data points (red points $\mathbf{x}$) and the mean function $\mathbf{f}$ (blue line) estimated from these observed data points, predict at new points $\mathbf{x}*$, resulting in $\mathbf{f}*$.
%
\begin{figure}
    \centering
    \vspace{0.2cm}
    \includegraphics[width=0.30\columnwidth]{figures/predictions.png}
    \caption{An illustrative process of conducting regressions by Gaussian processes. The red points are observed data, the blue line represents the mean function estimated by the observed data points, and predictions will be made at new blue points \cite{wang2023intuitive}.}
    \label{figure:gp_pred}
\end{figure}
%
Predicting new values $\mathbf{f}_*$ at points $\mathbf{x}_*$ involves the joint Gaussian distribution of both observed and predicted values:
%
\begin{equation}
       \begin{bmatrix}\mathbf{f} \\ \mathbf{f}_*\end{bmatrix} \sim \mathcal{N}\left(\begin{bmatrix} \boldsymbol\mu(\mathbf{x})\\ \boldsymbol\mu(\mathbf{x}_*)\end{bmatrix}, \begin{bmatrix}\mathbf{K} & \mathbf{K}_* \\ \mathbf{K}_*^\top & \mathbf{K}_{**}\end{bmatrix}\right) \, , \tag{7}
\end{equation}
%
where $\mathbf{K} = K(\mathbf{x}, \mathbf{x})$, $\mathbf{K}_* = K(\mathbf{x}, \mathbf{x}_*)$, and $\mathbf{K}_{**} = K(\mathbf{x}_*, \mathbf{x}_*)$ represent the covariance matrices between observed data, observed and new data, and new data points, respectively. While this equation outlines the joint probability distribution $P(\mathbf{f}, \mathbf{f}_* \,|\, \mathbf{x}, \mathbf{x}_*)$ for both the observed and predictive function values, regression analysis requires the conditional distribution $P(\mathbf{f}_* \,|\, \mathbf{f}, \mathbf{x}, \mathbf{x}_*)$ to predict exclusively on $\mathbf{f}_*$ given observed data. This conditional distribution is extracted from the joint distribution by applying the marginal and conditional distributions of the MVN theorem \cite[Sec.\ 2.3.1]{bishop2006pattern} as:
%
\begin{equation}
   \mathbf{f}_* \, \vert \, \mathbf{f}, \mathbf{x}, \mathbf{x}_* \sim \mathcal{N} \left(\mathbf{K}_*^\top \, \mathbf{K}^{-1} \, \mathbf{f}, \: \mathbf{K}_{**} - \mathbf{K}_*^\top \, \mathbf{K}^{-1} \, \mathbf{K}_* \right) \, . \tag{8}
\end{equation}
%
The conditional distribution provides the predictive mean and variance for $\mathbf{f}_*$, offering not only accurate predictions at new points but also quantifies the uncertainty associated with these predictions.

Real-world observations often include noises, modeled as $\mathbf{y} = \mathbf{f}(\mathbf{x}) + \boldsymbol{\epsilon}$, where $\boldsymbol{\epsilon}$ is an additive Gaussian noise with variance $\sigma_n^2$. The prior covariance of $\mathbf{y}$ becomes $\text{cov}(\mathbf{y}) = \mathbf{K} + \sigma_n^2 \mathbf{I}$. The inclusion of observational noise refines the GPR model's predictive equations to \cite{rasmussen2006}:
%
\begin{equation}
    \mathbf{\bar{f}_*} \,|\, \mathbf{x}, \mathbf{y}, \mathbf{x}_* \sim \mathcal{N} (\boldsymbol{\mu}(\mathbf{x}_*), \boldsymbol{\Sigma}(\mathbf{x}_*)) \, , \tag{9}
    \label{eqn:gp_conclusion}
\end{equation}
%
where the predictive mean $\boldsymbol{\mu}(\mathbf{x}_*)$ and variance $\boldsymbol{\Sigma}(\mathbf{x}_*)$ are determined as: 
%
\begin{ceqn}
    \begin{align}
        \boldsymbol{\mu}(\mathbf{x}_*) &= \mathbf{K}_*^\top [\mathbf{K} + \sigma_n^2 \mathbf{I}]^{-1} \mathbf{y} \, , \tag{10a} \label{eqn:gp_mean} \\
        \boldsymbol{\Sigma}(\mathbf{x}_*) &= \mathbf{K}_{**} - \mathbf{K}_*^\top [\mathbf{K} + \sigma_n^2 \mathbf{I}]^{-1} \mathbf{K}_* \, . \tag{10b} \label{eqn:gp_var}
    \end{align}
\end{ceqn}
%
In this expression, the variance function $\boldsymbol{\Sigma}(\mathbf{x}_*)$ reveals that the uncertainty in predictions depends solely on the input values $\mathbf{x}$ and $\mathbf{x}_*$, not on the observed outputs $\mathbf{y}$. This characteristic is a distinctive property of GPR \cite{rasmussen2006}.

A GP model describes a probability distribution over possible functions that fit a set of points. In essence, GPR is characterized by its non-parametric nature, leveraging a probability distribution over all possible functions as a mean function used for regression predictions. This approach allows for flexible modeling of complex relationships and provides a robust framework for making predictions with quantified uncertainty, making it a powerful tool in statistical learning and data analysis.

\subsection{Sparse Gaussian Process}
\label{section:sparse_gpr}
As shown in \eqref{eqn:gp_mean} and \eqref{eqn:gp_var}, the computational demands of the mean and variance in the standard GP model scale as $\mathcal{O}(n^2)$ and $\mathcal{O}(n^3)$, respectively, which increases with the number of training data points $n$ \cite{hewing2019}. This scaling is due to the need to invert a large $n \times n$ covariance matrix, rendering standard GPR computationally intensive for large datasets. Such computational requirements could limit the applicability of traditional GPR in scenarios requiring real-time analysis or involving large-scale data, such as model-based control in robotics \cite{wang2024learning-based}.

The sparse GPR technique offers a solution to these challenges by utilizing a subset of the full dataset, known as inducing points, to approximate the complete GP model \cite{liu2020gaussian}. This strategy focuses on condensing the full dataset's information into a smaller set of inducing variables. Consequently, this approach significantly reduces the size of the covariance matrix that needs to be inverted, thus lowering the computational complexity to depend on the number of inducing points $\tilde{n}$, rather than the full dataset size $n$. The computational complexity of sparse GP models is $\mathcal{O}(\tilde{n}^2n)$ for the mean and $\mathcal{O}(\tilde{n}^3)$ for the variance, thereby providing a more scalable alternative to traditional GPR \cite{hewing2018cautious}.

Choosing the right inducing points $\mathbf{x}^\text{ind} = [x_1^\text{ind}, \cdots, x^\text{ind}_{\tilde{n}}]^\top$ is crucial for preserving the accuracy of the model. These points aim to encapsulate the essential information of the dataset, selected to reflect its underlying structure with minimal information loss. Techniques like the fully independent conditional (FIC) approximation method facilitate this by optimizing the placement of inducing points automatically to maximize the model's likelihood, which is convenient and has been widely used to achieve computational efficiency with reasonable accuracy loss \cite{snelson2005sparse}. 

\section{Approximating Mean and Uncertainty Propagation}
\label{sec:mean_var_approx}
This section investigates the integration of GP with MPC, specifically targeting the creation of critical mathematical equations to approximate mean and uncertainty within the MPC prediction horizon. Such approximations are crucial due to the non-Gaussian outputs produced by GP models across multiple prediction steps. This characteristic of GP models requires approximation techniques to enable their practical integration into MPC frameworks. By accurately approximating mean and uncertainty, GP models can be effectively combined within MPC strategies, thereby improving control strategy performance and reliability in the face of system unpredictability and variability.

Highlighting this section is a key contribution of our tutorial. It offers a systematic and detailed explanation of GP-MPC integration, marking a novel contribution that addresses a notable void in the current literature. This section lays a solid foundation for understanding GP-MPC integration theoretically, leading to comprehensive discussions about its application in real-world scenarios. Through this exposition, our tutorial distinguishes itself as a critical resource for advancing the field of learning-based control systems, particularly in applications requiring sophisticated handling of uncertainty.

Consider a nonlinear dynamical system  represented by a discrete-time state-space model \cite{hewing2018cautious}:
%
\begin{ceqn}
    \begin{align} 
        x_{k+1}&=\overbrace{{f}\left(x_{k}, {u}_{k}\right)}^{\text {prior nominal model}}+\overbrace{{g}(x_{k}, {u}_{k})} ^{\text {learning-based model}} \, , \tag{11a} \label{eqn:process_model_general} \\ 
        &= {f}\left(x_{k}, {u}_{k}\right)+B_d \left({d}(x_{k}, {u}_{k}) + \omega_k\right) \, . \tag{11b} \label{eqn:process_model_Bd} 
    \end{align}
\end{ceqn}
%
In this system model, $x_{k}$ and $u_{k}$ represent the state and control input vectors at time step $k$, respectively. The system dynamics are captured by two components: a prior nominal model $f\left(x_{k}, {u}_{k}\right)$, which represents the known part of the system, and a learning-based model $g\left(x_{k}, {u}_{k}\right)$, designed to compensate for discrepancies between the nominal model and actual system behaviors. To manage the dimensionality of the learning-based model's output and direct its influence to specific subsystems or states, a matrix $B_d$ precedes $d\left(x_{k}, {u}_{k}\right)$. This matrix $B_d$ enables the model to target only a subset of the system states ${x}$, thus enhancing computational efficiency without sacrificing model fidelity. Additionally, the model includes spatially uncorrelated Gaussian noise $\omega_k$ with $\omega_k \sim \mathcal{N} (0, \Sigma^\omega)$, where $\Sigma^\omega = \operatorname{diag}([\sigma_1^2, \cdots, \sigma_{n_d}^2])$ represents the noise's diagonal variance matrix. It is worth noting that the use of $B_d$ is mainly aimed at enhancing computational efficiency by reducing the learning-based model's output on a subset of dimensions. However, it is entirely feasible to set $B_d = \mathbf{I}$, which allows the GP model $d\left(x_{k}, {u}_{k}\right)$ to influence across all system states ${x}$. 

Using \eqref{eqn:gp_conclusion}, the learning-based model $g\left(x_{k}, {u}_{k}\right)$ in \eqref{eqn:process_model_general} is approximated as a GP model $d\left(x_{k}, {u}_{k}\right)$ in \eqref{eqn:process_model_Bd} as: 
%
\begin{equation}
    d\left(x_{k}, {u}_{k}\right) \sim \mathcal{N} \left({\mu}^d\left(x_{k}, {u}_{k}\right), {\Sigma}^d\left(x_{k}, {u}_{k}\right)\right) \, , \tag{12} \label{eqn:gp_Bd} 
\end{equation}
%
which captures the learning-based adjustments to the system dynamics.

In the framework of GP modeling, the inputs at the current time step are assumed to follow a Gaussian distribution. However, the outputs of the GP model (posterior predictions) result in stochastic variables with unknown distribution. With such uncertain inputs (the predictive posterior of the current time step), the distribution of the GP output at the next time step is not Gaussian anymore \cite{quinonero2003}. This is a problem to use \eqref{eqn:process_model_Bd} as the prediction model in MPC, which needs to make predictions for multiple time steps ahead. 

To facilitate the integration of GP models with MPC frameworks, a common approach involves approximating the state distribution at each future time step as Gaussian, denoted by $x_k \sim \mathcal{N}(\mu_k^d, \Sigma_k^d)$ \cite{hewing2020learning}. This approximation enables the use of GP models within MPC by simplifying the predictive state distributions into a form that is tractable for MPC algorithms. However, it is essential to acknowledge that this simplification may introduce inaccuracies due to the non-Gaussian nature of the true predictive distributions arising from GP models. Under this assumption, the system state $x_{k}$, control input $u_{k}$, and the GP model ${d}(x_{k}, {u}_{k})$ are considered to have a multivariate Gaussian distribution at each time step \cite{hewing2019}, which facilitates the mathematical treatment of system dynamics and control actions within a probabilistic framework as \cite{hewing2018cautious}:
%
\begin{equation} 
    \begin{bmatrix}
    x_{k} \\
        u_{k} \\
        {d}(x_{k}, {u}_{k}) \\ \qquad + \omega_k
    \end{bmatrix}
    \sim
    \mathcal{N}\left(\begin{bmatrix}
    \mu_{k}^{x} \\
    \mu_{k}^{u} \\
    \mu_{k}^{d}
   \end{bmatrix},\begin{bmatrix}
    \Sigma_{k}^{x} & \Sigma_{k}^{x u} & \Sigma_{k}^{x d} \\
    {\Sigma_{k}^{x u}}^\top & \Sigma_{k}^{u} & \Sigma_{k}^{u d} \\
    {\Sigma_{k}^{x d}}^\top & {\Sigma_{k}^{u d}}^\top & \Sigma_{k}^{d}+\Sigma^{w}
   \end{bmatrix}\right) \, . \tag{13} \label{eqn:normal_dis_all} 
\end{equation}
%
Here, \(\mu_{k}^{x}\), \(\mu_{k}^{u}\), \(\mu_{k}^{d}\) denote the mean values of the state \(x_k\), control input \(u_k\), and GP model output \(d(x_{k}, {u}_{k})\), respectively. The variance matrices \(\Sigma_{k}^{x}\), \(\Sigma_{k}^{u}\), and \(\Sigma_{k}^{d}\), along with the covariance matrices \(\Sigma_{k}^{xu}\), \(\Sigma_{k}^{xd}\), and \(\Sigma_{k}^{ud}\), capture the uncertainties and correlations between these variables. The term \(\Sigma^{\omega}\) represents is the variance matrix of the noise \(\omega_k\) in \eqref{eqn:process_model_Bd}, reflecting the uncertainty introduced by the noise in the system dynamics.

By defining the state and control input into a combined vector $z_k = \left[x_k^\top, u_k^\top \right]^\top$ and denoting the GP model output $d_{k}={d}(x_{k}, {u}_{k})$, \eqref{eqn:normal_dis_all} can be reformulated into a more compact representation as:
%
\begin{ceqn} 
    \begin{align}
        \begin{bmatrix}
            z_{k} \\            
            d_{k} + \omega_k
        \end{bmatrix}
        &\sim 
        \mathcal{N}\left(\mu_{k}, \Sigma_{k}\right) 
        =
        \mathcal{N}\left(\begin{bmatrix}
        \mu_{k}^{z} \\
        \mu_{k}^{d}
       \end{bmatrix},\begin{bmatrix}
        \Sigma_{k}^{z} & \Sigma_{k}^{z d} \\
        \star & \Sigma_{k}^{d}+\Sigma^{w}
       \end{bmatrix}\right) \, , \tag{14} \label{eqn:normal_dis_z} 
    \end{align}
\end{ceqn}
%
where $ \star $ signifies symmetric elements within the covariance matrix. The notations for mean and covariance matrices are specified as follows:
%
\begin{equation}
    \mu_{k}^{z}=\begin{bmatrix}
    \mu_{k}^{x} \\
    \mu_{k}^{u}
    \end{bmatrix}, \ \ \Sigma_{k}^{z}=\begin{bmatrix}
    \Sigma_{k}^{x} & \Sigma_{k}^{x u} \\
    {\Sigma_{k}^{x u}}^\top & \Sigma_{k}^{u}
    \end{bmatrix},  \ \ \Sigma_{k}^{z d}=\begin{bmatrix}
    \Sigma_{k}^{x d} \\
    \Sigma_{k}^{u d}
    \end{bmatrix} \, . \tag{15} \label{eqn:normal_dis_z_variables} 
\end{equation}
%

\subsection{Mean Propagation Approximation}
\label{sec:mean_prop}
In this section and the subsequent Sec. \ref{sec:var_prop}, we detail the process of propagating the mean and variance of the system state from $x_k$ to $x_{k+1}$. We denote the mean \textit{m}$(x_{k+1})$ and variance $\textit{var}(x_{k+1})$ of the state $x_{k+1}$ as $\mu_{k+1}^x$ and $\Sigma_{k+1}^x$, respectively. The propagation is based on the theoretical foundation provided in Appendix \ref{sec:appendix_gp_approx}, following the steps:
%
\begin{ceqn} 
    \begin{align} 
        \mu_{k+1}^x &= \textit{m} (x_{k+1}) \, , \tag{16a} \label{eqn:mean_prop_a}  \\
                   &= \mathbb{E}_{z_k}\left[\mathbb{E}_{d} (x_{k+1}) \right] \, , \tag{16b} \label{eqn:mean_prop_b} \\
                   &= \mathbb{E}_{z_k}\left[\mathbb{E}_{d} (f(x_k, u_k)+ \mathbb{E}_{d} \left( B_d(d(x_k, u_k) + \omega_k)\right) \right] \, , \tag{16c} \label{eqn:mean_prop_c} \\
                   &= \mathbb{E}_{z_k}\left[\mathbb{E}_{d} \left(f(x_k, u_k)\right) +  B_d \mu^d(x_k, u_k) \right] \, . \tag{16d} \label{eqn:mean_prop_d}
    \end{align}
\end{ceqn}
%
Applying the mean propagation formula \eqref{eqn:mean_prop_general_final} in Appendix \ref{sec:appendix_gp_approx} to $\eqref{eqn:mean_prop_a}$, the mean of state $x_{k+1}$ equals the expected value of the GP model $\mathbb{E}_d$ at state $x_{k+1}$, results \eqref{eqn:mean_prop_b}. Incorporating the discrete-time state-space model into \eqref{eqn:mean_prop_c}, and then using \eqref{eqn:gp_Bd} to obtain the expected output of the GP model $d(x_k, u_k)$ as $\mu^d(x_k, u_k)$, we arrive at \eqref{eqn:mean_prop_d}. Also, in \eqref{eqn:mean_prop_d}, the term $\mathbb{E}_d \left(f(x_k, u_k)\right)$ represents the expected value of the function $f$ under the GP model $d$ at the point $(x_k, u_k)$, which equals to $f(x_k, u_k)$. Thus, we can express:

%
\begin{ceqn}
    \begin{align}
        \mu_{k+1}^x &= \mathbb{E}_{z_k}\left(f(x_k, u_k) +  B_d \mu^d(x_k, u_k) \right) \, , \tag{16e} \label{eqn:mean_prop_exp_a} \\
                    &= \mathbb{E}_{z_k}\left(f(x_k, u_k)\right) +  \mathbb{E}_{z_k}\left( B_d \mu^d(x_k, u_k) \right) \, . \tag{16f} \label{eqn:mean_prop_exp_b}
    \end{align}
\end{ceqn}
%

To ensure a balance between computational efficiency and accuracy, similar to the approach in extended Kalman filtering, we linearize the nominal model $f(x_k, u_k)$ around the current mean values ($\mu_k^x$ and $\mu_k^u$) using a first-order Taylor expansion:
%
\begin{ceqn}
    \begin{align}
        f(x_k, u_k) &\approx f \left(\mu_k^x, \mu_k^u \right) + \frac{\partial f (x, u)}{\partial x} \bigg|_{\mu_k^x, \mu_k^u} (x_k - \mu_k^x) + \frac{\partial f(x, u)}{\partial u} \bigg|_{\mu_k^x, \mu_k^u} (u_k - \mu_k^u) \, , \tag{17a} \label{eqn:mean_prop_taylor_a} \\
        &= f\left(\mu_k^x, \mu_k^u \right) + \nabla f\left(\mu^{z}_k \right)\left(z_k - \mu^{z}_k \right) \, . \tag{17b} \label{eqn:mean_prop_taylor_b} 
        % \mu^d(x_k, u_k) &\approx  \mu^d(\mu_k^x, \mu_k^u) + \frac{\partial \mu^d(x, u)}{\partial x} \bigg|_{\mu_k^x, \mu_k^u} (x_k - \mu_k^x) \nonumber \\
        % & \qquad \qquad + \frac{\partial \mu^d(x, u)}{\partial u} \bigg|_{\mu_k^x, \mu_k^u} (u_k - \mu_k^u) \, , \tag{17c} \label{eqn:mean_prop_taylor_c} \\
        % &= \mu^d \left(\mu_k^x, \mu_k^u \right) + \nabla \mu^d \left(\mu^{z}_k \right)\left(z_k - \mu^{z}_k \right) \, . \tag{17d} \label{eqn:mean_prop_taylor_d} 
    \end{align}
\end{ceqn}
%
Here, $z_k = [x_k^\top, u_k^\top]^\top$ represents the combined state-input vector, and $\mu^{z}_k = [{\mu^{x}_k}^\top, {\mu^{u}_k}^\top]^\top$ denotes its mean. Additionally, we use $\nabla f\left(\mu^{z}_k \right)$ to represent the gradient of $f$ evaluated at $\mu^{z}_k$ to obtain a more compact equation form as \eqref{eqn:mean_prop_taylor_b}. Applying \eqref{eqn:mean_prop_taylor_b}, the first term in \eqref{eqn:mean_prop_exp_b} is derived as:
%
\begin{ceqn}
    \begin{align}
        \mathbb{E}_{z_k} &\left(f(x_k, u_k)\right)  \nonumber \\
        &\approx \mathbb{E}_{z_k}\left(f\left(\mu_k^x, \mu_k^u \right) + \nabla f\left(\mu^{z}_k \right)\left(z_k - \mu^{z}_k \right)\right) \, , \tag{18a} \label{eqn:exp_nominal_a} \\
        &\approx f(\mu_{k}^x, \mu_k^u) \, . \tag{18b} \label{eqn:exp_nominal_b} 
    \end{align}
\end{ceqn}
%
Further by following \eqref{eqn:exp_mean_appendix} in Appendix \ref{sec:appendix_gp_approx}, the GP mean $\mu^d(x_k, u_k)$ is approximated by its first order Taylor expansion around $x_k = \mu_k^x$ and $u_k = \mu_k^u$, thus the second term in \eqref{eqn:mean_prop_exp_b} is derived as:
%
\begin{ceqn}
    \begin{align}
        \mathbb{E}_{z_k} &\left(B_d \mu^d(x_k, u_k) \right)  \nonumber \\
        &\approx \mathbb{E}_{z_k}\left(\mu^d \left(\mu_k^x, \mu_k^u \right) + \nabla \mu^d \left(\mu^{z}_k \right)\left(z_k - \mu^{z}_k \right)\right) \, , \tag{19a} \label{eqn:exp_mean_a} \\
        &\approx B_d \mu^d(\mu_{k}^x, \mu_k^u) \, . \tag{19b} \label{eqn:exp_mean_b} 
    \end{align}
\end{ceqn}
%
Subscribing \eqref{eqn:exp_nominal_b} and \eqref{eqn:exp_mean_b} to \eqref{eqn:mean_prop_exp_b}, the final mean propagation approximation is: 
%
\begin{equation}
    \mu_{k+1}^x \approx f(\mu_{k}^x, \mu_k^u) + B_d \mu^d(\mu_{k}^x, \mu_k^u)  \, . \tag{20} \label{eqn:mean_prop_final}          
\end{equation}
%

\subsection{Uncertainty Propagation Approximation}
\label{sec:var_prop}
\subsubsection{Taylor Approximation}
Uncertainty propagation within MPC loops is pivotal for ensuring robust decision-making under uncertainties \cite{deisenroth2010efficient}. The first widely used approach for approximation of uncertainty propagation is the Taylor approximation method, akin to the GP mean approximation discussed previously in Sec. \ref{sec:mean_prop}. By linearly approximating the impact of uncertainty on system dynamics, we can efficiently predict the variance of future states, which is detailed from equations 
\eqref{eqn:var_prop_exp_a} to \eqref{eqn:var_prop_exp_h}. 
%
\begin{ceqn}
    \begin{align} 
        \Sigma_{k+1}^x &= \textit{var}(x_{k+1}) \, , \tag{21a} \label{eqn:var_prop_exp_a} \\
        \text{use} \ \eqref{eqn:var_prop_general} \ &= \mathbb{E}_{z_k}\left[\Sigma^d (x_{k+1}) \right] \nonumber + \textit{var}_{z_k} \left(\mu^{d} (x_{k+1}) \right) \, , \tag{21b} \label{eqn:var_prop_exp_b} \\
        \text{use} \ \eqref{eqn:gp_Bd} \ \text{and} \ \eqref{eqn:mean_prop_final} \ &= \mathbb{E}_{z_k}\left( B_d \left(\Sigma^d(z_k) + \Sigma^\omega \right)B_d^\top \right ) + \operatorname{var}_{z_k} \left(f(z_k) +  B_d \mu^d(z_k) \right) \, , \tag{21c} \label{eqn:var_prop_exp_c} \\
        \text{use} \ \eqref{eqn:exp_var_appendix} \ \text{and} \ \eqref{eqn:var_mean_appendix} \ &= B_d \left(\Sigma^d(\mu_{k}^{z}) + \Sigma^\omega \right)B_d^\top  + \left(\nabla {f}(\mu_{k}^{z}) + {B_d} \nabla \mu^{d}(\mu_{k}^{z})\right) \Sigma_{k}^{z} \left(\nabla {f}(\mu_{k}^{z}) + {B_d} \nabla \mu^{d}(\mu_{k}^{z})\right)^\top , \tag{21d} \label{eqn:var_prop_exp_d} \\
        & = B_d \left(\Sigma^d(\mu_{k}^{z}) + \Sigma^\omega \right)B_d^\top + \nabla {f}(\mu_{k}^{z}) \Sigma_{k}^{z} \left(\nabla \mu^{d}(\mu_{k}^{z})\right)^\top B_d^\top + \nabla {f}(\mu_{k}^{z}) \Sigma_{k}^{z} {\nabla {f} ^\top (\mu_{k}^{z})} \nonumber \\
        & \qquad \ \ + B_d \left(\nabla \mu^{d}(\mu_{k}^{z})\right) \Sigma_{k}^{z} \left(\nabla \mu^{d}(\mu_{k}^{z})\right)^\top B_{d} ^\top + B_d \left(\nabla \mu^{d}(\mu_{k}^{z})\right) \Sigma_{k}^{z} {\nabla {f} ^\top (\mu_{k}^{z})} \, , \tag{21e} \label{eqn:var_prop_exp_e} \\
        &= \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d} \end{bmatrix} \begin{bmatrix}
        \Sigma_{k}^{z} & \Sigma_{k}^{z} \left(\nabla \mu^{d}(\mu_{k}^{z})\right)^\top \\
        \left(\nabla \mu^{d}(\mu_{k}^{z})\right) \Sigma_{k}^{z} &  \Sigma^{d}\left(\mu_{k}^{z}\right)+\nabla \mu^{d}\left(\mu_{k}^{z}\right) \Sigma_{k}^{z}\left(\nabla \mu^{d}\left(\mu_{k}^{z}\right)\right)^\top+\Sigma^{w}
        \end{bmatrix} \nonumber \\
        &\qquad \qquad \qquad \quad \, \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d} \end{bmatrix}^\top \, , \tag{21f} \label{eqn:var_prop_exp_f} \\
        &= \begin{bmatrix}\nabla {f}(\mu_{k}^{z}) & B_{d} \end{bmatrix} \begin{bmatrix}
        \Sigma_{k}^{z} & \Sigma_{k}^{z d} \\
        {\Sigma_{k}^{z d}}^\top & \Sigma_{k}^{d}+\Sigma^{w}
        \end{bmatrix} \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d} \end{bmatrix}^\top \, , \tag{21g} \label{eqn:var_prop_exp_g} \\
        &= \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d} \end{bmatrix} \Sigma_k \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d} \end{bmatrix}^\top \, . \tag{21h} \label{eqn:var_prop_exp_h}
    \end{align}
\end{ceqn}
%

It is worth remembering that the posterior predictions of the GP model in the MPC loop are not Gaussian due to multiple prediction steps needed. In order to integrate GP models into the MPC prediction model, it needs to assume the distribution of the states at every time step in the MPC loop is Gaussian distributed as $x_k \sim \mathcal{N}(\mu_k^d, \Sigma_k^d)$, thus we can obtain posterior predictions using the GP model. Intuitively, we need to consider the input uncertainty for the GP model at each time step to propagate the uncertainty in the MPC loop cumulatively.

Upon examining the definitive equation for uncertainty propagation \eqref{eqn:var_prop_exp_g}, it can be seen that for accurate uncertainty propagation when coupling a GP model $d(\cdot)$ with a nominal system model $f(\cdot)$, both the inherent uncertainty of the GP model $\Sigma_{k}^{d}$, and the covariance between the GP model's output and the combined state-control inputs $\Sigma_{k}^{z d}$, play pivotal roles. Comparing \eqref{eqn:var_prop_exp_f} and \eqref{eqn:var_prop_exp_g}, we obtain the general equations for $\Sigma_{k}^{d}$ and $\Sigma_{k}^{z d}$, articulated as: 
%
\begin{equation}
    \begin{bmatrix}
    \Sigma_{k}^{z d} \\
    \Sigma_{k}^{d}
    \end{bmatrix}  
    =\begin{bmatrix}
    \Sigma_{k}^{z}\left(\nabla \mu^{d}\left(\mu_{k}^{z}\right)\right)^{\top} \\
    \Sigma^{d}\left(\mu_{k}^{z}\right)+\nabla \mu^{d}\left(\mu_{k}^{z}\right) \Sigma_{k}^{z}\left(\nabla \mu^{d}\left(\mu_{k}^{z}\right)\right)^{\top}
    \end{bmatrix} \, . \tag{22} \label{eqn:var_prop_taylor}
\end{equation}
%
This equation encompasses the covariance, \(\Sigma_{k}^{z d}\), which includes the covariance between the state variables and the GP model output \(\Sigma_{k}^{x d}\) as well as the covariance between the control inputs and the GP model outputs \(\Sigma_{k}^{u d}\), as defined in \eqref{eqn:normal_dis_z_variables}. Moreover, the GP model's uncertainty variance, \(\Sigma_{k}^{d}\), incorporates adjustments to both the model's posterior covariance and variance. These adjustments are informed by the gradient of the model's posterior mean relative to the input, \(\nabla \mu^{d}\left(\mu_{k}^{z}\right)\), and the input variance, \(\Sigma_{k}^{z}\). This approach ensures the precision of GP model prediction by thoroughly accounting for the dynamic interplay between input variability and output uncertainty.

\subsubsection{Mean Equivalent Approximation}
The mean equivalent approximation method is another commonly used strategy for approximating uncertainty propagation \cite{langaaker2018cautious}. This technique simplifies the process by using only the mean values of input variables without propagating uncertainties. Specifically, it assumes no uncertainty accumulation within the GP model \(\Sigma_{k}^{d}\) across the MPC prediction horizons and disregards the covariance between the GP model \(d(z_k)\) and the state-control inputs \(z_k\), formalized as follows:
%
\begin{equation}
    \begin{bmatrix}
    \Sigma_{k}^{z d} \\
    \Sigma_{k}^{d}
    \end{bmatrix}  
    =\begin{bmatrix}
    0 \\
    \Sigma^{d}\left(\mu_{k}^{z}\right)
    \end{bmatrix} \, . \tag{23} \label{eqn:var_prop_mean_equiv}
\end{equation}
%
Without accumulating uncertainty propagation in the MPC prediction horizons, this method can lead to poor approximations of GP models. Its omission of covariance dynamics (\(\Sigma_{k}^{z d} = 0\)) can in addition deteriorate the quality of predictions when integrated with a nominal system $f(z)$ \cite{hewing2018cautious}. By applying \eqref{eqn:var_prop_exp_c}, the system uncertainty propagation approximation using the mean equivalent approximation method is: 
%
\begin{ceqn}
    \begin{align}
        \textit{var}(x_{k+1}) 
        &= \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d}\end{bmatrix} \begin{bmatrix}
        \Sigma_{k}^{z} & 0 \\
        0 & \Sigma^{d}\left(\mu_{k}^{z}\right)+\Sigma^{w}
        \end{bmatrix}  
        \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d}\end{bmatrix}^\top \, , \tag{24a} \label{eqn:var_prop_mean_equi_a} \\
        &= \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d}\end{bmatrix} \Sigma_k \begin{bmatrix} \nabla {f}(\mu_{k}^{z}) & B_{d}\end{bmatrix}^\top \, . \tag{24b} \label{eqn:var_prop_mean_equi_b}
    \end{align}
\end{ceqn}
%

\subsection{Mean and Uncertainty Approximation}
This section summarizes conclusive equations on approximating the mean ($\mu$) and uncertainty ($\Sigma$) propagation in dynamic systems \eqref{eqn:process_model_general}:

%
\begin{ceqn}
    \begin{align} 
        \mu_{k+1}^x &\approx f(\mu_{k}^x, \mu_k^u) + B_d \mu^d(\mu_{k}^x, \mu_k^u) \, , \quad \text{(Refer back to \eqref{eqn:mean_prop_final})} \tag{25a} \label{eqn:mean_prop_final_again} \\
        \Sigma_{k+1}^x &\approx \begin{bmatrix} \nabla {f}(\mu_{k}^x, \mu_k^u) & B_{d}\end{bmatrix} \Sigma_k \begin{bmatrix} \nabla {f}(\mu_{k}^x, \mu_k^u) & B_{d}\end{bmatrix}^\top \, , \tag{25b} \label{eqn:var_prop_final} 
    \end{align}
\end{ceqn}
%
where the system variance $\Sigma_k$ is defined in \eqref{eqn:var_prop_exp_g} and \eqref{eqn:var_prop_mean_equi_a} by using either the Taylor approximation or the mean equivalent approximation method, respectively. The difference of $\Sigma_k$ using two different approximation methods offers a trade-off between computational efficiency and the accuracy of uncertainty quantification in GP-based predictive models.

Specifically, the Taylor approximation method allows for a nuanced incorporation of uncertainty through the linearization of system dynamics, whereas the mean equivalent approximation method simplifies the computational process by assuming a deterministic pathway based solely on mean values, thereby eschewing direct uncertainty propagation. This distinction underscores the importance of method selection based on the specific requirements for model accuracy and computational resources, highlighting the inherent compromises between simplicity and fidelity in the modeling of dynamic systems.

Beyond these two approximation methods discussed in Sec. \ref{sec:var_prop}, exact moment matching method \cite{deisenroth2010efficient} introduces a technique for computing the GP prediction's mean and variance directly by integrating over the input distribution without approximations. This approach accounts for the behavior of the mean function and input variability, aiming for a precise representation of prediction uncertainty. However, its practicality is constrained by the presumption that state distributions at each step within the MPC prediction horizon adhere to a Gaussian distribution. This assumption introduces inaccuracies, given the GP's posterior is non-Gaussian over multiple prediction steps. This limitation is particularly highlighted in \cite{hewing2018cautious}, demonstrating that both Taylor approximation and exact moment matching tend to provide similar outcomes for the typical range of variation in GP's posterior mean and variance within the MPC prediction horizon. Despite the theoretical precision offered by the exact moment matching method, its substantial computational demands significantly restrict its widespread application in the propagation of mean and uncertainty, particularly when combining with MPC. The complexity of exact moment matching exacerbates the computational burden of MPC, a framework already known for its intensive computational demands, especially in real-world robotic applications where rapid decision-making is critical.

The introduction of these three methods illuminates a spectrum of options available to mean and uncertainty propagation, from the computationally light but potentially less accurate mean equivalent approximation, through the balanced approach of Taylor approximation, to the theoretically precise but computationally intensive exact moment matching. The choice among these methods hinges on the specific trade-offs between computational efficiency, model accuracy, and the practicality of incorporating complex uncertainty quantification within GP-based predictive models. 


\subsection{Mean and Uncertainty Approximation with Linear Nominal Model} 
This section details uncertainty approximation for systems with a linear nominal model in \eqref{eqn:process_model_general}. When the nominal model is linear, it is defined as ${f}\left(x_{k}, {u}_{k}\right) = Ax_{k}+B{u}_{k}$, with $A$ and $B$ representing the state transition and control input matrices, respectively. Leveraging equations \eqref{eqn:normal_dis_all} and \eqref{eqn:var_prop_final}, we derive the uncertainty propagation as follows:
%
\begin{ceqn}
    \begin{align}
        \Sigma_{k+1}^{x} &=\begin{bmatrix} A & B & B^{d} \end{bmatrix} \Sigma_{k}\begin{bmatrix} A & B & B^{d} \end{bmatrix}^\top \, , \tag{26a} \label{eqn:var_prop_linear_nominal_a}  \\
        &= \begin{bmatrix} A & B & B^{d} \end{bmatrix} \begin{bmatrix}
        \Sigma_{k}^{x} & \Sigma_{k}^{x u} & \Sigma_{k}^{x d} \\
        {\Sigma_{k}^{x u}}^\top & \Sigma_{k}^{u} & \Sigma_{k}^{u d} \\
        {\Sigma_{k}^{x d}}^\top & {\Sigma_{k}^{u d}}^\top & \Sigma_{k}^{d}+\Sigma^{w}
       \end{bmatrix} 
       \begin{bmatrix} A & B & B^{d} \end{bmatrix}^\top \, . \tag{26b} \label{eqn:var_prop_linear_nominal_b}  
    \end{align}
\end{ceqn}
%
When employing the mean equivalent approximation method, the variance calculation results as:
%
\begin{ceqn}
    \begin{align} 
        \Sigma_{k+1}^{x}
        &= \begin{bmatrix} A & B & B^{d} \end{bmatrix} \begin{bmatrix}
        \Sigma_{k}^{x} & \Sigma_{k}^{x u} & 0 \\
        {\Sigma_{k}^{x u}}^\top & \Sigma_{k}^{u} & 0 \\
        0 & 0 & \Sigma^{d}\left(\mu_{k}^{z}\right)+\Sigma^{w}
       \end{bmatrix}  
       \begin{bmatrix} A & B & B^{d} \end{bmatrix}^\top \, , \tag{27} \label{eqn:var_prop_linear_nominal_mean}   
    \end{align}
\end{ceqn}
%
Alternatively, using the Taylor approximation method, the variance is elaborated in \eqref{eqn:var_prop_linear_nominal_taylor} as: 
%
\begin{ceqn}
    \begin{align} 
        \Sigma_{k+1}^{x}
        = & \begin{bmatrix} A & B & B^{d} \end{bmatrix}  
        \begin{bmatrix}
        \Sigma_{k}^{x} & \Sigma_{k}^{x u} & \Sigma_{k}^{x}\left(\nabla \mu^{d}\left(\mu_{k}^{x}\right)\right)^{\top} \\
        {\Sigma_{k}^{x u}}^\top & \Sigma_{k}^{u} & \Sigma_{k}^{u}\left(\nabla \mu^{d}\left(\mu_{k}^{u}\right)\right)^{\top} \\
        \left(\nabla \mu^{d}(\mu_{k}^{x})\right) \Sigma_{k}^{x} & \left(\nabla \mu^{d}(\mu_{k}^{u})\right) \Sigma_{k}^{u} & \Sigma^{d}\left(\mu_{k}^{z}\right)+\nabla \mu^{d}\left(\mu_{k}^{z}\right) \Sigma_{k}^{z}\left(\nabla \mu^{d}\left(\mu_{k}^{z}\right)\right)^{\top}+\Sigma^{w}
        \end{bmatrix} \nonumber \\
        & \qquad \qquad \quad \, \: \begin{bmatrix} A & B & B^{d} \end{bmatrix}^\top \, . \tag{28} \label{eqn:var_prop_linear_nominal_taylor}   
    \end{align}
\end{ceqn}
%


\section{Combining Gaussian Processes with Model Predictive Control}
\label{sec:gp_mpc}
% We demonstrated techniques to efficiently approximate propagation of the system mean and uncertainty in Sec. \ref{sec:mean_var_approx}, and would present methods to either simplify the stochastic MPC as a deterministic optimal control problem in this section by ignoring the uncertainty propagation of the GP model or reformulate chance constraints deterministically in Sec. \ref{} to enable the use of standard optimization solvers to solve the GP-MPC problem. To illustrate the most simple yet essential implementation of combining GP and MPC, we focus on deriving equations to merely combine the GP mean (without uncertainty propagation) in the MPC prediction model, and MPC in the simplest optimization form without considering any explicit constraints. In this setting, the \eqref{eqn:mpc_general_a} becomes a deterministic optimization problem, and we employ the most commonly used cost function with quadratic form as

In Sec. \ref{sec:mean_var_approx}, we demonstrated techniques for the efficient approximation of the system's mean and uncertainty propagation. Building on this, this section introduces a straightforward yet fundamental application of GP within MPC, focusing on incorporating the GP means into the MPC prediction model and omitting uncertainty propagation. Through this focused simplification, we aim to underscore the GP model's capability to enhance MPC's predictive accuracy and overall control strategy effectiveness. 

Integrating a GP component into the MPC framework transforms the MPC into a stochastic MPC (SMPC) problem \cite{hewing2020learning}. This adaptation necessitates a structured approach to managing chance constraints, which involves setting maximum allowable probabilities for constraint violations. The formulation of this generalized stochastic optimal control problem is as follows:
%
\begin{ceqn}
    \begin{align}
        \min \limits_{U} \ & \mathbb{E} \left( \sum_{k=0}^{N-1} J(x_k, u_k) \right) \, , \tag{29a} \label{eqn:mpc_general_a} \\
        \text { s.t. } & x_{k+1}=f\left(x_k, u_k\right)+B_d\left(g\left(x_k, u_k\right)+w_k\right) , \tag{29b} \label{eqn:mpc_general_b} \\
        & \operatorname{Pr}\left(x_{k+1} \in \mathcal{X}_{k+1}\right) \geq p_x \, , \tag{29c} \label{eqn:mpc_general_c} \\
        & \operatorname{Pr}\left(u_k \in \mathcal{U}_k\right) \geq p_u \, , \tag{29d} \label{eqn:mpc_general_d} \\
        & x_0=x(k) \, . \tag{29e} \label{eqn:mpc_general_e} 
    \end{align}
\end{ceqn}
%
Here, $U = [u_0(\cdot), \ldots, u_{N-1}(\cdot)]$ denotes the control inputs across time intervals $i= [0, \ldots, N-1]$. The optimization aims to minimize the expected sum of the cost function $J(x_k, u_k)$ over the horizon $N$, subject to the system dynamics as the equality constraint \eqref{eqn:mpc_general_b}. The chance constraints \eqref{eqn:mpc_general_c} and \eqref{eqn:mpc_general_d} introduce inequality constraints, ensuring that system states and control inputs remain within predefined bounds $\mathcal{X}_{k+1}$ and $\mathcal{U}_k$ with associated satisfaction probabilities $p_x$ and $p_u$, respectively, alongside the initial state condition \eqref{eqn:mpc_general_e}.

Given the stochastic nature of the prediction model, this optimization problem is computationally intractable \cite{hewing2019}. To address this, approximation techniques for mean and uncertainty, as detailed in Sec. \ref{sec:mean_var_approx}, are employed alongside strategic handling of chance constraints. These methodologies collectively enable the formulation of a more tractable, deterministic approximation of the original stochastic optimization challenge, which will be further elaborated in Section \ref{sec:gp_mixed_platoon}.

Focusing on showing the GP model's predictive capabilities within an MPC framework, we demonstrate a foundational GP-MPC model that only integrates the GP mean into the prediction model and excludes the uncertainty propagation \cite{ostafew2016,wang2023learning}. Such a simplification redefines \eqref{eqn:mpc_general_a} as a deterministic optimization problem. We further focus on the optimization core by temporarily disregarding constraints \eqref{eqn:mpc_general_e}, and utilize a quadratic cost function commonly adopted in MPC formulations \cite{ostafew2016,sadeghzadeh2014payload}:
%
\begin{equation}
    \mathbf{J} (\mathbf{x}_k,\mathbf{u}_k) = (\mathbf{x}_{d, k+1} - \mathbf{x}_{k+1})^\top \mathbf{Q} (\mathbf{x}_{d, k+1} - \mathbf{x}_{k+1}) + \mathbf{u}_k^\top \mathbf{R} \mathbf{u}_k  \, ,  \tag{30} \label{eqn:mpc_quad_cost}
\end{equation}
%
where $\mathbf{u}_k$ represents a sequence of control inputs $\mathbf{u}_k = \left({u}_{k}, \cdots, {u}_{k+N-1}\right)$ and $N$ represents the MPC prediction horizon, $\mathbf{x}_{d, k+1}$ denotes the desired state trajectory $\mathbf{x}_{d, k+1} = \left({x}_{d, k+1}, \cdots, {x}_{d, k+N}\right)$, and $\mathbf{x}_{k+1}$ is the predicted state trajectory $\mathbf{x}_{k+1} = \left({x}_{k+1}, \cdots, {x}_{k+N}\right)$, derived from the GP mean approximation \eqref{eqn:mean_prop_final_again} by applying $\mathbf{u}_k$. The observable system state ${x}_{k} \in \mathbb{R}^{n}$ and control input ${u}_{k} \in \mathbb{R}^{m}$ at time $k$, with $\mathbf{Q} \in \mathbb{R}^{Pn \times Pn}$ and $\mathbf{R} \in \mathbb{R}^{Pm \times Pm}$ being positive semidefinite matrices, ensure the cost function's efficacy in guiding the system towards desired behaviors.

Adapting the prediction model within MPC to incorporate solely the GP mean, and excluding $B_d$ for simplicity without loss of generality, the prediction model can be formulated as:
%
\begin{equation}
    {x}_{k+1} \approx {f}\left({x}_{k}, {u}_{k}\right) + \mu^d \left({x}_{k}, {u}_{k}\right) \, . \tag{31} \label{eqn:nominal_gp_general_eqn}
\end{equation}
%

In general with a nonlinear nominal model $f(\cdot)$, we can linearize \eqref{eqn:nominal_gp_general_eqn} around a point $\left(\bar x_k, \bar u_k \right)$ as:
%
\begin{ceqn}
    \begin{align}
        {x}_{k+1} & \approx {f}\left(\bar x_k, \bar u_k\right) + \frac{\partial {f}(x, u)}{\partial x} \bigg|_{\bar x_k, \bar u_k} \left(x_k - \bar x_k \right) + \frac{\partial {f}(x, u)}{\partial u} \bigg|_{\bar x_k, \bar u_k} \left(u_k - \bar u_k \right) \nonumber \\
          & \qquad \qquad \quad + \mu^d \left(\bar x_k, \bar u_k\right) + \frac{\partial \mu^d(x, u)}{\partial x} \bigg|_{\bar x_k, \bar u_k} \left(x_k - \bar x_k \right)  + \frac{\partial \mu^d(x, u)}{\partial u} \bigg|_{\bar x_k, \bar u_k} \left(u_k - \bar u_k \right) \, .  \tag{32} \label{eqn:nominal_gp_general_eqn_lin}
    \end{align}
\end{ceqn}
%
By defining $\delta x_k = x_k - \bar x_k$ and $\delta u_k = u_k - \bar u_k$, we obtain:
%
\begin{ceqn}
    \begin{align}
        \delta x_{k+1} + \bar x_{k+1} & \approx {f}\left(\bar x_k, \bar u_k\right) + \frac{\partial {f}(x, u)}{\partial x} \bigg|_{\bar x_k, \bar u_k} \delta x_k + \frac{\partial {f}(x, u)}{\partial u} \bigg|_{\bar x_k, \bar u_k} \delta u_k \nonumber \\
          & \qquad \qquad \quad + \mu^d \left(\bar x_k, \bar u_k\right) + \frac{\partial \mu^d(x, u)}{\partial x} \bigg|_{\bar x_k, \bar u_k} \delta x_k + \frac{\partial \mu^d(x, u)}{\partial u} \bigg|_{\bar x_k, \bar u_k} \delta u_k \, .  \tag{33} \label{eqn:nominal_gp_general_eqn_lin_b}
    \end{align}
\end{ceqn}
%
If the linearization is conducted at the mean points for each time step, i.e. $\bar x_{k+1} = \mu_{k+1}^x$, $\bar x_{k} = \mu_{k}^x$ and $\bar u_{k} = \mu_{k}^u$, and according to \eqref{eqn:mean_prop_final_again}, we have $ \bar x_{k+1} \approx {f}\left(\bar x_k, \bar u_k\right) + \mu^d \left(\bar x_k, \bar u_k\right)$. The linearized prediction model \eqref{eqn:nominal_gp_general_eqn_lin} becomes:
%
\begin{ceqn}
    \begin{align}
        \delta x_{k+1} & \approx \frac{\partial {f}(x, u)}{\partial x} \bigg|_{\bar x_k, \bar u_k} \delta x_k + \frac{\partial {f}(x, u)}{\partial u} \bigg|_{\bar x_k, \bar u_k} \delta u_k  + \frac{\partial \mu^d(x, u)}{\partial x} \bigg|_{\bar x_k, \bar u_k} \delta x_k + \frac{\partial \mu^d(x, u)}{\partial u} \bigg|_{\bar x_k, \bar u_k} \delta u_k \, .  \tag{34} \label{eqn:nominal_gp_general_eqn_lin_final}
    \end{align}
\end{ceqn}
%
For time index $b \in \{ 0, \cdots, N-1\}$, the \eqref{eqn:nominal_gp_general_eqn_lin_final} over the next $N$ time steps yields a compact matrix form for delta changes:
%
\begin{equation}
    \delta x_{k+b+1} \approx H_{x, k+b}\delta x_{k+b} + H_{u, k+b}\delta u_{k+b} \, ,  \tag{35} \label{eqn:nominal_gp_general_eqn_lin_compact}
\end{equation}
%
where $H_{x, k+b}$ and $H_{u, k+b}$ are matrices capturing the combined effects of the linearized nominal model and the GP mean derivative as:
%
\begin{ceqn}
    \begin{align}
        H_{x, k+b} &=  \frac{\partial {f}(x, u)}{\partial x} \bigg|_{\bar x_{k+b}, \bar u_{k+b}} + \frac{\partial \mu^d(x, u)}{\partial x} \bigg|_{\bar x_{k+b}, \bar u_{k+b}} \, , \tag{36a} \label{eqn:nominal_gp_general_eqn_lin_compact_a} \\
        H_{x, k+b} &= \frac{\partial {f}(x, u)}{\partial u} \bigg|_{\bar x_{k+b}, \bar u_{k+b}} + \frac{\partial \mu^d(x, u)}{\partial u} \bigg|_{\bar x_{k+b}, \bar u_{k+b}} \, . \tag{36b} \label{eqn:nominal_gp_general_eqn_lin_compact_b}
    \end{align}
\end{ceqn}
%
Defining the deviations in state and control input vectors as $\delta \mathbf{x}_{k+1} = \left(\delta {x}_{k+1}, \cdots, \delta {x}_{k+N}\right)$, $\delta \mathbf{x}_{k} = \left(\delta {x}_{k}, \cdots, \delta {x}_{k+N-1}\right)$ and $\delta \mathbf{u}_k = \left(\delta {u}_{k}, \cdots, \delta {u}_{k+N-1}\right)$ yields a compact matrix formulation for the system dynamics as follows:
%
\begin{ceqn}
    \begin{align}
       \delta \mathbf{x}_{k+1} &= \mathbf{H}_{\mathbf{x}} \delta \mathbf{x}_k + \mathbf{H}_{\mathbf{u}} \delta \mathbf{u}_k  \, , \nonumber \\
        &= \left( \mathbf{I} - \mathbf{H}_{\mathbf{x}} \right)^{-1} \mathbf{H}_{\mathbf{u}} \delta \mathbf{u}_k \, , \nonumber \\
        &= \mathbf{H}^\prime \delta \mathbf{u}_k \, , \tag{37} \label{eqn:nominal_gp_general_eqn_lin_compact_final}
    \end{align}
\end{ceqn}
%
where $\mathbf{I}$ denotes the identity matrix, and $\mathbf{H}_{\mathbf{u}} = \operatorname{diag}(H_{u,k}, \cdots, H_{u,k+N-1})$ encapsulates the control dynamics across the prediction horizon. The matrices $\mathbf{H}_{\mathbf{x}}$ and $\mathbf{H}_{\mathbf{u}}$ reflect the response to state and control perturbations of the system and GP model, respectively with 
%
\begin{ceqn}
   \begin{align}
    {\Lambda}_{x, k+1} = \begin{bmatrix} {0} & {0} \\ {H}_{x, k+1} & {0} \end{bmatrix}\, , \quad
    \mathbf{H}_{\mathbf{x}} =\operatorname{diag}\left({\Lambda}_{x, k+1}, \cdots, {\Lambda}_{x, k+N-1}\right) \, . \tag{38} \label{eqn:nominal_gp_general_eqn_lin_compact_final_var}
    \end{align}
\end{ceqn}
%
Substituting $\delta \mathbf{x}_{k+1} = \mathbf{x}_{k+1}-\mathbf{\bar x}_{k+1}$, $\delta \mathbf{u}_{k} = \mathbf{u}_{k}-\mathbf{\bar u}_{k}$ and \eqref{eqn:nominal_gp_general_eqn_lin_compact_final} to \eqref{eqn:mpc_quad_cost}, results in an approximated cost function:
%
\begin{ceqn}
    \begin{align}
    \mathbf{J}(\mathbf{x}_k,\mathbf{u}_k,\delta\mathbf{u}_k) &\approx (\mathbf{x}_{d, k+1} - \mathbf{\bar{x}}_{k+1} - \mathbf{H}'\delta\mathbf{u}_k)^\top\mathbf{Q} (\mathbf{x}_{d, k+1} - \mathbf{\bar{x}}_{k+1} - \mathbf{H}'\delta\mathbf{u}_k) + (\mathbf{\bar{u}}_k + \delta\mathbf{u}_k)^\top\mathbf{R}(\mathbf{\bar{u}}_k + \delta\mathbf{u}_k) \, . \tag{39} \label{eqn:cost_function_solve}
    \end{align}
\end{ceqn}
%
To find the optimal $\delta\mathbf{u}_k$ that minimizes the cost function, we set its derivative with respect to $\delta\mathbf{u}_k$ to zero. The solution, detailed in the Appendix \ref{sec:appendix_cost_function_solve}, is given by:
%
\begin{equation}
    \delta\mathbf{u}_k =
    \left(\mathbf{H}^\mathsf{'T}\mathbf{Q}\mathbf{H}^{'} + \mathbf{R} \right)^{-1} \left(\mathbf{H}^\mathsf{'T} \mathbf{Q} \mathbf{\tilde x}_{k+1} - \mathbf{R}\mathbf{\bar{u}}_k \right) \, . \tag{40} \label{eqn:cost_function_solve_deltaU}
\end{equation}
%
where $\mathbf{\tilde x}_{k+1}$ represents the desired state trajectory deviation from the predicted mean as $\mathbf{\tilde x}_{k+1} \coloneqq \mathbf{x}_{d, k+1} - \mathbf{\bar{x}}_{k+1}$. This iterative update process for $\delta\mathbf{u}_k$, with $\mathbf{\bar u}_k \leftarrow \mathbf{\bar u}_k + \delta\mathbf{u}_k$ until it converges, ensures dynamic optimization of control actions, with only the first control input implemented at each step. This cycle repeats, recalculating optimal controls at each new timestep, thereby adapting to evolving system dynamics and optimizing control strategies over time.

\section{Application I: Improved Path Following For Mobile Robots}
\label{sec:path_following}
This section, alongside the next, investigates the application of GP-MPC strategies in the realm of mobile robotics, focusing on path-following controls for wheeled robots. It introduces two innovative approaches: GP-based nonlinear MPC (GP-NMPC) \cite{ostafew2016} and GP-based feedback linearization MPC (GP-FBLMPC) \cite{wang2023learning}. Building on the integration of GP means into MPC predictions discussed in Sec. \ref{sec:gp_mpc}, we illustrate the practical application of GP-MPC in elevating system performance in real-world scenarios.

\subsection{GP-based Nonlinear MPC}
\label{sec:gp-nmpc}
The most direct utilization of GP models is identifying and learning the discrepancies between theoretical nominal models and actual observed behavior in robotic systems. By precisely modeling these discrepancies, GP models significantly enhance the prediction accuracy of the system's dynamics. This improvement in predictive accuracy directly contributes to superior control performance, enabling the system to adjust its actions based on a more accurate representation of its interactions with the environment.

In mobile robotics, especially for path-following tasks, employing GP models has proven to be highly effective. Path following, a fundamental functionality for autonomous vehicles and robots, requires the robot to precisely adhere to a predetermined path without temporal constraints. This challenge is particularly challenging for wheeled robots navigating complex off-road terrains, where accurately modeling the dynamics of robot-terrain interaction becomes problematic. The work presented in \cite{ostafew2016} is a pioneering application of GP-based MPC to this challenge, demonstrating a significant improvement in path-following accuracy by adapting the MPC model to reflect actual field observations through GP learning, thereby underscoring the efficacy of GP models in complex environmental interactions.

A general robotic system model incorporating dynamic elements into kinematic equations can be expressed as:
%
\begin{equation} 
    \mathbf{x}_{k+1}=\overbrace{\mathbf{f}\left(\mathbf{x}_{k}, \mathbf{u}_{k}\right)}^{\text {nominal model }}+\overbrace{\mathbf{g}(\underbrace{\mathbf{x}_{k}, \mathbf{v}_{k-1}, \mathbf{u}_{k}, \mathbf{u}_{k-1}}_{{a}_{k}})}^{\text {GP learning model}} \, . \tag{41} \label{eqn:system_model_gp_nmpc}
\end{equation}
%
In this model, $\mathbf{x}_{k} = (x_k, y_k, \theta_k)$ denotes the robot's pose, $\mathbf{v}_{k} = (v_{k}^\text{act},\omega_{k}^\text{act})$ the actual velocity, and $\mathbf{u}_{k} = (v_{k}^\text{cmd},\omega_{k}^\text{cmd})$ the control inputs (linear and angular velocity) at time $k$. The disturbance query state is defined as:
%
\begin{equation}
    {a}_{k}=\left(\mathbf{x}_{k}, \mathbf{v}_{k-1}, \mathbf{u}_{k}, \mathbf{u}_{k-1}\right) \, . \tag{42} \label{eqn:gp_disturbance_state}
\end{equation}
%
Utilizing this model, at time $k-1$, discrepancies between the nominal model and actual system behavior are estimated by a GP disturbance model as:
%
\begin{ceqn}
    \begin{equation}
        \hat{\mathbf{g}}({a}_{k-1}) = \hat{\mathbf{x}}_{k}-\mathbf{f}\left(\hat{\mathbf{x}}_{k-1}, \mathbf{u}_{k-1}\right) \, . \tag{43} \label{eqn:gp_model_est}
    \end{equation}
\end{ceqn}
%
Here, $\hat{\mathbf{x}}_{k}$ and $\hat{\mathbf{x}}_{k-1}$ represent the robot poses from the on-board navigation system at time $k$ and $k-1$ respectively, $\mathbf{u}_{k-1}$ is the control input at time $k-1$. In the disturbance query state ${a}_{k-1}=\left(\hat{\mathbf{x}}_{k-1}, \hat{\mathbf{v}}_{k-2}, \mathbf{u}_{k-1}, \mathbf{u}_{k-2}\right)$, the $\hat{\mathbf{v}}_{k-2}$ is calculated by the estimated robot poses $\hat{\mathbf{x}}_{k-1}$ and $\hat{\mathbf{x}}_{k-2}$, which indicates the disturbance query state ${a}_{k}$ requires historic states data. In one experiment for data collection, the observed disturbance datasets are collected and prepared by following \eqref{eqn:gp_model_est} as:
%
\begin{ceqn}
    \begin{align}
       \mathcal{D}_m^x &= \{\mathbf{a} = [{a}_1, \cdots, {a}_{k-1}, \cdots, {a}_m]^\top, \mathbf{g}^{x}(\mathbf{a}) = [{g}^{x}({a_1}), \cdots, {g}^{x}({a_k}), \cdots, {g}^{x}({a_m})]^\top \} , \nonumber \\
       \mathcal{D}_m^y &= \{\mathbf{a} = [{a}_1, \cdots, {a}_{k-1}, \cdots, {a}_m]^\top, \mathbf{g}^{y}(\mathbf{a}) = [{g}^{y}({a_1}), \cdots, {g}^{y}({a_k}), \cdots, {g}^{y}({a_m})]^\top \} , \nonumber \\
       \mathcal{D}_m^{\theta} &= \{\mathbf{a} = [{a}_1, \cdots, {a}_{k-1}, \cdots, {a}_m]^\top, \mathbf{g}^{\theta}(\mathbf{a}) = [{g}^{\theta}({a_1}), \cdots, {g}^{\theta}({a_k}), \cdots, {g}^{\theta}({a_m})]^\top \} \, , \tag{44} \label{eqn:gp_dataset}
    \end{align}
\end{ceqn}
%
Using these datasets and \eqref{eqn:gp_Bd}, three separate GP models, ${d}^{x}(\mathbf{a})$, ${d}^{y}(\mathbf{a})$, and ${d}^{\theta}(\mathbf{a})$, are trained for each variable of the robot pose, $x$, $y$, and $\theta$ respectively, by assuming the disturbances are uncorrelated. The trained GP models with 60\,m field experiment data are shown in Fig. \ref{figure:GP-NMPC_gp_modeling} \cite{ostafew2016}. 
%
\begin{figure}
    \centering
    \includegraphics[width=0.90\columnwidth]{figures/GP-NMPC_gp_modeling.png}
    \caption{Illustration of the trained GP models for the robot pose variables $x$, $y$, and $\theta$ (${d}^{x}(\mathbf{a})$, ${d}^{y}(\mathbf{a})$, and ${d}^{\theta}(\mathbf{a})$ respectively), based on a 60\,m field experiment dataset \eqref{eqn:gp_dataset}. These models, developed under the assumption of uncorrelated disturbances, demonstrate the application of \eqref{eqn:gp_Bd} in creating separate GP models for each pose variable \cite{ostafew2016}.}
    \label{figure:GP-NMPC_gp_modeling}
\end{figure}
%

Utilizing the GP-enhanced prediction model \eqref{eqn:system_model_gp_nmpc}, a GP-NMPC algorithm \cite{ostafew2016} was developed following the methodology explained in Sec. \ref{sec:gp_mpc}. Through 3\,km field tests on three different robots, the GP-NMPC demonstrated its superior path-following capabilities in challenging off-road environments. These tests highlighted its ability to learn and reduce path-following errors by effectively combining GP with MPC. However, it encounters computational efficiency challenges due to the iterative optimization inherent in NMPC, and it cannot generalize to new, untrained paths. Addressing these limitations, a novel GP-FBLMPC strategy that combines feedback linearization (FBL) with GP and MPC was proposed to improve both computational efficiency and the system's adaptability to diverse untrained new paths, thereby providing a more robust and adaptable solution for mobile robot path-following in challenging terrains. 

\subsection{GP-based Feedback Linearization MPC}
\label{sec:gp-fblmpc}
This section introduces the innovative GP-FBLMPC methodology \cite{wang2023learning}, an advancement over the traditional GP-based nonlinear MPC (GP-NMPC). GP-FBLMPC ingeniously combines GP, MPC, and FBL techniques. This approach effectively addresses the computational efficiency and model generalization challenges encountered in GP-NMPC, positioning GP-FBLMPC as a superior strategy for path-following in mobile robotics across diverse and challenging terrains.

The essence of GP-FBLMPC lies in its integration of GP predictions within a feedback-linearized MPC strategy, offering an efficient and adaptable solution for navigating complex environments. The schematic representation provided in Fig.~\ref{fig:gpfblmpc} outlines the operational framework of GP-FBLMPC, illustrating how GP models incorporate learned dynamics from past experiences into the MPC's prediction loop for enhanced path-following control.
%
\begin{figure}
    \begin{center}
    \vspace{0.15cm}
        \includegraphics[trim=0cm 0cm 1.1cm 0cm, width=0.8\columnwidth]{figures/gpfblmpc_diagram.pdf}
        \caption{Block diagram of path-following control using the GP-FBLMPC algorithm. GP models capture unmodeled system dynamics from previous experiences. Estimated GP model means  ($\boldsymbol {\mu}^{\mathbf{d}}$) are integrated into the system model within the MPC prediction horizon loop \cite{wang2023learning}.}
        \label{fig:gpfblmpc}
    \end{center}
\end{figure}
%

\subsubsection{Feedback Linearization in MPC}
Before delving into the integration of GP with FBLMPC, it is helpful to understand the basics of feedback linearization as a standalone control strategy. Unlike traditional linearization techniques such as Taylor expansion shown in \eqref{eqn:nominal_gp_general_eqn_lin}, which approximate nonlinear systems around a specific operating point, feedback linearization transforms the entire nonlinear system dynamics into a globally linear form \cite{slotine1991}. This transformation is achieved through a change of variables and the application of a control input that exactly cancels the nonlinear characteristics of the system over its entire operating range, thereby yielding a linear system representation without local approximation errors.

For wheeled robots with a differential drive mechanism, the discretized kinematic model is:
%
\begin{equation}
    \begin{bmatrix} 
            x_{k+1} \\ y_{k+1} \\ \theta_{k+1}
            \end{bmatrix} =
        \begin{bmatrix}
            {x}_{k} \\ {y}_{k} \\ {\theta}_{k}
            \end{bmatrix}
            + T
        \begin{bmatrix}
            \cos\theta_{k} & 0 \\ 
            \sin\theta_{k} & 0 \\ 
            0 & 1
        \end{bmatrix}
        \begin{bmatrix}
            v_{k} \\ 
            \omega_{k} \\ 
        \end{bmatrix} \, . \tag{45} \label{eqn:robot_kinematics_discret}
\end{equation} 
%
where $x$, $y$, and $\theta$ represent the robot's pose states, and the control inputs are the commanded forward velocity $v$ and yaw rate $\omega$. Defining the path-following errors as lateral $\varepsilon_{L} \coloneqq y$ and heading $\varepsilon_{H} \coloneqq \theta$, the instantaneous rate of change of the path-following errors are: 
%
\begin{ceqn}
    \begin{align} 
        \dot \varepsilon_{L} &= \dot y = v\sin\varepsilon_{H}  \, , \tag{46a} \label{eqn:lateral_error} \\
        \dot \varepsilon_{H} &= \dot \theta = \omega \, .  \tag{46b} \label{eqn:heading_error}
    \end{align}
\end{ceqn}
%

The feedback linearization process begins with the introduction of new coordinates $z_{1} \equiv \varepsilon_{L} = y$ and $z_{2} \equiv \dot{\varepsilon}_{L} = \dot{y}$, designated as feedback linearization (FBL) states. This leads to a transformed system dynamics represented as:
%
\begin{ceqn}
    \begin{equation}
        \dot{\mathbf{z}} = 
        \begin{bmatrix}
        \dot z_{1} \\
        \dot z_{2}
        \end{bmatrix}
        =\begin{bmatrix}
        0 & 1\\
        0 & 0
        \end{bmatrix}
        \begin{bmatrix}
        z_{1} \\
        z_{2}
        \end{bmatrix}
        +
        \begin{bmatrix}
        0\\
        1
        \end{bmatrix}
        u
        = \mathbf{A}\mathbf{z} + \mathbf{B}u \, , \tag{47} \label{eqn:FLlinear_system}
    \end{equation}
\end{ceqn}
%
where $u$ symbolizes the new control input. In the context of constant linear velocity, $u = \dot z_{2} = v\:\omega \cos\varepsilon_{H}$, revealing a nonlinear relationship between $u$ and the robot's steering rate $\omega = {u}/(v \cos\varepsilon_{H})$. This relationship holds true under the condition that $v \neq 0$ and $\varepsilon_H \in (-{\pi}/{2}, {\pi}/{2})$. 

The FBLMPC strategy computes a sequence of control inputs $\mathbf{u}_k$ across a finite horizon $N$ to minimize the predicted path-following errors. The control sequence and the incremental control updates are represented by $\mathbf{u}_{k} \coloneqq \Delta\mathbf{u}_{k} + \mathbf{u}_{k-1}= (u_{k}, u_{k+1},..., u_{k+N-1})$ and $\Delta \mathbf{u}_{k} = (\Delta u_{k}, \Delta u_{k+1},..., \Delta u_{k+N-1})$, respectively. By discretizing the linearized system equation \eqref{eqn:FLlinear_system}, we get:
%
\begin{ceqn}
    \begin{equation}
        {\mathbf{z}}_{k+1} = \mathbf{F}\mathbf{z}_k + \mathbf{G}u_k = 
            \begin{bmatrix}
                1 & T\\
                0 & 1 
            \end{bmatrix}
            \begin{bmatrix}
                z_{1,k}\\
                z_{2,k}
            \end{bmatrix}
        +   \begin{bmatrix}
                \frac{T^2}{2}\\
                T   
            \end{bmatrix} u_k \, ,  \tag{48}  \label{eqn:discrete_lineareqn}
    \end{equation} 
\end{ceqn}
%
where $T>0$ is a small update interval, and $\mathbf{z}_k=\mathbf{z}(kT)$, $k=0,1,2,\ldots$. The FBL states over the prediction horizon are described by:
%
\begin{ceqn}
    \begin{equation} 
        \mathbf{y}_{k+1} \coloneqq \Delta \mathbf{y}_{k+1} + \mathbf{y}_{k} = (\mathbf{z}_{k+1}, \mathbf{z}_{k+2},..., \mathbf{z}_{k+N}) \, ,  \tag{49} 
        \label{eqn:y_k+1}
    \end{equation}
\end{ceqn}
%
where $\Delta \mathbf{y}_{k} = (\Delta \mathbf{z}_{k+1}, \Delta \mathbf{z}_{k+2},..., \Delta \mathbf{z}_{k+N})$ represents the updates of FBL states over the prediction horizon. The discrete updates in control input and FBL states are defined as $\Delta u_k \coloneqq u_{k} - u_{k-1}$ and  $\Delta \mathbf{z}_{k} \coloneqq \mathbf{z}_{k} - \mathbf{z}_{k-1}$, respectively. Utilizing \eqref{eqn:discrete_lineareqn}, the dynamics of FBL states across the prediction horizon can be expressed as:
%
\begin{ceqn}
    \begin{align}
        \mathbf{z}_{k+1} &= \mathbf{Fz}_k + \mathbf{G}u_{k} \, , \tag{50a} \label{eqn:z_k+1_a} \\
        \Delta \mathbf{z}_{k+1} + \mathbf{z}_{k} &= \mathbf{F}(\Delta \mathbf{z}_{k} + \mathbf{z}_{k-1}) + \mathbf{G}(\Delta u_{k} + u_{k-1})  \, , \tag{50b} \label{eqn:z_k+1_b} \\
        \Delta \mathbf{z}_{k+1} &= \mathbf{F}\Delta \mathbf{z}_{k} + \mathbf{G}\Delta u_{k} \, , \tag{50c} \label{eqn:z_k+1_c} \\
        \Delta \mathbf{z}_{k+2} &= \mathbf{F}\Delta \mathbf{z}_{k+1} + \mathbf{G}\Delta u_{k+1} \, , \tag{50d} \label{eqn:z_k+1_d} \\
        & \ \, \, \vdots \nonumber\\
        \Delta \mathbf{z}_{k+N}&= \mathbf{F}^{N}\Delta \mathbf{z}_{k} + \mathbf{F}^{N-1}\mathbf{G}\Delta u_{k} + \dots + \mathbf{G}\Delta u_{k+N-1} \, , \tag{50e} \label{eqn:z_k+1_e}
    \end{align}
\end{ceqn}
%
which are rewritten in matrix form as:
%
\begin{ceqn}
    \begin{align}
        \underbrace{
            \begin{bmatrix}
                \Delta \mathbf{z}_{k+1}  \\
                \Delta \mathbf{z}_{k+2} \\
                % \Delta \mathbf{z}_{k+3} \\
                \vdots\\
                \Delta \mathbf{z}_{k+N} 
            \end{bmatrix}
        }_{\Delta \mathbf{y}_{k+1}}
        = 
        \underbrace{
            \begin{bmatrix}
                \mathbf{F} \\
                \mathbf{F}^{2}\\
                % \mathbf{F}^{3}\\
                \vdots\\
                \mathbf{F}^{N}
                \end{bmatrix}
        }_{\mathbf{L}}
        \Delta \mathbf{z}_{k}  + 
        \underbrace{
            \begin{bmatrix}
            \mathbf{G} & 0 & \cdots & 0 & 0\\
            \mathbf{FG} & \mathbf{G} & \cdots & 0 & 0\\
            % \mathbf{F^2G} & \mathbf{FG} & \cdots & 0 & 0\\
            \vdots & \vdots & \ddots & \vdots & \vdots\\
            \mathbf{F}^{N-1}\mathbf{G} & \mathbf{F}^{N-2}\mathbf{G} & \cdots & \mathbf{FG} & \mathbf{G}\\
            \end{bmatrix}
        }_{\mathbf{M}}
        \underbrace{
        \begin{bmatrix}
        \Delta u_{k}  \\
        \Delta u_{k+1} \\
        \Delta u_{k+2} \\
        \vdots\\
        \Delta u_{k+N-1} 
        \end{bmatrix}
        }_{\Delta \mathbf{u}_k} \, , \tag{51} \label{eqn:ctrlupdatemat}
    \end{align}
\end{ceqn}
%
and more succinctly as:
%
\begin{ceqn}
    \begin{equation}
        \Delta \mathbf{y}_{k+1}
        = \mathbf{L} \Delta \mathbf{z}_{k} 
        + \mathbf{M}\Delta \mathbf{u}_k \, . \tag{52} \label{eqn:ctrlupdate-simp}
    \end{equation}
\end{ceqn}
%

In the GP-FBLMPC approach, the optimization of path-following control is achieved by minimizing the same quadratic cost function used in the GP-NMPC method, allowing for a consistent comparison of path-following performance between the two strategies:
%
\begin{ceqn}
    \begin{equation}
    \mathbf{J}\left(\mathbf{y}_k,\mathbf{u}_{k}\right)=\mathbf{y}_{k+1}^{\top} \mathbf{Q} \mathbf{y}_{k+1}+\mathbf{u}_{k}^{\top} \mathbf{R} \mathbf{u}_{k} \, , \tag{53} \label{eqn:cost-function}
    \end{equation}
\end{ceqn}
%
where $\mathbf{Q} \in \mathbb{R}^{2N \times 2N}$ and $\mathbf{R} \in \mathbb{R}^{N \times N}$ are the weighting matrices for path-following errors and control efforts, respectively. The term $\mathbf{y}_{k+1}$ represents the predicted FBL state $\mathbf{z}$ over the prediction horizon, and $\mathbf{u}_{k}$ is the control input sequence over the prediction horizon specified ahead of \eqref{eqn:discrete_lineareqn}. 

Integrating the equation of $\mathbf{u}_{k}$, \eqref{eqn:y_k+1}, and \eqref{eqn:ctrlupdate-simp} into the cost function \eqref{eqn:cost-function}, the optimization problem becomes:
%
\begin{ceqn}
    \begin{align} 
        \mathbf{J}(\mathbf{y}_k,\mathbf{u}_k,\Delta \mathbf{z}_{k},\Delta \mathbf{u}_k) =  (\mathbf{L} \Delta \mathbf{z}_{k} + \mathbf{M}\Delta \mathbf{u}_k + \mathbf{y}_{k})^{\top}\mathbf{Q}(\mathbf{L} \Delta \mathbf{z}_{k}
        + \mathbf{M}\Delta \mathbf{u}_k + \mathbf{y}_{k}) + (\Delta\mathbf{u}+\mathbf{u}_{k-1})^{\top}\mathbf{R}(\Delta\mathbf{u}+\mathbf{u}_{k-1}) \, . \tag{54} \label{eqn:costfuncdeltau1}
    \end{align}
\end{ceqn}
%
The optimization process seeks the sequence of control adjustments, $\Delta \mathbf{u}^{*}_k$, that minimizes this cost function. Given the quadratic and convex nature of $\mathbf{J}$, the optimal control sequence is derived by solving the equation ${\partial J(\Delta \mathbf{u}_k)}/{ \partial \Delta \mathbf{u}_k} = 0$ as:
%
\begin{equation}
    \Delta \mathbf{u}^{*}_k = -(\mathbf{M}^{\top}\mathbf{Q}\mathbf{M}+\mathbf{R})^{-1}\left(\mathbf{M}^{\top}\mathbf{Q}(\mathbf{y}_{k} + \mathbf{L}\Delta\mathbf{z}_k) + \mathbf{R}\mathbf{u}_{k-1} \right) \, . \tag{55}  \label{eqn:optimaldeltau}
\end{equation}
%

The final control sequence $\mathbf{u}^{}_k$ is then obtained by adding the optimal control adjustments to the previous control sequence: $\mathbf{u}^*_k = \Delta \mathbf{u}^{*}_k + \mathbf{u}_{k-1}$. The first element of this sequence, $u^*_k$, is applied in real-time to adjust the vehicle's steering rate, calculated as:
%
\begin{equation}
    \omega_k^* = \frac{u_k^*}{v \cos\varepsilon_{H,k}} \, , \tag{56} \label{eqn:discrete_omegacalc}
\end{equation}
%
where $v$ is the vehicle's linear velocity and $\varepsilon_{H,k}$ is the heading error at time $k$. Note that the matrices $\left(\mathbf{M}^{\top} \mathbf{Q} \mathbf{M} + \mathbf{R}\right)^{-1}$ and $\mathbf{M}^{\top} \mathbf{Q}$ are constants at all time steps and thus can be precomputed to significantly reduce real-time computational complexity, which is a key difference between the FBLMPC strategy and traditional nonlinear MPC. 

\subsubsection{GP-FBLMPC}
In GP-FBLMPC, the focus shifts to using feedback linearized (FBL) states $\mathbf{z}_k$ as the system variables, in contrast to the robot pose states $\mathbf{x}_k$ used in GP-NMPC. Utilizing \eqref{eqn:system_model_gp_nmpc}, the relationship between the actual and predicted robot pose state $\mathbf{x}_{k+1}$ is expressed as:
%
\begin{equation}
   \mathbf{x}_{k+1} - \mathbf{f}\left(\mathbf{x}_{k}, \mathbf{u}_{k}\right) = \mathbf{g}\left(\mathbf{x}_{k}, \mathbf{v}_{k-1}, \mathbf{u}_{k}, \mathbf{u}_{k-1} \right) \, . \tag{57} \label{eqn:gp_model_fbl}
\end{equation}
%
where the right side of \eqref{eqn:gp_model_fbl} are the FBL states $\mathbf{z}_{k+1}$. The GP model incorporating these FBL states is formulated as:
%
\begin{ceqn}
    \begin{equation}
        \mathbf{z}_{k+1}=\mathbf{g}({a}_{k}) \, , \tag{58} \label{eqn:gp_model_fbl_z}
    \end{equation}
\end{ceqn}
%
with the disturbance state defined as ${a}_{k}=\left(\mathbf{z}_{k}, \mathbf{v}_{k-1}, \mathbf{u}_{k}, \mathbf{u}_{k-1}\right)$. Like GP-NMPC, assuming uncorrelated disturbance states $z_1$ and $z_2$, two separate GP models ${d}^{z_1}(\mathbf{a})$ and ${d}^{z_2}(\mathbf{a})$, are developed for each FBL state.

The developed GP-FBLMPC algorithm was extensively tested across three different paths in sand and grass off-road terrains. Compared to the GP-NMPC algorithm, GP-FBLMPC performed equally well in reducing the path following errors. However, GP-FBLMPC showcases superior computational efficiency by eliminating the need for iterative optimization and requiring fewer GP models for prediction.

The GP-FBLMPC method's adaptability to different paths is another key advantage, as demonstrated in a field experiment shown in Fig. \ref{figure:infinite_track_path} \cite{wang2023learning}. In this experiment, GP models, initially trained using data from an infinite path (left image in Fig. \ref{figure:infinite_track_path}), were applied to a different, track path (right image in Fig. \ref{figure:infinite_track_path}) for both GP-FBLMPC and GP-NMPC setups. This was done without re-training the GP models with data specific to the track path. The results showed that GP-FBLMPC significantly reduced path errors in comparison to basic FBLMPC and notably outperformed GP-NMPC, which demonstrated worse performance compared to the standard NMPC in this instance.
%
\begin{figure}
    \centering
    \vspace{0.1cm}
    \
    \subfloat{{\includegraphics[width=0.45\columnwidth]{figures/infinite.jpg} }}
    \ 
    \subfloat{{\includegraphics[width=0.45\columnwidth]{figures/track.jpg} }}
    \caption{A Husky A200 robot is driven autonomously to follow the infinite path (left) and the track path (right) in sandy terrain. The desired paths, represented by black dotted lines, were blended into the field test scene image captured by a DJI Mini drone \cite{wang2023learning}.}
    \label{figure:infinite_track_path}
\end{figure}
%

Fig.~\ref{figure:gp_est_track_fbl_el_eh_E4} illustrates the alignment of GP predictions from GP-FBLMPC with actual lateral and heading errors on the track path. Notably, these predictions remain accurate despite the GP models being trained on a different path, underscoring the robust generalization capabilities of the GP-FBLMPC algorithm and its effectiveness in consistently reducing path-following errors across varied paths.
%
\begin{figure}
    \centering
    \vspace{0.15cm}
    \hspace{-0.1cm}\subfloat{\includegraphics[trim=1.2cm 0.4cm 1.6cm 1.1cm, width=0.75\columnwidth]{figures/gp_estimation_track_fbl_el_E4.pdf}}
    \vspace{0.7cm}
    \hspace{0.0cm}\subfloat{\includegraphics[trim=1.2cm 0.4cm 1.6cm 1.1cm, width=0.74\columnwidth]{figures/gp_estimation_track_fbl_eh_E4.pdf}}
    \caption{Graphs depicting the lateral and heading error predictions from the GP models and the actual observed errors over time, for the GP-FBLMPC applied on the track path using GP models trained on the infinite path \cite{wang2023learning}.
    }
    \label{figure:gp_est_track_fbl_el_eh_E4}
\end{figure}
%

\section{Application II: Enhanced Safety for Mixed-Vehicle Platoons}
\label{sec:mixed_platoon}
This section extends the application of GP-MPC to control autonomous vehicles, particularly focusing on enhancing safety in mixed-vehicle platoons. Here, GP-MPC is employed not only to integrate GP means into the MPC prediction model but also to explicitly account for GP uncertainty propagation as a constraint within the MPC optimization framework. This advanced approach significantly enhances safety in mixed-vehicle platoons by effectively modeling the uncertainties associated with human-driven vehicle (HV) behaviors, a critical aspect often overlooked in conventional control strategies.


\subsection{Standard GP-based MPC}
\label{sec:gp_mixed_platoon}
The integration of autonomous vehicles (AVs) into existing traffic systems, especially in the domain of AV platooning, holds transformative potential for public traffic management through synchronized vehicle movements. However, the coexistence of human-driven vehicles (HVs) alongside AVs in these mixed-traffic environments introduces complex challenges. Notably, the interaction between AVs and HVs has led to an increased rate of accidents that are predominantly caused by HVs rear-ending AVs, which underscores the urgent need for innovative control strategies tailored to mixed-traffic scenarios.

Addressing this gap, \cite{wang2024improving} proposed a novel GP learning-based MPC strategy (GP-MPC) specifically designed to enhance longitudinal car-following control within mixed-vehicle platoons, as illustrated in Fig. \ref{figure:mixed_platoon}. This approach is primarily aimed at improving safety in interactions between AVs and HVs. It does so by incorporating uncertainties inherent in HV behavior into the control strategy, thus ensuring safer and more efficient operations within mixed-vehicle platoons. The GP-MPC method distinguishes itself by maintaining increased minimum distances between vehicles and facilitating higher travel speeds, representing a significant advancement over traditional control methods, including standard MPC. This approach is particularly effective in complex traffic scenarios, such as emergency braking situations, where it adeptly handles the unpredictable nature of HVs by integrating quantified uncertainty estimated through GP models into the MPC framework.
%
\begin{figure}
    \centerline{\includegraphics[width=0.65\columnwidth]{figures/AVs_HVs_platoon.png}}
    \caption{A mixed vehicle platoon consists of $N_a$ connected AVs, labeled as ${A^1, A^2, \cdots, A^{N_a}}$, followed by a HV $H$. These AVs use a sequential bidirectional communication topology for data exchange, excluding direct communication with the HV. This configuration is motivated by recent studies highlighting that most accidents in mixed traffic involve HVs rear-ending AVs, leading to the specific platoon arrangement showcased \cite{wang2024improving}.
    }
    \label{figure:mixed_platoon}
\end{figure}
%

\subsubsection{HV Modeling}
In longitudinal car-following scenarios, HVs are traditionally modeled using a nominal function with a fixed human reaction time delay to emulate general human driving behaviors. A common model used for this purpose is an autoregressive with exogenous input (ARX) model, as described in \cite{wang2024improving}. The ARX model for HV velocity prediction is represented as:
%
\begin{ceqn} 
    \begin{align}
        v^{H}_{k} &= -c_1 v^{H}_{k-1} - c_2 v^{H}_{k-2} - c_3 v^{H}_{k-3} - c_4 v^{H}_{k-4} + b_1 v^{N_a}_{k-1} + b_2 v^{N_a}_{k-2} + b_3 v^{N_a}_{k-3} + b_4 v^{N_a}_{k-4} \, , \tag{59a} \\
        & = {f}\left(v_{k-1:k-4}^{H}, {v}_{k-1:k-4}^{N_a} \right) \, . \tag{59b} \label{eqn:arx}
    \end{align}
\end{ceqn}
%
Here, $v^{H}_{k-i}$ and $v^{N_a}_{k-i}$ represent the velocities of the HV and the last vehicle in the AV platoon at time step $k-i$, respectively. The coefficients $c_{1,\cdots, 4}$ and $b_{1,\cdots, 4}$ are constant coefficients associated with velocities of the HV and the last vehicle in the AV platoon at previous time steps respectively. Similar to combining GP models with the nominal model in these path-following control application examples, GP models are combined with the nominal model \eqref{eqn:arx} not only to enhance the accuracy of the HV model but also to offer a quantifiable measure of modeling uncertainties. The GP-enhanced ARX model is developed as: 
%
\begin{ceqn}
    \begin{align}
        v^H_k &= \sum_{i=1}^4 -c_i v^H_{k-i} + \sum_{i=1}^4 b_i v^{N_a}_{k-i}  = {f}(\cdot) \, , \tag{60a} \label{eqn:arxgp_a}\\
        \tilde{v}^{H}_{k}&=\overbrace{v^H_k}^{\text {ARX prediction}}+\overbrace{{g}(v^{H}_{k-1}, v^{N_a}_{k-1})} ^{\text {GP-based correction}} \, . \tag{60b} \label{eqn:arxgp_b}
    \end{align}
\end{ceqn}
%
In this model, $\tilde{v}^{H}_{k}$ represents the GP-compensated velocity prediction of the HV. The GP model ${g}(\cdot)$ learns the divergence between the actual system behaviors and the ARX predictions. It considers both $v^{H}$ (HV velocity) and $v^{N_a}$ (velocity of the last AV). This ensures that the GP model adequately captures the dynamics of the HV as influenced by the actions of the leading AV.

Data for developing the HV model were collected using a Unity simulator, where drivers were asked to follow an AV platoon while being distracted by answering algebraic questions, mimicking real-world distracted driving scenarios. The setup is illustrated in Fig. \ref{figure:car_simulator}.
%
\begin{figure}
    \centering
    \vspace{0.15cm}
    \includegraphics[trim=0cm 0cm 0cm 0cm, width=0.75\columnwidth]{figures/car_simulator.jpg}
    \caption{One of the drivers in a controlled experiment within a Unity driving simulator. The experiment was designed to collect data for HV modeling, simulating distracted driving conditions \cite{wang2024improving}.}
    \label{figure:car_simulator}
\end{figure}
%
Comparative analysis using root mean square error (RMSE) against actual HV velocity data showed that the GP-enhanced HV model \eqref{eqn:arxgp_b} yielded approximately a 35.64\% improvement in prediction accuracy over the standard ARX model, highlighting its effectiveness in modeling HV behavior in mixed-vehicle platoons.

\subsubsection{Mixed Platooning Model}
To effectively manage longitudinal tracking in mixed-vehicle fleets, a GP learning-based MPC strategy is developed, utilizing the GP-enhanced HV model \eqref{eqn:arxgp_b}. This strategy integrates crucial constraints like acceleration, speed, and safe distance. A key aspect of this approach involves maintaining a safe distance within the mixed platoon. For AVs in the platoon, defined by the set $\mathbf{n_a} = {1, 2, \cdots, N_a}$, the distance between consecutive vehicles must satisfy a minimum threshold $\Delta$, i.e., $p_{k}^{\mathbf{n_a}-1}-p_{k}^{\mathbf{n_a}} \geq \Delta$. Here, $N_a$ is the number of AVs, and $p_{k}$ indicates their position. The kinematics of AVs is formulated as:
%
\begin{ceqn}
    \begin{align}  
    v_{k+1}^{\mathbf{n_a}} &= v_{k}^{\mathbf{n_a}} + T \, \mathrm{acc}_{k}^{\mathbf{n_a}} \, , \tag{61a} \label{eqn:av_a} \\
    p_{k+1}^{\mathbf{n_a}} &= p_{k}^{\mathbf{n_a}} + T \, v_{k}^{\mathbf{n_a}}  \, . \tag{61b} \label{eqn:av_b}
    \end{align}
\end{ceqn}
%
where $0<T \ll 1$ indicates the sample time, and $v_{k}^{\mathbf{n_a}}$ and $\mathrm{acc}_{k}^{\mathbf{n_a}}$ denote the velocity and acceleration of $A^{\mathbf{n_a}}$ (shown in Fig. \ref{figure:mixed_platoon}) respectively. AVs are assumed to be deterministic, with their states measured and communicated error-free, i.e., $\Sigma(v_{k}^\mathbf{n_a}) = 0$. By applying \eqref{eqn:arxgp_b}, the HV model is derived as follows:
%
\begin{ceqn} 
    \begin{align} 
        \tilde{v}_{k}^{H} &= v_{k}^{H} + {d}(v_{k-1}^{H}, {v}_{k-1}^{N_a}) \, , \tag{62a} \label{eqn:sys_model_a} \\
        p_{k+1}^{H} &= p_{k}^{H} + T \, \tilde{v}_{k}^{H} \, , \nonumber \\ 
        &= p_{k}^{H} + T \, v_{k}^{H} + T \, {d}(v_{k-1}^{H}, {v}_{k-1}^{N_a}) \, . \tag{62b} \label{eqn:sys_model_b}
    \end{align}
\end{ceqn}
%
In this model, $\tilde{v}_{k}^{H}$ is the GP-enhanced HV velocity prediction, where $v_{k}^{H}$ is the nominal velocity (computed using \eqref{eqn:arx}), and $p_{k}^{H}$ is the position state. Using \eqref{eqn:sys_model_b} and \eqref{eqn:mean_prop_final_again}, the propagation of the HV position mean can then be derived as:
%
\begin{equation}
    \mu \left(p_{k+1}^{H} \right) = \mu \left( p_{k}^{H} \right) + T \, \mu \left( v_{k}^{H} \right) + T \, \mu^d \left( v_{k-1}^{H}, {v}_{k-1}^{N_a} \right) \, . \tag{63a} \label{eqn:mixed_vel_prop_c} 
\end{equation} 
%
Denoting $\mu \left(p_{k+1}^{H} \right)$ as $\mu_{k+1}^{p^{H}}$ and rewriting other terms similarly, \eqref{eqn:mixed_vel_prop_c} is expressed more compactly as:
%
\begin{ceqn} 
    \begin{align} 
        \mu_{k+1}^{p^{H}} &= \mu_{k}^{p^{H}} + T \, v_{k}^{H} + T \, \mu^d \left( v_{k-1}^{H}, {v}_{k-1}^{N_a} \right) \, , \label{eqn:mixed_vel_prop_d} \tag{63b}
    \end{align}
\end{ceqn}
%
with the initial value $\mu_{0}^{p^{H}} = p_{k}^{H}$. Using \eqref{eqn:sys_model_b} and \eqref{eqn:var_prop_linear_nominal_mean}, the propagation of the HV position variance is derived as:
%
\begin{equation}
    \Sigma \left(p_{k+1}^{H} \right) = \Sigma (p_{k}^{H}) + T^2 \Sigma^d \left(v_{k-1}^{H}, {v}_{k-1}^{N_a}\right) \, . \tag{64a} \label{eqn:var_prop_pH} 
\end{equation} 
%
Similarly, this can be compactly written as:
%
\begin{ceqn} 
    \begin{align} 
        \Sigma_{k+1}^{p^{H}} = \Sigma_{k}^{p^{H}} + T^2 \Sigma^d \left(v_{k-1}^{H}, {v}_{k-1}^{N_a}\right) \, . \tag{64b} \label{eqn:mixed_HV_var}
    \end{align}
\end{ceqn}
%
with $\Sigma_{0}^{p^{H}} = 0$, this equation allows for the tracking of the HV position variance, which is vital for ensuring safety in mixed platooning scenarios. It is important to note that in this model, covariances between $p_{k}^{H}$ and $v_{k}^{H}$ are not considered during the HV uncertainty propagation.

\subsubsection{Safe Distance Probability Constraint}
To ensure a safe distance within a mixed-vehicle platoon, a probabilistic constraint, also known as a chance constraint, is established. This constraint is crucial for maintaining a safe separation between the trailing AV and the HV, particularly given the uncertain nature of HV behavior. The constraint is formulated as:
%
\begin{equation} 
    \mathrm{Pr}\left(p_{k}^{N_a}-(p_{k}^{H} + \Delta) > \Delta_\text{ext} \right) \geq p_{\text{def}} \, . \tag{65} \label{eqn:chance_constraint} 
\end{equation}
%
In this formulation, $\Delta$ is the predefined safe distance between the AVs, and $\Delta_\text{ext} \geq 0$ is an additional buffer to accommodate the stochastic behavior of the HV. The predefined $p_{\text{def}}$ denotes the desired satisfaction probability. 

To express this probabilistic constraint in a more deterministic form, we use the concept of a half-space constraint $\mathcal{X}^{hs} := \bigl\{x \vert h^{\top}x \leq b \bigl\}$, $ h \in \mathbb{R}^n$, where $ h \in \mathbb{R}^n$, and $b \in \mathbb{R}$. The tightened constraint on the state mean, as derived in \cite{hewing2019}, is expressed as:
%
\begin{equation} 
    \mathcal{X}^{h s}\left(\Sigma_{i}^{x}\right):=\left\{x \mid h^{\top} x \leq b-\phi^{-1}\left(p_{\text{def}}\right) \sqrt{h^{\top} \Sigma_{i}^{x} h}\right\} \, . \tag{66} \label{eqn:half_space_constraint} 
\end{equation}
%
In this equation, $h^{\top} = \begin{bmatrix} -1 & 1\end{bmatrix}$, $x := \begin{bmatrix} p_{k}^{N_a} & p_{k}^{H}+\Delta \end{bmatrix}^{\top}$, and $b = -\Delta_\text{ext}$. Here, $\phi^{-1}$ is the inverse of the cumulative distribution function (CDF). In our scenario,
%
\begin{equation} 
    \Sigma_{k}^{x} := \begin{bmatrix} \Sigma_{k}^{p^{N_a}} \\ \Sigma_{k}^{p^{H}}+\Delta \end{bmatrix} = \begin{bmatrix} 0 & 0 \\ 0 & \Sigma_{k}^{p^{H}}\end{bmatrix} \, . \tag{67} \label{eqn:phi_cdf} 
\end{equation}
%
Considering there is no covariance between the positions of the HV and the leading AV ($\Sigma_{k}^{p^{N_a}}=0$), and the position variance of the HV ($\Sigma_{k}^{p^{H}}$) is computed using \eqref{eqn:mixed_HV_var}, we can establish a ``tightened'' constraint on the position state by incorporating \eqref{eqn:phi_cdf} into \eqref{eqn:half_space_constraint}. This leads to
%
\begin{equation} 
    p_{k}^{N_a}-p_{k}^{H} \geq \Delta + \Delta_\text{ext} + \phi^{-1}\left(p_{\text{def}}\right) \sqrt{ \Sigma_{k}^{p^{H}}} \, . \tag{68} \label{eqn:safe_dis_HV} 
\end{equation}
%

The chance constraint for maintaining safe distances, given by \eqref{eqn:chance_constraint}, is reduced to a deterministic representation in \eqref{eqn:safe_dis_HV}. It can be further simplified by omitting $\Delta_\text{ext}$ if the satisfaction probability $p_{\text{def}}$ is set high. By adaptively adjusting the safe distance based on the estimated uncertainties from the HV's GP model, as per \eqref{eqn:mixed_HV_var}, this approach ensures that the safe distance always exceeds the minimum requirement of $\Delta$ under varying conditions. This adaptive adjustment is key to enhancing safety in mixed-vehicle platoons, catering to the unpredictable nature of human driving behaviors.

\subsubsection{GP-Based MPC}
\label{sec:GP-MPC}
The proposed GP-based MPC strategy, specifically tailored for mixed-vehicle platoon scenarios, integrates an advanced HV model for a platoon consisting of $N_a$ AVs followed by an HV as depicted in Fig. \ref{figure:mixed_platoon}. The strategy can be expressed as:
%
\begin{ceqn}
    \begin{align} 
       \underset{\mathbb{V}}{\text{min}} \sum_{\mathbf{n_a}=1}^{N_a} \sum_{i=k}^{k+N-1} \Big\| \mathrm{acc}_{{i}|k}^{\mathbf{n_a}} \Big\|^2_R &+ \sum_{i=k}^{k+N} \Big\| v _{{i+1}|k}^1 - v_{{i+1}|k}^\text{ref} \Big\|^2_{Q_1} + \sum_{\mathbf{n_a}=2}^{N_a}\sum_{i=k}^{k+N} \Big\| v_{{i+1}|k}^{\mathbf{n_a}} - v_{{i+1}|k}^{\mathbf{n_a}-1} \Big\|^2_{Q_2} \tag{69a} \label{eqn:mpc_a} \\
       \text{with} \ \mathbb{V} = & \left\{v_{{i}|k}^1, v_{{i}|k}^{\mathbf{n_a}}, v_{{i}|k}^{H}, p_{{i}|k}^{\mathbf{n_a}}, \mu_{{i}|k}^{p^{H}}, \Sigma_{{i}|k}^{p^{H}}, \mathrm{acc}_{{i}|k}^{\mathbf{n_a}} \right\} \, \nonumber \\
        \text {subject to} \nonumber \\
        v_{{i+1}|k}^{\mathbf{n_a}} &= v_{{i}|k}^{\mathbf{n_a}} + T \, \mathrm{acc}_{{i}|k}^{\mathbf{n_a}} , \  p_{{i+1}|k}^{\mathbf{n_a}} = p_{{i}|k}^{\mathbf{n_a}} + T \, v_{{i}|k}^{\mathbf{n_a}} \, , \nonumber \\
        \mathbf{n_a} &= \{1, 2, \cdots, N_a\}  \, , \tag{69b} \label{eqn:mpc_b} \\ 
        v^{H}_{{i}|k} &= {f}\left(v_{i-1:i-4 | k}^{H}, {v}_{i-1:i-4 | k}^{N_a} \right) \, , \tag{69c} \label{eqn:mpc_c}\\
        \mu_{{i+1}|k}^{p^{H}} &= \mu_{{i}|k}^{p^{H}} + T \, v_{{i}|k}^{H} + T \, \mu^d (v_{{i-1}|{k}}^{H}, {v}_{{i-1}|{k}}^{N_a}) \, , \tag{69d} \label{eqn:mpc_d}\\
        \Sigma_{{i+1}|k}^{p^{H}} &= \Sigma_{{i}|k}^{p^{H}} + T^2 \Sigma^d (v_{{i-1}|{k}}^{H}, {v}_{{i-1}|{k}}^{N_a}) \, , \tag{69e} \label{eqn:mpc_e}\\
        p_{{i}|k}^{\mathbf{n_a}-1} & - p_{{i}|k}^{\mathbf{n_a}} \geq \Delta \, , \tag{69f} \label{eqn:mpc_f}\\
        p_{{i}|k}^{N_a} & - \mu_{{i}|k}^{p^{H}} \geq \Delta + \phi^{-1}\left(p_{\text{def}}\right) \sqrt{ \Sigma_{{i}|k}^{p^{H}}} \, , \tag{69g} \label{eqn:mpc_g}\\
        v_{\text{min}} & \leq v_{{i}|k}^{\mathbf{n_a}} \leq v_{\text{max}} \, , \ \mathrm{acc}_{\text{min}} \leq \mathrm{acc}_{{i}|k}^{\mathbf{n_a}} \leq \mathrm{acc}_{\text{max}} \, . \tag{69h} \label{eqn:mpc_h}
    \end{align}
\end{ceqn}
%
The cost function \eqref{eqn:mpc_a} emphasizes minimizing the acceleration of each AV, aligning the leader AV's velocity with the reference speed, and maintaining consistent velocities among the AVs. HV velocities are not directly controlled but are instead factored into the system through the HV model, enhancing the system's predictive accuracy and enabling the management of uncertainties associated with HV behavior. The constraints, \eqref{eqn:mpc_b}--\eqref{eqn:mpc_h}, encompass the vehicle dynamics, including the velocity and position relationships for both AVs and the HV, originally represented by \eqref{eqn:av_a}, \eqref{eqn:av_b}, \eqref{eqn:arx}, \eqref{eqn:mixed_vel_prop_d}, and \eqref{eqn:mixed_HV_var}. Additionally, the constraints ensure safe distances between vehicles and adhere to predefined velocity and acceleration limits.

In testing, the GP-MPC was benchmarked against a standard MPC in scenarios involving constant-velocity tracking and emergency braking. The results demonstrated the GP-MPC's superior performance in maintaining safety margins and higher average speeds, showcasing its effectiveness in mixed-traffic environments. By incorporating HV uncertainties, the GP-MPC strategy significantly enhances safety and efficiency, offering a robust and adaptable solution for complex traffic scenarios involving a mix of autonomous and human-driven vehicles.

\subsection{Sparse GP-based MPC}
We have shown that GP models are exceptionally effective in modeling the complex dynamics of robotic systems. The integration of GP models with MPC, forming GP-MPC frameworks, not only considerably improves the accuracy of MPC's predictive models but also effectively integrates quantified uncertainties into the optimization loop, thereby enhancing system performance significantly. However, applying standard GP models within the MPC framework presents a notable challenge, particularly in scenarios with large-scale data as discussed in Sec. \ref{section:sparse_gpr}. As the training dataset size increases, the prediction time for standard GP models escalates, rendering them less feasible for real-time MPC applications.

To address this challenge, in previous path-following application examples, strategies such as employing local GP models to maintain a manageable data size (Sec. \ref{sec:gp-nmpc}) or limiting the path lengths (Sec. \ref{sec:gp-fblmpc}) were implemented. To further mitigate computational demands, they also ignore the uncertainty propagation in GP models and neglect constraints in the MPC optimization process, which potentially compromise the overall performance of GP-MPC methods. In mixed-platoon control utilizing standard GP-based MPC strategies (Sec. \ref{sec:gp_mixed_platoon}), the computation time reaches approximately 19 seconds per time step, underscoring their impracticality for real-time operation.

A promising solution to this computational dilemma lies in the adoption of sparse GP models. Sparse GP models are a computationally efficient alternative to standard GP models, striking a critical balance between computational efficiency and the precision of approximations \cite{wang2023recent}. This balance is essential for ensuring that the GP models remain viable for real-time applications without significantly compromising their predictive accuracy or their ability to effectively manage uncertainties, which makes it feasible to apply sophisticated GP-MPC methods in real-time, large-scale data applications, thereby expanding the potential and applicability of these advanced control systems.

\subsubsection{Sparse GP+ARX Modeling} 
The research detailed in \cite{wang2024learning-based} illustrates a successful application of the fully independent conditional (FIC) approximation, a leading-edge sparse GP approach, for enhancing computational efficiency in dynamic systems modeling. The hyperparameters for the sparse GP model were directly loaded from the trained standard GP model, and 20 inducing points were automatically selected by the FIC method within the training datasets. This incorporation resulted in a remarkable boost in computational speed, where the sparse GP model required only about 5.6\% of the average prediction time needed by the standard GP model.

In terms of modeling precision, the standard GP+ARX model exhibited a notable 35.64\% improvement in forecasting HV velocities relative to the ARX nominal model. The sparse GP+ARX model achieved an approximate 23.94\% improvement compared to the ARX model, which provides a good balance of prediction accuracy and computational efficiency. To illustrate this improvement, Fig. \ref{figure:gp_sparse} displays a comparison of velocity predictions using the ARX model, the ARX+GP model, and the sparse GP+ARX model against measured HV velocities.
%
\begin{figure}
    \centering
    \vspace{0.1cm}
    \includegraphics[trim=0cm 0cm 0cm 0cm, width=0.88\columnwidth]{figures/G1_logdata3_YN_medium_vs_sparse.pdf}
    \caption{Comparative analysis of velocity prediction models. Plots show velocity predictions of the ARX, ARX+GP, and sparse GP+ARX models, against actual HV velocity measurements. Compared to the ARX model, the ARX+GP exhibits approximately 35.64\% improvement, and sparse GP+ARX achieves a 23.94\% enhancement with significantly reduced computational demands \cite{wang2024learning-based}. }
    \label{figure:gp_sparse}
\end{figure}
%
The comparison clearly demonstrates that both the standard GP+ARX and the sparse GP+ARX models significantly outperform the ARX model in accurately predicting the HV behaviors. These results highlight the sparse GP+ARX model's effectiveness in providing a good balance between enhanced modeling precision and substantial gains in computational efficiency.

\subsubsection{Dynamic Sparse GP Prediction in MPC}
\label{sec:dynamic_sparseGP_mpc}
Despite the notable reduction in computation time achieved by employing the sparse GP+ARX model for HV modeling, real-time integration of GP models within the MPC framework continues to pose challenges due to the inherently complex nature of MPC \cite{abdolhosseini2013efficient}. MPC involves solving an optimal control problem at each time step, adhering to constraints as outlined in equations \eqref{eqn:mpc_b}--\eqref{eqn:mpc_h}. Addressing this challenge, \cite{wang2024learning-based} introduced a dynamic sparse approximation method for GP-MPC, aimed at further speeding up the process.

Leveraging the receding horizon characteristic of MPC, where the predictive trajectory at the current time step closely resembles the trajectory calculated at the previous time step, the dynamic sparse GP approach computes calculations using the previously derived trajectory. These results are then utilized to update the mean and variance for the current time step, as per equations \eqref{eqn:mpc_d} and \eqref{eqn:mpc_e}. This strategy significantly reduces computational demands by replacing repetitive predictions for each time step within the horizon with a single sparse GP prediction for the entire prediction horizon. As a result, this dynamic sparse GP-MPC methodology becomes practicable for real-time applications, especially those requiring rapid sampling rates, thereby enhancing the feasibility and efficiency of GP-MPC schemes in time-sensitive control applications.

\subsubsection{Testing with Realistic Velocity Profiles}
In \cite{wang2024improving} and \cite{wang2024learning-based}, the HV model including both the nominal ARX and GP components, was estimated with data collected in a human-in-the-loop Unity driving simulator. In \cite{wang2024enhancing}, the HV model incorporates field experiment data, complementing the nominal model estimated with data from the simulator. This advancement involved collecting data for the GP component during field experiments where an HV followed an AV, as shown in Fig. \ref{figure:AV_HV_cars}. The data was gathered on an 850-meter real-world track, distinguished by its varying curvatures and bumps, to provide a detailed and realistic dataset. This dataset was pivotal in improving the GP model's accuracy and reliability. Notably, compared to the simulator-based ARX model, the field data-integrated GP model showed a significant 36.34\% improvement in RMSE accuracy.
%
\begin{figure}
    \vspace{0.15cm}
    \centerline{\includegraphics[width=0.85\columnwidth]{figures/AV_HDV_cars.jpg}}
    \caption{The autonomous vehicle platform, UW Moose, and a following human-driven vehicle on the test track \cite{wang2024enhancing}.
    }
    \label{figure:AV_HV_cars}
\end{figure}
%

Utilizing this improved HV model, the dynamic Sparse GP-based MPC policy was tested using the worldwide harmonized light vehicle test procedure (WLTP) as the reference speed profile for the leader HV. The WLTP, recognized for its realistic representation of driving conditions in car-following scenarios \cite{coppola2022eco}, makes it an ideal benchmark for evaluating the controller's performance in real-life car-following scenarios.

Fig. \ref{figure:gp_simulation_wltp} shows the outcomes of these WLTP scenario tests. This comprehensive display includes plots of the velocity response, position trajectories, and inter-vehicle distances, providing an in-depth perspective on the system's adaptability to the varied conditions presented by the WLTP cycle. These results underscore the model's ability to dynamically adjust safety margins in response to varying driving conditions, thereby affirming its applicability and effectiveness in a range of traffic scenarios. The GP-MPC showcases enhanced safety by increasing the minimum distance between the HV and the following AV by 0.4 meters compared to the nominal MPC. Furthermore, the position plots reveal that vehicles under GP-MPC management maintain positions several meters ahead (4--9 meters) of those managed by nominal MPC, indicating more efficient traffic flow in realistic driving situations.
%
\begin{figure}
    \centering
    \vspace{0.15cm}
    \subfloat{{\includegraphics[trim=0.0cm 0cm 1.3cm 0cm, width=0.72\columnwidth]{figures/gp_wltp_vel.pdf} }}
    \qquad \qquad 
    \vspace{0.01cm}
    \subfloat{{\includegraphics[trim=0cm 0cm 0cm 1.3cm, width=0.76\columnwidth]{figures/gp_wltp_pos.pdf} }}
    \qquad \qquad 
    \vspace{0.01cm}
    \subfloat{{\includegraphics[trim=0.0cm 0cm 1.0cm 2.0cm, width=0.74\columnwidth]{figures/gp_wltp_dist.pdf} }}
    \caption{WLTP scenario test results using the dynamic sparse GP-based MPC. Arranged in descending order, these plots include velocity responses, vehicle position trajectories, and inter-vehicle distances. Notably, the GP-MPC ensures increased safety by augmenting the minimum inter-vehicle distance compared to the nominal MPC. Moreover, the vehicle positions in GP-MPC scenarios are substantially ahead of the nominal MPC, indicating enhanced traffic efficiency under realistic driving conditions \cite{wang2024enhancing}.}
\label{figure:gp_simulation_wltp}
\end{figure}
%


\section{Conclusion}
\label{sec:conclusion}

This tutorial has systematically explored the integration of Gaussian process (GP) models with model predictive control (MPC), presenting a comprehensive and accessible guide for its implementation in complex systems, especially in robotics. Our detailed mathematical exposition on GP-MPC, a novel contribution to the field, demystifies the intricacies of integrating GP models within the MPC framework. We have highlighted the importance of approximating means and variances for multi-step predictions, a crucial aspect in dynamic environments, thus addressing a significant gap in the current literature.

This tutorial began with the fundamentals of GP regression, transitioning smoothly into the integration of these principles within MPC, emphasizing the enhancement of MPC’s predictive capabilities. The theoretical discussions are supported by practical applications, including robotic path-following and vehicle platooning, demonstrating GP-MPC's applicability and effectiveness in real-world scenarios.

The GP-MPC approach presented in this tutorial not only bridges the knowledge gap for practitioners but also opens new avenues for research and application in learning-based control systems. It provides the necessary tools and understanding for researchers and practitioners to navigate and innovate in the evolving landscape of robotics control, where dealing with uncertainties and dynamic environments is paramount.

The contributions of this tutorial extend beyond academic understanding, offering practical solutions and insights that are critical in advancing applications of learning-based control systems. By providing a solid theoretical background coupled with practical implementation strategies, this tutorial stands as a pivotal resource in the field of GP-MPC, encouraging further exploration and innovation.



\section{Acknowledgments}

The author wishes to extend heartfelt thanks to Prof. Joshua Marshall at Queen's University for his invaluable support and mentorship. His guidance, particularly during the first author's postdoctoral tenure at Queen's University, provided not only academic direction but also inspiration and encouragement. This work, with its intricate explorations into the domain of GP-MPC, has been greatly influenced by his deep understanding and innovative approach towards robotics control. 

\section{Appendices}

\subsection{Theorems of Gaussian Mean and Variance Approximation}
\label{sec:appendix_gp_approx}
This appendix presents the theoretical basis for Gaussian mean and variance approximation in GP regression. The foundational principles of Gaussian process (GP) regression are developed in \cite{Girard2002} and \cite{girard2002gaussian}, where a GP model $f(x)$ is used to approximate a function $y = f(x) + \epsilon$. The approximations of the GP mean and variance use the principles of iterated expectations and conditional variances, respectively. These calculations are represented as follows:
%
\begin{align}
    m(x^*) &= \mathbb{E}_{x^*}\left[\mathbb{E}_{f(x^*)} [f(x^*) \vert x^*] \right] \, , \nonumber \\
           &= \mathbb{E}_{x^*}\left[\mu (x^*) \right] \, . \tag{A.1} \label{eqn:mean_prop_general}   \\
    \textit{var}(x^*) &= \mathbb{E}_{x^*}\left[\operatorname{var}_{f(x^*)} (f(x^*) \vert x^*) \right] + \operatorname{var}_{x^*} \left(\mathbb{E}_{f(x^*)} [f(x^*) \vert x^*] \right) , \nonumber \\
           &= \mathbb{E}_{x^*}\left[{\Sigma} (x^*) \right] + \operatorname{var}_{x^*} \left(\mu (x^*) \right) \, . \tag{A.2} \label{eqn:var_prop_general} 
\end{align}
%

In \eqref{eqn:mean_prop_general}, $\mathbb{E}_{f(x^*)}\left[f(x^*) \vert x^*\right]=\mu (x^*)$ implies that the expected value of the GP model, $\left(\mathbb{E}_{f(x)}\right)$, evaluated at a test point $x^*$, is equivalent to the mean at that test point. The notation $x^*$ represents the test points for which predictions are desired. For clarity, \eqref{eqn:mean_prop_general} and \eqref{eqn:var_prop_general} are expressed explicitly with a time index:
%
\begin{align}
    m(x_{k+1}^*) &= \mathbb{E}_{x_k^*}\left[\mathbb{E}_{f(x^*)} [f(x^*) \vert x_{k+1}^*] \right] \, ,  \nonumber \\
     &= \mathbb{E}_{x_k^*}\left[\mu (x_{k+1}^*) \right] \, . \tag{A.3} \label{eqn:mean_prop_general_final} \\
    \textit{var}(x_{k+1}^*) &= \mathbb{E}_{x_k^*}\left[\operatorname{var}_{f(x^*)} (f(x^*) \vert x_{k+1}^*) \right] + \operatorname{var}_{x_k^*} \left(\mathbb{E}_{f(x^*)} [f(x^*) \vert x_{k+1}^*] \right) \, , \nonumber \\
    &= \mathbb{E}_{x_k^*}\left[{\Sigma} (x_{k+1}^*) \right] + \operatorname{var}_{x_k^*} \left(\mu (x_{k+1}^*) \right) \, . \tag{A.4} \label{eqn:var_prop_general_final} 
\end{align}
%

\subsubsection{Predictive Mean Approximation}
The approximation of the expectation under $x_k^*$ of the GP mean $\mu(x_k^*)$, as described in \eqref{eqn:mean_prop_general_final}, involves its first-order Taylor expansion around $x^*=\mu_{x_k^*}$. Following the equations in \cite[Eq. 14]{Girard2002}, this can be expressed as:
%
\begin{align}
    \mu(x_k^*) \approx \mu(\mu_{x_k^*}) + \frac{\partial \mu(x^*)}{\partial x^*} \bigg|_{x^*=\mu_{x_k^*}}^\top (x^* - \mu_{x_k^*}) + \mathcal{O} \left( \lvert\lvert x^* - \mu_{x_k^*} \lvert\lvert^2 \right) \, . \tag{A.5} \label{eqn:mean_taylor} 
\end{align}
%
Subsequently, the expectation $\mathbb{E}_{x_k^*}\left[\mu (x_{k}^*) \right]$ is approximated following the process outlined in \cite[Eq. 15]{Girard2002}:
%
\begin{align}
    \mathbb{E}_{x_k^*} \left[ \mu(x_k^*) \right] &\approx \mathbb{E}_{x^*_k} \left[ \mu(\mu_{x_k^*}) + \frac{\partial \mu(x^*)}{\partial x^*} \bigg|_{x^*=\mu_{x_k^*}}^\top (x^* - \mu_{x_k^*}) \right] \, , \nonumber \\
       &= \mu(\mu_{x_k^*}) \, . \tag{A.6} \label{eqn:exp_mean_appendix} 
\end{align}
%

\subsubsection{Predictive Variance Approximation}
Similarly, for the expectation under $x_k^*$ of the GP variance $\Sigma(x_k^*)$ in \eqref{eqn:var_prop_general_final}, we approximate $\Sigma(x_k^*)$ through its first-order Taylor expansion around $x^*=\mu_{x_k^*}$ as:
%
\begin{align}
    \Sigma(x_k^*) \approx {\Sigma}(\mu_{x_k^*}) + {\frac{\partial {\Sigma}(x^*)}{\partial x^*}} \bigg|_{x^*=\mu_{x_k^*}}^\top (x^* - \mu_{x_k^*}) + \mathcal{O} \left( \lvert\lvert x^* - \mu_{x_k^*} \lvert\lvert^2 \right) \, . \tag{A.7} \label{eqn:var_taylor} 
\end{align}
%
The expectation $\mathbb{E}_{x_k^*}\left[\Sigma (x_{k}^*) \right]$, following the derivations in \cite[Eq. 18]{Girard2002} and \cite[Appendix I]{hewing2018cautious}, is approximated as:
%
\begin{align}
    \mathbb{E}_{x_k^*} \left[ {\Sigma}(x_k^*) \right] & \approx \mathbb{E}_{x^*_k} \left[ {\Sigma}(\mu_{x_k^*}) + {\frac{\partial {\Sigma}(x^*)}{\partial x^*}} \bigg|_{x^*=\mu_{x_k^*}}^\top (x^* - \mu_{x_k^*}) \right] \nonumber \\
       & = {\Sigma}(\mu_{x_k^*}) \, . \tag{A.8} \label{eqn:exp_var_appendix} 
\end{align}
%
For the second term of \eqref{eqn:var_prop_general}, $\operatorname{var}_{x^*} \left(\mu (x^*) \right)$ is derived as follows, based on \cite[Eq. 20]{Girard2002}:
%
\begin{align}
    \operatorname{var}_{x_k^*} \left(\mu(x_k^*) \right) 
       &\approx \operatorname{var}_{x_k^*} \left[ \mu(\mu_{x_k^*}) + \frac{\partial \mu(x^*)}{\partial x^*} \bigg|_{x^*=\mu_{x_k^*}}^\top (x^* - \mu_{x_k^*}) \right] \nonumber \\
       &= \frac{\partial \mu(x^*)}{\partial x^*} \bigg|_{x^*=\mu_{x_k^*}} \Sigma_{x^*_k} \frac{\partial \mu(x^*)}{\partial x^*} \bigg|_{x^*=\mu_{x_k^*}} ^\top \, . \tag{A.9} \label{eqn:var_mean_appendix} 
\end{align}
%

\subsection{Calculation of the Cost Function }
\label{sec:appendix_cost_function_solve}
To compute the partial derivatives of the cost function, we need to refer to equations (69) and (81) from \cite[Sec. 2.4]{petersen2012}:
%
\begin{ceqn}
    \begin{align}
        \frac{\partial \mathbf{x}^\top \mathbf{a}} {\partial \mathbf{x}} &= \frac{\partial \mathbf{a}^\top \mathbf{x}} {\partial \mathbf{x}} = \mathbf{a} \, , \tag{A.10} \label{eqn:matrix_cook_book_69}  \\
        \frac{\partial \mathbf{x}^\top \mathbf{A} \mathbf{x}} {\partial \mathbf{x}} &= \left(\mathbf{A} + \mathbf{A}^\top\right)\mathbf{x} \, . \tag{A.11} \label{eqn:matrix_cook_book_81}
    \end{align}
\end{ceqn}
%
Given that $\mathbf{Q}$ and $\mathbf{R}$ are positive semi-definite symmetric matrices in the cost function \eqref{eqn:mpc_quad_cost}, we have:
%
\begin{equation}
    \frac{\partial \mathbf{x}^\top \mathbf{A} \mathbf{x}} {\partial \mathbf{x}} = 2 \mathbf{A}\mathbf{x} \, , \tag{A.12} \label{eqn:matrix_cook_book_81_usage}
\end{equation}
%

The partial derivative of the cost function \eqref{eqn:cost_function_solve} in Sec. \ref{sec:gp_mpc}, can be calculated:
%
\begin{ceqn}
    \begin{align}
        \frac{\partial \mathbf{J}(\delta \mathbf{u}_k)}{\partial\delta\mathbf{u}_k} &\approx  \nonumber \\  
        & \frac{\partial \left( (\mathbf{x}_{d, k+1} - \mathbf{\bar{x}}_{k+1} - \mathbf{H}'\delta\mathbf{u}_k)^\top\mathbf{Q}(\mathbf{x}_{d, k+1} - \mathbf{\bar{x}}_{k+1} - \mathbf{H}'\delta\mathbf{u}_k) \right) }{\partial\delta\mathbf{u}_k}  + \frac{\partial \left((\mathbf{\bar{u}}_k + \delta\mathbf{u}_k)^\top\mathbf{R}(\mathbf{\bar{u}}_k + \delta\mathbf{u}_k) \right) }{\partial\delta\mathbf{u}_k} \, , \nonumber \\  
        &= \frac{\partial \left( (\tilde{\mathbf{x}}_{k+1} - \mathbf{H}'\delta\mathbf{u}_k)^\top\mathbf{Q}(\tilde{\mathbf{x}}_{k+1} - \mathbf{H}'\delta\mathbf{u}_k) \right) }{\partial\delta\mathbf{u}} + \frac{\partial \left( (\mathbf{\bar{u}}_k + \delta\mathbf{u}_k)^\top\mathbf{R}(\mathbf{\bar{u}}_k + \delta\mathbf{u}_k) \right) }{\partial\delta\mathbf{u}} \, , \nonumber \\
        &= 2 \mathbf{Q} (\tilde{\mathbf{x}}_{k+1} - \mathbf{H}^{'}\delta\mathbf{u}_k) (-\mathbf{H}') + 2 \mathbf{R} (\mathbf{\bar{u}}_k + \delta\mathbf{u}_k) \, , \nonumber \\
        &= 2 \left(-\mathbf{Q} \mathbf{\tilde x}_{k+1} \mathbf{H}^{'} + \mathbf{Q}\mathbf{H}^{'} \delta\mathbf{u}_k\mathbf{H}^{'}+ \mathbf{R}\mathbf{\bar{u}}_k + \mathbf{R} \delta\mathbf{u}_k \right) \, , \nonumber \\
        &= 2 \left(-\mathbf{H}^\mathsf{'T} \mathbf{Q} \mathbf{\tilde x}_{k+1}  + \mathbf{H}^\mathsf{'T}\mathbf{Q}\mathbf{H}^{'} \delta\mathbf{u}_k+ \mathbf{R}\mathbf{\bar{u}}_k + \mathbf{R} \delta\mathbf{u}_k \right) \, , \nonumber \\
        &= 2 \left((\mathbf{H}^\mathsf{'T}\mathbf{Q H}^{'}+\mathbf{R})\delta\mathbf{u}_k + \mathbf{R}\mathbf{\bar{u}}_k -\mathbf{H}^\mathsf{'T} \mathbf{Q} \mathbf{\tilde x}_{k+1} \right) \, , \nonumber \\
        &= 0 \, . \tag{A.13} \label{eqn:mpc_cost_function_solve}
    \end{align}
\end{ceqn}
%
This leads to the solution,
%
\begin{equation}
    \delta\mathbf{u}_k =
    \left(\mathbf{H}^\mathsf{'T}\mathbf{Q}\mathbf{H}^{'} + \mathbf{R} \right)^{-1} \left(\mathbf{H}^\mathsf{'T} \mathbf{Q} \mathbf{\tilde x}_{k+1} - \mathbf{R}\mathbf{\bar{u}}_k \right) \, . \tag{A.14} \label{eqn:mpc_cost_function_solve_result}
\end{equation}
%



\bibliographystyle{IEEEtran}
\bibliography{bibliography}



\end{document}

\endinput
%%
%% End of file `sample-manuscript.tex'.
