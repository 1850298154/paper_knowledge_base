For a fixed $n \in \mathbb{N}_+$, define for every robot $i$ the PRM
roadmap $\graph_i = (\nodes_i, \edges_i)$ constructed over $\cfree_i$,
such that $|\nodes_i|=n$ with connection radius \rad. Then, $\mmgimp 
= (\mmnodes, \mmedges) = \graph_1\times \ldots \times \graph_R$ is the 
\emph{tensor product roadmap} in space $\ccross$ (for an illustration,
see Figure~\ref{fig:tprm}).  Formally, $\mmnodes 
= \{ ( v_1, v_2, \dots, v_R ), \forall i, v_i \in \nodes_i\}$ is the 
Cartesian product of the nodes from each roadmap $\graph_i$.  For two 
vertices $V =(v_1,\ldots,v_m) \in \mmnodes, V'=(v'_1,\ldots,v'_m) \in 
\mmnodes$ the edge set $\mmedges$ contains edge $(V,V')$ if for every 
$i$ it is that $v_i=v'_i$ or $(v_i,v'_i)\in \edges_i$.\footnote{Notice this slight difference from
  $\drrt$~\cite{SoloveySH16:ijrr} so as to allow edges where some
  robots remain motionless while others move.}

\begin{figure}[t]
\centering
\includegraphics[height=1.5in]{tprm}
\caption{An illustration of a two-robot tensor product roadmap $\hat
  \graph_{i,j}$ between roadmaps $\graph_i$ and $\graph_j$. Two nodes
  in the tensor-product roadmap share an edge if all the individual
  robot configurations share an edge in the individual robot
  roadmaps.}
\label{fig:tprm}
\end{figure}

As shown in Algorithm~\ref{algo:drrtstar}, $\drrtstar$ grows a tree
$\tree$ over $\mmgimp$, rooted at the start configuration $S$ and
initializes path $\pi_{\textup{best}}$ (line~1).  The method 
stores the node added each iteration $V$ (Line~2), as part of an 
informed process to guide the expansion of \tree\ towards the goal.  
The method iteratively expands $\tree$ given a time budget (Line~3), 
as detailed by Algorithm~\ref{algo:drrtstar_expand}, storing the newly 
added node $V$ (Line~4).  After expansion, the method traces the path 
which connects the source $S$ with the target $T$ (Line~5).  If such a 
path is found, it is stored in $\pi_{\textup{best}}$ if it improves 
upon the cost of the previous solution (Lines~6,~7).  Finally, the 
best path found $\pi_{\textup{best}}$ is returned (Line~8).

\input{algo_drrtstar}

The expansion step is given in Alg. \ref{algo:drrtstar_expand}.  The
default initial step of the method is given in Lines~1-4, i.e., when
no $\vlast$ is passed (Line~1), which corresponds to an exploration
step similar to {\tt RRT}: a random sample \qrand\ is generated in
\ccross\ (Line~2), its nearest neighbor \vnear\ in $\tree$ is found
(Line~3) and the oracle function $\oracle(\cdot,\cdot)$ returns the
implicit graph node \vnew\ that is a neighbor of \vnear on the
implicit graph in the direction of $\qrand$ (Line~4). If a $\vlast$,
however, is provided (Line~5)---which happens when the last iteration
managed to generate a node closer to the goal relative to its
parent---then the $\vnew$ is greedily generated so as to be a
neighbor of $\vlast$ in the direction of the goal $T$ (Line~6).

\input{algo_drrtstar_expand}

In either case, the method next finds neighbors $N$, which
are adjacent to \vnew\ in $\mmgimp$ and have also been added to
$\tree$ (Line~7).  Among $N$, the best node \vparent is chosen, for 
which the local path $\local(\vparent, \vnew)$ is collision-free and 
that the total path cost to $\vnew$ is minimized (Line~8).  If no such 
parent can be found (Line~9), the expansion fails and no node is 
returned (Line~10).  Then, if $\vnew$ is not in $\tree$, it is added
(Lines~11-13).  Otherwise, if it exists, the tree is rewired so as to 
contain edge $(\vparent, \vnew)$, and the cost of the $\vnew$'s
sub-tree (if any) is updated (Lines~14,~15).  Then, for all nodes in
$N$ (Line~16), the method tests $\tree$ should be rewired through 
$\vnew$ to reach this neighbor.  Given that $\local(\vnew, v)$ is 
collision-free and is of lower cost than the existing path to $v$ 
(Line~17), the tree is rewired to make $\vnew$ be the parent of $v$ 
(line~18).

Finally, if in this iteration the heuristic value of $\vnew$ is 
lower than its parent node $\vparent$ (line 19), the method returns 
$\vnew$ (Line~20), causing the next iteration to greedily expand
$\vnew$.  Otherwise, $NULL$ is returned so as to do an exploration 
step.  Note that the approach is implemented with helpful 
branch-and-bound pruning after an initial solution is found, though
this is not reflected in the algorithmics.

\vnew\ is determined via an oracle function.  Using this oracle
function and a simple rewiring scheme is sufficient for showing
asymptotic optimality for $\drrtstar$ (see 
Section~\ref{sec:analysis}).  The oracle function $\oracle$ for a
two-robot case is illustrated in Figure \ref{fig:oracle}.  First, let
$\rho(Q,Q')$ be the ray from configuration $Q$ terminating at $Q'$.
Then, denote $\angle_{Q} (Q',Q'')$ as the minimum angle between
$\rho(Q,Q')$ and $\rho(Q,Q'')$.  When \qrand\ is drawn in $\ccross$,
its nearest neighbor \vnear\ in $\tree$ is found. Then, project the
points \qrand\ and \vnear\ into each robot space $\cspace_i$, i.e.,
ignore the configurations of other robots.


\begin{figure}[ht]
\centering
\includegraphics[height=1.45in]{oracle}
\caption{(A) The method reasons over all neighbors $q'$ of $q$ so as
  to minimize the angle $\angle_{q}(q', q'')$. (B)
  $\oracle(\cdot,\cdot)$ finds graph vertex \vnew by minimizing angle
  $\angle_{\vnear}(\vnew,\qrand)$. (C,D) \vnear and \qrand are
  projected into each robot's $\cspace$-space so as to find nodes
  $v^{\textup{new}}_{\textup{i}}$ and $v^{\textup{new}}_{\textup{j}}$,
  respectively, which minimize angle $\angle_{
    v^{\textup{near}}_{\textup{i/j}}}
  (v^{\textup{new}}_{\textup{i/j}}, q^{\textup{rand}}_{\textup{i/j}}
  )$.}
\label{fig:oracle}
\end{figure}

The method separately searches the single-robot roadmaps to discover 
\vnew. Denote $\vnear= (v_1,\ldots,v_R), \qrand= (\tilde{q}_1,\ldots,
\tilde{q}_R)$.  For every robot $i$, let $N_i\subset \nodes_i$ be the 
neighborhood of $v_i \in \nodes_i$, and identify $v'_i = 
\argmin_{v \in N_i} \angle_{v_i} (q^{rand}_i, v)$.  The oracle 
function returns node $\vnew = (v'_1,\ldots,v'_R)$.

\begin{figure}[ht]
\centering
\includegraphics[height=1.1in]{voronois}
\hspace{-0.2in}
\includegraphics[height=1.1in]{combined_vor}
\caption{(A) The Voronoi region $\textup{Vor}(V)$ 
of vertex $V$ is shown where if \qrand\ is drawn, vertex $V$ is 
selected for expansion. (B) When \qrand\ lies in the directional 
Voronoi region $\textup{Vor}'(V)$, the expand step expands to \vnew.  
(C) Thus, when \qrand\ is drawn within volume $\textup{Vol}(V) = 
\textup{Vor}(V) \cup \textup{Vor}'(V)$, the method will generate 
\vnew\ via $V$.}
\label{fig:voronoi}
\end{figure}


As in the standard $\rrt$ as well as in $\drrt$, the $\drrtstar$
approach has a Voronoi-bias property
~\cite{DBLP:conf/icra/LindemannL04}.  It is, however, slightly more
involved to observe as shown in Figure \ref{fig:voronoi}.  To generate
an edge $(V, V')$, random sample \qrand\ must be drawn within the
Voronoi cell of $V$, denoted $\textup{Vor}(V)$ (A) and in the general
direction of $V'$, denoted $\textup{Vor}'(V)$ (B).  The intersection
of these two volumes $\textup{Vol}(V) = \textup{Vor}(V) \cap
\textup{Vor}'(V)$ is the volume to be sampled generate \vnew\ via
\vnear.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../isrr"
%%% End:
