SNOPY presents a novel yet intuitive approach to optimizing
non-Cartesian sampling trajectories.
Via differentiable programming,
SNOPY enables applying gradient-based
and data-driven methods to trajectory design.
Various applications and in-vivo experiments
showed the applicability and robustness of SNOPY.

Experiments \ref{exp:freeform} and \ref{exp:sos} used training data to 
improve image quality
by trajectory optimization.
SNOPY can tailor the sampling trajectory to
specific training datasets and reconstruction algorithms
by formulating the reconstruction image quality as a training loss.
An accompanying question is
whether the learned sampling trajectories
could overfit the training dataset.
In experiment \ref{exp:sos},
the training set used an MP-RAGE sequence,
while the prospective sequence was an RF-spoiled GRE.
In a 2D experiment \cite{wang:22:bjork-tmi},
we found that trajectories learned with
one anatomy (brain), contrast (T1w),
and vendor (Siemens) still improved the image quality of
other anatomies (like the knee),
contrasts (T2w), and vendors (GE).
These empirical studies indicate that
trajectory optimization is robust to a 
moderate distribution shift between training and inference.
An intuitive explanation is that 
SNOPY can improve the PSF by reducing the aliasing,
and such improvement is universally beneficial.
In subsequent investigations
with more diverse datasets,
we plan to study the robustness of SNOPY in more settings.
For instance,
one may optimize the trajectories with healthy controls
and prospectively test the trajectories with pathological participants,
to examine the image quality of pathologies.
Testing SNOPY with different FOVs,
resolutions, and field strengths
will also be desirable.

An MRI system suffers from imperfections,
such as field inhomogeneity \cite{sutton:2003:FastIterativeImagea},
eddy currents \cite{ahn:1991:AnalysisEddycurrentInduced},
and gradient non-linearity \cite{hidalgo-tobon:2010:TheoryGradientCoil}.
Many correction approaches exist,
such as B0-informed reconstruction \cite{fessler:05:tbi}
and trajectory mapping \cite{duyn:1998:SimpleCorrectionMethod,robison:2019:CorrectionB0Eddy}.
SNOPY-optimized trajectories are compatible with these existing methods. 
For example, we implemented eddy-current correction
for a 2D freeform optimized trajectory in \citestd{wang:22:bjork-tmi}.
It is also possible to consider these perfections 
in the forward learning/optimization phase,
so the optimized trajectory
has innate robustness to imperfections.
For instance,
the forward system model \A in \eqref{eqn:image} could
include off-resonance maps.
This prospective
learning approach
will require prior knowledge of the
distribution of system imperfections,
which is usually scanner-specific and hard to simulate.
In future studies, we plan to investigate approaches
to simulate such effects prospectively.

SNOPY uses a relatively simplified model of PNS.
More precise models, such as \citestd{davids2019prediction},
may lead to improved PNS suppression results.

The training uses several loss terms,
including image quality, PNS suppression,
hardware limits, and image contrast.
By combining these terms,
the optimization can lead to trajectories that
boast multiple desired characteristics.
The weights of different loss terms were determined empirically.
One may control the optimization results by altering the coefficients.
For example, with a larger coefficient of the hardware constraint loss, the trajectory will better conform to \smax and \gmax.
Bayesian experiment design is also applicable to
finding the optimal loss weights.
Additionally,
the training losses (constraints)
may contradict each other,
and the optimization may get stuck in a local minimizer.
We considered several empirical solutions
to this problem.
Similar to SPARKLING \cite{sparklingmrm},
one may relax the constraint on maximum gradient strength
by using a higher receiver bandwidth.
Using SGLD can also help escape the local minima
because of its injected randomness.
One may also use a larger B-spline kernel width
to optimize the gradient waveform
in the early stages
of a coarse-to-fine search.

Trajectory optimization is a non-convex problem.
SNOPY uses several methods,
including effective Jacobian approximation,
parameterization, multi-level optimization, and SGLD,
to alleviate the non-convexity and lead to better optimization results.
Such methods were found to be effective in this and previous studies
\cite{wang:22:bjork-tmi,wang:21:eao}.
Initialization is also important
for non-convex problems.
SNOPY can take advantage of 
existing knowledge of MR sampling
as a benign optimization initialization.
For example,
our experiments used the well-received 
golden-angle stack-of-stars
and rotational EPI as optimization bases.
The SNOPY algorithm can continue to improve 
these skillfully designed trajectories 
to combine the best of both stochastic optimization
and researchers' insights.

SNOPY can be extended to many applications,
including dynamic and quantitative imaging.
These new applications may require 
task-specific optimization objectives in addition to
the ones described in \ref{subsec:obj}.
In particular,
if the reconstruction method
is not readily differentiable,
such as the  MR fingerprinting reconstruction
based on dictionary matching \cite{MRF},
one needs to design a surrogate objective
for image quality.

