In optimization,
the sampling trajectory is
embedded in the forward system matrix
within the similarity loss \eqref{eqn:image}.
The system matrix for non-Cartesian sampling
usually includes a NUFFT operation
\cite{fessler:03:nff}.
Updating the sampling trajectory
in each optimization step
requires the Jacobian, or the gradient w.r.t.
the sampling trajectory.
The NUFFT operator typically involves interpolation 
in the frequency domain,
which is non-differentiable in typical implementations
due to rounding operations.
Several previous works used auto-differentiation
(with sub-gradients)
to calculate an approximate
numerical gradient \cite{pilot,alush-aben:2020:3DFLATFeasible},
but that approach is inaccurate and slow \cite{wang:21:eao}.
We derived an efficient and accurate
Jacobian approximation method \cite{wang:21:eao}.
For example,
the efficient Jacobian of a forward system model \A is:
\begin{equation}
\frac{\partial \A\x}{\partial \omd} = -\imath \, \diag{\A (\x\odot\rd)}
\label{e,Ax}
,\end{equation}
where $d \in \{1,2,3\}$ denotes a spatial dimension,
and $\rd$ denotes the Euclidean spatial grid.
Calculating this Jacobian
simply uses another NUFFT, 
which is more efficient than the auto-differentiation approach.
See 
\citestd{wang:21:eao} for more cases,
such as $\frac{\partial \A'\A\x}{\partial \omd}$ and the detailed derivation.