\section{Phase I: Finding a Feasible Point} \label{sec:p1}

\revision{The feasible set of \eqref{eqn:2-26-7} is a polytope $\F(x_0) \subseteq \R^{m\tau}$, defined by the following inequalities in $\u$: \begin{subequations} \begin{align}
        H_s(M_0 x_0 + M_u \textbf{u}) &\leq \tilde{h}_s, \label{eqn:5-22-22-4}\\
        H_u \textbf{u} &\leq h_u \label{eqn:5-22-22-5}
    \end{align} \end{subequations} where $H_s,H_u,M_0,M_u,\tilde{h}_s,$ and $h_u$ are block matrices and vectors derived from the system dynamics and constraints}.
\revision{In this paper, we assume that $\F(x_0)$ \newrevision{has nonempty interior} for all $x_0 \in \S$. Since the state constraints $\S$ form an RCI, $\F(x_0)$ is already guaranteed to be nonempty, and the assumption of nonempty interior is only marginally more restrictive.} 

\revision{The gauge map technique introduced in \cite{Tabas2021a} provides a way to constrain the outputs of a neural network $\mu_\theta: \R^n \rightarrow \R^{m\tau}$ to $\F(x_0)$ without a projection or penalty function, but $\F(x_0)$ must contain the origin in its interior. If this is not the case, then we must temporarily ``shift'' $\F(x_0)$ by subtracting any one of its interior points. In this section, we discuss several ways to reduce the complexity of finding an interior point.}

\revision{We begin by considering the feasibility problem for the one-step safe action set defined as $\V(x_0) = \{u \in \R^m \mid u \in \U, Ax_0 + Bu \in \T\},$ which is guaranteed to have an interior point by the assumption on $\F(x_0).$ \newrevision{One way to find an interior point of $\V(x_0)$ is to minimize the maximum constraint violation:}} \begin{subequations} \label{eqn:3-17-3} \begin{gather}
    \min_{u,s} s \label{eqn:8-23-22-1}\\
    \text{subject to: } F_s(Ax_0 + Bu) \leq \tilde{g}_s + s\textbf{1} \label{eqn:5-24-22-1}\\
    F_u u \leq g_u + s\textbf{1} \label{eqn:5-24-22-2}
\end{gather} \end{subequations} \revision{which has an optimal cost $s^* \leq 0$ if \newrevision{$\V(x_0)$ is nonempty}, and $s^* < 0$ if \newrevision{$\V(x_0)$ has nonempty interior} \cite{Boyd2009}. To avoid solving a linear program online during closed-loop implementation, the solution to \eqref{eqn:3-17-3} can be stored as a piecewise affine (PWA) function $\pi_0(x_0):\R^n \rightarrow \R^m$ \cite{Jones2007}. Although solutions to multiparametric LPs can be demanding on computer memory, we take advantage of the fact that feasibility problems have low accuracy requirements: any \newrevision{suboptimal} solution to \eqref{eqn:3-17-3} that achieves a cost $s < 0$ for all $x_0 \in \S$ is acceptable.
}
\newrevision{ \begin{definition}
A function $\pi_0: \R^n \rightarrow \R^m$ is said to solve \eqref{eqn:3-17-3} if,  for all $x_0 \in \S$, the optimal cost of \eqref{eqn:3-17-3} is negative when the decision variable $u$ is fixed at $\pi_0(x_0)$. 
\end{definition}}

\revision{Existing techniques for approximate multiparametric linear programming \cite{Filippi2004}, especially those that generate continuous solutions \cite{Spjotvold2005}, can be used to reduce the memory requirements of offline solutions to \eqref{eqn:3-17-3}.} 

\ifx
\newrevision{To characterize the set of allowable approximations to the optimal solution of \eqref{eqn:3-17-3}, we pose the following feasibility problem: \begin{align}
    \min_{u,s} 0
    \text{ s.t. } s < 0, \eqref{eqn:5-24-22-1}, \eqref{eqn:5-24-22-2}. \label{eqn:8-24-22-1}
\end{align} We will say that a function $\pi_0$ solves \eqref{eqn:8-24-22-1} if $\pi_0(x_0)$ solves \eqref{eqn:8-24-22-1} for all $x_0 \in \S$.}
\fi

\revision{To show just how far one can go with reducing complexity, we will construct an affine (rather than PWA)} 
%\newrevision{approximate} solution to \eqref{eqn:3-17-3} \newrevision{achieving negative cost \eqref{eqn:8-23-22-1} 
\newrevision{function that solves \eqref{eqn:3-17-3},} 
\revision{for the system studied in Section \ref{sec:sims}.} 
Let $\pi_0(x_0) = Wx_0 + w$. If $W \in \R^{m \times n}$ and $w \in \R^m$ satisfy
\begin{subequations} \label{eqn:3-17-1}
\begin{align}
    F_x(Ax_0 + B(Wx_0+w)) &< \tilde{g}_x \\
    F_u (Wx_0+w) &< g_u 
\end{align} \end{subequations} for all $x_0 \in \S$, then $\pi_0(x_0) = Wx_0 + w$ \newrevision{solves \eqref{eqn:3-17-3}}. %returns an interior point of $\V(x_0)$ for all $x_0 \in \S$. 
\newrevision{The following optimization problem} can be solved to find $W$ and $w$ or certify that none exists. Let $\Y(s) = \{x_0 \in \R^n \mid F_s(Ax_0 + B(Wx_0+w)) \leq \tilde{g}_s + s \textbf{1}, F_u (Wx_0 + w) \leq g_u + s \textbf{1}\}.$ \newrevision{If the optimal cost of} \begin{gather}
    \min_{W,w,s} s 
    \text{ subject to } \newrevision{\S} \subseteq \Y(s) \label{eqn:3-17-4}
\end{gather} \newrevision{is negative, then %$x_0 \in \Y(s^*)$ for all $x_0 \in \S$, thus
\eqref{eqn:3-17-1} holds for all $x_0 \in \S$, thus $\pi_0$ solves \eqref{eqn:3-17-3}. This happens to be the case for the example in Section \ref{sec:sims}, taken from \cite{Zeilinger2011}}. The constraint in \eqref{eqn:3-17-4} is a polytope containment constraint in halfspace representation, \newrevision{thus \eqref{eqn:3-17-4} can be solved as} a linear program \cite{Sadraddini2019}.

\revision{Now consider the feasibility problem for $\F(x_0)$, which is obtained by replacing \eqref{eqn:5-24-22-1} and \eqref{eqn:5-24-22-2} with \eqref{eqn:5-22-22-4} and \eqref{eqn:5-22-22-5}, and changing the optimization variable from $u \in \R^m$ to $\u \in \R^{m\tau}$. One would naturally expect the complexity of the PWA solution to this feasibility problem to increase rapidly with the time horizon $\tau$, as more decision variables and constraints are added. However, the next proposition shows that the cardinality of the stored partition can be made constant in $\tau$.}
\revision{\begin{proposition}[Phase I solution] \label{prop:2-27-1} If $\pi_0$ \newrevision{solves \eqref{eqn:3-17-3},} then the \newrevision{vector $\mu_0(x_0) := \m{\pi_0(x_0)^T,\ldots,\pi_0(x_{\tau-1})^T}^T$}, where $x_{k+1} = Ax_k + B \pi_0(x_k)$, is an interior point of $\F(x_0)$ for any $x_0 \in$ \newrevision{$\S$}.
\end{proposition}
\begin{proof} \newrevision{If $\pi_0$ solves \eqref{eqn:3-17-3}, then $\pi_0(x) \in \int \V(x)$ for all $x \in \S$. Applying the definition of $\V$ in an inductive argument,} it is straightforward to show that the \newrevision{state trajectory associated with $\mu_0(x_0)$ is entirely contained } %policy $\pi_0$ generates trajectories
in $\S$. Fix any such trajectory $\{x_1,\ldots,x_\tau\} \subset \S$ originating from $x_0 \in \S$ under policy $\pi_0$. For any $k \in \{1,\ldots,\tau\}$, \newrevision{$x_k \in \S$ implies $\pi_0(x_k) \in \int \V(x_k)$, which} implies $\pi_0(x_k) \in \int \U$ and $Ax_k + B\pi_0(x_k) \in \int \T$. Since this holds for all $k$, the constraints defining $\F(x_0)$ hold strictly at $\mu_0(x_0)$. %We conclude $\mu_0(x_0) \in \int \F(x_0)$.
%Using induction and the definition of $\V$, it is straightforward to show that if $x_0 \in \S$ then $\pi_0$ generates a trajectory in $\S$. For any trajectory $\{x_0,\ldots,x_\tau\} \subset \S,$ the Cartesian product $\V(x_0) \times \cdots \V(x_{\tau-1})$ is nonempty and contains $\mu_0(x_0)$ in its interior. By the definition of $\V$, this product set is a subset of $\F(x_0),$ thus $\mu_0(x_0) \in \int \F(x_0).$
%For any $x_k \in \S, k \in \{0,\ldots,\tau-1\},$ we have $\pi_0(x_k) \in \int \V(x_k),$ implying $x_{k+1} := Ax_k + B \pi_0(x_k) \in \int \T \subset \S$. Since $x_0 \in \S$, we conclude from induction that $\pi_0$ generates trajectories in $\S$. Therefore, $\pi_0(x_k) \in \int \U$ and $Ax_k + B\pi_0(x_k) \in \int \T$ for all $k$. We conclude that $\mu_0(x_0) \in \int \F(x_0)$. 
\end{proof}}

%Proposition \ref{prop:2-27-1} removes dependence on the length of the time horizon $\tau$ but leaves unanswered the question of how to find an interior point of $\V(\cdot)$. Next, we show how to construct an affine or PWA function $\phi$, which returns such an interior point. Unsurprisingly, the approximation $\phi$ is of substantially lower complexity than a PWA solution to \eqref{eqn:2-26-7}, since it is often significantly easier to find a feasible control action compared to the optimal action. 

% in the sense of Proposition \ref{prop:2-27-1}.

%Let $\phi_{\text{affine}}(x) = Wx + w$ where $W \in \R^{m \times n}$ and $w \in \R^m$, and let $\Y(s) = \{x \in \R^n \mid F_x(Ax + B \phi_{\text{affine}}(x)) \leq \tilde{g}_x + s \textbf{1},\ F_u \phi_{\text{affine}}(x) \leq g_u + s\textbf{1}\}.$

%If $s^* \geq 0,$ then $\phi$ cannot be expressed as an affine function. In that case, we can increase its complexity by expressing it as a PWA function generated by solving the following multiparametric linear programming (mpLP) problem over the parameter set $x \in \X$: 

%Solving the mpLP \eqref{eqn:3-17-3} is substantially more efficient than solving \eqref{eqn:2-26-7} because \eqref{eqn:3-17-3} has a linear cost, lower accuracy requirement, and a factor of $\tau$ fewer decision variables and constraints. 
In our simulations on the example from \cite{Zeilinger2011},  $\eqref{eqn:3-17-4}$ was feasible with negative optimal cost, \newrevision{meaning that a polyhedral partition of the state space was not needed}
%i.e only one region was needed
(see Section \ref{sec:sims}). This indicates that the minimum number of regions \newrevision{in a polyhedral state space partition associated with a PWA
%to find an admissible 
solution to \eqref{eqn:3-17-3}} is in general very small relative to the number of regions in an explicit solution to \eqref{eqn:2-26-7}. %\todo{Say something about in our simulation how many pieces was needed. E.g., linear function was successful or only one piece.} 
%Any technique for approximate mpLP (e.g. \cite{Filippi2004,Spjotvold2005} and the references therein) can solve \eqref{eqn:3-17-3}.

\section{Phase II: Optimizing Performance} \label{sec:p2}

In this section, we construct a class of policies from $x_0 \in \S$ to $\F(x_0)$, that can be trained using standard machine learning packages. Although it is difficult to constrain the output of a neural network to an arbitrary polytope such as $\F(x_0)$, it is easy to constrain the output to the hypercube $\B_\infty$ by applying a clamping function elementwise in the output layer. We apply a mapping between polytopes that is closed-form, differentiable, and bijective. This mapping establishes an equivalence between $\B_\infty$ and $\F(x_0)$, allowing one to constrain the outputs of the policy to $\F(x_0)$. The mapping from $\B_\infty$ to $\F(x_0)$ is called the \textit{gauge map}. The concept is illustrated in Figure \ref{fig:nn_diagram}. 

\begin{figure}
    \centering
    \includegraphics[width=7cm]{Figures/nn_diagram.png}
    \caption{The proposed control policy uses a neural network combined with the Phase I solution and a \textit{gauge map} to constrain the decision $\u$ to the MPC feasible set $\F(x_0)$. The first action from the sequence $\u$ is extracted and implemented. On the right, the action of the gauge map is illustrated.}
    \label{fig:nn_diagram}
\end{figure}

We begin constructing the gauge map by introducing some preliminary concepts. A \textit{C-set} is a convex, compact set that contains the origin as an interior point. The \newrevision{\textit{gauge function} with respect to C-set $\P \subset \R^n$, denoted $\gamma_{\P}: \R^n \rightarrow \R_+$, is the function whose sublevel sets are scaled versions of $\P$. Specifically,} the gauge of a vector $v$ with respect to $\P$ is given by $\gamma_\P(v) = \inf\{\lambda \geq 0 \mid v \in \lambda \P\}.$ If $\P$ is a polytopic C-set given by $\{v \in \R^k \mid Fv \leq g\}$, then \newrevision{$\gamma_{\P}$ is the pointwise maximum over a finite set of affine functions \cite{Tabas2021a}:} \begin{align} \gamma_\P(v) = \max_i \frac{F^{(i)T}v}{g^{(i)}}. \label{eqn:5-25-22-2} \end{align} %\cite{Tabas2021a}. 
%The gauge function of a point in the $\infty$-norm ball $\B_\infty$ is the $\infty$-norm of the point, i.e. $\gamma_{\B_\infty}(\cdot) = \|\cdot\|_\infty$. 
Given two C-sets $\P$ and $\Q$, the \textit{gauge map} $G: \P \rightarrow \Q$ is %defined as 
\begin{align} G(v \mid \P,\Q) = \frac{\gamma_\P(v)}{\gamma_\Q(v)} \cdot v. \label{eqn:3-21-1} \end{align} 
\newrevision{This function maps level sets of $\gamma_{\P}$ to level sets of $\gamma_{\Q}$.}
%\revision{The gauge map from $\P$ to $\Q$ applies a scaling factor to points in $\P$ such that the image of any level set of $\gamma_{\P}$ under the gauge map is equal to the corresponding level set of $\gamma_{\Q}$. }

\begin{proposition} \label{prop:2-27-2}
Given two polytopic C-sets $\P$ and $\Q$, the gauge map $G: \P \rightarrow \Q$ is subdifferentiable and bijective. Further, given a function $\pi_0$ from Proposition \ref{prop:2-27-1}, the set $\tilde{\F}(x) := [\F(x)-\pi_0(x)]$ is a C-set for all $x \in \S$.
\end{proposition}

\begin{proof}
The properties of subdifferentiability and bijectivity come from \cite{Tabas2021a}. For the C-set property, fix $x \in \S$. Since $\S,$ $\U,$ and $\D$ are convex and compact, so is $\F(x)$. Since $\mu_0(x)$ is an interior point of $\F(x),$ the set $\tilde{\F}(x)$ contains the origin as an interior point and is therefore a C-set.
\end{proof}

We now use the gauge map in conjunction with the Phase I solution to construct a neural network whose output is confined to $\F(x_0).$
%present a novel class of functions with superior flexibility to approximate the solution to \eqref{eqn:2-26-7}. 
%From there, the gauge map and Phase I solution will map the output to $\F(x_t)$.
Let $\psi_\theta: \S \rightarrow \B_\infty$ be a neural network parameterized by $\theta$. \revision{A safe policy is constructed by composing the gauge map $G: \B_\infty \rightarrow \tilde{\F}(x_0)$ with $\psi_\theta$, then adding $\mu_0(x_0)$ to map the solution into $\F(x_0)$:}%, and define $\mu_\theta: \S \rightarrow \F(x_0)$ as 
\begin{align}
    \mu_\theta(x_0) = G(\cdot \mid \B_\infty, \tilde{\F}(x_0)) \circ \psi_\theta(x_0)  + \mu_0(x_0). \label{eqn:3-24-1}
\end{align} \revision{Computing the gauge map online simply requires evaluating $H_s M_0 x_0$ from \eqref{eqn:5-22-22-4} as well as the operations in \eqref{eqn:5-25-22-2}.}

The function $\mu_\theta$ has several important properties for approximating the optimal solution to \eqref{eqn:2-26-7}. First, it leverages the universal function approximation properties of neural networks \cite{Hornik1989} along with the bijectivity of the gauge map (Proposition \ref{prop:2-27-2}) to explore all interior points of $\F(x_0).$ This is an advantage over projection-based methods \cite{Chen2018d} which may be biased towards the boundary of $\F(x_0)$ when the optimal solution may lie on the interior. Second, $\mu_\theta$ is evaluated in closed form, and its outputs are constrained to $\F(x_0)$ without the use of an optimization layer \cite{Maddalena2020} that may have high computational overhead. Finally, the subdifferentiability of the gauge map (Proposition \ref{prop:2-27-2}) enables selection of parameter $\theta$ using standard automatic differentiation techniques.

%The class $\Pi$ inherits the property of universal function approximation from standard feedforward neural networks with ReLU activation functions \cite{Hornik1989}, and since the range of all functions in $\Pi$ is constructed to be exactly the feasible set of \eqref{eqn:2-26-7} for any initial condition $x_t \in \X$, the class $\Pi$ can approximate any feasible policy.

%and, by Proposition \ref{prop:2-27-2}, inherits the approximation capabilities of $\psi_\theta$. 
\subsection*{Optimizing the parameter $\theta$}

Similar to the approach taken in \cite{Akesson2006}, we optimize $\theta$ by sampling $x \in \S$ and applying stochastic gradient descent. At each iteration, a new batch of initial conditions $\{x_0^j\}_{j=1}^M$ is sampled from $\S$ and the loss is computed as \begin{align}
    J(\theta) = \frac{1}{M} \sum_{j=1}^M \sum_{k=0}^{\tau-1} l(x_k^j,u_k^j) + l_F(x_{\tau}^j) \label{eqn:2-27-10}
\end{align} with the control sequences $\u^j$ given by $\mu_\theta(x_0^j)$ and state trajectories $\x^j$ generated according to the nominal dynamics. \revision{The parameters $\theta$ are updated in the direction of $\nabla_\theta J$, which is easily computed using automatic differentiation~\cite{Gune2018}.}

%where $\hat{\u}^j_t = \pi_\theta(x^j)$, $\hat{x}_{k+1}^j = A\hat{x}_k^j + B\hat{u}_k^j,$ and $\hat{x}_0^j = x^j$.