\documentclass{article}

\usepackage{times}
\pdfpagewidth=8.5in
\pdfpageheight=11in
\usepackage{ijcai18}

\usepackage{siddmath}
\usepackage[ruled,vlined]{algorithm2e}
%\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{hhline}
\usepackage{paralist}
\usepackage{fancyhdr}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage[small]{caption}

\newcommand{\absai}{$\mathcal{\tilde{D}}_{AI}$}
%\nocopyright

\renewcommand{\headrulewidth}{0pt}
\newcommand{\?}{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {\small ?}}}}

%% \title{Dynamic Hierarchical Abstractions for Solving Large MDPs\thanks{This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center Pacific (SSC Pacific) under Contract No. N66001-16-C-4050. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the DARPA or SSC Pacific.}}
%% \author{Siddharth Srivastava$^\ddagger$, Nishant Desai$^\dagger$, Richard Freedman$^\mathsection$, Shlomo Zilberstein$^\mathsection$  \\ 
%% $^\ddagger$Arizona State University, $^\dagger$United Technologies Research Center, $^\mathsection$University of Massachusetts}
\title{An Anytime Algorithm for Task and Motion MDPs} % \thanks{This
  % material is based upon work supported by the Defense Advanced
  % Research Projects Agency (DARPA) and Space and Naval Warfare Systems
  % Center Pacific (SSC Pacific) under Contract
  % No. N66001-16-C-4050. Any opinions, findings and conclusions or
  % recommendations expressed in this material are those of the authors
  % and do not necessarily reflect the views of the DARPA or SSC
  % Pacific.}
\author{Siddharth Srivastava\thanks{Some of the work was done while this author as at United Technologies Research Center}$^\ddagger$, Nishant Desai$^\dagger$, Richard Freedman$^\mathsection$, Shlomo Zilberstein$^\mathsection$  \\
  $^\ddagger$Arizona State University, $^\dagger$United Technologies
  Research Center, $^\mathsection$University of Massachusetts}
%\author{Paper ID 3843}

\begin{document}
\maketitle

\begin{abstract}
  Integrated task and motion planning has emerged as a challenging
  problem in sequential decision making, where a robot needs to
  compute high-level strategy and low-level motion plans for solving
  complex tasks. While high-level strategies require decision making
  over longer time-horizons and scales, their feasibility depends on
  low-level constraints based upon the geometries and continuous
  dynamics of the environment. The hybrid nature of this problem makes
  it difficult to scale; most existing approaches focus on
  deterministic, fully observable scenarios.  We present a new
  approach where the high-level decision problem occurs in a
  stochastic setting and can be modeled as a Markov decision
  process. In contrast to prior efforts, we show that complete MDP
  policies, or contingent behaviors, can be computed effectively in an
  anytime fashion. Our algorithm continuously improves the quality of
  the solution and is guaranteed to be probabilistically complete. We
  evaluate the performance of our approach on a challenging, realistic
  test problem: autonomous aircraft inspection. Our results show that
  we can effectively compute consistent task and motion policies for
  the most likely execution-time outcomes using only a fraction of the
  computation required to develop the complete task and motion
  policy.
\end{abstract}

\input{intro}

\input{background}

\input{formal}

\input{alg}

\input{empirical}

\input{related}

\input{conclusions}



\section*{Acknowledgements}
This  material is based upon work supported by the Defense Advanced
  Research Projects Agency (DARPA) and Space and Naval Warfare Systems
  Center Pacific (SSC Pacific) under Contract
  No. N66001-16-C-4050. Any opinions, findings and conclusions or
  recommendations expressed in this material are those of the authors
  and do not necessarily reflect the views of the DARPA or SSC
  Pacific.
\bibliographystyle{named}
\bibliography{planning}

\end{document}
