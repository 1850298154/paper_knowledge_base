\section{Other Related Work}
\label{sec:related}
There has been a renewed interest in integrated task and motion planning algorithms. Most research in this direction has been focused on deterministic environments~\citep{cambon09_asymov,plaku10_sampling,dornhege12_semantic,kaelbling11_hierarchical,garrett15_ffrob,dantam16_incremental}. \cite{kaelbling13_hpnPOMDP} consider  a partially observable formulation of the problem. Their approach utilizes regression modules on belief fluents to develop a regression-based solution algorithm. \cite{sucan12_tmp_mdp} use an explicit multigraph to represent the plan or policy for which motion planning refinements are desired.  \cite{hadfield15_modular} address problems where the high-level formulation is deterministic and the low-level is determinized using most likely observations. In contrast, our approach employs abstraction to bridge MDP solvers and motion planners to solve problems where the high-level model is stochastic. In addition, the transitions in our MDP formulation depend on properties of the refined motion planning trajectories (e.g., battery usage). 

Principles of abstraction in MDPs have been well studied~\citep{hostetler14_state,bai16_markovian,li06_abstractMDP,singh95_abstractRL}. However, these directions of work assume that the full, unabstracted MDP can be efficiently expressed as a discrete MDP. \cite{marecki06_cmdp} consider continuous time MDPs with finite sets of states and actions. In contrast, our focus is on MDPs with high-dimensional, uncountable state and action spaces. Recent work on deep reinforcement learning  (e.g., \citep{hausknecht16_iclr,mnih15_drl}) presents  approaches for using deep neural networks in conjunction  with reinforcement learning to solve MDPs with continuous state spaces. We believe that these approaches can be used in a complementary fashion with our proposed approach. They could be used to learn maneuvers spanning shorter-time horizons, while our approach could be used to efficiently abstract their representations and to use them as actions or macros in longer-horizon tasks. 

Efforts towards improved representation languages are orthogonal to our contributions~\citep{fox02_pddl+}. The fundamental computational complexity results indicating growth in complexity with increasing sizes of state spaces, branching factors, and time horizons remain true regardless of the solution approach taken. It is unlikely that a uniformly precise model, a simulator at the level of precision of individual atoms, or even circuit diagrams of every component used by the agent will help it solve the kind of complex tasks on which humans would appreciate assistance. On the other hand, not using any model at all would result in dangerous agents that would not be able to safely evaluate the possible outcomes of their actions. Our results show that these divides can be bridged using hierarchical modeling and solution approaches that simplify the representational requirements and offer computational advantages that could make autonomous robots feasible in the real world. 

