In  this  section,  we  evaluate the  proposed algorithms on dense instances.
% 
All experiments are performed on an Intel\textsuperscript{\textregistered} Core\textsuperscript{TM} i7-9700 CPU at 3.0GHz.
% 
We compare the proposed methods with \ecbs($w=1.5$)\cite{barer2014suboptimal} and \ddm~\cite{han2019ddm}.
% Each data point is an average over 20 runs on randomly generated instances, unless otherwise stated.
%
All algorithms are implemented in C++.
% 
We evaluate the makespan, \soc, computation time, and success rate on a diverse set of maps and under different robot density levels.
% 
We repeated each experiment 20 times for each specific setting using different randomly generated instances for the agents, and report the mean values.
% 
Each algorithm is given 60 seconds time limit for each instance and the success rate is the number of solved instances divided by the total number of instances.  
% 
% A video of the simulation can be found at \url{https://youtu.be/XPpOB5f7CzA}.%temporary video
The source code and evaluation data associated with this research will be made available at \url{https://github.com/arc-l/dcbs}. 

\subsection{Evaluation on globally dense instances}
In this section, we evaluate \decbs on different maps with different high robot densities.
% 
Here, the starts and goals are \emph{uniformly} randomly generated.
% 
We evaluate the algorithms on three maps as shown in Fig.~\ref{fig:maps_used}.
% 
The results are presented in Fig.~\ref{fig:20x20_data}-\ref{fig:lak103_data}.
% 
Here, we tested three variants of \decbs.
% 
They differ in the strategy used to start database conflict resolution.
% 
\decbs(NOC=20) applies the database conflict resolution  when \noc of the high-level node drops below 20 and uses $w_2=\infty$.
% 
\decbs(POC=$10\%$) applies the database conflict resolution when the ratio of the \noc of the current node to the \noc of the initial node  is less than $10\%$ and uses $w_2=\infty$. 
% 
\decbs($w_2=2$) applies the database conflict resolution when it finds that the \noc enters stagnation for 100 iterations and uses $w_2=2$.
% 
Here for \decbs($w_2=2$), we check the \makespan suboptimality. 
% 
\begin{figure}[h!]
    \centering
      \begin{overpic}               
        [width=\columnwidth]{./figures/maps_used.pdf}
             \small
             \put(15.5, -3) {(a)}
             \put(48.5, -3) {(b)}
             \put(81.5, -3) {(c)}
        \end{overpic}
    \vspace{1mm}
    \caption{The map used in the evaluation. (a) $20\times 20$ empty grid graph. (b) $24\times 18$ warehouse-like map. It has 360 non-blocked vertices. (c) $24\times 24$ ``lak103" game map adapted from DAO benchmarks \cite{stern2019mapf}. It has 293 non-blocked vertices.}
    \label{fig:maps_used}
    \vspace{2mm}
\end{figure}% 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./figures/20x20_data-e.pdf}
    \caption{Performance (computation time, conservative makespan optimality ratio, conservative sum-of-cost optimality ratio, and success rate) on $20\times 20$ empty grid graph (Fig.~\ref{fig:maps_used}(a)) for DDM, ECBS, multiple \decbs variants. \decbs with $w_2 = 2$ scales much better than ECBS without losing much optimality guarantee. \decbs with POC- and NOC-based heuristics achieves an excellent balance between computation time and solution optimality.}
    \label{fig:20x20_data}
    \vspace{2mm}
\end{figure}% 
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./figures/warehouse_data-e.pdf}
    \caption{Performance (computation time, conservative makespan optimality ratio, conservative sum-of-cost optimality ratio, and success rate) on the warehouse map (Fig.~\ref{fig:maps_used}(b)) for DDM, ECBS, multiple \decbs variants. All \decbs variants achieve an excellent balance between computation time and solution optimality compared to DDM and ECBS; \decbs with $w_2 =2$ does especially well.}
    \label{fig:warehouse_data}
    \vspace{2mm}
\end{figure}% 
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./figures/lak103_data.pdf}
    \caption{Performance (computation time, conservative makespan optimality ratio, conservative sum-of-cost optimality ratio, and success rate) on the DAO gamp map (Fig.~\ref{fig:maps_used}(c)) for DDM, ECBS, multiple \decbs variants. \decbs still does reasonably well in balancing solution computation speed and optimality.}
    \label{fig:lak103_data}
    \vspace{2mm}
\end{figure}% 
% 
From the experimental data, we observe that the \makespan and \soc suboptimality ratio of \decbs variants are much better than \ddm.
% 
When enabling the suboptimality checking mechanism, the suboptimality ratio of \decbs is around $1.x$, which is quite acceptable.
% 
On the other hand, \decbs variants and \ddm are more scalable than \ecbs and thus yield a higher success rate.
% 
On the empty grid and the warehouse map, the success rate of \decbs variants is almost always $100\%$, capable of tackling instances with robot density more than $60\%$-$70\%$.
% 
On the  DAO map that is more complex and has some narrow passages, \decbs  is still able to solve more instances than \ecbs.
% 
Despite the lower success rate, the suboptimality checking mechanism is essential to preserve the solution quality.
% 

\subsection{Evaluation on locally dense instances}
In this section, we evaluate \secbs with DDM, ECBS, and \secbs in two classes of locally dense instances, named multi-robot rearrangement and Gaussian distributed \mpp instance.
% 
To generate a Gaussian distributed \mpp instance,  for each point, we generate a 2D vector $(\lfloor x \rfloor,\lfloor y\rfloor)$ where $x,y\sim \mathcal{N}(0,\sigma^2)$ if point $(\lfloor x \rfloor,\lfloor y\rfloor)$ has not been used yet.
% 
In the first class, the robots are randomly concentrated in the lower-left corner square area in start/goal configurations (e.g., the top row of Fig.~\ref{fig:dense_example}).
% 
In the second class, the configurations are generated following a two-dimensional normal distribution with $\sigma=5$. 
% 
In both classes, the graph size can be arbitrarily large (we set a sufficiently large boundary in the actual implementation).
% 

The results are shown in Fig.~\ref{fig:rearrangement}-\ref{fig:gauss}.
% 
In the first class (rearrangement), robots are so strongly-correlated that \ecbs struggles to solve instances with more than 36 robots.
% 
\secbs($\rho^{*}=50\%$) yields $100\%$ success rate and is able to deal with 100+ robots.
% 
The unlabeled \mpp only introduces small overheads to the solution, and the suboptimality ratio of \secbs is around $1.x$-$2.x$.
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{figures/rearrangement_data.pdf}
    \caption{Performance (computation time, conservative makespan optimality ratio, conservative sum-of-cost optimality ratio, and success rate) on multi-robot rearrangement settings (e.g., the top row of Fig.~\ref{fig:dense_example}) for DDM, ECBS, \decbs, and \secbs. Whereas \decbs does better than DDM and ECBS, \secbs leaves all methods far behind in achieving an excellent balance between optimality and computational efficiency.}
    \label{fig:rearrangement}
    \vspace{2mm}
\end{figure}% 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{./figures/gauss_data.pdf}
    \caption{Performance (computation time, conservative makespan optimality ratio, conservative sum-of-cost optimality ratio, and success rate) on Gaussian distributed \mpp instances for DDM, ECBS, \decbs, and \secbs. Again, \secbs trades very nicely between scalability and solution optimality.}
    \label{fig:gauss}
    \vspace{2mm}
\end{figure}% 


