\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Modern workloads often demand three properties from concurrent queues
simultaneously: (1) unbounded capacity, to absorb bursty or
unpredictable workloads without artificial limits; (2) strict FIFO
ordering, so elements are dequeued in the exact order they were
enqueued, regardless of which thread performs the operation; and (3)
scalable performance, so per-operation cost remains constant as thread
count grows, with lock-free progress ensuring one operation never stalls
another.

Despite decades of research, existing non-blocking (lock-free or
wait-free) queue algorithms still trade among throughput, ordering, and
memory safety. High-throughput designs often relax FIFO ordering or
impose fixed capacity. A central obstacle is the ABA problem: when a
thread reads a value A, another thread changes it to B and then back to
A, and the first thread later performs a CAS that succeeds under the
false assumption that nothing has changed. This hazard can cause stale
pointers to be mistaken for valid ones, leading to use-after-free (UAF)
errors or corrupted states in both linked and array-based designs.
Preventing ABA without prohibitive synchronization remains a major
challenge, especially in unbounded queues where nodes are frequently
allocated and freed.

We introduce Cyclic Memory Protection (CMP), a fully lock-free queue
where enqueue, dequeue, and reclamation proceed concurrently without
blocking or coordination. CMP provides formal safety guarantees,
tolerates stalled or failed threads without delaying progress, and makes
the following contributions:

\begin{itemize}
\tightlist
\item
  \textbf{Lock-free progress with unbounded capacity.} Supports bursty
  and unpredictable workloads without artificial limits.
\item
  \textbf{Strict FIFO ordering.} Preserves the exact global enqueue
  order across all threads, regardless of which thread performed the
  enqueue.
\item
  \textbf{Scalable performance.} Achieves constant per-operation cost
  under contention.
\item
  \textbf{Memory safety.} Provides formal guarantees against ABA and UAF
  hazards.
\item
  \textbf{Bounded reclamation.} Provides guaranteed reclamation within
  finite cycles, unlike hazard pointers or epoch-based schemes that may
  indefinitely retain nodes.
\item
  \textbf{Fault tolerance.} Ensures progress and reclamation despite
  stalled or failed threads, without global pauses or manual cleanup.
\end{itemize}

To our knowledge, no existing production-ready queue achieves all of
these properties together with comparable performance and scalability.

\hypertarget{background-and-prior-work}{%
\section{Background and Prior Work}\label{background-and-prior-work}}

\hypertarget{history-of-lock-free-queues}{%
\subsection{History of Lock-Free
Queues}\label{history-of-lock-free-queues}}

The Michael and Scott linked-list queue \citep{michael1996simple}
introduced a simple, lock-free, multi-producer/multi-consumer design
that remains a template for many modern concurrent queues. While it
solved the basic synchronization problem, it left a critical correctness
gap: the ABA problem.

For nearly a decade, lock-free queues saw limited adoption due to unsafe
memory management. Deployment required either accepting memory leaks,
relying on garbage-collected languages, or adopting ad hoc, often unsafe
schemes. In 2004, Maged Michael, one of the original queue's authors,
introduced hazard pointers \citep{michael2004hazard}, the first widely
adopted reclamation scheme for lock-free data structures. This was
followed by a series of other reclamation techniques, each attempting to
address the limitations of its predecessors.

\hypertarget{memory-reclamation-and-coordination-complexity}{%
\subsection{Memory Reclamation and Coordination
Complexity}\label{memory-reclamation-and-coordination-complexity}}

Michael's hazard pointers prevents ABA problems by requiring threads to
publish the pointers they are currently accessing in shared hazard
pointer slots. Before reclaiming any retired object, a thread must scan
all hazard pointer slots across all threads to ensure no other thread
holds a reference. This requires \(O(P \times K)\) comparisons per
reclamation pass, where \texttt{P} is the number of threads and
\texttt{K} is the number of hazard slots per thread. This scan
introduces coordination costs that scale linearly with \texttt{P}, and
frequent updates to hazard slots can cause cache-line contention and
memory-barrier overheads that can be prohibitive under modern multicore
systems with hundreds or even thousands of threads.

These coordination bottlenecks and overheads motivated alternative
approaches including Quiescent-State-Based Reclamation (QSBR)
\citep{mckenney1998read}, reference counting schemes
\citep{valois1995lock}, tagged pointer approaches \citep{ibm1983system},
Pass The Buck methods \citep{herlihy2005ptb}, Epoch-Based Reclamation
(EBR), distributed epoch-based techniques like DEBRA
\citep{brown2015reclaiming} and more. However, each of these approaches
either introduces different coordination overheads, suffers from
unpredictable reclamation delays, or faces fundamental scalability
limitations as thread counts increase.

Epoch-Based Reclamation (EBR) batches retired nodes into epochs and
reclaims only after all threads advance past the target epoch. This
amortizes coordination to \texttt{O(P)} but makes reclamation depend on
the slowest (or crashed) thread, causing unbounded retention; if
allocation or reclamation lies on the hot path, this can impede
system-level lock-free progress under stalls. Distributed variants such
as DEBRA reduce overhead with per-thread retire lists and lighter
synchronization, but reclamation still requires every thread to pass a
quiescent state, so a stalled participant can delay frees
\citep{brown2015reclaiming}.

QSBR/RCU rely on application quiescent points; they work well when
threads cooperate, but guarantees weaken outside that model
\citep{mckenney1998read}. Reference counting prevents use-after-free but
not ABA under reuse and also adds per-access atomic overhead
\citep{valois1995lock}. Tagged/sequence pointers help detect stale CAS
values (ABA) but do not prevent premature reuse; larger tags reduce
wraparound risk at the cost of wider atomics and still require a
reclamation mechanism \citep{michael2004hazard, brown2015reclaiming}.

Beyond the raw costs, threads must constantly validate that their
protection remains valid, handle failures gracefully, and maintain
complex retry state machines. The overhead of these coordination-heavy
protocols exceeds that of the core queue operations themselves, making
memory safety more expensive than the data structure it protects.
Schemes like reference counting, although based on a different design,
incurs high per-access atomic overhead and is typically slower than
coordinated schemes.

A comprehensive survey by Hart et al. \citep{hart2007performance}
demonstrates that existing reclamation schemes struggle to achieve both
safety and performance at scale, motivating the search for truly
coordination-free alternatives.

\hypertarget{the-scalability-paradox-in-memory-reclamation}{%
\subsection{The Scalability Paradox in Memory
Reclamation}\label{the-scalability-paradox-in-memory-reclamation}}

While these techniques made important progress toward addressing ABA and
UAF hazards in concurrent data structures, they introduced a different
class of problems: the coordination itself became a source of
complexity, fragility, and performance bottlenecks. What begins as a
mechanism to ensure safety ends up creating new correctness and
scalability challenges --- the scalability paradox.

\hypertarget{fragility-under-thread-failure}{%
\subsubsection{Fragility under Thread
Failure}\label{fragility-under-thread-failure}}

Despite these layers of coordination, the schemes remain fragile under
thread failure. All these protocols rest on a common assumption that
every thread will eventually participate, but in practice, threads may
stall or crash unexpectedly. A stalled hazard pointer can prevent
reclamation permanently, a crashed participant can halt epoch
advancement, and missing quiescent state reports can extend grace
periods indefinitely. Even distributed schemes like DEBRA remain
vulnerable to group blocking when a member fails. Attempts to work
around this through watchdogs, external monitors, or heartbeat
mechanisms \citep{dice2016recoverable} introduce additional
infrastructure requirements, moving parts, and heuristic-based tuning.
These measures add complexity and fragility, compounding the paradox
rather than resolving it.

\hypertarget{real-world-queue-designs-and-trade-offs}{%
\subsubsection{Real-World Queue Designs and
Trade-offs}\label{real-world-queue-designs-and-trade-offs}}

To work around these limitations and the performance penalty, modern
high-throughput queue designs often relax one or more fundamental
properties. The result is a spectrum of trade-offs, where scalability is
gained at the expense of FIFO ordering, unbounded capacity, or
lock-freedom.

Moodycamel's ConcurrentQueue achieves excellent performance by using
per-producer segmented subqueues. However, this comes at the cost of
strict FIFO: ordering is preserved only within each producer, while
interleaving between producers is permitted. Vyukov's queue delivers
near-O(1) operations with strict per-slot FIFO but requires capacity to
be fixed at initialization, sacrificing unboundedness. General-purpose
concurrency frameworks such as Intel TBB and Meta's Folly retain both
FIFO and unbounded capacity by introducing fine-grained or hybrid locks,
but giving up lock-freedom and incurring blocking overhead under
contention.

Even with these trade-offs, these coordination-heavy reclamation
protocols become prohibitively expensive in modern many-core
environments requiring hundreds or thousands of concurrent threads.

The root cause is not the trade-off itself but the chosen protection
model. Existing schemes attempt to guarantee indefinite protection
against ABA and UAF, which is not only unrealistic in production but
also introduces complexity and fragility. This tension gives rise to
what is known as \textbf{the protection paradox}.

\hypertarget{the-protection-paradox}{%
\subsubsection{The Protection Paradox}\label{the-protection-paradox}}

To remain safe in the face of stalls, existing schemes adopt
conservative policies: nodes are not reclaimed until all threads
cooperate again. While this guarantees safety in theory, it rests on two
flawed assumptions.

First, they assume stalled threads will eventually recover. In
production systems, this assumption rarely holds. The consequence is
unbounded and unpredictable reclamation delays, leading to uncontrolled
memory retention and no automatic recovery from failed threads.

Second, they impose a hot-path tax on every operation to guard against
failures that occur less than 0.1\% of the time in production
deployments. This results in slower performance 99.9\% of the time, yet
those rare failures still stall reclamation indefinitely. A crashing or
stalled thread is a separate bug to fix---not a justification for taxing
the fast path 99.9\% of the time. Worse, ``infinite'' protection
inevitably leads to ``infinite'' leak duration.

This is the classic protection paradox: adding more protection against
rare failures makes the system less resilient and reduces practical
safety and scalability. It also introduces overhead greater than that of
the queue itself. Cyclic Memory Protection (CMP) takes the opposite
stance: it replaces indefinite protection with a bounded temporal safety
window, eliminating inter-thread coordination while tolerating stalled
or failed threads. This keeps the common case lean, bounds the uncommon
case, and provides predictable memory use and stable latency for
unbounded, strictly FIFO, lock-free queues.
