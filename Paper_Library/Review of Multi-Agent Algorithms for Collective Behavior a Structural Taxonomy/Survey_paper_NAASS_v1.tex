%\documentclass[conference]{IEEEtran}
\documentclass{ifacconf}

% numbers option provides compact numerical references in the text. 
%\usepackage[numbers]{natbib}
\usepackage{natbib}
%\usepackage{ifaconf}
\usepackage{multicol}
%\usepackage[bookmarks=true]{hyperref}

% \pdfinfo{
%    /Author (Homer Simpson)
%    /Title  (Robots: Our new overlords)
%    /CreationDate (D:20101201120000)
%    /Subject (Robots)
%    /Keywords (Robots;Overlords)
% }
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{amsbsy}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{graphicx}
%\usepackage{subcaption}
\usepackage{color}
\usepackage{pdflscape}
\usepackage{pifont}
%\usepackage{hyperref}
\usepackage{booktabs,multirow}
%\usepackage{cite}
\graphicspath{{./},{./fig/}}

\newif\ifjournalv
\journalvfalse

\ifjournalv\else
\renewcommand{\baselinestretch}{1.085}
%\addtolength{\abovecaptionskip}{-.5mm}
%\addtolength{\belowcaptionskip}{-.5mm}
%\addtolength{\abovedisplayskip}{-.5mm}
%\addtolength{\belowdisplayskip}{-.5mm}
%\usepackage[uppercase]{titlesec}
%\titlespacing*{\section}{0\baselineskip}{0\baselineskip}{0.8\baselineskip plus 0.1\baselineskip minus 0.1\baselineskip}
%\titlespacing*{\subsection}{0\baselineskip}{-0.2\baselineskip plus 0.1\baselineskip minus 0.1\baselineskip}{-0.2\baselineskip plus 0.1\baselineskip minus 0.1\baselineskip}
 %  \titlespacing*{\subsection}{<left-value>}{<above-value>}{<below-value>}
 %  \titlespacing*{\subsubsection}{<left-value>}{<above-value>}{<below-value>}
\fi

\newcommand{\sapmargin}[2]{{\color{cyan}#1}\marginpar{\color{cyan}\raggedright\footnotesize [SAP]:
#2}}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\newcommand{\frmargin}[2]{{\color{Apricot}#1}\marginpar{\color{Apricot}\raggedright\footnotesize [FR]:
#2}}
\newcommand{\mwmargin}[2]{{\color{WildStrawberry}#1}\marginpar{\color{WildStrawberry}\raggedright\footnotesize [MW]:
#2}}
\renewcommand{\sapmargin}[2]{#1}
\renewcommand{\frmargin}[2]{#1}
\renewcommand{\mwmargin}[2]{#1}

\newcommand{\RCM}{\textcolor{red}{\ding{51}} }
\newcommand{\GCM}{\textcolor{green}{\ding{51}} }
\newcommand{\BCM}{\textcolor{blue}{\ding{51}} }

\begin{document}
\begin{frontmatter}
% paper title
\title{Review of Multi-Agent Algorithms for Collective Behavior: a Structural Taxonomy}

% You will get a Paper-ID when submitting a pdf file to the conference system

\author[First]{Federico Rossi} 
\author[Second]{Saptarshi Bandyopadhyay} 
\author[Second]{Michael Wolf}
\author[First]{Marco Pavone}

\address[First]{Department of Aeronautics and Astronautics, Stanford University (e-mail: \{frossi2, pavone\}@stanford.edu).}
\address[Second]{Jet  Propulsion  Laboratory,  California  Institute  of  Technology %,  Pasadena,  CA  91109,  USA
(e-mail: \{Saptarshi.Bandyopadhyay,michael.t.wolf\}@jpl.nasa.gov)}

   \thanks[footnoteinfo]{Part of this research was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration. Federico Rossi and Marco Pavone were partially supported by the Office of Naval Research, Science of Autonomy Program, under Contract N00014-15-1-2673.
%\copyright 2018 California Institute of Technology
}

%\author{\authorblockN{Michael Shell}
%\authorblockA{School of Electrical and\\Computer Engineering\\
%Georgia Institute of Technology\\
%Atlanta, Georgia 30332--0250\\
%Email: mshell@ece.gatech.edu}
%\and
%\authorblockN{Homer Simpson}
%\authorblockA{Twentieth Century Fox\\
%Springfield, USA\\
%Email: homer@thesimpsons.com}
%\and
%\authorblockN{James Kirk\\ and Montgomery Scott}
%\authorblockA{Starfleet Academy\\
%San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212\\
%Fax: (888) 555--1212}}


% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership


% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\authorblockN{Michael Shell\authorrefmark{1},
%Homer Simpson\authorrefmark{2},
%James Kirk\authorrefmark{3}, 
%Montgomery Scott\authorrefmark{3} and
%Eldon Tyrell\authorrefmark{4}}
%\authorblockA{\authorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: mshell@ece.gatech.edu}
%\authorblockA{\authorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\authorblockA{\authorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\authorblockA{\authorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}


\maketitle


\begin{abstract}
In this paper, we  review multi-agent collective behavior algorithms in the literature and classify them according to their underlying mathematical structure. For each mathematical technique, we identify the multi-agent coordination tasks it can be applied to, and we analyze its scalability, bandwidth use, and demonstrated maturity. We highlight how versatile techniques such as artificial potential functions can be used for applications ranging from low-level position control to high-level coordination and task allocation, we discuss possible reasons for the slow adoption of complex distributed coordination algorithms in the field, and we highlight areas for further research and development. 
%We highlight how a few mathematical techniques (e.g., artificial potential functions) can be adapted for a wide variety of tasks, ranging from low-level position control to high-level coordination and task allocation. 
%Similarly, some tasks (like pattern formation) can be accomplished by a wide variety of mathematical techniques.
%Based on this survey, we also identify areas for further research and development. 
\end{abstract}

\begin{keyword}
Autonomous mobile robots, Agents, Distributed Control, Decentralized Control
\end{keyword}

\end{frontmatter}


\ifjournalv\else \vspace{-1.8mm} \fi\section{Introduction}\ifjournalv\else \vspace{-1.8mm} \fi
\label{sec:intro}
%We present a survey of multi-agent collective behavior algorithms from a mathematical perspective and propose a taxonomy of such algorithms according to the mathematical properties of the underlying algorithms. We show that: 
%(1) A few mathematical techniques can be used for a wide variety of tasks, which will be crucial for developing multi-purpose multi-agent systems. 
%(2) The same task can be accomplished by multiple mathematical techniques. 
%
%To our knowledge, this is the first review of collective behavior algorithms focusing on the mathematical techniques. Earlier review papers have focused either on a particular mathematical technique (e.g., consensus \citep{Ref:Garin10,Ref:Cao13}) or a particular task (e.g., formation control \citep{Ref:Oh15survey}, coverage \citep{Ref:Schwager09}). 
%\frmargin{Add}{
Multi-agent robotic systems hold promise to enable new classes of missions in aerospace, terrestrial, and maritime
 applications, delivering higher resilience and adaptability at lower cost compared to existing monolythic systems. In particular, in the aerospace domain, multi-agent systems hold great promise for applications including multi-UAV patrolling, satellite formations for astronomy and Earth observation, and multi-robot planetary exploration. A number of algorithms have been proposed to control the collective behavior of such systems, ranging from low-level position control to high-level motion planning and  task allocation algorithms.

Many excellent surveys of algorithms for collective behavior exist in the literature; however, such papers generally focus either on single applications (e.g., formation control \citep{Ref:Oh15survey} or coverage \citep{Ref:Schwager09}) or on specific control techniques (e.g., consensus \citep{Ref:Garin10,Ref:Cao13}).
%
In contrast, in this paper, we survey the \emph{general} family of collective behavior algorithms for multi-agent systems and classify them according to their underlying mathematical \emph{structure}, without  restricting our focus to specific tasks or individual classes of algorithms.
In doing so, we aim to capture fundamental mathematical properties of algorithms (e.g. scalability with respect to the number of agents and bandwidth use) and to show how the same algorithm or family of algorithms can be applied to multiple tasks and missions.

In particular, the goal of this paper is threefold:
\begin{itemize}
\item to act as a guide to practitioners in the selection of control algorithms for a given task or application;
\item to highlight how mathematically similar algorithms can be used for a variety of tasks, ranging from low-level control to high-level coordination;
\item to explore the state-of-the-art in the field of control of multi-agent systems and identify areas for future research.
\end{itemize}
%} 
%\frmargin{ }{Expand a bit? The field of control of multi-agent systems is rapidly growing, and a number of surveys of algorithms for such systems is available in the literature. However, existing surveys focus either on specific tasks (e.g. ...) or on specific classes of algorithms (e.g. consensus, or TODO). In contrast, in this paper, we provide a high-level overview of ... (shown in Table \ref{tab:all_algos}).}
%\subsubsection{Tasks in multi-agent systems} We adopt the taxonomy of \emph{tasks} in multi-agent systems proposed in \cite{Ref:Brambilla13}. Tasks are classified as:\\
\emph{Tasks in multi-agent systems} 
can be broadly %\frmargin{
categorized
%}{captures most of the task of interest for robotics}
 into the following classes \citep{Ref:Brambilla13}: \\
(1) \textbf{Spatially-organizing behaviors}, where agents coordinate to achieve a given spatial configuration and have negligible interactions with the environment. These tasks can be further classified into: 
(a)~\textit{Aggregation:} converging to one location.
(b)~\textit{Pattern Formation:} achieving a desired formation. 
(c)~\textit{Coverage:} covering an area. \\
(2) \textbf{Collective explorations}, where agents interact with the environment but have minimal interaction among themselves. These tasks can be classified into:
(a)~\textit{Area Exploration:} exploring the environment for mapping or surveillance.
(b)~\textit{Goal Searching:} searching for targets. \\
(3) \textbf{Cooperative decision making}, where agents both coordinate among themselves and interact with the environment to accomplish complex tasks. These tasks can be further classified into:
(a)~\textit{Task Allocation:} distributing tasks among agents.
(b)~\textit{Collective Transport:} coordinating to transport large objects.
(c)~\textit{Motion Planning:} finding paths in cluttered environments.
(d)~\textit{Distributed Estimation:} estimating the state of one or multiple targets. \\ 
These simple tasks are the fundamental building blocks of many complex multi-agent applications. 

\rowcolors{2}{gray!25}{white}
\begin{table*}[htpb]
\centering
%\begin{subtable}[h]{\textwidth}
\begin{tabular}{l|lll|ll|llll||lll}
\toprule
{} & \rotatebox{90}{Aggregation} & \rotatebox{90}{Pattern Formation} & \rotatebox{90}{Coverage} & \rotatebox{90}{Area Exploration} & \rotatebox{90}{Goal Searching} & \rotatebox{90}{Task Allocation} & \rotatebox{90}{Collective Transport} & \rotatebox{90}{Motion Planning} & \rotatebox{90}{Distributed Estimation} & \rotatebox{90}{High Scalability} & \rotatebox{90}{Low Bandwidth Use} &    \rotatebox{90}{Maturity} \\
\midrule
\hline \textbf{Consensus}                                         &  \BCM &  \BCM &  \BCM &   &   &   &   &   &  \BCM &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
\hline \textbf{Artificial Potential Functions (APF)}              &  \BCM &  \BCM &  \BCM &  \BCM &   &  \BCM &  \BCM &  \BCM &   &  \BCM &  \BCM &  \textcolor{blue}{F} \\
\hline \textbf{Distributed Feedback Control}                      &  \BCM &  \BCM &   &   &   &   &   &   &  \BCM &  \BCM &  \BCM &  \textcolor{blue}{F} \\
\hline \textbf{Geometric Algorithms}                              &   &   &   &   &   &   &   &   &   &   &   &   \\
Voronoi-based Algorithms                                          &  \BCM &   &  \BCM &  \BCM &   &   &   &  \BCM &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Circumcenter Algorithms                                           &  \BCM &  \BCM &   &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Bearing-only Algorithms                                           &  \BCM &  \BCM &   &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Maze Searching Algorithms                                         &   &   &   &   &   &   &   &  \BCM &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Leader-Follower (LF) Algorithms                                   &   &  \BCM &   &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Velocity Obstacle (VO) based Algorithms                           &   &   &   &   &   &   &   &  \BCM &   &  \BCM &  \BCM &  \textcolor{blue}{F} \\
\hline \textbf{State Machines and Behavior Composition}           &   &   &   &   &   &   &   &   &   &   &   &   \\
Automata-based Algorithms                                         &   &   &   &   &   &  \BCM &   &   &  \BCM &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Behavior Composition                                              &   &   &   &   &   &  \BCM &  \BCM &   &   &   &   &  \textcolor{ForestGreen}{H} \\
Petri Networks                                                    &   &   &   &   &   &  \BCM &   &   &   &   &  - &  \textcolor{ForestGreen}{H} \\
Game Theory based Algorithms                                      &   &   &   &   &   &  \BCM &   &   &   &   &  - &  \textcolor{RedOrange}{S} \\
Resource Allocation Systems                                       &   &   &   &   &   &   &   &  \BCM &   &  \BCM &  - &  \textcolor{RedOrange}{S} \\
\hline \textbf{Bio-Inspired Algorithms}                           &   &   &   &   &   &   &   &   &   &   &   &   \\
Kilobot Self-Assembly Algorithm                                   &   &  \BCM &   &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Optimotaxis Source-Searching Algorithm                            &   &   &   &   &  \BCM &   &   &   &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Beeclust Foraging Algorithm                                       &   &   &   &  \BCM &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Shepherding Algorithm                                             &  \BCM &   &   &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Termite-Inspired Collective Construction Algorithm                &   &   &   &   &   &  \BCM &  \BCM &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Fish-inspired Goal Searching Algorithms                           &   &  \BCM &   &   &  \BCM &   &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Gillespie Self-Assembly Algorithm                                 &   &  \BCM &   &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Mergeable Modular Robots                                          &   &  \BCM &   &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
\hline \textbf{Density based Control}                             &   &   &   &   &   &   &   &   &   &   &   &   \\
Markov Chain-based Algorithms                                     &   &  \BCM &  \BCM &   &   &  \BCM &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Smoothed Particle Hydrodynamics (SPH)                             &   &  \BCM &  \BCM &   &   &   &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Optimal Transport based Algorithm                                 &   &  \BCM &   &   &   &   &   &  \BCM &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
\hline \textbf{Distributed Optimization Algorithms}               &   &   &   &   &   &   &   &   &   &   &   &   \\
Distributed Linear Programming                                    &   &  \BCM &   &   &   &  \BCM &   &   &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Distributed Convex Optimization                                   &   &   \BCM &   &   &   & \BCM  &   &   &  \BCM &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Distributed Dynamic Programming                                   &   &   &   &   &   &  \BCM &   &  \BCM &   &   &   &  \textcolor{ForestGreen}{H} \\
Sequential Convex Programming                                     &   &   &   &   &   &   &   &  \BCM &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
Distributed Auction                                               &   &   &   &   &   &  \BCM &   &   &   &  \BCM &  \BCM &  \textcolor{ForestGreen}{H} \\
\hline \textbf{Local Optimization Algorithms for Global Behavior} &   &   &   &   &   &   &   &   &   &   &   &   \\
Decentralized Model Predictive Control (DMPC)                     &   &  \BCM &   &   &   &   &   &  \BCM &   &  \BCM &   &  \textcolor{ForestGreen}{H} \\
Formal Methods                                                    &   &   &   &   &   &   &   &  \BCM &   &  \BCM &  \BCM &  \textcolor{RedOrange}{S} \\
Sampling-based Motion-Planning Algorithms                         &   &   &   &   &   &   &   &  \BCM &   &   &   &  \textcolor{ForestGreen}{H} \\
\hline \textbf{Centralized Optimization Algorithms}               &   &   &   &   &   &   &   &   &   &   &   &   \\
MILPs and MINLPs                                                  &   &  \BCM &   &   &   &  \BCM &   &  \BCM & \BCM  &   &  - &  \textcolor{ForestGreen}{H} \\
Linear and Convex Optimization                                    &   &   &   &   &   &  \BCM &   &  \BCM &   \BCM&  \BCM &  - &  \textcolor{RedOrange}{S} \\
Markov Decision Processes (MDP)                                   &   &   &   &   &   &  \BCM &   &  \BCM &   &   &  - &  \textcolor{ForestGreen}{H} \\
Multi-Agent Traveling Salesman Problems                           &   &   &  \BCM &  \BCM &  \BCM &  \BCM &   &   &   &   &  - &  \textcolor{ForestGreen}{H} \\
Multi-Armed Bandits                                               &   &   &   &  \BCM &  \BCM & \BCM  &   &   &  \BCM &  \BCM &  - &  \textcolor{RedOrange}{S} \\
Direct Methods for Optimal Control                                &   &   &  \BCM &  \BCM &   &   &   &  \BCM &   &   &  - &  \textcolor{blue}{F} \\
Multiagent Reinforcement Learning                                 &   &   &   &  \BCM &   &  \BCM &   &   &   &   &  - &  \textcolor{ForestGreen}{H} \\
Frontier Techniques                                               &   &   &   &  \BCM & \BCM  &   &   &   &   &   &  - &  \textcolor{blue}{F} \\
Network Flow Algorithms                                           &   &   &   &   &   &  \BCM &   &  \BCM &   &  \BCM &  - &  \textcolor{RedOrange}{S} \\
Combinatorial Motion Planning                                     &   &   &   &   &   &   &   &  \BCM &   &  \BCM &  - &  \textcolor{RedOrange}{S} \\
\bottomrule
\end{tabular}
%\small{
\caption{Categorization of collective behavior algorithms according to their mathematical structure and applicability of each algorithm to common multi-agent tasks. The scalability, bandwidth use, and level of demonstrated maturity of each algorithm (formally defined in Section \ref{sec:intro}) are also reported. }\label{tab:all_algos}%}
\end{table*}


\ifjournalv\else \vspace{-2.1mm} \fi
\subsubsection{Communication structure}  
In \textbf{centralized} algorithms, all agents share their information with a central node, which computes and issues a joint set of control actions. 
%Although these algorithms can leverage the state of the entire system to make decisions, they are inherently brittle (loss of the central node disables the entire system) and have hefty bandwidth requirements.
In \textbf{distributed} algorithms, agents can only explicitly share information with their neighbors. %this makes them robust to failures. 
% (either through single-hop communication with their neighbors or through multi-hop communication spanning the system). 
% Distributed algorithms may also be used to create a hierarchy among the agents: however, crucially, such hierarchy is not pre-defined but rather established at run-time. %A key difficulty with distributed algorithms is that agents may have different states of knowledge about the system: this introduces a \frmargin{TODO}{TODO}.
 Centralized algorithms can be implemented in a distributed fashion with a \textbf{shared-world} approach, discussed in Section \ref{sec:centralized-optimization-algo}.
%(3)~\textbf{Shared-world} algorithms lie in the middle, because agents share information with their neighbors so that every agent has full knowledge of the entire system's state. 
%Then the agents can locally execute any centralized algorithm and execute only the actions assigned to themselves. %Every agent has the same information about the system and executes the same algorithm: thus, the agents' actions are  implicit coordination.
%But these algorithms have very onerous communication requirements and high computation complexity.
%, since all agents must share their state with all other agents, and high computation complexity, since each agents must solve a control problem for the entire system.
 
\ifjournalv\else \vspace{-2.1mm} \fi
\subsubsection{Methodology}
%\subsubsection{Literature Review and Taxonomy} 
We performed a thorough review of papers on multi-agent systems in major controls and robotics journals and conferences. 
It is not feasible to cite all existing works on control of multi-agent systems; accordingly, in this paper, we focus on identifying and classifying the key mathematical \emph{structures} and \emph{techniques}  that drive coordination algorithms, as opposed to individual contributions.  
%\frmargin{}{We refer the reader to the extended version of this paper for a more thorough literature review and to a detailed discussion of the mathematical formulation and properties of each mathematical techniques} 
%\subsubsection{Scalability, Bandwidth, and Maturity}

We classify mathematical techniques according to their: 
(1)~\textbf{Scalability:} Highly scalable algorithms have been demonstrated on systems with more than 50 agents (in simulations or hardware). 
(2)~\textbf{Bandwidth use:} In low bandwidth algorithms, agents only communicate with their physical neighbors and do not exchange large messages. 
%\frmargin{(i.e. messages whose size grows linearly or superlinearly with the number of agents in the system)}{Questionable}.
(3)~\textbf{Maturity:} The three classes of algorithms are: 
(i) only demonstrated in `simulation'~(\textcolor{RedOrange}{S})  
(ii) demonstrated in `hardware'~(\textcolor{ForestGreen}{H}) either in the lab or in technology demonstration missions
(iii) demonstrated in `field'~(\textcolor{Blue}{F}) deployments (excluding technology demonstrator missions).
% Algorithm maturity is assessed according to three classes: (i) 'simulation' (\textcolor{RedOrange}{S}) for , (ii) 'hardware' (\textcolor{ForestGreen}{H}) for algorithms that have been demonstrated in hardware either in a lab environment or in proof-of-concept field experiments, and (iii) 'field' (\textcolor{green}{F}) for algorithms that have been used as part of a larger stack in field-based multi-agent systems.
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Notation}\ifjournalv\else \vspace{-2.1mm} \fi
%\textbf{\textit{Notation:}} We adopt a discrete-time framework. 
%The communication network topology at the $k^{\textrm{th}}$ time step is represent by the graph $\mathcal{G}_{k}=(\mathcal{V},\mathcal{E}_{k})$, where $\mathcal{V}$ represents the set of agents and $\mathcal{E}_{k}$ represents the time-varying set of directed edges in the graph.
%If the $i^{\textrm{th}}$ agent receives information from the $j^{\textrm{th}}$ agent at the $k^{\textrm{th}}$ time step, then the edge $\overrightarrow{ji}\in\mathcal{E}_{k}$.
%The set of neighbors that the $i^{\textrm{th}}$ agent receives information from at the $k^{\textrm{th}}$ time step are denoted by $\mathcal{N}_{k}^{i}$. The set of inclusive neighbors of the $i^{\textrm{th}}$ agent at
%the $k^{\textrm{th}}$ time step are denoted by $\mathcal{J}_{k}^{i}=\mathcal{N}_{k}^{i}\cup\{i\}$. 
%
%Let $\mathbb{N}$ and $\mathbb{R}$ be the set of natural numbers (positive integers) and real numbers, respectively.
%Let $x_{k}^{i}\in\mathbb{R}^{n_{x}}$ represent the state of the $i^{\textrm{th}}$ agent at the the $k^{\textrm{th}}$ time step, where $n_{x}$ represents the dimension of the state.
\ifjournalv\else \vspace{-2.1mm} \fi
\subsubsection{Organization}
%In Section \ref{sec:comm-architectures}, we briefly review a taxonomy of communication architectures for multi-agent systems. 
Our key contribution is Table \ref{tab:all_algos}, which reports the proposed taxonomy of mathematical techniques for collective behavior, highlights the tasks that each mathematical technique can achieve, and lists relevant performance metrics.
In Sections~\ref{sec:Consensus-algorithm}--\ref{sec:centralized-optimization-algo} we provide a synthetic description of the classification and relevant references. 
%We propose a taxonomy of mathematic techniques in  Sections~\ref{sec:Consensus-algorithm}--\ref{sec:centralized-optimization-algo} and Table~\ref{tab:all_algos}. Table~\ref{tab:all_algos} also reports the tasks that each mathematical technique can achieve and relevant performance metrics.
Finally, in Section~\ref{sec:conclusion} we draw conclusions and suggest directions for future research. 


% \ifjournalv\else \vspace{-1.8mm} \fi\section{Communication architectures}\ifjournalv\else \vspace{-1.8mm} \fi\label{sec:comm-architectures}
% The proposed taxonomy of mathematical techniques for control of multi-agent collective behavior is shown in \frmargin{Fig. \ref{fig:taxonomy}}{Upcoming}. We first classify algorithms according to their communication structure: within each class, we identify distinct mathematical techniques and label them according to their scalability, bandwidth use, maturity, and applications.

% \subsubsection{Communication structure}
% The first proposed classification of algorithms for multi-agent collective behavior is according to the communication structure they require. 
% \textbf{Centralized} algorithms assume that all agents share their state with a central node which, in turn, computes a joint set of control actions and issues it to the agents. By exploiting a centralized decision architecture, algorithms in this class can leverage the state of the entire system to make decisions, and they do not have to explicitly reason about the knowledge available to individual agents. However, centralized algorithms are inherently brittle (since the loss of a single central node disables the entire system), have hefty bandwidth requirements (since every agent is required to share its state with a central node), and often do not scale as well as distributed algorithms.

% In \textbf{distributed} algorithms, no central node is established a priori and agents explicitly share information with their peers (either through single-hop communication with their neighbors or through multi-hop communication spanning the system). Distributed algorithms may also be used to create a hierarchy among the agents: however, crucially, such hierarchy is not pre-defined but rather established at run-time. %A key difficulty with distributed algorithms is that agents may have different states of knowledge about the system: this introduces a \frmargin{TODO}{TODO}.

% \textbf{Shared-world} algorithms bridge the gap between centralized algorithms and distributed algorithms. Such algorithms focus on sharing state information among the agents so that every agent has full knowledge of the entire system's state. Agents can then locally execute any deterministic centralized algorithm and execute only the actions assigned to themselves. Every agent has the same information about the system and executes the same algorithm: thus, the agents' actions are 
% implicit coordination.
% Shared-world algorithms have very onerous communication requirements, since all agents must share their state with all other agents, and high computation complexity, since ech agents must solve a control problem for the entire system.
 
\ifjournalv\else \vspace{-1.8mm} \fi\section{A Structural Taxonomy of Multi-Agent Collective Behavior Algorithms}

\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Consensus algorithms}\ifjournalv\else \vspace{-2.1mm} \fi\label{sec:Consensus-algorithm}
\textbf{Consensus} is among the oldest and most widely used distributed algorithms. Each agent shares and averages its state with its neighbors \ifjournalv\citep{Ref:Tsitsiklis86,Ref:Jadbabaie03,Ref:Saber04,Ref:Ren07}\else\citep{Ref:Tsitsiklis86,Ref:Ren07}\fi. 
%At each time instant, each agent shares and averages its state with its neighbors: thus, the algorithm is highly scalable and its bandwidth use is moderate (especially with broadcast communication protocols).  
Applications include synchronization 
\ifjournalv\citep{Ref:Dorfler14,Ref:Dorfler13,Ref:Yu09pinning,Ref:Li2006global}\else \citep{Ref:Li2006global}\fi,
flocking \ifjournalv\citep{Ref:Tanner07,Ref:Tanner2003stable,Ref:Tanner2003stable2,Ref:Spong08b,Ref:Dorigo12}\else\citep{Ref:Tanner07,Ref:Saber06}\fi,
%with collision avoidance \ifjournalv\citep{Ref:Saber06,Ref:Cucker08}\else\citep{Ref:Saber06}\fi,
formation flying \ifjournalv\citep{Ref:Lawton03decentralized,Ref:Leonard08,Ref:Chung12,Ref:Chung09,Ref:Hadaegh13}\else\citep{Ref:Chung12}\fi, 
% coverage control \citep{Ref:Schwager08}, localization \citep{Ref:Franceschelli14}, distributed error detection and recovery \citep{Ref:Franceschelli08}, 
and distributed estimation \ifjournalv\citep{Ref:Speyer79,Ref:Borkar82,Ref:Chen02,Ref:Tomlin08,Ref:Saber09,Ref:Battistelli15,Ref:Rabbat04,Ref:Murray05,Ref:Smith2007,Ref:Freeman08}\else\citep{Ref:Rabbat04}\fi.
In \textit{gossip algorithms} \citep{Ref:Shah06}, each agent communicates with a single randomly-selected neighbor at each step.
In \textit{cyclic pursuit algorithms} \citep{Ref:Marshall04}, the consensus algorithm is executed on a directed ring communication topology. 
% Cyclic pursuit algorithms can be used for formation flying \ifjournalv\citep{Ref:Marshall04,Ref:Ramirez10,Ref:Singh15}\else\citep{Ref:Ramirez10} \fi and rendezvous \citep{Ref:Ramirez10}.

% We refer the reader to \citep{Ref:Ren07,Ref:Garin10} for in-depth surveys of applications of the consensus algorithm.
% \ifjournalv
% \frmargin{\textbf{Consensus}}{TODO violently shorten reference list} is among the oldest and most widely used distributed algorithms for coordination of multi-agent systems \citep{Ref:Tsitsiklis86,Ref:Ren07}. At each time instant, each agent shares and averages its state with its neighbors: thus, the algorithm is highly scalable and its bandwidth use is moderate (especially with broadcast communication protocols).  Applications of consensus include synchronization \citep{Li2006global}, flocking, \citep{Ref:Tanner07} with collision avoidance \citep{Ref:Saber06}, formation flying \citep{Ref:Lawton03decentralized}, 
% coverage control \citep{Ref:Schwager08}, localization \citep{Ref:Franceschelli14}, distributed error detection and recovery \citep{Ref:Franceschelli08}, and distributed estimation \citep{Ref:Rabbat04}.
% In \textit{gossip algorithms} \citep{Ref:Shah06}, each agent communicates with a single randomly-selected neighbor at each time step, minimizing bandwidth use.
% In \textit{cyclic pursuit algorithms} \citep{Ref:Marshall04}, the consensus algorithm is executed on a directed ring communication topology. Cyclic pursuit algorithms can be used for formation flying \citep{Ref:Marshall04,Ref:Ramirez10,Ref:Singh15} and rendezvous \citep{Ref:Ramirez10}.
% \fi

\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Artificial Potential Functions (APF)}\ifjournalv\else \vspace{-2.1mm} \fi
\textbf{APF} algorithms synthesize agents' control inputs using the gradient of a suitably-defined potential function \citep{Ref:Khatib86}. 
% Potential functions  where the goal position (or positions) is guaranteed to be reachable from any feasible initial state are known as navigation functions \ifjournalv\citep{Ref:Koditschek90,Ref:Rimon92}\else\citep{Ref:Rimon92}\fi. Distributed implementations of APF techniques generally offer excellent scalability and low bandwidth use, requiring agents to communicate with a limited number of their immediate neighbors \citep{Ref:Vadakkepat01}. 
These algorithms are very popular due to their simplicity, scalability, and ability to adapt to a number of tasks. Applications include pattern formation \ifjournalv\citep{Ref:Tanner05,Ref:Tanner12,Ref:Leonard07,Ref:Gazi05,Ref:Hsieh08,Ref:Spong08,Ref:Barnes09swarm,Ref:De2006formation}\else \citep{Ref:Leonard07} \fi,
%\ifjournalv in satellites \citep{Ref:Pinciroli08,Ref:Saaj06spacecraft,Ref:Peck07spacecraft} \fi,
%shape formation \citep{Ref:Slotine09},
flocking \ifjournalv\citep{Ref:Chuang07,Ref:Zavlanos2007flocking}\else\citep{Ref:Zavlanos2007flocking}\fi,
%perimeter formation \citep{Ref:Bruemmer02},
% coverage control  \ifjournalv\citep{Ref:Hussein07,Ref:williams13}\else\citep{Ref:Hussein07}\fi,
% area exploration \citep{Ref:Xu11},
% information gathering \cite{Ref:Rus12},
%  foraging \ifjournalv\citep{Ref:Passino04,Ref:Gazi07}\else\citep{Ref:Passino04}\fi,
 path planning \ifjournalv\citep{Ref:Koditschek90,Ref:Loizou02,Ref:Loizou06,Ref:Dimarogonas03,Ref:Dimarogonas05,Ref:Lionis07,Ref:Warren90,Ref:Lee13,Ref:Vadakkepat01,Ref:Ayanian10}\else\citep{Ref:Koditschek90}\fi,
% cooperative manipulation \ifjournalv\citep{Ref:Khatib96,Ref:Bai10}\else\citep{Ref:Khatib96}\fi,
% network connectivity maintenance \ifjournalv\citep{Ref:Dani12,Ref:Dimarogonas08,Ref:Zavlanos07,Ref:De2006decentralized}\else\citep{Ref:Zavlanos07}\fi,
and task allocation \ifjournalv\citep{Ref:Weigel02,Ref:Pappas08b}\else\citep{Ref:Weigel02}\fi.
%Notably, APFs have been used as part of larger control stacks in RoboSoccer \frmargin{\citep{Ref:Weigel02} and TODO}{CHECK}.

\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Distributed Feedback Control}\ifjournalv\else \vspace{-2.1mm} \fi
Each agent is endowed with a feedback controller that uses the agent's and its neighbors' states as the input
 \citep{Ref:Bamieh02,Ref:Feddema02}. In particular, tools for synthesis of \textbf{distributed LQG control} are available that can adapt to noisy communication links \citep{Ref:Sahai06}, and packet losses \ifjournalv \citep{Ref:Garone11,Ref:Liu04}\else \citep{Ref:Liu04}\fi, with applications to formation flying \citep{Ref:Ogren02} and distributed estimation.
%also see Decentralized Control \citep{Ref:Swigart10} (very less citations)
%Complexity analysis \citep{Ref:Goldman04}

%Old paper on decentralized control \citep{Ref:Barrett00}
%Lyapunov techniques for formation flying \citep{Ref:Ogren02} (simulation, three agents, connectivity unclear but seems fixed)
%Decentralized overlapping control of subsystems leads to control of the entire system \citep{Ref:Stipanovic04decentralized}



\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Geometric Algorithms}\ifjournalv\else \vspace{-2.1mm} \fi
In geometric algorithms, agents leverage their neighbors' location and speed information to perform spatially organizing tasks and path planning. 
\textbf{Voronoi algorithms} compute Voronoi partitions for coverage
\ifjournalv\citep{Ref:Bullo04,Ref:Bullo08,Ref:Bullo09book,Ref:Schwager07,Ref:Bhattacharya14,Ref:Martinez07a,Ref:Martinez07b,Ref:Gao08,Ref:Pappas13} \else \citep{Ref:Bullo04}\fi,
%flocking \citep{Ref:Johansson05}, area exploration \citep{Ref:Guruprasad11}, 
path planning \ifjournalv\citep{Ref:Sud08,Ref:Bandyopadhyay14MSC,Ref:Zhou17} \else \citep{Ref:Zhou17}\fi, %\ifjournalv\frmargin{learning}{??} \citep{Ref:Wood12},\fi 
and task allocation problems \citep{Ref:Pavone11}.
Other geometric algorithms include \textbf{circumcenter algorithms} for rendezvous  \ifjournalv\citep{Ref:Cortes06,Ref:Dimarogonas07}\else\citep{Ref:Cortes06}\fi, 
\textbf{bearing-only algorithms} for formation control \citep{Ref:Fredslund02} and rendezvous \citep{Ref:Yu08rendezvous}, \textbf{maze searching algorithms} for  path planning \citep{Ref:Lumelsky97}, 
\textbf{leader-follower algorithms} for formation flying \ifjournalv\citep{Ref:Mesbahi99formation,Ref:Beard00feedback,Ref:Consolini09}\else\citep{Ref:Mesbahi99formation}\fi,
%and formation control \citep{Ref:Desai01modeling}; 
and \textbf{velocity obstacles} for collision avoidance
\ifjournalv\citep{Ref:vabdenBerg08,Ref:Bareiss15,Ref:Hoy14}\else\citep{Ref:vabdenBerg08}\fi.

\ifjournalv\else \vspace{-2.1mm} \fi\subsection{State Machines and Behavior Composition}\ifjournalv\else \vspace{-2.1mm} \fi
\textbf{Automata-based algorithms} leverage complex state machines and message-passing among agents to establish communication graphs and elect leaders for task allocation 
\ifjournalv\citep{Ref:Rossi14,Ref:Lynch97,Ref:Gallager83,Ref:Awerbuch87,Ref:Burns80}\else \citep{Ref:Lynch97,Ref:Rossi14}\fi.
\textbf{Behavior composition} algorithms rely on composition of elementary behaviors for collective transport
\ifjournalv\citep{Ref:Parker98,Ref:Huntsberger03,Ref:Rus1995moving,Ref:Werger00broadcast}\else\citep{Ref:Rus1995moving}\fi.
%A number of \emph{centralized} algorithms based on state machines can be used for control of multi-agent systems. 
\textbf{Petri networks} \ifjournalv\citep{Ref:King03,Ref:Kotb12} \else\citep{Ref:King03} \fi
and \textbf{game theory} \citep{Ref:Arslan07} algorithms are used for centralized task allocation.
\textbf{Resource allocation systems} are used for multi-agent motion planning \citep{Ref:Reveliotis11}.
% \frmargin{\textbf{Game theory} based algorithms leverage rich tools from game theory, including satisficing \citep{Ref:Stirling01,Ref:Beard02} and mechanism design \citep{Ref:Arslan07}, for task allocation applications.}{Are these centralized? If so, mention, it is surprising.}


\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Bio-Inspired Algorithms}\ifjournalv\else \vspace{-2.1mm} \fi
Bio-inspired algorithms mimic the behavior of swarms of animals such as insects and fish. 
% They typically require very limited communication and on-board computation resources, and exhibit low bandwidth use and excellent scalability.
We present a non-exhaustive list:
the \textbf{Kilobot algorithm} achieves complex two-dimensional shapes and was demonstrated on a thousand-agent testbed \citep{Ref:Nagpal14};
the \textbf{Optimotaxis source-searching algorithm} is inspired by the run and tumble behaviors of bacteria \citep{Ref:Hespanha08};
 the  \textbf{Beeclust foraging algorithm} is inspired by the behavior of honey bees \citep{Ref:Hereford11};
\textbf{Shepherding algorithms} enable control of large numbers of uncontrolled agents with few controlled agents \citep{Ref:Strobom14};
a \textbf{Termite-inspired algorithm} generates low-level rules for construction of complex structures \ifjournalv\citep{Ref:Nagpal14termite,Ref:Nagpal06}\else\citep{Ref:Nagpal14termite}\fi;
a \textbf{Fish-inspired goal-searching algorithm} switches between individual and collective behavior based on confidence level \citep{Ref:Wu12};
the \textbf{Gillespie self-assembly algorithm} leverages chemical kinetics;
\textbf{Mergeable modular robots} connect to form larger bodies or split into separate bodies, with self-healing properties \ifjournalv\citep{Ref:Dorigo17,Ref:Dorigo06,Ref:Mondada2004swarm,Ref:Dorigo2013swarmanoid,Ref:Kotay1998self}\else\citep{Ref:Dorigo17}\fi.

\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Density based Control}\ifjournalv\else \vspace{-2.1mm} \fi
As opposed to the agent-based \emph{Lagrangian} framework, density-based algorithms  adopt an \emph{Eulerian} framework by treating agents as a continuum and controlling their density.  
\textbf{Markov chain} based algorithms partition the workspace into disjoint cells and control the transition probabilities between cells for pattern formation and goal searching applications \citep{Ref:Acikmese12,Ref:Bandyopadhyay17_TRO}.
% Additional applications include multi-agent surveillance \citep{Ref:Grace05stochastic}, coverage
% \ifjournalv\citep{Ref:Leonard13,Ref:Gundry12markov}\else \citep{Ref:Leonard13} \fi
% , and task allocation
% \ifjournalv\citep{Ref:Kumar09,Ref:Mather12}\else\citep{Ref:Kumar09}\fi. 
\textbf{Smoothed particle hydrodynamics (SPH)} \citep{Ref:MKumar11} and \textbf{optimal transport} \citep{Ref:Bandyopadhyay14MSC}  based algorithms are also used for swarm formation control.


\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Distributed Optimization Algorithms}\ifjournalv\else \vspace{-2.1mm} \fi
Distributed optimization algorithms allow agents to jointly solve optimization problems through information exchange and local computations. %; they are used in multi-agent robotic systems to solve spatial organization, exploration, and cooperative decision-making problems.
\textbf{Distributed linear programming} \ifjournalv\citep{Ref:Cortes15,Ref:Bullo12,Ref:Bullo07} \else\citep{Ref:Bullo12} \fi 
is used for pattern formation and task allocation; \textbf{distributed convex optimization} can encode richer convex constraints \citep{Ref:Boyd11}. \textbf{Distributed dynamic programming} \citep{Ref:Bertsekas1982distributed} is used for task allocation and motion planning.
\textbf{Sequential Convex Programming} can solve non-convex motion planning problems through local convexification and iteration \citep{Ref:Morgan15_SATO}.
%\subsubsection{Model-Predictive Control} 
The above algorithms can also be used in a \textbf{distributed model-predictive control} framework \citep{Ref:Scattolini09}. 
%n DMPC the control problem is divided into a set of local MPCs of smaller size and the agent cooperate through inter-agent communication \citep{Ref:How07MPC,Ref:Bemporad10}. We refer the reader to \citep{Ref:Scattolini09} for a thorough review. It has been used for flocking and motion planning \citep{Ref:Zhan13,Ref:Dunbar02,Ref:How06,Ref:Kuwata11}
Market-based protocols like \textbf{distributed auction} \ifjournalv\citep{Ref:Bertsekas98,Ref:Pappas08,Ref:Shoham08,Ref:Gerkey02,Ref:Stojmenovic10,REf:Sujit11}\else\citep{Ref:Gerkey02}\fi, mechanism design \ifjournalv\citep{Ref:Dias99,Ref:Dias04}\else\citep{Ref:Dias04}\fi, and coalition formation \citep{Ref:Shehory98} are widely used for task allocation.
%\ifjournalv\cite{Ref:Dias99,Ref:Dias04} design \else\cite{Ref:Dias04} designs \fi  coordination mechanisms to obtain emergent optimal behavior from a network of self-interested agents, and \cite{Ref:Shehory98} proposes algorithms for distributed coalition formation. 
%\textbf{Machine Learning} algorithms have been used to design local policies resulting in optimal global behavior for  collision avoidance and foraging \citep{Ref:Long17,Ref:Waibel09}. 

\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Local optimization algorithms for global behavior}\ifjournalv\else \vspace{-2.1mm} \fi
\label{sec:local-optimization-algo}
In local optimization algorithms, each agent solves an optimization problem; while the resulting behavior is not generally optimal for the entire system, favorable global properties such as collision avoidance can be guaranteed.
%All algorithms in this section solve a local-approximation of the multi-agent optimization problem (\ref{eq:MAOP-cost}) in a distributed manner in order to achieve near-optimal global behavior.}{Explain better, redo}
In \textbf{decentralized model predictive control (DMPC)}
%\frmargin{*}{short}
%\frmargin{
each agent employs a local model-predictive control algorithms; inter-agent communication is used to coordinate the agents' plans \ifjournalv\citep{Ref:How07MPC,Ref:Bemporad10}\else\citep{Ref:How07MPC}\fi. Distributed MPC has been used for flocking and motion planning \ifjournalv\citep{Ref:Zhan13,Ref:Dunbar02,Ref:How06,Ref:Kuwata11}\else\citep{Ref:Dunbar02,Ref:How06}\fi.
%}{Weird section, we use receding-horizon a lot elsewhere and we generally talk about optimization techniques (e.g. LP, MILP, etc.) separately. How do we reconcile?}
\textbf{Formal methods} are used in concert with low-level control primitives for multi-agent motion planning with guaranteed collision avoidance \citep{Ref:KressGazit08}.
Decentralized multi-agent \textbf{sampling-based motion planning algorithms} have enjoyed significant practical success because of their ease of implementation, ability to handle higher-dimensional spaces, probabilistic completeness, and asymptotic optimality \ifjournalv\citep{Ref:Bandyopadhyay17_MA_SESCP,Ref:Bandyopadhyay17_MAMO_SESCP,Ref:How12,Ref:Solovey17arxiv}\else\citep{Ref:Bandyopadhyay17_MA_SESCP,Ref:How12}\fi.

\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Centralized optimization algorithms}\ifjournalv\else \vspace{-2.1mm} \fi \label{sec:centralized-optimization-algo}
\textbf{Mixed-integer linear programs (MILPs)} and mixed-integer convex programs (MICPs), can %for model-predictive control of systems with linear system dynamics, linear constraints, and complex \emph{logical} constraints encoded by integer-valued variables. % \cite{Ref:Morari99} provides a comprehensive introduction to MILPs and MIQPs for control of dynamical systems.
%MILPs can be used
 solve simultaneous task allocation and path planning \citep{Ref:How03}, tracking \citep{Ref:Zhe13}, formation flying \citep{Ref:How02}, and defend-the-flag problems \citep{Ref:Earl02modeling}\ifjournalv; they can encode collision avoidance and connectivity constraints  \citep{Ref:How02,Ref:Atay06,Ref:How06,Ref:Bezzo11}\fi.
%The computational complexity of MILPs is exponential in the problem size (and, in particular, in the number of agents) and, in general, MILPs are not amenable to a distributed solution.
\textbf{Linear and convex optimization} problems can also be used to solve task allocation problems  \citep{Ref:Bertsekas98b,Ref:Kumar14} with  collision avoidance constraints \citep{Ref:Acikmese06convex}, and for distributed estimation and target tracking \citep{Ref:Aslam2003tracking}.
%State-of-the-art solvers can efficiently solve linear and convex programming problems with millions of variables: thus, problems with hundreds or thousands of agents can be solved efficiently.
\textbf{Markov decision processes (MDPs)} and partially observable MDPs capture the stochastic nature of the environment and model the agents' \emph{coordination mechanism} \citep{Ref:Boutilier99b}% and capture the effect of miscoordination on the system
. POMDPs have been used for multi-agent path planning \citep{Ref:Ali15} and task allocation. %, and , the authors leverage MDPs to schedule battery swaps in a hardware platform with three UAVs. 
%In general, the complexity of muti-agent MDPs scales exponentially number of agents: thus, MDPs with more than a few agents are often intractable. A number of techniques are available to make large-scale MDPs and POMDPs tractable: e.g., \citep{Ref:Chen14} proposes hierarchical decomposition techniques for multi-agent MDPs.
\ifjournalv We refer the reader to \citep{Ref:Amato13} for a survey.\fi
%taxonomy of multi-agent POMDP problems and a survey of solution algorithms.
Several approximation algorithms are available to solve the \textbf{m-vehicle traveling salesman problem (TSP)} and the team orienteering problem, building blocks for spatial task allocation, persistent monitoring, and information-gathering problems \citep{Ref:Rus14}.
\ifjournalv \cite{Ref:Betkas06} and \cite{Ref:Vansteenwegen11} provide a review of formulations and algorithms for the m-TSP and the Team Orienteering problems respectively. \fi 
\textbf{Multi-agent multi-armed bandit} problems \citep{Ref:Gittins79} capture the trade-off between exploration and exploitation: they have been employed for task allocation \ifjournalv\citep{Ref:Le06,Ref:Le08} \else\citep{Ref:Le08} \fi, goal searching, and tracking applications \citep{Ref:Leonard16}.
\textbf{Direct methods for trajectory optimization} \citep{Ref:VonStryk92} are used for area coverage, goal searching, and motion planning \citep{Ref:Leonard10b}.
\textbf{Multi-agent reinforcement learning (MARL)}
 %enables robots to adapt to unknown environments and learn high-quality individual and joint policies with little to no \textit{a priori} information; it
 has been used for exploration \citep{Ref:Chalkiadakis03} and task allocation \citep{Ref:Liu16}.
\ifjournalv We refer the reader to \ifjournalv\cite{Ref:Boutilier98} and\fi \cite{Ref:Busoniu08} for thorough reviews. \fi
\textbf{Frontier techniques} \ifjournalv for area exploration use cost-based heuristics to assign robots to unexplored regions of the environment \citep{Ref:Yamauchi98,Ref:Burgard00}. They \else\citep{Ref:Burgard00} \fi are used for  urban search-and-rescue, reconnaissance \citep{Ref:Olson12} and sample collection \citep{Ref:Eich14}.
\ifjournalv \frmargin{\textbf{Genetic algorithms} have been used for searching targets in complex stochastic structures \citep{Ref:Sisso10}.
}{Redo, kinda awful}\fi
\ifjournalv In \textbf{network flow algorithms}, the environment that the agents move in is represented as a capacitated graph.
Network flow \else \textbf{Network flow}  \fi formulations have been proposed for Air Traffic Control \citep{Ref:Menon04} and for control of  autonomous vehicles offering on-demand transportation \citep{Ref:Pavone11b, Ref:Rossi17a}. %; problems with thousands of robotic agents can be solved efficiently on commodity hardware.
Several \textbf{cooperative combinatorial motion planning} algorithms have been proposed for multi-agent systems: we refer the reader to \citep{Ref:Sturtevant15} for a thorough review. % \emph{Complete} algorithms reduce the size of the problem with no loss of generality \ifjournalv\citep{Ref:Ryan08,Ref:Standley10,Ref:Standley11}\else\citep{Ref:Ryan08}\fi, but have worst-case exponential computation complexity; \emph{approximate} multi-agent motion planning algorithms employ heuristics to reduce the problem size and achieve polynomial complexity \ifjournalv\citep{Ref:Silver05,Ref:Botea08,Ref:Botea11}\else\citep{Ref:Silver05}\fi.
Centralized optimization algorithms can be implemented in a distributed fashion with a \textbf{shared-world} approach, where agents exchange their state and observations so that every robot has full knowledge of the entire system's state. However, shared-world algorithms have very onerous communication requirements (due to large messages and all-to-all communication) and high computation complexity, since each agent must solve the full centralized optimization problem.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Consensus Algorithm}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:Consensus-algorithm}
%Consensus is among the oldest and most widely used techniques for coordination of multi-agent systems \citep{Ref:Tsitsiklis86,Ref:Jadbabaie03,Ref:Saber04,Ref:Ren07}. 
%
%\textbf{\textit{Mathematical description:}} In the consensus algorithm, each agent updates its state
%using the following agreement equation:
%\begin{equation}
%x_{k+1}^{i}=\sum_{j\in\mathcal{J}_{k}^{i}}A_{k}[i,j]\thinspace x_{k}^{j}\thinspace,\quad\forall i\in\mathcal{V}\thinspace,\thinspace\forall k\in\mathbb{N}\thinspace,
%\end{equation}
%where the non-negative matrix $A_{k}\in\mathbb{R}^{\left|\mathcal{V}\right|\times\left|\mathcal{V}\right|}$ conforms to the graph $\mathcal{G}_{k}$ and is row stochastic, i.e., $\sum_{j\in\mathcal{V}}A_{k}[i,j]=1$ for all $i\in\mathcal{V}$.
%If the graph $\mathcal{G}_{k}$ is  periodically strongly-connected, then the states of all the agents converge to a unique state \citep{Ref:Jadbabaie03}. 
%If the matrix $A_{k}$ is balanced (i.e., doubly stochastic), then the final state is the center of mass of all the agents' states (i.e., $\frac{1}{\left|\mathcal{V}\right|}\sum_{i\in\mathcal{V}}x_{1}^{i}$). 
%Alternatively, if one of the agents (denoted as a leader) does not execute the consensus protocol but moves according to an exogenous trajectory, the other agents converge to the leader's state \citep{Ref:Hong06tracking}.
%
%\textbf{\textit{Mathematical guarantees:}} The convergence proof of the consensus algorithm on connected and periodically connected undirected networks where the agents are characterized by first-order linear dynamics follows from the Perron--Frobenius theorem \citep{Ref:Fax04,Ref:Saber07,Ref:Lafferriere05}. 
%Extensions of the consensus algorithm provide convergence guarantees in directed graphs with  time-varying network topology \citep{Ref:Ren05TAC}, arbitrary network topology \citep{Ref:Qin15}, random networks \citep{Ref:Tahbaz2008necessary}, and networks with time-varying network topology and communication delays \citep{Ref:Murray05b,Ref:Lin09} with sampled and quantized information \citep{Ref:Yu13, Ref:Olshevsky09}.
%Further extensions with second-order linear dynamics \citep{Ref:Cao10,Ref:Kurths10},  nonlinear Lagrangian dynamics \citep{Ref:Slotine04,Ref:Slotine05c,Ref:Slotine07,Ref:Chung09_TRO}, Lipschitz nonlinearities \citep{Ref:Rezaee17}, and neural network for uncertain dynamics \citep{Ref:Cheng10} have been studied.  
%In \citep{Ref:Kingston10}, the authors prove convergence for \emph{continuous} distributions of agents. Consensus algorithms that maintain the connectivity of the communication network are proposed in \citep{Ref:Egerstedt07}. In \citep{Ref:Rahmani09,Ref:Egerstedt12,Ref:Liu2011controllability}, the authors study the stability and controllability of the consensus protocol with multiple leaders. 
%Byzantine consensus algorithms for networks with Byzantine faults \citep{Ref:Lamport82} with two communication steps have been developed \citep{Ref:Martin06fast}. 
%
%For static communication graphs, the convergence rate of the consensus algorithm is proportional to the the second smallest eigenvalue of the  graph Laplacian.
%The convergence speed of a wide class of linear consensus algorithms employing the consensus protocol admits a quadratic upper bound as a function of the number of agents \citep{Ref:Tsitsiklis09}, even with a time-invariant communication network. However, nonlinear consensus-based control laws can achieve consensus in finite time \citep{Ref:Cortes06b,Ref:Khoo09,Ref:Wang10}. 
%
%\textbf{\textit{Communication bandwidth:}} At each time instant, each agent shares its state with all its neighbors. Thus, the resulting bandwidth use scales with the number of links in the communication graph. 
%
%\textbf{\textit{Applications:}} \textit{Spatially-organizing behaviors}: 
%Synchronization  \citep{Ref:Dorfler14,Ref:Dorfler13,Ref:Yu09pinning,Ref:Li2006global}, 
%Flocking \citep{Ref:Tanner07,Ref:Tanner2003stable,Ref:Tanner2003stable2,Ref:Spong08b,Ref:Dorigo12} with collision avoidance \citep{Ref:Saber06,Ref:Cucker08}, 
%Formation flying \citep{Ref:Lawton03decentralized,Ref:Leonard08,Ref:Chung12,Ref:Chung09,Ref:Hadaegh13}, 
%Coverage control \citep{Ref:Schwager08}.   
%\textit{Collective decision making}: 
%Localization \citep{Ref:Franceschelli14}, 
%Distributed error detection and recovery \citep{Ref:Franceschelli08}. 
%We refer the reader to \citep{Ref:Ren07,Ref:Garin10} for in-depth surveys of applications of the consensus algorithm.
%
%\textit{Distributed estimation} algorithms can be broadly classified into three categories based
%on their representation of the states of the target dynamics: (i) 
%Algorithms that estimate only the mean and the covariance matrix of the target's states \citep{Ref:Speyer79,Ref:Borkar82,Ref:Chen02,Ref:Tomlin08,Ref:Saber09,Ref:Battistelli15,Ref:Rabbat04,Ref:Murray05,Ref:Smith2007,Ref:Freeman08}.
%(ii) Algorithms that reach an agreement across the sensor network over a discrete set of hypotheses about the states of the target \citep{Ref:Pavlin10,Ref:Jadbabaie12,Ref:Nedic14_Cesar}.
%(iii) Algorithms that estimate the posterior probability distribution of the states of the target \citep{Ref:Bailey12,Ref:Ahmed13,Ref:Fraser12,Ref:Hlinka12,Ref:Hlinka14,Ref:Battistelli14,Ref:Bandyopadhyay14_ACC_BCF,Ref:Bandyopadhyay_BCF_arxiv,Ref:Bandyopadhyay18_Auto}.
%This category forms the most general class of distributed estimation algorithms because these algorithms can be used for estimation over continuous domains, and can incorporate nonlinear target dynamics, heterogeneous nonlinear measurement models, and non-Gaussian uncertainties.
%These algorithms also use the entire information in the estimated probability distribution of the target's states.
%
%
%In \textit{gossip algorithms} \citep{Ref:Shah06}, each agent communicates with a single randomly-selected neighbor at each time step, minimizing bandwidth use.
%In \textit{cyclic pursuit algorithms} \citep{Ref:Marshall04}, the consensus algorithm is executed on a directed ring communication topology. Cyclic pursuit algorithms can be used for formation flying \citep{Ref:Marshall04,Ref:Ramirez10,Ref:Singh15} and rendezvous \citep{Ref:Ramirez10}.
%%Consensus and cyclic pursuit algorithms have been implemented and validated in hardware experiments in numerous papers (e.g. \citep{Ref:Regmi05,Ref:Ren08,Ref:Schwager09}), including on the Spheres testbed on the International Space Station \citep{Ref:Ramirez10}. 
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Artificial Potential Functions (APF)}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:potential-functions}
%
%APF algorithms are a family of control techniques where the agents' control inputs or reference trajectory  are synthesized on the basis of the gradient of a suitably-defined potential function \citep{Ref:Khatib86}. 
%Potential functions  where the goal position (or positions) is guaranteed to be reachable from any feasible initial state are known as navigation functions \citep{Ref:Koditschek90,Ref:Rimon92}.
%
%\textbf{\textit{Mathematical description:}}
%In the APF algorithm, each agent updates its position using the following equation:
%\begin{equation}
%x_{k+1}^{i} = x_{k}^{i} - \nabla_{x_{k}^{i}} J\thinspace, \qquad \forall i\in\mathcal{V}\thinspace, \thinspace\forall k\in\mathbb{N}\thinspace, 
%\end{equation}
%where
%\begin{equation*}
%J = f_{\textrm{attraction}}(x_{k}^{i}, \textrm{target}) + f_{\textrm{repulsion}}(x_{k}^{j} \thinspace \forall j\in\mathcal{V}, \textrm{obstacles}) \thinspace. 
%\end{equation*}
%Here the nonlinear function $f_{\textrm{attraction}}$ creates a potential field that attracts the agent to its target, and the nonlinear function $f_{\textrm{repulsion}}$ creates a potential field that repels the agent from other agents and obstacles in the environment \citep{Ref:Merheb16}. 
%
%\textbf{\textit{Mathematical guarantees:}}
%\mwmargin{**}{This actually points out limitations rather than discussing ``guarantees''}
%Although APFs are widely used due their ease of implementation, they present a number of well-understood limitations, including the presence of local minima that may cause agents to become stuck, difficulty in navigating narrow passages, and potential oscillations when traversing narrow passages and in proximity to obstacles \citep{Ref:Koren91}.
%
%\textbf{\textit{Communication bandwidth:}} 
%Distributed implementations of APF techniques generally offer excellent scalability, requiring agents to communicate with a limited number of their immediate neighbors \citep{Ref:Vadakkepat01}.
%%; if a broadcast communication mechanism is available, agents can simply broadcast their position for their neighbors to use. APF techniques have been widely tested in hardware and are often used as as part of larger robotic systems \citep{Ref:Vadakkepat01}. 
%
%\textbf{\textit{Applications:}}
%\textit{Spatially-organizing behaviors}: Formation control and pattern formation \citep{Ref:Tanner05,Ref:Tanner12,Ref:Leonard07,Ref:Gazi05,Ref:Hsieh08,Ref:Spong08,Ref:Barnes09swarm,Ref:De2006formation} in satellites \citep{Ref:Pinciroli08,Ref:Saaj06spacecraft,Ref:Peck07spacecraft}, 
%Shape formation \citep{Ref:Slotine09},
%Flocking \citep{Ref:Chuang07,Ref:Zavlanos2007flocking},
%Perimeter formation \citep{Ref:Bruemmer02},
%Coverage control  \citep{Ref:Hussein07,Ref:williams13}.
%\textit{Collective explorations}: Area exploration \citep{Ref:Xu11}, 
%Foraging \citep{Ref:Passino04,Ref:Gazi07}. 
%\textit{Collective decision making}: Multi-agent path planning \citep{Ref:Koditschek90,Ref:Loizou02,Ref:Loizou06,Ref:Dimarogonas03,Ref:Dimarogonas05,Ref:Lionis07,Ref:Warren90,Ref:Lee13,Ref:Vadakkepat01,Ref:Ayanian10},
%Multi-agent cooperative manipulation \citep{Ref:Khatib96,Ref:Bai10},
%Network connectivity maintenance \citep{Ref:Dani12,Ref:Dimarogonas08,Ref:Zavlanos07,Ref:De2006decentralized},
%Task allocation \citep{Ref:Weigel02,Ref:Pappas08b}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\ifjournalv\else \vspace{-1.8mm} \fi\section{Geometric Algorithms}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:geometric-algo} 
%In this section, we present algorithms that use some geometric technique. 
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Voronoi-based Algorithms \label{subsec:Voronoi}\ifjournalv\else \vspace{-2.1mm} \fi}
%A Voronoi diagram partitions the space into regions based on the distance from the individual agents. 
%
%\textbf{\textit{Mathematical description and guarantees:}} 
%In coverage algorithms based on Voronoi-partitions \citep{Ref:Bullo04,Ref:Bullo08,Ref:Bullo09book}, each agent first computes its Voronoi partitions as follows:
%\begin{equation}
%\mathcal{V}_k^i = \{ q \in \mathcal{X} | \| q - x_k^i \|_2 \leq \| q - x_k^j \|_2 \thinspace, \forall j \neq i \} \thinspace ,
%\end{equation}
%where $\mathcal{X} \subset \mathbb{R}^{n_{x}}$ represent the space to be covered by these agents.
%Then each agent moves towards the centroid $\mathcal{C}_{\mathcal{V}_k^i} = \frac{\int_{\mathcal{V}_k^i} q \thinspace dq}{\int_{\mathcal{V}_k^i} dq}$ of its Voronoi.
%The agents asymptotically achieve an optimal coverage of the space because the centroidal-Voronoi configurations are fixed points of this algorithm \citep{Ref:Bullo04}.
%
%\textbf{\textit{Communication bandwidth:}} 
%These algorithms offer excellent scalability, since the agents only communicate with their immediate neighbors.
%
%\textbf{\textit{Applications:}} 
%\textit{Spatially-organizing behaviors}: Coverage \citep{Ref:Bullo04,Ref:Bullo08,Ref:Bullo09book,Ref:Schwager07,Ref:Bhattacharya14,Ref:Martinez07a,Ref:Martinez07b,Ref:Gao08,Ref:Pappas13},
%Flocking \citep{Ref:Johansson05}.
%\textit{Collective explorations}: Area Exploration \citep{Ref:Guruprasad11}.
%\textit{Collective decision making}: Multi-agent path planning \citep{Ref:Sud08,Ref:Bandyopadhyay14MSC,Ref:Zhou17},
%Learning \citep{Ref:Wood12},
%Task allocation \citep{Ref:Pavone11}.
%
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Circumcenter Algorithm \label{subsec:circumcenter}\ifjournalv\else \vspace{-2.1mm} \fi}
%In the circumcenter algorithm for rendezvous, each agent moves towards the circumcenter of the point set comprised of its inclusive neighbors \citep{Ref:Cortes06,Ref:Dimarogonas07}. 
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Bearing-only Algorithms \label{subsec:bearing-only}\ifjournalv\else \vspace{-2.1mm} \fi}
%In these algorithms, each agent maintains its neighbor at a desired bearing angle and no inter-agent communication in order to achieve a formation \citep{Ref:Fredslund02}, rendezvous \citep{Ref:Yu08rendezvous}, or cooperative localization \citep{Ref:Sharma12}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Maze Searching Algorithms}\ifjournalv\else \vspace{-2.1mm} \fi
%This is a decentralized multi-agent path planning algorithm through unknown stationary obstacles and no inter-agent communication \citep{Ref:Lumelsky97}, which is an extension of the single-agent maze searching algorithm \citep{Ref:Lumelsky87}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Leader-Follower (LF) Algorithms}\ifjournalv\else \vspace{-2.1mm} \fi
%LF algorithms have been used for formation flying \citep{Ref:Mesbahi99formation,Ref:Beard00feedback,Ref:Consolini09} and formation control \citep{Ref:Desai01modeling}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Velocity Obstacle (VO) based Algorithms \label{subsec:velocity-obstacle}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Would this deserve its own subsection,given that it is ubiquitous?}
%VO based collision avoidance algorithms have been developed for multi-agent motion planning \citep{Ref:vabdenBerg08,Ref:Bareiss15,Ref:Hoy14}.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{State Machines and Behavior Composition}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:automata-algo}
%\frmargin{*}{I think a single intro and then short paragraph (akin to the current ones) for each method would be perfect here.}
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Automata based Algorithms \label{subsec:message-passing}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Long, all others below short}Automata-based algorithms is used for a wide class of applications like leader election and coordination \citep{Ref:Rossi14,Ref:Lynch97,Ref:Gallager83,Ref:Awerbuch87,Ref:Burns80}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Behavior Composition\label{subsec:behavior-composition}\ifjournalv\else \vspace{-2.1mm} \fi}
%This algorithm involves composition of elementary behaviors to achieve common tasks \citep{Ref:Huntsberger03}, like task allocation \citep{Ref:Parker98}.
%
%\textcolor{red}{Moving Furniture with Teams of Autonomous Robots \citep{Ref:Rus1995moving}, Broadcast of Local Eligibility \citep{Ref:Werger00,Ref:Werger00broadcast}}
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Petri Networks\label{subsec:petri-nets}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{This algorithm allows centralized task allocation and recovery from deadlock/livelock \citep{Ref:King03,Ref:Kotb12}.}{This is CENTRALIZED, consider moving elsewhere.}
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Resource Allocation Systems\label{subsec:RAS}\ifjournalv\else \vspace{-2.1mm} \fi}
%This algorithm partitions the space into grids and generates multi-agent motion planning algorithms by allocation resources from the grid appropriately \citep{Ref:Reveliotis11}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Game Theory based Algorithms\label{subsec:game-theory}\ifjournalv\else \vspace{-2.1mm} \fi}
%Game theory based algorithms have been used for multi-agent task allocation \citep{Ref:Stirling01,Ref:Beard02,Ref:Arslan07}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Bio-Inspired Algorithms}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:bio-inspired-algo}
%\frmargin{*}{Same as above: one intro with mathematical description, then two sentences for each. Say we are not exhaustive lest we annoy some reviewer.}
%These algorithms are inspired by biological phenomena in birds, bacteria, cells, etc. They usually require low bandwidth and are highly scalable. 
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Kilobot Self-Assembly Algorithm \label{subsec:nagpal}\ifjournalv\else \vspace{-2.1mm} \fi}
%A thousand-robot swarm of Kilobots can achieve complex two-dimensional shapes using this algorithm, which relies on inter-agent communication for localization, edge-following, and gradient-based formation control algorithm inspired by multi-cellular organisms \citep{Ref:Nagpal14}. 
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Optimotaxis Source-Searching Algorithm \label{subsec:optimotaxis}\ifjournalv\else \vspace{-2.1mm} \fi}
%Inspired by the run and tumble behaviors of bacteria (chemotaxis), this algorithm induces a signal-concentration-based random walk in the swarm's agents and estimates the spatial distribution of the source signal \citep{Ref:Hespanha08}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Beeclust Foraging Algorithm \label{subsec:beeclust}\ifjournalv\else \vspace{-2.1mm} \fi}
%Inspired by the behavior of honey bees, this algorithm searches for signal peaks in the environment by making the swarm's agent wait at any location for a time that is proportional to the signal concentration at that location \citep{Ref:Hereford10,Ref:Hereford11}. 
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Shepherding Algorithm\label{subsec:shepherding}\ifjournalv\else \vspace{-2.1mm} \fi}
%Inspired by dogs herding flocks of sheep, this behavioral-primitives-based algorithm enables shepherding a large number of uncontrolled agents with a few controlled agents \citep{Ref:Strobom14}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Termite-Inspired Collective Construction Algorithm\label{subsec:stymergy}\ifjournalv\else \vspace{-2.1mm} \fi} 
%This termite-inspired collective behavior algorithm generates low-level rules for independent climbing robots to enable construction of complex structures \citep{Ref:Nagpal14termite,Ref:Nagpal06,Ref:Terada04stymergy}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Fish-inspired Goal Searching Algorithms \label{subsec:bio-flocking}\ifjournalv\else \vspace{-2.1mm} \fi}
%Inspired by schools of fish, agents executing this goal (local-minima) searching algorithm switch between individual and cooperative behaviors based on their level of confidence \citep{Ref:Wu12}. 
%%Bio-inspired flocking with limited communication. Sims only. Bandwidth: exchange speed, heading with neighbors. Scales: well. \citep{Ref:Savkin10}. -> This is the same as consensus
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Gillespie Self-Assembly Algorithm\label{subsec:gillespie}\ifjournalv\else \vspace{-2.1mm} \fi}
%This stochastic, decentralized algorithm for the self-assembly of a group of modular robots into a geometric shape is based on the Gillespie algorithm for chemical kinetics \citep{Ref:Ayanian08stochastic}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Mergeable Modular Robots\label{subsec:MNS}\ifjournalv\else \vspace{-2.1mm} \fi} 
%Here groups of robots can connect to form larger bodies or split into separate bodies, with independent
%controllers, and self-heal by removing or replacing malfunctioning body parts \citep{Ref:Dorigo17,Ref:Dorigo06,Ref:Mondada2004swarm,Ref:Dorigo2013swarmanoid,Ref:Kotay1998self}.
%
%%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Ant Colony Optimization}\ifjournalv\else \vspace{-2.1mm} \fi
%%This distributed optimization algorithm is based on ants cooperating and communicating among themselves using pheromones deposited on the edges of the graph \citep{Ref:Dorigo96ant,Ref:Dorigo2006Ant}. It has been applied to the traveling salesman problem \citep{Ref:Dorigo97ant}. 
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Density-Based Control Algorithms}\ifjournalv\else \vspace{-1.8mm} \fi
%As opposed to the standard agent-based approach (\emph{Lagrangian} framework), the techniques in this section treat the swarm as a continuum and control the density of agents in the workspace (\emph{Eulerian} framework).  
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Markov Chain (MC) based Algorithm \label{subsec:markov-chain}\ifjournalv\else \vspace{-2.1mm} \fi}
%MC based algorithms are extremely useful for guidance of large swarms ($10^3-10^6$ agents), where it is not practical for the agents to share their individual states.  
%
%\textbf{\textit{Mathematical description and guarantees:}} 
%The workspace $\mathcal{X} \subset \mathbb{R}^{n_x}$ is partitioned into disjoint bins (cells), which are represented as $B[\ell], \forall \ell \in \{1,\ldots,n_{bin}\}$. 
%The transition probability between bins for the $i^{\textrm{th}}$ agent at the $k^{\textrm{th}}$ time instant is dictated by the Markov matrix $\mathbf{M}_k^i$. For example, the $i^{\textrm{th}}$ agent's transition probability from bin $B[\ell_1]$ to bin $B[\ell_2]$ at the $k^{\textrm{th}}$ time instant is given by:
%\begin{equation}
%\mathbf{M}_k^i[\ell_1, \ell_2] = \mathbb{P}(i^{\textrm{th}} \textrm{ agent transitions from } B[\ell_1] \textrm{ to } B[\ell_2]) \thinspace .
%\end{equation}
%For a well designed Markov matrix $\mathbf{M}_k^i$, it can be shown that the swarm exponentially converges to the desired distribution \citep{Ref:Bandyopadhyay17_TRO}. 
%
%\textbf{\textit{Communication bandwidth:}} 
%Homogeneous MC algorithms require no communication \citep{Ref:Acikmese12,Ref:Acikmese15asian}, while inhomogeneous MC algorithms \citep{Ref:Bandyopadhyay17_TRO} use the consensus algorithm to estimate the current swarm distribution. 
%
%\textbf{\textit{Applications:}} 
%Both homogeneous MC \citep{Ref:Milutinovic06,Ref:Acikmese12,Ref:Acikmese15asian,Ref:Chattopadhyay09,Ref:Acikmese15convex,Ref:Acikmese15_AR} and inhomogeneous MC \citep{Ref:Bandyopadhyay_IROS16,Ref:Bandyopadhyay17_TRO,Ref:Giri14} algorithms can be used for pattern formation, coverage, area exploration, and goal searching. 
%Additional applications include multi-agent surveillance \citep{Ref:Grace05stochastic}, coverage \citep{Ref:Leonard13,Ref:Gundry12markov}, task allocation \citep{Ref:Kumar09,Ref:Mather12}. 
%
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Smoothed Particle Hydrodynamics (SPH) \label{subsec:SPH}\ifjournalv\else \vspace{-2.1mm} \fi}
%SPH is used for density-based control of the swarm to achieve spatially-organizing behaviors  \citep{Ref:MKumar11,Ref:Kumar13,Ref:Erkmen07}.
%%Similarly, an abstraction map is used to transform the high-dimensional state space into a smaller, tractable state space which captures only the position, orientation, and shape of the formation \citep{Ref:Michael08,Ref:Michael09}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Optimal Transport based Algorithm \label{subsec:optimal-transport}\ifjournalv\else \vspace{-2.1mm} \fi}
%Optimal transport \citep{Ref:Villani08} is a mathematical technique for transporting the swarm, represented as a probability distribution, from its current distribution to a desired distribution while optimizing a cost function \citep{Ref:Bandyopadhyay14MSC,Ref:Bandyopadhyay17_Rainbow}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Centralized Optimization Algorithms}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:centralized-optimization-algo}
%\frmargin{*}{Here, communication bandwidth can be treated in the introduction to the section}
%A multi-agent optimization problem often takes the form: 
%\begin{align}
%\underset{variables}{\textrm{minimize }}   & Cost \thinspace function \label{eq:MAOP-cost} \\
%\textrm{subject to } & Constraints \thinspace , \nonumber 
%\end{align}
%where the $variables$, $Cost \thinspace function$, and $Constraints$ depend on the states of the multi-agent systems and the task. 
%All algorithms in this section solve this multi-agent optimization problem (\ref{eq:MAOP-cost}) in a centralized manner.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Mixed-Integer Linear Programming (MILP) and Mixed-Integer Nonlinear Programming (MINLP) Algorithms \label{subsec:MILP}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Add paragraphs for math description and applications}
%Mixed-integer linear programs (MILPs) can be used for optimal control of systems with linear system dynamics, linear constraints, and complex \emph{logical} constraints encoded by integer-valued variables. Mixed-integer quadratic programs (MIQPs) and mixed-integer convex programs (MICPs) allow further expressivity by incorporating quadratic and convex constraints. We refer the reader to \citep{Ref:Morari99} for a comprehensive introduction to MILPs and MIQPs for control of dynamical systems.
%
%MILPs and MICPs have been widely used for task allocation and path planning in multi-agent robotic systems problems. In particular, MILPs can be used to solve \emph{simultaneous} task allocation and path planning problems with applications including tracking of multiple targets \citep{Ref:Zhe13},  task assignment for UAVs \citep{Ref:How03,Ref:Alighanbari05}, spacecraft formation flying \citep{Ref:How02,Ref:Tillerson02}, and defend-the-flag games (RoboFlag, \citep{Ref:Earl02modeling}, \citep{Ref:Shamma05}). 
%MILPs can encode collision avoidance constraints, and communication or connectivity constraints \citep{Ref:How02,Ref:Atay06,Ref:How06,Ref:Bezzo11}; collision avoidance constraints capture both the presence of static obstacles and the other agents' trajectories, and they can include complex constraints such as thruster plume impingement \citep{Ref:How02}.
%
%Several implementations of MILP algorithms in hardware are reported in the literature, e.g. \citep{Ref:Zhe13,Ref:How06,Ref:Kushleyev13}.
%Scalability of MILPs with the number of agents is problematic: in general, the complexity of MILPs is exponential in the problem size (and, in particular, in the number of agents). In \citep{Ref:Kushleyev13}, the authors demonstrate path planning and collision avoidance on a hardware testbed with 20 UAVs: however, the resulting controller requires several seconds to produce a feasible solution, and multiple minutes to achieve an optimal solution.
%
%In general, MILPs are not amenable to distributed solution.
%However, linear relaxation of MILPs (LPs) are amenable to a distributed implementation; rounding can then be used to recover a suboptimal integral solution \citep{Ref:Zhe13,Ref:Shamma05}.
%
%MILPs can also be solved in a shared-world framework (Sec. \ref{sec:shared-world-optimization-algo}): in \citep{Ref:Alighanbari05}, the authors proposed MILP models that are robust to synchronisation errors among the agents, and the approach is demonstrated in hardware in \citep{Ref:Bethke06}. %20 agents sim, 3 agents hw
%
%Finally, MILPs can be used for \emph{local} optimization in path planning: every agent optimizes its own path given the other agents' planned paths, and iterative communication  ensures feasibility of the optimal solution (although convergence to an optimum is generally not guaranteed) \citep{Ref:How06,Ref:Kuwata11}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Markov Decision Processes (MDP) \label{subsec:MDP}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Add paragraphs for math description and applications}
%Markov decision processes (MDPs) \citep{Ref:Puterman14} and partially observable Markov Decision Processes (POMDPs) \citep{Ref:Monahan82} offer a natural description of multi-agent systems that captures the stochastic nature of the agents' dynamics and of the environment: thus, they are widely used for motion planning and task allocation in robotic systems. Critically, for multi-agent systems, MDPs can explicitly model the agents' \emph{coordination mechanism} \citep{Ref:Boutilier99b} and capture the effect of miscoordination on the system. MDPs can be leveraged to compute optimal \emph{policies} offline for each state of the system: such policies allow systems of agents to react to stochastic occurrences in real-time with minimal computation and communication overhead. As such, MDPs are especially well-suited to path planning under uncertainty and task allocation applications for multi-agent systems. Accordingly,  \citep{Ref:Ali15} proposes techniques for multi-agent path planning using Partially Observable Markov Decision Processes (POMDPs). In \citep{Ref:Ure15}, the authors leverage MDPs to schedule battery swaps in a hardware platform with three UAVs. 
%In general, the complexity of muti-agent MDPs scales exponentially number of agents: thus, MDPs with more than a few agents are often intractable. A number of techniques are available to make large-scale MDPs and POMDPs tractable: in particular, \citep{Ref:Chen14} proposes hierarchical decomposition techniques for multi-agent MDPs. We refer the reader to \citep{Ref:Amato13} for a taxonomy of multi-agent POMDP problems and a survey of solution algorithms.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Multi-Agent Traveling Salesman Problem (TSP) \label{subsec:TSP}\ifjournalv\else \vspace{-2.1mm} \fi}
%
%\frmargin{*}{Add paragraphs for math description and applications}
%The traveling salesman problem (TSP) consists of finding a route of minimal length that visits a set of prescribed points; the closely related Orienteering problem consists of finding a route that maximizes the number of points visited without exceeding a length constraint.  
%The TSP and the orienteering problem are not algorithms but rather combinatorial problems. However, a number of high-quality approximation algorithms are available to solve many variations of the TSP and the Orienteering problem (including the m-vehicle TSP, and the team orienteering problem). In turn, solutions to the TSP and Orienteering problems are often used as fundamental building blocks to solve complex problems in robotics. 
%\citep{Ref:Betkas06} provides an excellent review of formulations and algorithms for the multi-agent Traveling Salesman Problem (m-TSP). \citep{Ref:Vansteenwegen11} provides a similar review for the Orienteering and Team Orienteering problems. 
%
%The m-vehicle Traveling Salesman Problem can be used to solve spatial task allocation problems; the team orienteering problem can be used as a building block for persistent monitoring and information-gathering problems \citep{Ref:Rus14}.
%
%In \emph{dynamic} versions of the TSP, the list of locations to be visited is progressively revealed to the agents and drawn from a stochastic distribution. \citep{Ref:Bullo11} provides solutions to the multi-agent Dynamic Traveling Repairman Problem, a version of the multi-agent TSP where agents must spend a set amount of time at each visited location. 
%
%% \frmargin{TODO}{I can not find an example of mTSPs in hardware. But there must be hundreds!} scalability, hardware. mTSP: benchmarks consider 3-5 agents. In special cases, one can reduce mTSP to TSP, and TSP can be approximately solved for thousands of nodes \citep{Ref:Betkas06,Ref:Applegate03} . Orienteering: seconds to solve problems with hundreds of nodes but few (four) agents \citep{Ref:Vansteenwegen11}. 
%% \frmargin{TODO k-rural postman problem for perimeter coverage \citep{Ref:Easton05} with hardware experiments \citep{Ref:Correll07}}{TODO}
%% \frmargin{Hierarchical strategy \citep{Ref:Jingjin14}}{Not TSP - review with Saptarshi}
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Multi-Armed Bandits (MAB) \label{subsec:MAB}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%In  Multi-Armed Bandit (MAB)  problems \citep{Ref:Gittins79}, an agent must repeatedly select an action from a finite set of possibilities. Each action yields a stochastic reward with an initially unknown distribution; the goal is to maximize the expected discounted reward collected by the agent over an infinite horizon. Variations of the MAB problem allow the stochastic distribution of the rewards to evolve in time, possibly depending on whether the action is selected or not \citep{Ref:Whittle88}. In multi-agent MAB problems, multiple agents may each select an action independently.  MAB problems capture well the trade-off between exploration and exploitation: as such, they have been employed for task allocation \citep{Ref:Le06,Ref:Le08} and surveillance applications \citep{Ref:Leonard16} %after \citep{Ref:Leonard14}, which is single-agent
%for multi-agent systems. MAB algorithms can also be implemented in a shared-world framework \citep{Ref:Leonard16}; a consensus algorithm  (Sec. \ref{sec:Consensus-algorithm}) is used to synchronize the agents' beliefs.
%%Centralized, can use consensus. Hardware: not that I know of, check papers.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Direct Methods for Optimal Control \label{subsec:direct-methods}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%Direct methods for trajectory optimization \citep{Ref:VonStryk92} %can be used to find approximately optimal trajectories that maximize . Such methods are generally not suitable for real-time control; however, they
%can be used to design multi-agent trajectories that approximately minimize a cost function over a known environment. Applications of direct methods for trajectory optimization to multi-agent robotic systems include area coverage, goal searching, and distributed estimation. While direct methods are generally not suitable for real-time optimization due to their high computational complexity, they can be used to design open-loop trajectories that can be tracked in real-time by a lower-level controller.
%Direct methods have been employed as part of larger control architectures and are technologically mature. For instance, in \citep{Ref:Leonard07b}, the authors leverage direct methods to design trajectories for autonomous underwater vehicles that maximize the information gain over an information field with known distribution; such techniques are demonstrated in the field with a system of six underwater gliders in \citep{Ref:Leonard10b}. 
%
% Widely used, mature (as in integrated in larger systems). For example, Leonard07 uses such techniques to design trajectories that maximize information gain for a group of autonomous underwater vehicles in the Monterey Bay ; field trials with six gliders are reported in \citep{}

%Optimization of parametrized trajectories to maximize information gain \citep{Ref:Leonard07b}, hardware experiments in Monterey Bay with six gliders \citep{Ref:Leonard10b}.

% \ifjournalv\else \vspace{-2.1mm} \fi\subsection{Dynamic Programming \label{subsec:DP}\ifjournalv\else \vspace{-2.1mm} \fi}
% \frmargin{Centralized approach}{Consider skipping - we kind of already cover this in MDPs} \citep{Ref:De02}
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Multi-agent Reinforcement Learning}\ifjournalv\else \vspace{-2.1mm} \fi
%\label{subsec:RL}
%\frmargin{*}{Short}
%Multi-agent reinforcement learning (MARL) enables robots to adapt to unknown environments and learn high-quality individual and joint policies with little to no \textit{a priori} information. In \emph{independent learners} MARL algorithms, each agent attempts to learn an optimal policy for itself; in \emph{joint action learners} algorithms, agents collaborate to learn a \emph{joint} optimal policy. We refer the reader to \citep{Ref:Boutilier98} for a taxonomy of problems in multi-agent reinforcement learning and to \citep{Ref:Busoniu08} for a more up-to-date review of the problem and of solution algorithms. 
%\citep{Ref:Chalkiadakis03} proposes a Bayesian multi-agent reinforcement learning algorithm that explicitly captures the value of information sharing between the agents and the cost of exploration. In the model, each agent holds a Bayesian model of the other agents' policy, allowing agents to adapt to each other's policies with no communication.
%\citep{Ref:Liu16} proposes use of a centralized hierarchical reinforcement learning approach for human-in-the-loop control of robots in urban search-and-rescue situations: the RL algorithm is used for multi-robot exploration and task allocation on a two-robot hardware testbed.
%
%%Q-learning for multiagent systems, a taxonomy of problems \citep{Ref:Boutilier98}. Discusses each agent learning its own policy (independent learners) vs. agents learning a joint policy (joint learners), not a huge difference and convergence to optimum not guaranteed.
%
%%Bayesian approach\citep{Ref:Chalkiadakis03}. Captures "value of information" and cost of exploration. Each agent has a Bayesian model of other agents.
%% Comprehensive review: \citep{Ref:Busoniu08} (700+ citations!). Hierarchical RL approach with human in the loop and lab hardware trials \citep{Ref:Liu16}
%
%
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Frontier Techniques \label{subsec:centralized-frontier}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%Frontier techniques for area exploration leverage a cost-based heuristic to assign robots to unexplored regions of the environment so as to approximately minimize the time required for full exploration \citep{Ref:Yamauchi98,Ref:Burgard00,Ref:Burgard05}. Frontier techniques are generally centralized; however, they can be adapted to accommodate the agents' limited communication range with good performance in practical applications \citep{Ref:Burgard05}.
%Frontier techniques have seen wide adoption as part of robotic stacks for applications including urban search-and-rescue and reconnaissance (\citep{Ref:Olson12}, with a fourteen-robot team), and proposed Lunar sample collection missions (\citep{Ref:Eich14}, with a shared-world three-robot architecture).
%
%
%
%%\citep{Ref:Burgard00}, probabilistic method to explore an area. Heuristic
%%\citep{Ref:Olson12}: centralized exploration via frontier methods. Tested in the MAGIC 2010 competition.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Genetic Algorithms \label{subsec:ga}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%Genetic algorithms have been used for searching targets in complex stochastic structures \citep{Ref:Sisso10}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Linear and Convex Optimization}\ifjournalv\else \vspace{-2.1mm} \fi
%\frmargin{*}{Discuss}
%\label{subsec:convex_opt}
%The task allocation problem, a central problem in multi-agent robotics, can be posed\mwmargin{**}{Is this always true? (for all task allocation problems)} as a linear program \citep{Ref:Bertsekas98b}, and can therefore be solved very efficiently. This observation has motivated significant research on extensions of the task allocation problem that capture additional constraints (in particular collision avoidance constraints) while preserving the tractability of the problem. 
%In \citep{Ref:Acikmese06convex}, an algorithm for task allocation with collision avoidance constraints is proposed: a heuristic is proposed to approximate the collision avoidance constraints with a convex constraint. The overall problem is a second-order cone program; the algorithm is used for reconfiguration of spacecraft formations.
% \citep{Ref:Kumar14} shows that, if a cost function minimizing the integral of the squared velocity of the agents is selected, the task allocation problem is guaranteed to yield collision-free trajectories; under mild conditions, the result also holds for agents of finite size. The authors also propose a decentralized implementation of the algorithm, based on message-passing, that yields locally-optimal and collision-free solutions. 
%
%State-of-the-art solvers can efficiently solve linear and convex programming problems with millions of variables: thus, problems with hundreds or thousands of agents can be solved efficiently.
%\frmargin{LPs can also be used for estimation, etc.}{Improve}
%
%\textcolor{red}{The task assignment problem can be stated as a LP and efficiently solved using Kuhn's Hungarian algorithm \citep{Ref:Kuhn55,Ref:Bertsekas1981new}.
%Target tracking using a binary sensor network can be stated as a LP \citep{Ref:Aslam2003tracking}.}
%
%%\citep{Ref:Shamma05}
%%Centralized convex problem for formation reconfiguration \citep{Ref:Acikmese06convex}. Time is discretized, A heuristic is used to convexify the collision avoidance constraints. Problem is a SOCP.
%
%%Concurrent assignment and planning of trajectories \citep{Ref:Kumar14}. Matching problem is solved as a QP minimizing integral of velocity squared. The problem is shown to yield collision-free trajectories with something that looks like an extension of the triangle inequality. Demonstrated in HW with quadcopters. \frmargin{Decentralized solution proposed that leverages message-passing among close-by agents to yield a locally optimal solution.}{Move}
%
%%Linear programming-based multi-agent motion planning with adversaries (modeled as a resource allocation problem) \citep{Ref:Shamma05}. Problem is modeled as a MILP. Adversary's dynamics are assumed to be known (and MPC is used to replan). \frmargin{Rounding}{Move to MILPs?} (picking the maximum) is used to compute a strategy.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Network Flow Algorithms \label{subsec:network-flow}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%In network flow algorithms, the environment that the agents move in is represented as a capacitated graph.
%The agents move from origin nodes to destination nodes; the assignment of robotic agents to destinations may either be fixed or an optimization variable. A traversal cost is associated with each edge; the agents' routes are optimized so as to minimize a cost function defined on the edges while satisfying constraints (e.g., capacity constraints on the edges).
%
%Network flow formulations have been proposed for Air Traffic Control \citep{Ref:Menon04} and for control of  fleets of self-driving vehicles offering on-demand transportation (also known as Autonomous Mobility-on-Demand) \citep{Ref:Pavone11b, Ref:Rossi17a, Ref:Rossi17b}. Network flow problems can be solved either as linear programs or with dedicated combinatorial algorithms \citep{Ref:Goldberg90}: problems with thousands of robotic agents can be solved efficiently on commodity hardware.
%
%
%
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Combinatorial Motion-Planning Algorithms \label{subsec:combinatorial-mp}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Break out mathematical description and guarantees}
%%Combinatorial motion planning ubiquitously used for motion planning in robotic systems \citep{Ref:Lavalle06}. A* can be used on the joint search space \citep{Ref:Ryan08}, but it is huge.
%%
%%Multiple classes of approximate solutions (incomplete algorithms).  
%%
%%Cooperative A$^{\star}$, Hierarchical CA*, Windowed Hierarchical A* \citep{Ref:Silver05}. Improvements on A* for cooperative multi-agent path planning. Heuristics to resolve conflicts between the agents by planning in a round-robin fashion and "reserving" parts of the path (possibly for finite amounts of time, i.e. windowed A*). Experiments with 100s of agents on 2d maze.  \citep{Ref:Silver05}
%%
%%FAR \citep{Ref:Botea08}: ensure that agents can not collide with local "one-way" rules, heuristic for deadlock avoidance.
%%MAPP \citep{Ref:Botea11} also proposes heuristics for run-time conflict resolution: the proposed algorithm offers 
%% and offers analytical guarantees on certain classes of problem instances and performs well on benchmark problems.
%%
%%Complete algorithms
%%Search the entire state \citep{Ref:Ryan08}. Recognize subproblems that can be solved in a decoupled way \citep{Ref:Standley10}. Extended pruning and an anytime algorithm \citep{Ref:Standley11}
%%
%%\citep{Ref:Sharon13} proposes an alternative search technique based on a two-level search. An ``increasing cost tree'' is used to guide the search and prune suboptimal solutions. On certain problem instances, the technique is shown to sometimes offer significant improvements in computational complexity compared to A*. 
%%
%%Conflict-based search \citep{Ref:Sturtevant15}. Local searches with A*, a "conflict tree" keeps track of conflicts.
%
%Combinatorial motion planning algorithms such as $A^\star$ are ubiquitously used for motion planning in robotic systems. Several extensions of such algorithms to cooperative motion planning in multi-agent systems have been proposed: we refer the reader to \citep{Ref:Sturtevant15} for a thorough review.
%
%The A* algorithm can be used to search the joint state space of \emph{all} agents: however, the resulting problem is generally intractable \citep{Ref:LaValle13}. A class of \emph{complete} algorithms have been proposed to reduce the size of the problem with no loss of generality: \citep{Ref:Ryan08} and \citep{Ref:Standley10} propose techniques to efficiently prune the search space, and an anytime algorithm is proposed in \citep{Ref:Standley11}.
%In \citep{Ref:Sharon13}, the authors propose a search technique based on a two-level search: an ``increasing cost tree'' is used to quickly prune suboptimal solutions. On certain problem instances, the technique is shown to sometimes offer significant improvements in computational complexity compared to A*.  In \citep{Ref:Sturtevant15}, a conflict-based search algorithm is proposed where a "conflict tree" is used to keep track of conflicts between the agents' paths.
%
%Since the multi-agent motion planning problem is NP-hard, the worst-case complexity of complete algorithms is exponential in the number of agents.
%Accordingly, several \emph{approximate} multi-agent motion planning algorithms have been proposed. Such algorithms are not guaranteed to find the optimal solution (and, indeed, they may fail to find a feasible solution when one exists): however, they generally offer good performance in practical applications. 
%In \citep{Ref:Silver05}, the Cooperative A$^{\star}$, Hierarchical CA$^{\star}$ and Windowed Hierarchical A$^{\star}$ are proposed: agents plan their routes in round-robin fashion and consider the other agents' routes as obstacles. 
%The FAR algorithm \citep{Ref:Botea08} labels the environment with one-way rules to ensure that agents can plan collision-free routes. The MAPP algorithm \citep{Ref:Botea11} also proposes heuristics for run-time conflict resolution: the proposed algorithm offers analytical guarantees for a class of problem instances and performs well on benchmark problems.
%
%Conflict-based search techniques are employed in \citep{Ref:Thomas15} to study the Convoy Movement Problem, an extension of the combinatorial motion planning problem where agents have nonzero length and can occupy multiple edges simultaneously. Simulations show that the algorithm can solve problems with up to 800 simultaneous convoys.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Shared-World Optimization Algorithms}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:shared-world-optimization-algo}
%These algorithms\mwmargin{**}{Should we characterize as a `shared world approach' (or similar) rather than an `algorithm'? Essentially you can apply arbitrary centralized algorithms by using a shared-world approach...} build a shared-world model (blackboard) of all the information, so that centralized algorithms can be executed in a distributed fashion. They have been used for information filtering for multi-UAV tracking \citep{Ref:Campbell07}, planning for teams of autonomous maritime vehicles \citep{Ref:Elkins10,Ref:Wolf17,Ref:Sotzing10}, and spacecraft formation control \citep{Ref:Beard01}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Distributed Optimization Algorithms}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:distributed-optimization-algorithms}
%All algorithms in this section solve the multi-agent optimization problem (\ref{eq:MAOP-cost}) in a distributed manner.
%Since most multi-agent tasks can be stated as (\ref{eq:MAOP-cost}), these techniques are extremely powerful for multi-agent applications.  
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Distributed Linear Programming \label{subsec:LP}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{I suggest lumping together distributed LP and distributed convex opt and making it a long subsection.}
%If the the multi-agent optimization problem (\ref{eq:MAOP-cost}) is a linear program (LP), then it can be solved in a distributed manner \citep{Ref:Cortes15,Ref:Bullo12,Ref:Bullo07,Ref:Yang10} where agents asymptotically reach the optimal solution of the LP.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Distributed Convex Optimization \label{subsec:ADMM}\ifjournalv\else \vspace{-2.1mm} \fi}
%If the the multi-agent optimization problem (\ref{eq:MAOP-cost}) is convex, then the alternating direction method of multipliers (ADMM) technique can be used to solve it in a distributed manner \citep{Ref:Boyd11}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Distributed Auction and Market-Based Techniques \label{subsec:auction}\ifjournalv\else \vspace{-2.1mm} \fi} 
%Market-based protocols for distributed task allocation have enjoyed immense success in the robotics community. In particular, 
%auction-based protocols \citep{Ref:Bertsekas98,Ref:Pappas08,Ref:Shoham08,Ref:Gerkey02,Ref:Stojmenovic10,REf:Sujit11} are widely used for distributed coordination of agents.  \citep{Ref:Dias99,Ref:Dias04} proposes mechanisms  to obtain emergent coordination behavior from a network of self-interested agents, and \citep{Ref:Shehory98} proposes algorithms for distributed coalition formation for task allocation. 
%
%\textbf{\textit{Mathematical description and guarantees:}} 
%Let there be $n$ agents and $m \geq n$ tasks.
%Let $\beta[i,\ell] \in \mathbb{R}$ the benefit of assigning task $\ell, \forall \ell \in \{1,\ldots,m\}$ to agent $i, \forall i \in \{1,\ldots,n\}$.
%The $i^{\textrm{th}}$ agent keeps track of its bid $\alpha^i_k \in \{1,\ldots,m\}$. 
%The $i^{\textrm{th}}$ agent maintains a local copy of the highest task prices $P^i_k[\ell]$ and highest bidder $B^i_k[\ell]$ for all $\ell \in \{1,\ldots,m\}$, which it updates as follows \citep{Ref:Pappas08}:
%\begin{align}
%P^i_{k+1}[\ell] &= \max_{j \in \mathcal{J}_k^i} P^j_{k}[\ell] \thinspace , \\
%B^i_{k+1}[\ell] &= \max_{q \in \arg \max_{j \in \mathcal{J}_k^i} P^j_{k}[\ell]} B^q_{k}[\ell] \thinspace .
%\end{align}
%If the $i^{\textrm{th}}$ agent has been outbid, then it updates its bid and sets a new price for its updated bid as follows:
%\begin{align}
%\textrm{\textbf{if} }& P^i_{k+1}[\alpha^i_k] \geq  P^i_{k}[\alpha^i_k] \textrm{ and } B^i_{k+1}[\alpha^i_k] \neq i \textrm{, \textbf{then}} \nonumber \\
%& \alpha^i_{k+1} = {\arg \max}_{\ell \in \{1,\ldots,m\}} (\beta[i,\ell] - P^i_{k+1}[\ell]) \thinspace, \\
%& B^i_{k+1}[\alpha^i_{k+1}] = i \thinspace, \\
%& P^i_{k+1}[\alpha^i_{k+1}] = P^i_{k+1}[\alpha^i_{k+1}] + (\beta[i,\alpha^i_{k+1}] - P^i_{k+1}[\alpha^i_{k+1}]) \nonumber \\
%& \qquad - \max_{\ell \in \{1,\ldots,m\} \setminus \{\alpha^i_{k+1}\}} (\beta[i,\ell] - P^i_{k+1}[\ell]) + \varepsilon \\
%\textrm{\textbf{else} }& \alpha^i_{k+1} = \alpha^i_k \thinspace .
%\end{align}
%It can be shown that the above algorithm reaches equilibrium assignment with $\varepsilon$ error \citep{Ref:Pappas08}. 
%
%\textbf{\textit{Communication bandwidth:}} The agents exchange pricing information with other agents using multi-hop communication links between adjacent agents.  
%
%\textbf{\textit{Applications:}} \textit{Cooperative decision making:}Multi-UAV lifting \citep{Ref:Maza11}, multi-agent display \citep{Ref:Siegwart12}, network connectivity maintenance \citep{Ref:Zavlanos08}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Sequential Convex Programming \label{subsec:SCP}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%If the multi-agent optimization problem (\ref{eq:MAOP-cost}) is non-convex, then it is convexified using local information and iteratively solved using sequential convex programming. 
%This technique has been used for control of spacecraft swarms \citep{Ref:Morgan14,Ref:Morgan15_SATO}, and motion planning \citep{Ref:Bandyopadhyay17_MA_SESCP,Ref:Bandyopadhyay17_MAMO_SESCP}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Distributed Control \label{subsec:distributed-control}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{This section is still ill-defined}
%Distributed control \citep{Ref:Bamieh02,Ref:Feddema02,Ref:Swigart10,Ref:Barrett00} has been widely used for a variety of applications: 
%distributed LQG on networks \citep{Ref:Rotkowitz06,Ref:Drew05,Ref:Sahai06,Ref:Garone11,Ref:Liu04,Ref:Zhang12}, 
%stabilization of distributed systems \citep{Ref:Wang73}, 
%formation flying \citep{Ref:Ogren02}, 
%overlapping control of subsystems \citep{Ref:Stipanovic04decentralized},
%complexity analysis \citep{Ref:Goldman04}.
%Distributed control using Partial Differential Equations (PDEs) has been applied to multi-agent trajectory optimization \citep{Ref:Ferrari14}, multi-agent formation \citep{Ref:Krstic15}, particle swarm control \citep{Ref:Allain14optimal}, and stability analysis with integro-differential equation \citep{Ref:Mogilner99}.
%
%\textcolor{red}{Optimal Control of Spatially Distributed Systems \citep{Ref:Motee2008optimal}}
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Machine Learning\label{subsec:ML}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%Machine learning and neural networks has been applied for multi-agent collision avoidance \citep{Ref:Long17} and foraging \citep{Ref:Waibel09}. 
%
%\textcolor{red}{\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Robust Quadrilaterals \label{subsec:robust-quadrilaterals}\ifjournalv\else \vspace{-2.1mm} \fi}
%If each agent can estimate the distance of its neighbors but have no absolute reference, then this algorithm can estimate the the position of each agent up to a global rotation and translation using the probabilistic notion of robust quadrilaterals \citep{Ref:Moore2004robust}.}\frmargin{*}{Saptarshi: what application does this map to? If it maps to no application, we should consider either adding new applications or removing it.}
%
%\textcolor{red}{\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Dynamic Programming \label{subsec:distributed-dp}\ifjournalv\else \vspace{-2.1mm} \fi}
%Rossi: Should we have this section on Distributed Dynamic Programming? \citep{Ref:Bertsekas1982distributed}}
%
%This algorithm solves a dynamic programming problem in a distributed manner, where each agent computes the partial solution with its neighboring agent's information and iteratively communicates with its neighbors so that all agents reach the globally optimal solution.
%
%Distributed dynamic programming has been used for task allocation \citep{Ref:Sukhatme04} and path planning \citep{Ref:Balch07} in multi-agent systems operating in environments equipped with a pre-deployed, static sensor network.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\ifjournalv\else \vspace{-1.8mm} \fi\section{Local Optimization Algorithms}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:local-optimization-algo}
%\frmargin{All algorithms in this section solve a local-approximation of the multi-agent optimization problem (\ref{eq:MAOP-cost}) in a distributed manner in order to achieve near-optimal global behavior.}{Explain better, redo}
%
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Decentralized Model Predictive Control (DMPC) \label{subsec:MPC}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{short}
%\frmargin{
%In DMPC the control problem is divided into a set of local MPCs of smaller size and the agent cooperate through inter-agent communication \citep{Ref:How07MPC,Ref:Bemporad10}. We refer the reader to \citep{Ref:Scattolini09} for a thorough review. It has been used for flocking and motion planning \citep{Ref:Zhan13,Ref:Dunbar02,Ref:How06,Ref:Kuwata11}.}{Weird section, we use receding-horizon a lot elsewhere and we generally talk about optimization techniques (e.g. LP, MILP, etc.) separately. How do we reconcile?}
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Formal Methods \label{subsec:formal-methods}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{short}
%In this algorithm, local control for multi-agent coordination is synthesized by concatenating lower level primitives (common set of rules) with guarantees through formal logic \citep{Ref:KressGazit08}.
%
%\ifjournalv\else \vspace{-2.1mm} \fi\subsection{Sampling-based Motion Planning Algorithms \label{subsec:sampling-based-mp}\ifjournalv\else \vspace{-2.1mm} \fi}
%\frmargin{*}{Short}
%Sampling-based motion planning algorithms (e.g., rapidly exploring random trees RRT$^{\ast}$~\citep{Ref:Karaman11}) have enjoyed significant practical success because of their ease of implementation, ability to handle higher-dimensional spaces, probabilistic completeness, and asymptotic optimality.
%Decentralized multi-agent sampling-based motion planning algorithms have been developed \citep{Ref:Bandyopadhyay17_MA_SESCP,Ref:Bandyopadhyay17_MAMO_SESCP,Ref:How12,Ref:Solovey17arxiv}.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ifjournalv\else \vspace{-1.8mm} \fi\section{Conclusion}\ifjournalv\else \vspace{-1.8mm} \fi \label{sec:conclusion}
%In this paper, we presented a wide variety of multi-agent collective behavior algorithms from the mathematical perspective.
%We show that a few mathematical techniques (like consensus, APF) can be used for a wide variety of tasks. 
%Similarly, some tasks (like pattern formation) can be accomplished by a wide variety of mathematical techniques.
%Based on this survey, we also identify ares for further research and development. 
%We envisage that the results in this paper will enable future researchers to build practical swarms to benefit humanity.  

The proposed taxonomy and the properties shown in Table \ref{tab:all_algos} highlight some surprising characteristics of collective behavior algorithms.
The majority of existing mathematical techniques is tailored to either low-level spatially organizing tasks (e.g., bio-inspired algorithms and density-based control) or high-level coordination applications (e.g., state machines and optimization-based algorithms).
Only a small number of mathematical techniques (in particular, Artificial Potential Functions) can be adapted to a wide variety of tasks that include both low-level and high-level application.
This prompts further research into non-APF algorithms for multi-agent systems that share APF's key properties of simplicity, scalability, and high expressivity. %\frmargin{This suggests that simple, scalable, and \frmargin{expressive}{define?} algorithms can be adapted to a variety of tasks, and that research in algorithms with such properties can be beneficial to multiple applications}{This prompts further research into non-APF algorithms for multi-agent systems that share the three key properties of simplicity, scalability, and versatility.}. 

Very few algorithms are mature and field-tested. %; perhaps surprisingly, many algorithms has never been tested on hardware.
Such algorithms exchange very simple information (e.g. the agents' locations) or rely on centralized implementations: this may be justified by the difficulty of characterizing and certifying the behavior of an entire multi-agent system when distributed algorithms are used. To overcome this, (i) research in formal methods and adoption of tools from the distributed algorithms literature to provide stronger guarantees for distributed systems and (ii) creation of standardized software and hardware test-beds to characterize the end-to-end behavior of such systems are needed.

%\frmargin{We hope that this paper will foster a discussion ...}{TODO}

Several avenues for future research are of interest. In particular, we hope to evaluate the performance of collective behavior algorithms according to additional metrics including 1) bandwidth use in broadcast and in point-to-point networks, 2) computational complexity, 3) availability of formal guarantees, 4) resilience to disruptions in communication network and to \emph{adversarial} failures, and 5) availability of a reference implementation.
We also wish to explore other possible taxonomies for coordination algorithms based, e.g., on the content of messages exchanged by the agent (which vary from simple ``beacon'' messages reporting the agent's location to complex messages carrying intentions and bids), and the communication topology induced by the algorithm (single-hop vs. multi-hop)
Finally, we plan to further explore high-level multi-agent tasks, including adversarial ``swarm vs. swarm'' problems, and to assess the applicability and performance of collective behavior algorithms with respect to such tasks. 


%\section*{Acknowledgments}

%% Use plainnat to work nicely with natbib. 

%\bibliographystyle{ifacconf}
{\small
\ifjournalv\else \vspace{-2mm} \fi
\bibliography{SurveyBib}
}


\end{document}


