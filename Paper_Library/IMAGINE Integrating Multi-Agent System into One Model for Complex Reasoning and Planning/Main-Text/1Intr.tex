\section{Introduction}
Although large language models (LLMs) have demonstrated immense potential in many areas, they still face significant challenges in complex reasoning and planning tasks. For instance, Xie et al.~\cite{xie2024travelplanner} proposed the TravelPlanner dataset, which is based on real-world travel planning scenarios. In this task, the model needs to perform complex reasoning and planning before providing a final travel plan. On this dataset, even with carefully designed prompts and prior information explicitly provided, GPT-4o achieves only a 7\% Final Pass Rate in the sole-planning mode. Similarly, even in the thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B achieve Final Pass Rates of only 5.9\% and 40\%, respectively.

Large Language Model-based Multi-Agent Systems (LLM-MAS) have showcased remarkable proficiency in tackling intricate and multifaceted problems that demand sophisticated reasoning and planning \cite{guo2024large,zeeshan2025large,chen2024survey,qian2025scaling,liu2025symagent,qiao2025thematic,wang2025cooperative}. By harnessing the unique capabilities of multiple agents, each with distinct roles and responsibilities, these systems facilitate collaborative problem-solving through dynamic, multi-round interactions. This collective approach allows LLM-MAS to address challenges that are far more complex than those that can be effectively managed by a single-agent system, enhancing both the depth and accuracy of the solutions they generate. As such, these systems are increasingly being recognized for their potential to revolutionize fields ranging from advanced robotics to multi-agent coordination and decision-making.

Recently, a simple Reflective Multi-Agent System~\cite{shinn2023reflexion} can perform self-reflection and correction of previous reasoning, ultimately producing a more reliable response after validation. 
Chen et al.~\cite{chen2024reprompt} introduced REPROMPT, which optimizes “step-by-step instructions” in the prompts provided to LLM agents by leveraging conversation history derived from multi-agent interaction and reflection. This method achieved a Final Pass Rate of 3.89\% on TravelPlanner.
Guo et al.~\cite{guo2025mirror} proposed a Multi-Agent System that integrates intra-reflection and inter-reflection mechanisms, achieving a Final Pass Rate of 2.2\% on the TravelPlanner benchmark.
Zhang et al.~\cite{zhang2025swarmagentic} built a Multi-Agent System from scratch, inspired by Particle Swarm Optimization (PSO). This system maintains a population of candidate solutions and evolves them using feedback-driven updates, reaching a Final Pass Rate of 32.2\% on TravelPlanner.
Choi et al.~\cite{choi2025atlas} proposed a multi-agent framework called ATLAS, designed to handle the constraint-aware complexity of real-world travel planning. ATLAS incorporates a formalized methodology with dedicated mechanisms for constraint handling, iterative plan evaluation, and adaptive interleaved search.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{Main-Text/Figures/Performance_Comparison_Chartv2.pdf}
    \caption{Final Pass Rate under different models}
    \label{fig:main-1}
\end{figure}

Despite the advantages of Multi-Agent Systems, they face several significant limitations. Firstly, these systems require the manual design of complex prompts for each agent and the construction of intricate workflows, which increases both the difficulty and cost of development. Additionally, due to the multi-turn interactions within the system, the computational overhead grows substantially as the number of pairwise interactions among agents increases, leading to significant delays in response times for individual queries. The large amount of redundant communication between agents due to multi-turn interactions further exacerbates the computational overhead. As the number of agents expands, the interaction cost tends to grow without bound, which fundamentally limits their practical deployment and application. Furthermore, the presence of multiple LLMs in the system results in high storage space consumption. If external LLM APIs are used, multi-round interactions with the APIs can incur considerable costs. Finally, the complexity of multi-agent interactions makes end-to-end training challenging, and improving performance through training becomes difficult. 

To address the aforementioned challenges, we propose a new framework called IMAGINE, which integrates a Multi-Agent System into a single model to enhance complex reasoning tasks. This framework consolidates the capabilities of an entire large-scale multi-agent system into a smaller, more efficient model, allowing a single LLM Agent to embody the abilities of a carefully designed multi-agent system. The performance is shown in Figure \ref{fig:main-1}. This approach is analogous to equipping an individual with the capabilities of a well-organized team. 
Specifically, our approach consists of three stages: New Query Generation, Multi-Agent System-based Inference Data Generation, and Agentic Reasoning Training.
In the New Query Generation stage, we augment the model’s training dataset by creating new queries, allowing the model to be exposed to more diverse training data.
In the Multi-Agent System-based Inference Data Generation stage, the newly generated queries from the previous stage are fed into a Multi-Agent System to perform inference. This process produces inference data from the Multi-Agent System, which is then used to enhance the reasoning capabilities of our model—effectively distilling the collective reasoning abilities of a well-organized and powerful team into a single, smaller model.
Finally, we propose Agentic Reasoning Training, which consists of two key components: Agentic SFT and Agentic RL. Agentic SFT takes the concatenation of the queries generated in the first stage and the corresponding Multi-Agent System-based inference data from the second stage as training data. This enables the integration of the Multi-Agent System’s reasoning capabilities into a single, much smaller model, serving as an effective cold-start stage in our approach. Agentic RL further builds upon Agentic SFT through end-to-end reinforcement learning, aiming to further strengthen the model’s agentic reasoning capabilities.

Our approach offers several key advantages. First, compared to Multi-Agent Systems, our single, compact model can be conveniently trained in an end-to-end manner to enhance performance, significantly reducing training complexity and cost. After end-to-end training, the reasoning capabilities of our model can easily surpass those of carefully designed and well-organized Multi-Agent Systems.
Moreover, since our model is a single, end-to-end compact model, it does not require the complex internal multi-turn interactions that are typical in Multi-Agent Systems. This allows for significantly reduced user wait times and greatly lowers inference costs.
In addition, being a single small model, it eliminates the need for the substantial storage space typically required by Multi-Agent Systems, as well as the cost of invoking external APIs. As a result, it offers substantial cost savings.

Our main contributions are summarized as follows:
\begin{itemize} [leftmargin=0.5cm]
	\item We propose IMAGINE, an effective, general, and scalable Agentic Reasoning Training method for a single model. This approach enables a small single model to outperform even a carefully designed and well-organized Multi-Agent System in reasoning. This is analogous to empowering an individual to surpass a well-coordinated team in reasoning ability.
    \item A scalable and general training method: The IMAGINE framework is model-agnostic. It provides a scalable and general approach to injecting Multi-Agent System behaviors into a single model, significantly improving performance through simple end-to-end training, ultimately surpassing carefully designed, well-organized Multi-Agent Systems, greatly reducing training complexity. This approach possesses broad applicability across various domains.
    \item Our method does not require the complex multi-turn interactions of a Multi-Agent System, enabling high-quality responses within a short time and significantly reducing inference costs.
	\item Using the Qwen3-8B-Instruct model as a base, we achieve an 82.7\% Final Pass Rate on the TravelPlanner dataset, greatly outperforming the DeepSeek-R1-671B model(40\%). Our model is smaller, more efficient, and delivers superior inference performance.
\end{itemize}

\begin{figure*}
    \centering
    \includegraphics[width=0.95\linewidth]{Main-Text/Figures/Overall_Flow_Chartv5.pdf}
    \caption{Overview of our proposed framework: IMAGINE.}
    \label{Overall_Flow_Chart}
\end{figure*}

