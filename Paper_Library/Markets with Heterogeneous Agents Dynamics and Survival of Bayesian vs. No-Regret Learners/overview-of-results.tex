To the best of our knowledge, this work is the first to analyze the dynamics of no-regret learners in competition with agents using other learning paradigms; to study the conditions under which no-regret learners survive in investment settings (in contrast to only bounding their regret level); and to establish a connection between the frameworks of regret minimization and Bayesian learning in asset markets. 
Our analysis yields a clear characterization of the relationship between regret rates, wealth shares, and long-term survival in such competitive environments. 

Beyond the theoretical contribution, our results provide practical insights for selecting learning strategies in market-facing applications. 
We show that competition imposes a high-stakes tradeoff between faster and more robust learning. 
The right approach depends on the extent to which campaign managers can access and trust information about the environment and the strategies of competitors. Bayesian methods, as suggested by economic theory, are powerful when the model class is accurate and known, and the update implementation is precise, but risky otherwise. No-regret learning methods, by contrast, are useful and robust when such knowledge is limited. Our hybrid approach, adding regularization to Bayesian updates, combines advantages of both, highlighting regularization as a practical and effective tool for balancing this tradeoff.

\vspace{8pt}
\noindent
\textbf{Main Theorems:} Before turning to related work, we conclude this part of the introduction with an informal summary of our main theorems. 

\empar{Regret and Survival}  
Theorem~\ref{thm:survival-by-finite-regret-gap} characterizes the regret condition for survival in a competitive asset market: an agent survives if and only if its regret remains bounded by an additive constant relative to every competitor at all times.  
Remarkably, if two players both have similar regret asymptotics with respect to the best strategy in hindsight (e.g., both have $O(\log T)$ regret) but with different coefficients, the agent with the larger constant almost surely vanishes from the market.  

\empar{Regret of the Optimal Investment Strategy}  
Regret with respect to the best strategy in hindsight is a strong benchmark; as we discuss in Section~\ref{sec:compare}, due to stochasticity in market dynamics, even the best implementable strategy (i.e., one that does not depend on future outcomes, but uses the true probabilities of states) has positive regret. In Theorem~\ref{thm:regret-of-q}, in Section~\ref{sec:no-regret}, we calculate this expected regret level, showing that it is constant and depends only on the number of assets in the market.
As a corollary of this result and Theorem \ref{thm:survival-by-finite-regret-gap}, any agent who survives in competition with an agent who invests knowing the true distribution of states must have regret bounded by a constant at all times. 

\empar{Survival against Perfect Bayesians}  
Theorem~\ref{thm:regret-of-a-Bayesian} shows that perfect Bayesian learners with a finite support have constant expected regret.  
Consequently, a learning agent survives in competition with perfect Bayesians if and only if it has constant regret as well.  
The proof uses Proposition~\ref{thm:Bayesians-suvive-against-q} about Bayesian learners together with the results described above.  

\empar{Bayesians with Inaccurate Priors}  
Theorem~\ref{thm:wrong-Bayesians-vanish} shows that a Bayesian agent with the correct state distribution not within its support suffers linear regret, and, as a result, vanishes from the market in competition with any no-regret learner.  
This theorem is followed by an analysis of the expected survival times of Bayesians with inaccurate priors, as a function of the size of the errors in the models considered in their priors and the regret rate of the best competitor.  

\empar{Bayesians with Inaccurate Updates}  
In Section~\ref{sec:noisy-Bayesian}, we analyze a scenario where a Bayesian learner performs ``trembling hand'' updates, making small zero-mean errors in the weight given to the current prior and the new data at each step.  
Theorem~\ref{thm:wrong-update-Bayesians-vanish} demonstrates that even such tiny errors break Bayesian learning, causing the learner to fail to converge and incur linear regret.  
As a result, any no-regret (or other) learner that converges to the correct model at any rate outperforms such an inaccurate Bayesian, driving it out of the market.  

\empar{Robust Bayesian Updates}  
In Section~\ref{sec:robust-Bayes-update}, we study a regularized version of Bayesian updating that offers greater robustness to distribution shifts.  
Proposition~\ref{thm:dist-shift-linear-regret-proposition} shows that standard Bayesian learning can incur linear regret under distribution shifts. Theorem~\ref{thm:robust-Bayesian} provides regret bounds for the method we propose: regret is constant when there are no distribution shifts and logarithmic in $T$ with shifts.

\vspace{8pt}
\noindent
\textbf{Roadmap:}
The paper is structured as follows. After a review of related work,   
Section~\ref{sec:model} presents the market model and preliminary analysis, discussing relative wealths and the role of relative entropy in characterizing survival under stationary investment rules.  
Section~\ref{sec:compare} reviews known results from no-regret learning and analyzes the relation between regret and wealth shares, showing how regret can be used to compare learners.  
Section~\ref{sec:Bayesians} restates in the language of our market setting several known analyses of Bayesian learning that are important for our comparison of Bayesians, no-regret learners, and imperfect Bayesians.   
Section~\ref{sec:no-regret} analyzes the regret of a player who knows the correct stochastic model, leading to a characterization of survival conditions in competition with a perfect Bayesian.  
Section~\ref{sec:imperfect-Bayesians} studies imperfect Bayesians with small mistakes in their priors or update process.  
Section~\ref{sec:robust-Bayes-update} presents a method for regularizing Bayesian updates to better handle distribution shifts, and analyzes its regret guarantees.   
Finally, Section~\ref{sec:simulations} presents simulation results for several scenarios of competition between no-regret learners, perfect Bayesian, and imperfect Bayesians, to complement our analysis and provide further intuition. Formal proofs are deferred to Appendix~\ref{sec:appendix-proofs}.