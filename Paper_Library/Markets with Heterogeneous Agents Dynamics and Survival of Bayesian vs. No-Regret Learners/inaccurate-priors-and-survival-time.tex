As mentioned in Section \ref{sec:Bayesians}, a Bayesian learner with $q$ not within the support of its prior converges to using the best strategy within its prior (i.e., the one closest to $q$ in relative entropy), denoted here by $q'$. 
This convergence property leads to the following result. 
\begin{theorem}\label{thm:wrong-Bayesians-vanish}
    A Bayesian agent with the state distribution $q$ not in its support incurs regret 
    linear in $T$, and vanishes from the market in competition against any no-regret learner.   
\end{theorem}
Note that this contrasts with the case of Theorem \ref{thm:regret-of-a-Bayesian}, where a perfect Bayesian dominates the market in competition with any learners with regret increasing in time.
The proof is in Appendix \ref{sec:appendix-proofs}.

\vspace{5pt}
\noindent
{\em Remark:}
The possible strategies that the Bayesian can play span the entire convex hull of the prior. 
Bayesians with a finite prior can (and do) play convex combinations of the prior during the dynamic, but still, they always converge to the vertices---even when a more profitable strategy lies in the interior. 
In this sense, this convergence property of Bayesians is both a strength (if they have an accurate prior) and a weakness (if they do not). 
\vspace{5pt}

\bfpar{Typical Survival Time}
A question that arises now is what happens when errors are small.  
In the following analysis, we consider ``$\epsilon$-inaccurate Bayesians'' who have in their prior a close approximation of $q$, but still with some small error. Specifically, the total variation distance between the best strategy in the prior and the state distribution $q$ satisfies $TV(q', q) = \epsilon$ for some $\epsilon > 0$. 

On the one hand, we know that such an agent asymptotically fails to survive against a regret-minimizing agent for any error $\epsilon$. On the other hand, when $\epsilon$ is small, the inaccurate Bayesian will initially converge very quickly to a distribution close to the correct state distribution, and may capture a significant share of the market value during the early stages. 

Our goal now is to analyze the survival time during which the inaccurate Bayesian may still maintain a significant market share, and to understand how this survival time is related to the level of error $\epsilon$. This, of course, also depends on the best competitor and how fast they converge.

To estimate this relation and provide an upper bound on the survival time of an inaccurate Bayesian learner, we consider a player using $q'$ with $TV(q', q) = \epsilon$ (having already converged to this distribution), competing against a second player playing a dynamic strategy with expected regret level increasing as $f(t)$ that is sub-linear in $t$.

First, we would like to express the first player's error in terms of entropy (i.e., KL-divergence with $q$). We can bound the entropy using Pinsker's inequality~\citep{pinsker1964information} for a lower bound and its inverse for an upper bound, were the latter holds for finite distributions with full support, as in our case. We have (recall that $\Delta = \min_s q_s$),
\[
2\epsilon^2 \leq 
% D_{KL}(q || q') 
I_q(q')
\leq \frac{2}{\Delta} \epsilon^2.
\]
Using Lemma \ref{thm:expected-regret-lemma}, this can be translated into the regret of the inaccurate agent playing strategy $q'$ where $R$ is the regret of an investor using the true state distribution $q$ (see Theorem \ref{thm:regret-of-q}): 
\[
% D_{KL}(q \| q') 
I_q(q')
= \frac{1}{T} \big(\mathbb{E}[R^{T}(q'_{1:T})] - R \big).
\]

To maximize the survival time, we pick the distribution $q'$ to be the one with the smallest regret, which is when $I_q(q')$ is the smallest possible: $I_q(q') = 2\epsilon^2$. So we have\footnote{If the inaccurate agent uses the worst $q'$ with error $\epsilon$, the regret calculation is similar, but with $\epsilon$ rescaled by a factor of $1/\sqrt{\Delta}$, using the inverse of Pinsker's inequality: 
$2 \epsilon^2 \tau/\Delta  + R$. The smallest-regret  $q'$ is used for the bound.} 
$\mathbb{E}[R^{T}(q'_{1:T})] = 2\epsilon^2 T + R$. 
% 
By Equation (\ref{eq:logshare-as-regret}), the regret difference between two players is equal to the log of their wealth ratios  plus a constant. By comparing regret levels between the agents, we obtain a bound on the typical survival time $\tau$ up to which the inaccurate player holds, in expectation, more than half the market value; beyond this point, their expected share is less and continues decaying to zero:\footnote{An alternative question one may ask is: how accurate does my prior need to be to allow retaining a share of the market for $T$ steps against the competitor? For this, one can invert the equation and get: $\epsilon = \sqrt{(f(T) - R)/T}$.}
\[
f(\tau) = 2\epsilon^2 \tau + R.
\]

\vspace{5pt}
\noindent
{\em Remark:} Note that $f(t)$ is the competitor's actual regret. Regret bounds for known learning algorithms (e.g., bandit algorithms such as UCB (see, e.g.,   \cite{slivkins2019introduction}) or gradient-descent and second-order methods like those described in \cite{hazan2016introduction}) are typically worst-case bounds. Estimating the expected regret (or the most likely one) in game dynamics in general, or specifically in our investment scenario, is an interesting open problem.
\vspace{5pt}

For the special cases that the competitor has constant regret (for example, an accurate Bayesian), or the competitor has a $\log T$ or $\sqrt{T}$ regret level, we get the following results. 
\begin{observation}\label{obs:survival-time-gainst-constant-regret}
    The expected survival time of a Bayesian learner with $\epsilon$-inaccurate prior against any player with constant regret (e.g., a perfect Bayesian) is $O\big(\frac{1}{\epsilon^2}\big)$. 
\end{observation}

For a competitor with logarithmic regret, we get an equation of the form $\tau = c_1 \cdot \exp(c_2 \epsilon^2\tau)$. For small errors $\epsilon$, by expanding the exponent, we have the following bound:
\begin{observation}\label{obs:survival-time-gainst-log-regret}
    The expected survival time of a Bayesian learner with $\epsilon$-inaccurate prior against any player with logarithmic regret (e.g., a no-regret convex optimizer) is $O\big(\frac{1}{\epsilon^3}\big)$.   
\end{observation}

Finally, in competition against a learner with regret $f(T) = \sqrt{T}$ the survival time is longer:
\begin{observation}\label{obs:survival-time-gainst-sqrt-regret}
    The expected survival time of a Bayesian learner with $\epsilon$-inaccurate prior against any player with $\sqrt{T}$ regret is $O\big(\frac{1}{\epsilon^4}\big)$. 
    % For $c$ is $\tau \leq \frac{c-R^q}{2 \epsilon^2}$.  
\end{observation}

The interpretation of this analysis naturally depends on the time scale of interest. When $T$ is large, which is our main focus (e.g., when trade occurs at high frequency or if investments are long-term), only long-term survival matters. In this case, a Bayesian with an inaccurate prior will eventually vanish in competition with any learner who converges to the truth (e.g., a regret minimizer). However, when transient dynamics are also relevant, it is possible that a Bayesian with a prior that is inaccurate but relatively close to the true distribution may retain a significant market share for some time before ultimately vanishing. See Section~\ref{sec:simulations} for an example.
