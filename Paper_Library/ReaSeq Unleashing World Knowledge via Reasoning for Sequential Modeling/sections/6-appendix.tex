\section{Prompt Templates}
\label{sec:appendix}




\begin{promptbox}[colback=SkyBlue!6, colframe=RoyalBlue!60!black]{User Demand Orientation}\label{prompt:user_demand}
    \textbf{Task:} You are designing a category taxonomy for an e-commerce platform. Given the item category name and a collection of user demand expressions (queries and search terms), construct a structured demand taxonomy by clustering semantically related expressions into orthogonal dimensions.\\
    \textbf{Procedure:}
    \begin{enumerate}
        \item Iterate through demand expressions sequentially. For each expression, determine if it fits within an existing demand dimension based on semantic similarity.
        \item If no existing dimension fits the expression, create a new orthogonal one.
        \item Give each dimension a concise, representative label.
    \end{enumerate}
    \textbf{Requirements:}
    \begin{itemize}
        \item \textit{Orthogonality}: Output dimensions must be mutually exclusive and capture distinct aspects of user demand.
        \item \textit{User-centricity}: Ground all dimensions in user needs and motivations—focus on \textit{why} users seek items, not product features.
        \item \textit{Comprehensiveness}: Ensure dimensions collectively cover the major aspects of user intent within the category.
    \end{itemize}
    \textbf{Output:}
    \begin{enumerate}
        \item Document your clustering decisions step-by-step.
        \item Analyze the resulting dimensions: verify orthogonality, identify potential merges, and justify the final structure.
        \item Provide the final taxonomy as a list of dimension labels only.
    \end{enumerate}
\end{promptbox}


\begin{promptbox}[colback=SpringGreen!10, colframe=ForestGreen!60!black]{Product Attribute Taxonomy Construction}\label{prompt:product_attribute}
        \textbf{Task:} You are designing a product category taxonomy for an e-commerce platform. Given the category name and a collection of merchant-provided product attributes (key-value specifications), construct a structured attribute taxonomy by clustering semantically related attributes into orthogonal dimensions from a product categorization perspective.\\
        \textbf{Procedure:}
        \begin{enumerate}
        \item Iterate through product attributes sequentially. For each attribute, analyze whether it describes the same underlying product aspect as any existing dimension based on semantic similarity.
        \item If no existing dimension adequately captures the attribute's product aspect, create a new orthogonal dimension.
        \item Label each dimension with a concise term that represents the product aspect covered by all attributes within that cluster.
        \end{enumerate}
        \textbf{Requirements:}
        \begin{itemize}
        \item \textit{Orthogonality}: Output dimensions must be mutually exclusive and capture distinct product characteristics.
        \item \textit{Product-centricity}: Ground all dimensions in intrinsic product properties and features—focus on \textit{what} items inherently are, not user perceptions.
        \item \textit{Normalization}: Ensure the taxonomy transcends merchant-specific naming conventions and provides a unified semantic framework.
        \end{itemize}
        \textbf{Output:}
        \begin{enumerate}
        \item Document your clustering decisions step-by-step, explaining why attributes are grouped or separated.
        \item Analyze the resulting dimensions: verify orthogonality, identify potential merges, and justify the final structure.
        \item Provide the final taxonomy as a list of dimension labels only.
        \end{enumerate}
    \end{promptbox}


\begin{promptbox}[colback=Lavender!10, colframe=Purple!60!black]{Dimension Refinement for Subcategories}\label{prompt:dimension_refinement}
    \textbf{Task:} You are refining a category taxonomy for subcategories in an e-commerce platform. Given a subcategory name (under parent category parent category name) and the parent category's perspective taxonomy from Layer 1, refine the taxonomy to capture subcategory-specific characteristics. The perspective is either \textit{user demand orientation} (focusing on user needs and motivations) or \textit{product attribute orientation} (focusing on intrinsic product properties).\\
    \textbf{Refinement Principles:}
    \begin{itemize}
    \item \textit{Orthogonality}: Refined dimensions must be mutually exclusive and capture distinct aspects without redundancy.
    \item \textit{Comprehensiveness}: The dimension set must collectively cover the semantic space relevant to the subcategory from the given perspective.
    \item \textit{Objectivity}: All dimensions must be grounded in observable information—either verifiable product attributes or documented user expressions—and derived through logical reasoning.
    \end{itemize}
    \textbf{Refinement Procedure:}
    \begin{enumerate}[leftmargin=15pt]
    \item[] \textit{Stage 1 - Inherit from Parent}: Review the parent category's taxonomy. Identify which dimensions remain applicable to the subcategory and which require modification or removal due to subcategory-specific characteristics.
    \item[] \textit{Stage 2 - Adapt to Subcategory}: Analyze the subcategory's unique attributes (for product orientation) or demand patterns (for user orientation). Determine whether inherited dimensions need adaptation, and identify new dimensions that are distinctive to this subcategory.
    \end{enumerate}
    \textbf{Output Format:}
    \begin{enumerate}
    \item \textit{Reasoning Trace}: Document your refinement decisions step-by-step. For each dimension, explain whether it is inherited from the parent taxonomy, adapted from a parent dimension, or newly created for the subcategory. Justify these decisions based on subcategory-specific characteristics.
    \item \textit{Dimension Justification}: For each refined dimension, provide: (a) a concise dimension label ($\leq$15 characters), (b) the rationale for inclusion (inherited, adapted, or subcategory-specific), and (c) the corresponding item attributes (for product orientation) or user expressions (for user orientation) that this dimension captures.
    \item \textit{Final Taxonomy}: Summarize the refined dimensions as a structured list of labels only, without explanations.
    \end{enumerate}
\end{promptbox}




\begin{promptbox}[colback=SkyBlue!6, colframe=RoyalBlue!60!black]{Item-Specific Knowledge Generation}\label{prompt:knowledge_generation}
\textbf{Task:} Generate structured, evidence-based knowledge for a given item across predefined analysis dimensions. Analysis should be objective, factually grounded, and derived through explicit reasoning from provided item information.\\
\textbf{Input:} (1) Item metadata (title, attributes, price, \textit{etc.}); (2) user demand dimensions; (3) product attribute dimensions.\\
\textbf{Analysis Procedure:}
\begin{itemize}
    \item \textit{User Demand Analysis}: For user demand dimension, characterize how the item addresses that aspect of user need. Explicitly cite supporting attributes (e.g., ``100\% cotton fabric'' for comfort preference) and translate abstract dimensions into concrete item characteristics.
    
    \item \textit{Product Attribute Analysis}: Extract and synthesize key product elements from item metadata. Infer relevant usage scenarios, style characteristics, or functional features based on observable attributes and domain knowledge. All characterizations should be derivable from provided metadata through logical reasoning.
\end{itemize}
\textbf{Output Format:} JSON object with user demand and product attribute entries:
\begin{verbatim}
{
  "user_demand": [
    {
      "dimension": "<dimension label>",
      "analysis": "<evidence-based characterization>",
      "keywords": "<3-5 key concepts>"
    }, ...
  ],
  "product_attribute": [
    {
      "dimension": "<dimension label>",
      "analysis": "<factual description>",
      "keywords": "<3-5 key elements>"
    }, ...
  ]
}
\end{verbatim}

\textbf{Requirements:} Ensure all analysis is traceable to specific item attributes. Ground inferences in observable properties and avoid introducing unsupported features or subjective judgments.
\end{promptbox}

\section{Semantic Item Tokenization}
\label{sec:item_tokenizer}

% The knowledge-enhanced semantic representations $\mathbf{h}_i^t$ encode explicit item knowledge, yet integrating them with collaborative signals from behavioral sequences remains challenging. Semantic embeddings capture what items \textit{are}, while behavioral patterns reveal how items \textit{function} through interactions. Direct concatenation risks suboptimal fusion without structural guidance. We introduce a \textbf{semantic item tokenization} mechanism that transforms continuous semantic vectors into discrete semantic item IDs (SIDs) through learned vector quantization, creating a unified framework where semantic understanding and collaborative patterns can be jointly modeled through shared embedding layers.
The knowledge-enhanced semantic representations $\mathbf{h}_i^t$ encode explicit item knowledge, yet effectively integrating them with collaborative signals from behavioral sequences remains challenging. Semantic embeddings capture
% ``\textcolor{purple}{\textit{what items are}}'',
 ``{\textit{what items are}}'',
while behavioral patterns reveal
% ``\textcolor{orange}{\textit{how they function}}''
``{\textit{how they function}}''
through interactions. To bridge this gap, we introduce a \textbf{semantic item tokenization} mechanism that transforms continuous semantic vectors into discrete semantic item IDs (SIDs) through learned vector quantization. This approach produces high-quality discrete identifiers grounded in semantic knowledge, which serve as enhanced item representations that facilitate more effective semantic-collaborative fusion in the ranking model.

\paragraph*{Architecture Design.}
Our tokenization framework is built upon a Residual Quantized Variational Autoencoder (RQ-VAE)~\citep{zeghidour2021soundstream}, which progressively decomposes continuous vectors into hierarchical discrete codes. The architecture consists of three core components:

\textbf{(1) Semantic Adapter.} To align the dimensionality of knowledge-enhanced representations with the quantization framework, we first apply a linear projection adapter:
\begin{equation*}
\mathbf{z}_i = \mathbf{W}_{\text{adapt}} \mathbf{h}_i^t + \mathbf{b}_{\text{adapt}} \in \mathbb{R}^{d'}
\end{equation*}
where $\mathbf{W}_{\text{adapt}} \in \mathbb{R}^{d' \times d}$ and $\mathbf{b}_{\text{adapt}} \in \mathbb{R}^{d'}$ are learnable parameters, and $d' < d$ represents the target embedding dimension for quantization.

\textbf{(2) Residual Quantization.} The adapted representation $\mathbf{z}_i$ is then quantized through $L$ hierarchical codebook layers. Let $\mathcal{C}^{(\ell)} = \{\mathbf{c}_1^{(\ell)}, \mathbf{c}_2^{(\ell)}, \ldots, \mathbf{c}_K^{(\ell)}\} \subset \mathbb{R}^{d'}$ denote the $\ell$-th codebook containing $K$ learnable code vectors. The quantization process proceeds iteratively:
\begin{align*}
\mathbf{r}_i^{(0)} &= \mathbf{z}_i \\
\mathbf{q}_i^{(\ell)} &= \argmin_{\mathbf{c} \in \mathcal{C}^{(\ell)}} \left\| \mathbf{r}_i^{(\ell-1)} - \mathbf{c} \right\|_2^2, \quad \ell = 1, \ldots, L \\
\mathbf{r}_i^{(\ell)} &= \mathbf{r}_i^{(\ell-1)} - \mathbf{q}_i^{(\ell)}
\end{align*}
where $\mathbf{r}_i^{(\ell)}$ represents the residual after the $\ell$-th quantization step, and $\mathbf{q}_i^{(\ell)}$ denotes the selected code vector from codebook $\mathcal{C}^{(\ell)}$. The final quantized representation is the sum of all selected codes:
\begin{equation*}
\hat{\mathbf{z}}_i = \sum_{\ell=1}^{L} \mathbf{q}_i^{(\ell)}
\end{equation*}

\textbf{(3) Reconstruction Decoder.} To ensure the quantized representation preserves semantic information, we employ a decoder network $f_{\text{dec}}: \mathbb{R}^{d'} \rightarrow \mathbb{R}^{d}$ that reconstructs the original knowledge-enhanced representation:
\begin{equation*}
\tilde{\mathbf{h}}_i^t = f_{\text{dec}}\left(\hat{\mathbf{z}}_i\right)
\end{equation*}

\paragraph*{Training Objective.}
The RQ-VAE is trained through a composite loss function that balances reconstruction fidelity and codebook commitment:
\begin{equation*}
\mathcal{L}_{\text{RQ-VAE}} = \mathcal{L}_{\text{recon}} + \beta \mathcal{L}_{\text{commit}}
\end{equation*}

The \textbf{reconstruction loss} measures the semantic preservation quality:
\begin{equation*}
\mathcal{L}_{\text{recon}} = \frac{1}{|\mathcal{I}|} \sum_{i \in \mathcal{I}} \left\| \mathbf{h}_i^t - \tilde{\mathbf{h}}_i^t \right\|_2^2
\end{equation*}


\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{figs/makr.pdf}
    \caption{Output comparison of the common single-agent and our multi-agent approaches.}
    \label{fig:makr}
\end{figure}



The \textbf{commitment loss} encourages the encoder to commit to codebook entries while allowing codebook vectors to adapt:
\begin{equation*}
\mathcal{L}_{\text{commit}} = \frac{1}{|\mathcal{I}|} \sum_{i \in \mathcal{I}} \sum_{\ell=1}^{L} \left\| \text{sg}\left[\mathbf{r}_i^{(\ell-1)}\right] - \mathbf{q}_i^{(\ell)} \right\|_2^2 + \left\| \mathbf{r}_i^{(\ell-1)} - \text{sg}\left[\mathbf{q}_i^{(\ell)}\right] \right\|_2^2
\end{equation*}
where $\text{sg}[\cdot]$ denotes the stop-gradient operator, and $\beta$ is a hyperparameter balancing the two loss.



\paragraph*{Semantic ID Extraction.}
Once trained, the RQ-VAE extracts discrete semantic IDs for each item by recording the codebook indices at each quantization layer:
\begin{equation*}
\mathbf{s}_i = \left[s_i^{(1)}, s_i^{(2)}, \ldots, s_i^{(L)}\right], \quad s_i^{(\ell)} \in \{1, 2, \ldots, K\}
\end{equation*}
where $s_i^{(\ell)}$ denotes the index of the selected code from codebook $\mathcal{C}^{(\ell)}$ at layer $\ell$.



\section{Case Studies for Reasoning-Enhanced Representation}
To visually demonstrate the effectiveness of our MAKR in providing information gain through reasoning, we present a case comparing the reasoning outputs of multi-agent MAKR with those of a single‑agent approach. As shown in Figure~\ref{fig:makr}, the inference results of the single-agent method suffer from problems such as missing information, factual errors, and vague description. This weakens the representation quality and affects its effectiveness for downstream tasks, while the results produced by MAKR effectively address these issues.


