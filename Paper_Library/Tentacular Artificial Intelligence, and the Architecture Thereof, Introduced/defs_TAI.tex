\begin{small}
%%  \begin{quote}
    \begin{enumerate}

      \item[$\mathbf{D_1}$] \textit{Capable of problem-solving}.  Whereas, as we've
        noted, standard AI counts simple mappings from percepts to
        actions as \textit{bona fide} AI, TAI agents must be capable
        of problem-solving.  This may seem like an insignificant first
        attribute of TAI, but a consequence that stems from this
        attribute should be noted: Since problem-solving entails
        capability across the main sub-divisions of AI, TAI agents
        have multi-faceted power.  Problem-solving requires capability
        in these sub-areas of AI: planning, reasoning, learning,
        communicating, creativity (at least relatively simple forms
        thereof), and --- for making physical changes in physical
        environments --- cognitive robotics.\footnote{Cognitive
          robotics is defined in \cite{Levesque07cognitiverobotics} as
          a type of robotics in which all substantive actions
          performed by the robots are a function of the cognitive
          states (e.g.\ beliefs \& intentions) of these robots.}
        Hence, all TAI agents can plan, reason, learn, communicate;
        and they are creative and capable of carrying out physical
        actions.

      \item[$\mathbf{D_2}$]  \textit{Capable of solving at least important instances of
        problems that are at and/or \textbf{above} Turing-unsolvable
        problems}.  AI of today, when capable of solving problems,
        invariably achieves this success on problems that are merely
        algorithmically solvable and tractable (e.g., checkers, chess,
        Go).

      \item[$\mathbf{D_3}$]  \textit{Able to supply justification, explanation, and
        certification of supplied solutions, how they were arrived at,
        and that these solutions are safe/ethical}.  We thus say that
        the problem-solving of a TAI agent is \textbf{rationalist}.
        This label reflects the requirement that any proposed solution
        to the problem discovered by a TAI agent must be accompanied
        by a justification that defends and explains that the proposed
        solution \emph{is} a solution, and, when appropriate, also
        that the solution (and indeed perhaps the process used to
        obtain the solution) has certain desirable properties.
        Minimally, the justification must include an argument or proof
        for the relevant conclusions.  In addition, the justification
        must be verified, formally; we thus say that
        \textbf{certification} is provided by a TAI agent.

      \item[$\mathbf{D_4}$] \textit{Capable of ``theory-of-mind''
        level reasoning, planning, and communication}.  Discussion of
        this attribute is omitted to save space; see
        e.g.\ \cite{ka_sb_scc_seqcalc} for our lab's first foray into
        automated reasoning at this level.  (The truth is, it's more
        accurate to say the fourth requirement is that a TAI agent
        must have \textit{cognitive consciousness}, as this phenomenon
        is explained and axiomatized in
        \cite{axiomatizing_consciousness1}.)

      \item[$\mathbf{D_5}$] \textit{Capable of creativity, minimally
        to the level of so-called \textbf{m-creativity}}.  Creativity
        in artificial agents, and the engineering thereof, has been
        discussed in a number of places by Bringsjord
        \citeaffixed{brutus}{e.g.}, but recently
        \citeasnoun{creative_cars} have called for a form of
        creativity in artificial agents using I/IoT.

      \item[$\mathbf{D_6}$] \textit{Has ``tentacular'' power wielded
          throughout I/IoT, Edge Computing, and cyberspace}.  This is
        the most important attribute possessed by TAI agents, and is
        reflected in the `T' in `TAI.' To say that such agents have
        tentacular problem-solving power is to say that they can
        perceive and act through the I/IoT (or equivalent networks)
        and cyberspace, across the globe.  TAI agents thus operate in
        a planet-sized, heterogeneous environment that spans the
        narrower, fixed environments used to define conventional,
        present-day AI, such as is found in \cite{aima.third.ed}.

    \end{enumerate}
%%  \end{quote}
\end{small}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}



\newpage
\noindent
%
In the basic geography of AI, as given in any orthodox, comprehensive
introduction to the field \citeaffixed{aima.third.ed}{e.g.}, AIs
(a.k.a.\ \textbf{artificial intelligent agents}) invariably operate in
\textbf{environments}.  An AI like AlphaGo, e.g.,~operates at least
mostly in the rigid, simple environment circumscribed by the familiar
game board; the mental states of a human opponent, or of human
onlookers, etc.\ aren't part of this limited environment.  In
addition, the field of AI is in such introductions standardly
partitioned into sub-areas --- planning, reasoning, learning,
communicating, creativity, robotics (at least of the cognitive
variety), and so on \citeaffixed{aima.third.ed}{see again e.g.}.  

We conceive of the challenge of \textbf{rationalist problem-solving}
(RPS; pronounced ``rips'') for an AI in such a way that the part of
the field of AI devoted to building AIs able to meet this challenge
must consider vast, heterogeneous environments (including,
specifically, human epistemic and emotional states), and also must
subsume the sub-areas of planning, reasoning, learning, communicating,
creativity (at least relatively simple forms thereof), and cognitive
robotics.\footnote{Cognitive robotics is defined in
  \cite{Levesque07cognitiverobotics}.}  The concept of RPS thus
deductively entails that planning, reasoning, learning, communication,
creativity, and cognitive robotics are each a proper part of RPS.
This entailment is desirable, as shown by even simple examples of RPS
in action.

E.g.,~suppose a household AI wishes to move a cup on a kitchen table
onto a saucer that is also on that table.  In certain circumstances
the most efficient way for the AI to accomplish this may be to say to
a human (whose mind the AI, to a degree, understands) sitting at the
table in question: ``Would you be so kind as to place that cup on top
of the saucer?''  It follows from this, immediately, that the
communication sub-area of AI (in this case specifically
\textbf{natural language generation}) is active; but since NLG isn't a
proper part of the sub-area of planning in AI, it follows in turn that
RPS includes more than planning: it includes, as we have already said,
communication as well.  Many other such examples could be easily
devised in order to make the general point, which, again, is that
planning, reasoning, learning, communication, creativity, and
cognitive robotics are each a proper part of RPS.

RPS will not be found in introductions to or overviews of AI.  What,
then, \emph{is} RPS?

We don't give a formal defintion in the present short summary.
Informally, and unsurprisingly, RPS starts with an AI being given a
problem to solve.  But the ``rationalist'' dimension of RPS is
reflected by the requirement that any proposed solution to the problem
discovered by the AI must be accompanied by a justification that
defends and explains that the proposed solution \emph{is} a solution,
and, when appropriate, also that the solution (and indeed perhaps the
process used to obtain the solution) has certain desirable properties.
Minimally, the justification must include an argument or proof for the
relevant conclusions.  In addition, the justification must be
verified, formally; we thus say that \textbf{certification} is
provided.  It may be illuminating to observe that standard --- as it's
called --- QA isn't technically subsumed by RPS.  However, if the
Answer to the Question in QA must be accompanied by a Justification of
the required sort, then we do have a special case of RPS; and we could
refer to the sub-area of AI here as `QAJ.'  More accurate is `QAJC,'
with the `C' indicating that the Justification is accompanied by a
\textbf{certificate}.  Imagine a \textit{Jeopardy!}-like game in which
contestants must not only give answers, but also proofs that their
answers are correct, and verification that these proofs are correct.
An AI able to excel at this new game is a simple example of one able
to excel in QAJC, and hence by definition one able to excel on a
particular RPS challenge.\footnote{RPS subsumes genuine and demanding
  ethical reasoning tasks for humans and AIs, such as those at the
  center of moral dilemmas.  See the use of our general-purpose
  reasoner in hard ethical reasoning tasks in
  \cite{dde_self_sacrifice_2017,nsg_sb_dde_2017}. $\mathsf{Spectra}$
  \href{https://naveensundarg.github.io/Spectra/}{https://naveensundarg.github.io/Spectra/}
  is our planner that extends classical planning in the direction of
  RPS.}

It's important to recognize that an AI that succeeds at RPS can be
assumed to have at its disposal any number of implemented computing
machines to call upon in order to get the job done.  E.g.\ our
cup-and-saucer AI alluded to above might have at its disposal a small
tabletop robot that can be called upon to move the cup onto the saucer
independent of any human assistance, if no humans are at the table.
In general, in RPS, there is no limit to the number of computing
machines an RPS AI might harness to provide a solution.  In addition,
such an AI is expected to sometimes succeed at RPS via creativity.  A
simple form of creativity that every RPS-capable AI must have is
\textbf{m-creativity}.  In this kind of creativity, reminiscent of
fictional but ingenious MacGyver, the agent in question uses things in
ways that are unconventional.  E.g.,~suppose that the kitchen table
invoked above is in the home of a family one member of which received
beforehand a small blimp that can fly around inside the home and pick
things up.\footnote{Such a blimp is a simple adaptation of what is
  readily available as a relatively inexpensive toy, one that Selmer
  has played with.}  An RPS-capable AI in the home might then call
upon this blimp to put the cup atop the saucer.  The concept of
m-creativity and m-creative AI is discussed in \cite{creative_cars}.

Another special case of RPS, one that seems quite relevant to the sort
of AI that is important to IBM and its future, is the automated and
semi-automated creation and composition of software services.
Usually, some of these services will pre-exist relative to a problem
$P$ given to some AI at a time $t$, and their composition might well
secure a solution to $P$ --- and if this solution is accompanied by a
justification and certificate, we have here a special case of RPS.
[Note that the justification and certification may include that the
  composition of the services has some particular property/ies, such
  as safety, or ethical correctness, or immunity to certain kinds of
  malicious attacks, and so on.  A survey of web-service composition
  is provided by \citeasnoun{web_service_composition_srivastava}.]
But sometimes new software services may be needed in order for an AI
to solve $P$, and to justify and certify the solution given to $P$.
Sometimes this solution may be solved in ways that make use of
computing machines outside the collection of all available software
services.  This fact reveals that RPS can be expected to provide
solutions to problems that clients and customers present to IBM even
when these problems can't be solved by any composition of any software
services.  What this means, in short, is that \emph{consulting}
services, not just software services, is a target for what RPS-capable
AI can achieve.  In fact, RPS would include the problem of persuading
a potential customer to agree to become one.

Now we come to \emph{tentacular} RPS.  What is this form of
problem-solving?  In a nutshell, TRPS (sounds like ``trips'') is RPS
in an unrestricted environment distinguished by the maximization of:
(1) today's laboratory-level AI, and (2) the Internet of Things (IoT).
By `maximization' here is meant, in turn, that (1) cutting-edge AI
seen in laboratories of today (but not yet in the marketplace) is
assumed to be mature and perfected,\footnote{In contrast with
  far-fetched notions such as the Singularity, the assumption that
  such wild-eyed things should be \emph{minimized} in setting a course
  for the advancement of AI, but that extant AI should be assumed to
  have \emph{maximal} power in the foreseeable future, is accordingly
  called `The MiniMaxularity' by
  \citeasnoun{bringsjordx2_minimaxularity}.} and that (2) the full
interconnectivity of a virtually infinite and ubiquitous ensemble of
computing machines (some of which are themselves AIs), which entails
the ``shrouding'' of most ordinary physical objects (cups, saucers,
tables, chairs, candles, vehicles, tires, toys, $\ldots$) in
intelligent software, is available to TRPS-capable AI.  Aspect (1) of
the heterogenesous environment that is part and parcel of TRPS is
discussed in \cite{bringsjordx2_minimaxularity}; aspect (2) is
discussed in \cite{cyber_new_disanalogy_phil_tech}.

And now, what is it that is proposed?  That should be obvious.  This
is proposed: the invention, design, specification, and engineering of
TRPS-capable AIs.


\end{comment}
