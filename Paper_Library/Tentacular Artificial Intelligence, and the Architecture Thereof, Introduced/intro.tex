We briefly introduce herein a new form of distributed, multi-agent
artificial intelligence.  An AI artifact $s$ is currently understood
as an agent with a predetermined set of goals, a set of fixed inputs
and outputs, and obligations and permissions.  The agent does not have
any leeway in accomplishing its goals or adhering to its obligations,
prohibitions, or other legal/ethical principles that bind it.  Do we
need agents that go beyond these limitations?  A humble example
follows: During your daily commute to work, an agent $a_c$ in your car
observes that there is more traffic than usual headed toward the local
store.  It then consults a weather service and finds that a major
storm is headed toward your town.  $a_c$ conveys this information to
$a_h$, an agent in your home.  $a_h$ then communicates with an agent
$a_p$ on your phone and finds out that you do not know about the storm
coming your way, as you have not made any preparations for it; and as
further evidence of your ignorance, you have not read any
notifications about the storm.  $a_h$ then infers from your calendar
that you may not have enough time to get supplies after you read your
notifications later in the day.  $a_h$ commands $a_c$ to recommend to
you a list of supplies to shop for on your way home, including at
least $n$ items in certain categories (e.g.\ 3 gallons of bottle
water).

AI of today, as defined by any orthodox, comprehensive overview of it
(e.g.\ \cite{aima.third.ed}), consists in the design, creation,
implementation, and analysis of \textbf{artificial
  agents}.\footnote{This is the exact phrase used by
  \citeasnoun{aima.third.ed}.  Other comprehensive overviews match the
  Russell-Norvig orientation; e.g.\ \cite{luger_ai_book_6thed}.} Each
such agent $a$ takes in information about its particular environment
$E$ (i.e.\ takes in \textbf{percepts} of $E$), engages in some
computation, and then, on the strength of that computation, performs
an action/actions in that environment.  (Of course, for an agent that
persists, this cycle iterates through time.)  On this definition, a
computer program that implements, say, the factorial function $n!$
qualifies as an artificial agent (let's dub it
`$a_{\scriptstyle{\textsc{fac}}}$'), one operating in the environment
$\mathbf{E}_{\scriptstyle{\mathcal{N}}}$ of basic arithmetic; and the
human who has conceived and written this program has built an
artificial agent.  While plenty of the artificial agents touted today
are rather more impressive than $a_{\scriptstyle{\textsc{fac}}}$, our
aim is to bring to the world, within a decade, a revolutionary kind of
AI that yields artificial agents with a radically higher level of
intelligence (including intelligence high enough to qualify the
agents as \textit{cognitively conscious}) and power.  This envisioned
AI we call \textbf{Tentacular AI}, or just `TAI' for short (rhymes
with `pie').  Before presenting architectural-level information about
TAI, we give an example that's a bit more robust than our
first-paragraph one.

%% \subsubsection{The Kitchen-Table Example}
%% \label{subsubsection:kitchen-table_example}
Let's suppose that an AI agent $a_{\scriptstyle{\textsc{home}}}$
overseeing a home is charged with the single, unassuming task of
moving a cup on the home's kitchen table onto a saucer that is also on
that table.  How shall the agent make this goal happen?  If the AI can
delegate to a robot in the house capable of manipulating standard
tabletop objects in a narrow tabletop environment
$\mathbf{E}_{\scriptstyle{\textsc{table}}}$, and that robot is at the
table or can get there in a reasonable amount of time, then of course
$a_{\scriptstyle{\textsc{home}}}$ can direct the robot to pick up
the cup and put it on the saucer.  This is nothing to write home
about, since AI of today has given us agent-robot combos that, in labs
(our own, e.g.)~and soon enough in homes across the technologized
world, can do this kind of thing routinely and reliably.  In fact,
this kind of capability to find plans and move tabletop objects around
in order to obtain goals in tabletop environments\footnote{Such
  environments are variants of those traditionally termed
  `blocks-worlds.'} has been a solved problem from the research point
of view for decades \citeaffixed{logical.foundations.ai}, e.g.
Not only that, but there are longstanding theorems telling us that the
intrinsic difficulty of finding plans to move various standard
tabletop objects in arbitrary starting configurations in tabletop
environments is algorithmically solvable and generally
tractable.\footnote{E.g., see \cite{blocks-world_complexity}.}

However, AI of today is, if you will, living a bit of a lie.  Why?
Because in real life, the agent $a_{\scriptstyle{\textsc{home}}}$
would \emph{not} be operating in only the tabletop environment
$\mathbf{E}_{\scriptstyle{\textsc{table}}}$; rather the idea is that
this agent should be able to understand and manage the overall
environment $\mathbf{E}_{\scriptstyle{\textsc{home}}}$ of the home,
which surely comprises much more than the stuff standardly on one
kitchen table!  Homes can have parents, kids, dogs, visitors, $\ldots$
\textit{ad indefinitum}.

For example, suppose that $a_{\scriptstyle{\textsc{home}}}$ finds
that the tabletop robot is broken, having been mangled by the home's
frisky beagle.  \emph{Then} how does
$a_{\scriptstyle{\textsc{home}}}$ solve the problem of getting
the saucer moved?  Artificial agents of today capable of the kind of
planning that worked before this complication are now hamstrung.  But
not so a TAI agent.  One reason is that TAI agents are capable of
human-level communication.  In certain circumstances within
$a_{\scriptstyle{\textsc{home}}}$ the most efficient way for the
agent $a_{\scriptstyle{\textsc{home}}}$ to accomplish the task
may be to simply say politely via I/IoT (Internet or Interent of Things) through a speaker or a
smartphone or a pair of smart glasses to a human in the home (of whose
mind the TAI agent has a model) sitting at the table in question:
``Would you be so kind as to place that cup on top of the saucer?''
Of course, $a_{\scriptstyle{\textsc{home}}}$ may not be so
fortunate as to have the services of a human available: maybe no human
is at home, yet the task must be completed.  In this case, a TAI agent
can still get things done, in creative fashion.  E.g.,~suppose that in
the home a family member received beforehand a small blimp that can
fly around inside the home and pick things up.\footnote{Such a blimp
  is a simple adaptation of what is readily available as a relatively
  inexpensive toy.}  The TAI agent might then activate and use this
blimp through I/IoT to put the cup atop the saucer.  But what, more
precisely, is a TAI agent?
%% These agents are distinguished by six attributes, the last of which
%% puts the `T' in `TAI,' and makes clear that TAI agents will make
%% unprecedented use of I/IoT and its edge, through to which its
%% ``tentacles'' will reach.
We say that a TAI agent must be:


\input{defs_TAI.tex}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
