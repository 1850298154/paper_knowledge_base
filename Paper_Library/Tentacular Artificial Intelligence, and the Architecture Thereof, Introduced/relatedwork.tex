Given the limited scope of the present paper, we only make some brief
comments about related work, which can be partitioned for convenience
into that which is can be plausibly regarded as on the road toward the
level of expressivity and associated automated reasoning that TAI
requires, and prior work that provides a stark and illuminating
contrast with TAI.

First, as to work we see as reaching toward TAI, we note that recently
\citeauthor{Miller2018} [\citeyear{Miller2018}] present a planning
framework that they call \emph{social planning}, in which the agent
under consideration can plan and act in a manner that takes account of
the beliefs of other agents.  The goal for an agent in social planning
can either be a particular state of the external world, or a set of
beliefs of other agents (or a mix of both).  The system is built upon
a simplified version of a propositional modal logic (unlike our
system, presented below, which is more expressive and can accommodate
more complex goals, e.g.\ goals over unbounded domains or goals that
involve numerical quantification; such statements require going beyond
propositional modal logic).  In addition, certainly the NARS system
from Wang [\citeyear{nars_rigid_flexibility}] has elements that one
can rationally view as congenial to TAI.  For instance, NARS is
multi-layered and reasoning-centric.  On the other hand, the `N' in
`NARS' is for `Non-axiomatic,' and TAI, and indeed the entire approach
to logicist AI pursued by at least Bringsjord and Govindarajulu, seeks
whenever possible to leverage automated reasoning over powerful axiom
systems, such as Peano Arithmetic.\footnote{The layering of TAI is in
  fact anticipated by the increasingly powerful axiom-centric
  cognition described in
  \cite{general_intelligence_implies_creativity}, which takes Peano
  Arithmetic as central.} In addition, TAI is deeply and irreducibly
intensional, while NARS appears to be purely extensional.  Clever
management of computational resources in TAI is clearly going to be
key, and we see the work of Thorisson and colleagues (e.g.\
\cite{attention_mechanisms_thorisson}) to be quite relevant to TAI and
the challenges the implementation of it will encounter.  For a final
example of work that is generally aligned with TAI, we bring to the
reader's attention a recent comprehensive treatment of proof-based
work in computer science: \cite{fpmics}.  As TAI is steadfastly
proof-based AI, this tome provides very nice coverage of the kind of
work required to implement TAI.

Secondly, for illuminating contrast, we note first that some have
considered the concept of corporate intelligence composed of multiple
agents, including machines, where inspiration comes from biology.  A
case in point is the fascinating modeling in
\cite{intelligence_campus_chella}.\footnote{Though out of reach for
  now, given that our chief objective is but an informative
  introduction to TAI, the relationship between our conception of
  cognitive consciousness, which is central to TAI agents (Attribute
  \#4 above), and consciousness as conceived by Chella, is a fertile
  topic for future investigation.  A multi-faceted discussion of
  artificial consciousness is by the way to be had in
  \cite{artificial_consciousness_chella}.  For a first-draft
  axiomatization of the brand of consciousness central to TAI agents,
  see \cite{axiomatizing_consciousness1}.}  In our case, TAI is a
thoroughly formal conception independent of terrestrial biology, one
that is intended to include types of agents of greater intelligence
than those currently on Earth.  Another illuminating contrast comes
via considering established languages for planning that are purely
extensional in nature (e.g.\ PDDL, which in its early form is given in
\cite{pddl1}), as therefore quite different than planning of the type
that is required for TAI, which must be intensional in character, and
is (since cognitive calculi are intensional computational logics).
MA-PDDL is an extension of PDDL for handling domains with multiple
agents with varying actions and goals \cite{kovacsmapddl2012}, and as
such would seem to be relevant to TAI.  But unlike social planning
discussed above, MA-PDDL does not aim to change beliefs (nor for that
matter other epistemic attitudes) of other agents.  While MA-PDDL
could be used to do so, representing beliefs and other cognitive
states in PDDL's extensional language can lead to undesirable
consequences, as demonstrated in
\cite{selmer_naveen_metaphil_web_intelligence}.  Extensions of the
original PDDL (PDDL1), for example PDDL3 \cite{pddl3}, are still
extensional in nature.
%% NAVEEN: Why note make use of the nice graphic/slide you did on PDDL
%% vs Spectra for Robophil 2018 corporate presentation, and cite PDDL
%% paper or two for the stark contrast?  //S

This concludes the related-work section.  Note that below we describe
and define TAI from the point of view of AI planning.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
