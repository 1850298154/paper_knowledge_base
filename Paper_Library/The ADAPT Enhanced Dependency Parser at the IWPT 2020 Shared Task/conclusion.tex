% section: conclusions

In this system submission,
we use a graph-based semantic parser to parse enhanced dependencies and compare to a baseline in which we create enhanced graphs from the basic tree using a very limited set of heuristics.
Avenues for future work include:
%\begin{itemize}
    
    %\setlength\itemsep{-0.5em}
    \paragraph{Post-processing} Predict the head and label for edges connecting fragments (as opposed to a dummy ``0:root'' edge) where this information could come from new edges available from lowering the score threshold or from the basic tree.
    \paragraph{Label Prediction} The semantic parser  performs competitively despite treating enhanced dependency labels containing lemmas and case information 
    %(e.g. \textit{nmod:of} and \textit{nmod:for}) 
    as atomic units. However, a more sophisticated approach should still be tried.
  
   
    \paragraph{Multi-treebank Parsing} When randomising the proxy treebank for multi-treebank models,
          use a different randomisation for each ensemble member.
    Predict the best proxy treebank for each test sentence or paragraph \cite{wagner-etal-2020-treebank}.
    
    %\item
    \paragraph{Elided Tokens} Our semantic parser handles elided tokens by appending the elided token to the adjacency matrix and offsetting the head indices.
    While we used this approach during training on gold data, we did not predict elided tokens 
    %as part of our pipeline
    and we wish to explore methods for doing so.

%\end{itemize}

% eof