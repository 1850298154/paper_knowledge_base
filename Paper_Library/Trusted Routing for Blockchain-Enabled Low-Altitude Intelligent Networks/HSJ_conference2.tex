\documentclass[a4paper,conference]{IEEEtran}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float} 

\usepackage{CJK}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{cases}
\usepackage{setspace}

\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=1,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}

\hypersetup{
 pdftitle={Your Title},
 pdfauthor={Your Name},
 pdfpagelayout=OneColumn, 
 pdfnewwindow=true, 
 pdfstartview=XYZ, 
 plainpages=false}
\makeatletter


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LateX commands.
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LateX commands.

\setlength{\columnsep}{0.21 in}

%\usepackage{emptypage}
%\pagestyle{empty}  % no page number for the second and the later pages
%\thispagestyle{empty} % no page number for the first page


\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{multirow} %multirow for format of table 
\usepackage{amsmath} 
\usepackage{xcolor}

\renewcommand{\algorithmicrequire}{\textbf{Input:}} 
\renewcommand{\algorithmicensure}{\textbf{Output:}}


\allowdisplaybreaks[4]

\ifCLASSOPTIONcompsoc
\usepackage[caption=false,font=normalsize,labelfont=sf,
textfont=sf]{subfig}
\else
\usepackage[caption=false,font=footnotesize]{subfig}
\fi

\usepackage{cite}
\usepackage{bm}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\interdisplaylinepenalty=2500
\IEEEoverridecommandlockouts

\usepackage{lettrine}

\usepackage{geometry}
\geometry{left=0.625in, right=0.625in, bottom=1in, top=0.75in}


\usepackage{subfig}
\makeatother

\begin{document}

\title{\textcolor{black}{
    Trusted Routing for Blockchain-Enabled  Low-Altitude Intelligent Networks}}   
\author{
    \IEEEauthorblockN{Sijie He$^{\dagger}$, 
        Ziye Jia$^{\dagger}$,
        Qiuming Zhu$^{\dagger}$, 
        Fuhui Zhou$^{\dagger}$,
        % Yilu Cao$^{\dagger}$, 
        % Yang Yang$^{\ddagger }$, 
        and Qihui Wu$^{\dagger}$\\}
        \IEEEauthorblockA{$^{\dagger}$The Key Laboratory of Dynamic Cognitive System of 
         Electromagnetic Spectrum Space, Ministry of Industry and\\
          Information Technology, 
         Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, 211106, China\\
          \{hesijie, jiaziye, zhuqiuming, zhoufuhui, wuqihui\}@nuaa.edu.cn}
        
\thanks{{
This work was supported in part by the Natural Science Foundation on 
Frontier Leading Technology Basic Research Project of Jiangsu under Grant BK20222001, 
in part by National Natural Science Foundation of China under Grant 62301251, 
in part by the Aeronautical Science Foundation of China 2023Z071052007, 
and in part by the Young Elite Scientists Sponsorship Program by CAST 2023QNRC001.
}} 
}
        
\maketitle
% \pagestyle{fancy}
% \fancyhf{}
% \fancyhead[R]{\fontsize{7}{9}\selectfont \thepage}
% \renewcommand{\headrulewidth}{0pt} 
% \renewcommand{\footrulewidth}{0pt}

\pagestyle{empty} 

\thispagestyle{empty}

\begin{abstract}
    Due to the scalability and portability, the low-altitude intelligent networks (LAINs)
    are essential in various fields such as surveillance and disaster rescue. 
    However, in LAINs, unmanned aerial vehicles (UAVs) are characterized by 
    the distributed topology and high dynamic mobility, and vulnerable to security threats,
    which may degrade the routing performance for data transmission. 
    Hence, how to ensure the routing stability and security of LAINs is a challenge.
    In this paper, we focus on the routing process in LAINs with multiple UAV clusters 
    and propose the blockchain-enabled zero-trust architecture to manage the joining and exiting of UAVs. 
    Furthermore, we formulate the routing problem to minimize the end-to-end (E2E)
    delay, which is an integer linear programming and intractable to solve.
    Therefore, considering the distribution of LAINs, 
    we reformulate the routing problem into a decentralized partially observable Markov decision process.
    With the proposed soft hierarchical experience replay buffer, 
    the multi-agent double deep Q-network based adaptive routing algorithm is designed.  
    Finally, simulations are conducted and numerical results show that the total 
    E2E delay of the proposed mechanism decreases by 22.38\% than the benchmark on average.

\begin{IEEEkeywords}
    Low-altitude intelligent networks, trusted routing, blockchain, soft hierarchical experience replay buffer,
    multi-agent deep reinforcement learning.
\end{IEEEkeywords}
\end{abstract}

\newcommand{\CLASSINPUTtoptextmargin}{0.8in}

\newcommand{\CLASSINPUTbottomtextmargin}{1in}
% The trust mechanism employ blockchain as a trusted ledger to record status of UAVs. 
% due to the diversity of UAV network deployment scenarios and the features of high- mobility and dynamic topology.
% that provide verifiable and traceable records of interactions {\cite{Trusted_Blockchain}}. 
% Additionally, in dense UAV networks or environments with obstacles, low delay is crucial for collision avoidance systems. 
% Quick data exchange ensures that UAVs can detect and respond to potential collisions in time.
% At the same time, security is a major factor considered when a system is designed, and invariably, the efficiency of UAV network data routing is heavily influenced by security.
% For example, in {\cite{MARL-o-Manage-1}}, to address the multi-UAV cooperative task scheduling, 
% the author proposes the clustering-based multi-agent deep deterministic plicy gradient algorithms 
% which leverages dynamic UAV clustering to partition UAVs into clusters, each managed by a cluster head UAV, 
% facilitating a distributed-centralized control approach. 
\section{Introduction}
\lettrine[lines=2]{A}{s} key components of the six generation communication networks, 
the low-altitude intelligent network (LAINs) are widely applied to multiple tasks, 
such as disaster rescue and real-time monitoring {\cite{10418158, 10599389, 11006480}}. 
In these applications, the data generated from sensor devices (SDs) are required to be 
relayed to the remote ground base stations (BSs) by unmanned aerial vehicles (UAVs){\cite{10899883}}.
Particularly, UAVs act as aerial relays and cooperatively accomplish the data collection
and transmission, providing low-cost, flexible, and versatile services.
In LAINs, routing is a significant issue for data transmission  {\cite{Routing_UAV_Survey, He_Routing, 10574195}}. 

However, since UAVs in LAINs are characterized by the complex application
environment, high mobility and distributed topology, they are vulnerable 
to security threats and unreliable, i.e., attacks and node failures.
Thus, the availability of communication links is susceptible, 
which leads to the reduction of routing performances. 
Hence, it is significant to efficiently manage the mobility of UAVs in the zero-trust environment.
There exist a couple of works related to the management of UAVs.
For instance, in {\cite{GCS_1}}, the ground control station (GCS) is responsible 
for managing the connection among all UAVs, through the status message sent by UAVs.
In {\cite{GCS_2}}, the authors present that as the center controller and manager, 
the GCS receives the data transmitted by UAVs, which is suffered from long distances, 
undulating terrains or other interferences.
Authors in {\cite{GCS_3}} present that the GCS remotely controls UAVs by sending controlling information, 
in which the relay UAV is limited within the communication range of the GCS, 
restricting the scope of operations.
Moreover, the above works rely on a center controller, which is not resilient 
to fault tolerance and may be susceptible to tampering.
Hence, how to guarantee the reliability and security of routing remains challenging
in the distributed and zero-trust network.

Meanwhile, the transmission delay is a key quality of service,
since low delay can significantly improve the timeliness and reliability for 
various emergency applications, such as the surveillance information transmission {\cite{ Wang_security}}.
Therefore, it is necessary to  design an adaptive and 
dynamic algorithm to enable timely and reliable routing 
in the varying network topology.
To tackle this issue, the multi-agent reinforcement learning (MARL) can be applied {\cite{10638237}}.
Specifically, there exist a couple of works focusing on MARL-based routing problems in dynamic scenarios. 
For example, in {\cite{MARL-o-Manage-4}}, the authors propose a value decomposition network based MARL algorithm to 
minimize the end-to-end (E2E) delay of packet routing within dynamic aerial and terrestrial hybrid networks.
{\cite{MARL-o-Manage-5}} formulates the packet routing as a max-min problem using the Lagrange method, 
% while prioritizing fast communication and meeting energy efficiency and packet loss requirements, 
and proposes a constrained MARL dynamic routing algorithm to balance the objective improvement and constraint satisfaction.
Authors in {\cite{MARL-o-Manage-6}} establish the mean-field enhanced heterogeneous MARL framework
to optimize the communication energy efficiency during routing.
The above studys illustrate that the MARL can solve the routing problem effectively.
However, these works do not consider the mobility management of UAVs in the zero-trust environment.

To deal with the above challenges, in this paper, the routing process is depicted 
in the zero-trust LAINs with multiple UAV clusters, considering the dynamic joining and exiting of UAVs.   
Meanwhile, to improve the network reliability and security, the blockchain technique with a distributed ledger is 
introduced to manage the mobility of nodes and avoid being tempered with, by leveraging the smart contract. 
Further, a couple of UAVs with powerful capabilities are selected to construct the decentralized controller in the blockchain.
In light of the constructed LAIN, 
the routing problem is formulated to minimize the total E2E delay, 
which is an integer linear programming (ILP) and intractable to solve. 
Besides, it is tricky to obtain the global information due to decentralized UAVs.
Hence, we reformulate the routing problem into a decentralized partially observable Markov decision process (Dec-POMDP).
To improve the efficiency of learning and training, 
we propose the multi-agent double deep Q-network (MADDQN)-based adaptive routing approach 
with the designed soft hierarchical experience replay buffer (SHERB). 
Finally, numerical simulations are conducted to verify the performance of the proposed algorithm.

% In short, the major contributions of the proposed work are summarized as
% follows:
% \begin{itemize}
%     % Accordingly, the problem is reformulated into a decentralized partially observable Markov decision process and a multi-agent 
%     % double deep Q network-based routing algorithm is designed. Finally, simulations are conducted and numerical results show that the delay 
%     % of the proposed mechanism decreases by 16.8$\%$ and 8.5$\%$ than the proximal policy optimal algorithm and deep Q network algorithm, respectively.

%     % Then, a node trust evaluation mechanism by combining blockchain consensus is presented 
%     % to recognize and isolate low-trusted UAVs. Moreover, we design a consensus UAV update mechanism and an improved 
%     % UAV-enhanced practical Byzantine fault tolerance algorithm is proposed. 
%     \item We characterize the routing process via a time-varying
%     UAV network with malicious nodes. Besides, we formulate the routing 
%     problem to minimize the total E2E delay, which is an ILP and
%     tricky to solve by traditional optimization schemes.
    
%     \item To deal with the issue of network security, the blockchain-based trust management 
%     mechanism (BTMM) is designed, which records the malicious behaviors and 
%     trust values of UAVs. Further, to promote the routing security in UAV
%     networks, we design the consensus node update mechanism to improve  
%     practical Byzantine fault tolerance (PBFT) algorithms. 
    
%     \item 
%     Since it is challenging to obtain global information due to the decentralized
%     UAV networks, we reformulate the routing problem into a Dec-POMDP. Furthermore, an 
%     MADDQN-based routing algorithm is proposed to learn the dynamically changing
%     network topology and make decisions to minimize the E2E routing delay.
%     \item Extensive simulations are conducted to evaluate the proposed BTMM-MADDQN 
%     algorithms with attacked UAVs. Numerical results show that the proposed
%     algorithm decreases the delay compared to BTMM-multi-agent proximal policy 
%     optimal (BTMM-MAPPO) algorithms, BTMM-multi-agent deep Q-network (BTMM-MADQN) 
%     algorithms, and the MADDQN algorithm without BTMM when there exist malicious UAVs.
% \end{itemize}

    % The rest of the paper is organized as follows. 
    % The system model and problem formulation are illustrated in Section {\ref{Sec:System-model}}.
    % Then, we reformulate the problem and design the algorithm in Section {\ref{Sec:GATDRL}}. 
    % Simulations are conducted and the performance analyses are shown in Section {\ref{sec:Simulation Results}}.
    % Finally, the conclusions are drawn in Section {\ref{sec:Conclusions}}.
\vspace{0.5cm}
\section{System Model and Problem Formulation\label{Sec:System-model}}
\vspace{0.1cm}
\subsection{Network Model}
The routing process in zero-trust LAINs is show in Fig. \ref{fig:Network_of_UAV}, 
including $N$ nodes, and each node holds a unique identity. 
Specifically, when there exist UAVs applying to joining or exiting, 
the identities are authenticated and managed by smart contracts via the blockchain technique.
Moreover, the periodical authentication is performed on all UAVs for the persistent verification.
In detail, the ground layer consists of $B$ BSs and $I$ SDs.
%  where the SDs are far away from BSs. 
The air layer is composed of $U$ UAVs. 
$\mathcal{B}\! =\!\{1,...,b,...,B\}$, $\mathcal{I}\! =\!\{1,...,i,...,I\}$, 
and $\mathcal{U}\! =\!\{1,...,u,...,U\}$ denote the sets of 
BSs, SDs, and UAVs, respectively. 
Besides, UAV set $\mathcal{U}=\mathcal{U}_\mathtt{s} \cup \mathcal{U}_\mathtt{r} \cup \mathcal{U}_\mathtt{d}$ 
is divided based on clusters, in which $\mathcal{U}_\mathtt{s}$, $\mathcal{U}_\mathtt{r}$, 
and $\mathcal{U}_\mathtt{d}$ denote the data collection, relay forwarding, and downlinking clusters, respectively.
In each cluster, the UAV with the most energy and computing power is selected as the cluster head.
$\mathcal{E}\!=\!\mathcal{E}_{iu}\!+\!\mathcal{E}_{uu}\!+\!\mathcal{E}_{ub}$ indicates the set of communication 
link status among all nodes, where $e_{iu}\!\in\!\mathcal{E}_{iu}$, $e_{ub}\!\in\!\mathcal{E}_{ub}$, 
and $e_{u u }\!\in\!\mathcal{E}_{uu}$ represent the connection of links
between the SD and UAV, the BS and UAV, and the UAV and UAV, respectively.
$e_{nm}\in \mathcal{E}$ indicates whether there exists a communicable link 
between nodes $n\in \mathcal{I} \cup \mathcal{U}$ and $m\in \mathcal{U} \cup \mathcal{B}$. 
Specifically, $e_{nm}=1$ indicates the link is effective, 
and $e_{nm}=0$ denotes there exist no direct links. 

In particular, the time period is divided into $\mathsf{T}$ steps. 
% and the length of each time step is $\tau$
The set of time steps is represented as $T \!=\! \{1,...,t,...,\mathsf{T}\}$.      
At the beginning of time step $t$, demand $r$ is transmitted from SD $i\in \mathcal{I}$ to 
destination BS $b\in \mathcal{B}$, denoted by 
$\varUpsilon^r\!=\!\{\mathtt{s}^r,\mathcal{L}^r,\mathtt{d}^r,\mathcal{T}^r_{max}\}$,  
in which the source is $\mathtt{s}^r\!=\!i$, and the destination is $\mathtt{d}^r\!=\!b$.
Here, the size of demand $r$ is $\mathcal{L}^r$ (in bit), 
and $\mathcal{T}^r_{max}$ is the maximum delay tolerance of the demand transmission.
Further, demands are uploaded from SD $i \!\in\! \mathcal{I}$ to UAV $u\!\in\! \mathcal{U}_\mathtt{s}$,  
relayed by UAV $u\! \in\! \mathcal{U}_\mathtt{r}$, and downloaded 
from UAV $u\!\in\!\mathcal{U}_\mathtt{d}$ to BS $b \!\in\! \mathcal{B}$. 
$\mathcal{P}_{ib}^{r}\!=\!{(e_{iu},\cdots,e_{ub})}$ 
indicates a completed routing path for transmitting demand $r$. 
% from source SD $i\!\in\!\mathcal{I}$ to corresponding destination BS $b\! \in\!\mathcal{B}$. 

The coordinates of SD $i$ 
and BS  $b$ remain fixed and are ${\varTheta}_{i}\!=\!{(x_{i},y_{i},0)}$ and 
${\varTheta}_{b}\!=\!{(x_{b},y_{b},0)}$, respectively. 
The location of UAV $u$  is indicated by 
${\varTheta}_{u}(t)={(x_{u}(t),y_{u}(t),z_{u}(t))}$ in three-dimensional Cartesian coordinates at time step $t$. 
% In one time step, the UAV is quasi-static. 
% The velocity in $x$, $y$, and $z$ directions of UAV $u$ is 
% represented by ${{{\bm{\nu}}}}_{u(t)}={(\nu^{x}_{u(t)},\nu^{y}_{u(t)},\nu^{z}_{u(t)})}$, 
% and the velocities of all UAVs are denoted as
%  $\bm{V(t)}=\{\bm{\nu}_{1(t)},\cdots,\bm{\nu}_{u(t)},\cdots,\bm{\nu}_{U(t)}\}$ at time step $t$. 
% Further, $\bm{\nu}_{i}=(\bm{\nu}_{i}(1),\bm{\nu}_{i}(2),\cdots,\bm{\nu}_{i}(T))$ indicates the velocities sequence of UAV $i\in\mathcal{U}$. 
Additionally, the Euclidean distance between nodes $n \in \mathcal{I}\cup\mathcal{U}$ and $m \in \mathcal{U}\cup\mathcal{B}$
is indicated by $d_{n  m}(t)$ at time step $t$, i.e., 
\begin{equation}{\label{distance}}
    \begin{aligned}
    &d_{n  m}(t) \!= \!\\
    &\sqrt{(x_{n}(t)\!-\! x_{m}(t))^2\!+\!(y_{n}(t)\!-\!y_{m}(t))^2\!+\!(z_{n}(t)\!-\!z_{m}(t))^2}.
    \end{aligned}
\end{equation}
In particular, the distance between UAVs should satisfy
\begin{equation}{\label{distance_min}}
    d_{min} \leqslant d_{n  m}(t), \forall n ,m \in\mathcal{U}, n\neq m, t\in T.
\end{equation}
Here, $d_{min}$ represents the safe distance to avoid collisions among UAVs.
At time step $t$, the set of connected UAVs for UAV $u$ is denoted as $\Gamma_{u}(t)$,   
and distance $d_{u\kappa }(t)$ between UAV $u$ and UAV $\kappa \in \Gamma_{u}(t) $ satisfies 
\begin{equation}{\label{distance_max}}
    d_{u \kappa}(t)\leqslant d_{u,max},\forall \kappa \in \Gamma_{u}(t), u\in \mathcal{U}, t \in T,
\end{equation}
in which $d_{u,max}$ is the maximum communication distance of UAV $u$.
 \begin{figure}[t]
\vspace{-0.1cm}
    \centering
    \includegraphics[width=0.9\linewidth]{Scenario.4.20.pdf}
    % \small % 这里设置字体为小一号，可按需调整
    \caption{\label{fig:Network_of_UAV} Routing scenario in zero-trust LAINs with the mobility management of UAVs via the blockchain technique. 
    } 
\vspace{-0.1cm}
\end{figure}

% Due to the unsecure environment, UAVs may be vulnerable to attacks and 
% become malicious nodes. Hence, the impact of attacks on the network 
% performance is analyzed. Since most attacks are launched 
% via specific standards to destroy the network, such as attacking critical 
% nodes at first, we design a deliberate attack model based on the node ranking 
% mechanism, in which UAVs with higher importance are attacked in priority 
% {\cite{attacks, He_Routing}}. Considering the node degree $\zeta_{u(t)}$ of UAV $u$ and the 
% weight $\chi _{u(t)j(t)}$ of link $e({u,j})$, the importance $\varLambda_{u(t)}$ 
% of UAV $u$ at time step $t$ is calculated as 
% \begin{equation}
%     \varLambda _{u(t)} = \zeta_{u(t)} + \sum_{{k(t)} \in \Gamma_{u(t)}}\left[\chi _{u(t)k(t)}\cdot(1-\frac{\zeta_{k(t)} - 1}{\zeta_{u(t)} + \zeta_{k(t)} - 2})\right], t \in T,
% \end{equation}
% in which
% \begin{equation}
%     \zeta_{u(t)}=\sum_{j(t) \in \mathcal{U}} e(u(t), j(t)), t \in T,
% \end{equation}
% and
% \begin{equation}
%     \chi _{u(t)k(t)}={Z}\cdot\frac{2}{m+2}.
% \end{equation}
% Wherein, $Z= (\zeta_{u(t)} - m - 1)\cdot(\zeta_{k(t)} - m - 1)$ indicates the 
% connectivity ability of link $e({u,k})$, and $m$ represents the number of 
% triangles containing link $e({u,k})$ in the UAV network topology.

% Besides, we utilize $f$ and $\mathcal{F}$ to
% denote the number and set of malicious UAVs in networks, respectively.
% When malicious UAVs are recognized, they are isolated from the network, 
% leading to the unavailability of original routing paths.
% Therefore, a new transmission path should be found for recovering 
% the routing, as in shown Fig. {\ref{fig:Network_of_UAV}}. 

% \subsection{Trust Model}
% % The malicious behaviors of UAVs are analyzed in two aspects. In particular, 
% % when the malicious UAVs receive the demand, they may drop it or do not 
% % transmit it following the specific routing path. 
% % Hence,
% % 
% Considering the delivery rate and the correctness of transmission paths, 
% the trust evaluation mechanism for each UAV is designed as follows.
% The value of the delivery rate is represented as the ratio of 
%     total transmitted demands $\mathfrak{N}^{tr}_i(t)=\sum_{k=1}(t)\varepsilon^{tr}_{i(k)}$ to total received
%     demands $\mathfrak{N}^{re}_i(t)=\sum_{k=1}(t)\varepsilon^{re}_{i(k)}$ by UAV $i$ at time step $t$, i.e.,
%     \begin{equation}{\label{equ:dr}}
%         \mathbb{T}_{i(t)}^{dr}\!=\!\frac{\mathfrak{N}^{tr}_i(t)}{\mathfrak{N}^{re}_i(t)}, \forall i \in \mathcal{U},\mathfrak{N}^{re}(t)> \!0, t \in T.
%     \end{equation} 
%     Besides, $\mathfrak{N}^{re}(t)=0$ denotes UAV $i$ does not receive demands, 
%     and $\mathbb{T}_{i(t)}^{dr}$ remains the initial value.


%     In particular, we can calculate the evaluation value of UAV $i$ in terms of the 
%     transmission path at time step $t$ by 
%     \begin{equation}{\label{equ:tp}}
%         \mathbb{T}_{i(t)}^{tp}=1-\frac{\mathfrak{M}^{non}_i(t)}{\mathfrak{M}^{tot}_i (t)}, \forall i \in \mathcal{U}, \mathfrak{M}^{tot}_i (t)\!>\!0, t \in T,
%     \end{equation}
%     where $\mathfrak{M}^{non}_i (t)=\sum_{k=1}(t)\mathfrak{B}_{i(t)}$ and $\mathfrak{M}^{tot}_i (t)=\sum_{k=1}(t)\mathbb{B}_{i(t)}$ indicate the numbers of non-specified and 
%     total transmission paths of UAV $i$ at time step $t$, respectively. In addition, when $\mathfrak{M}^{tot}(t)=0$, 
%     $\mathbb{T}_{i(t)}^{tp}$ remains unchanged at the initial value.


% Considering the above two factors, the comprehensive trust value of UAV 
% $i$ at time step $t+1$ is calculated as 
% \begin{equation}
%     {\label{equ:trust-total}}
%     \begin{aligned}
%     \mathbb{T}_{i(t+1)}\! =\! \psi _{i(t)}^0\mathbb{T}_{i(t)}\! +\!  \psi_{i(t)}^1 \mathbb{T}^{dr}_{i(t)}  \! +\! \psi_{i(t)}^2 \mathbb{T}^{tp}_{i(t)},  
%       \forall  i\!  \in\!  \mathcal{U}, t\! \in\!  T.      
%     \end{aligned}
% \end{equation}
% % Wherein, $\mathbb{T}_{i(1)}\! = \!1, \mathbb{T}_{i(1)}^{dr}\!=\!1,  \text{and } \mathbb{T}^{tp}_{i(1)}\!=\!1$ 
% % indicate the initial trust values for UAV $i$. 
% $\psi _{i(t)}^0$, $\psi _{i(t)}^1$, and $\psi _{i(t)}^2$ are hyperparameters, 
% denoting the weights of $\mathbb{T}_{i(t)}$,
%  $\mathbb{T}^{dr}_{i(t)}$, and $\mathbb{T}^{tp}_{i(t)}$, respectively, and $\psi_{i(t)}^0\!+\!\psi _{i(t)}^1\!+\!\psi_{i(t)}^2\!=\!1$.
% Moreover,  we propose the adaptive method to determine the weights of $\mathbb{T}^{dr}_{i(t)}$ and $\mathbb{T}^{tp}_{i(t)}$.

%     Moreover, considering that $\mathbb{T}^{dr}_{i(t)}$ and  $\mathbb{T}^{tp}_{i(t)}$ are directly related 
%     to the trust value evaluation, we propose the adaptive method to determine the weights of trust values,  detailed as 
% \begin{align}
%     \left\{\begin{aligned}{\label{Adaptive_weights}}
%         \psi _{i(t)}^0&\!=\! 0.5 \times \frac{\mathbb{T}_{thr}}{\mathbb{T}_{i(t)}}, \\
%         \psi _{i(t)}^1 &\!=\! \frac{(1\!-\!\psi _{i(t)}^0)\cdot(1\!-\!\mathbb{T}^{dr}_{i(t)})}{2\! -\! \mathbb{T}^{dr}_{i(t)}\! +\! \mathbb{T}^{tp}_{i(t)}}, 0\leq\! \mathbb{T}^{dr}_{i(t)} \!+ \!\mathbb{T}^{tp}_{i(t)}\!\leq 2,\\
%         \psi _{i(t)}^2 &\!=\! \frac{(1\!-\!\psi _{i(t)}^0)\cdot(1\!-\!\mathbb{T}^{tp}_{i(t)})}{2 \!-\! \mathbb{T}^{dr}_{i(t)}\! + \!\mathbb{T}^{tp}_{i(t)}}.
%     \end{aligned}\right.
% \end{align}
% When $\mathbb{T}^{dr}_{i(t)}\! +\! \mathbb{T}^{tp}_{i(t)}\!=\!2$, $\psi _{i(t)}^1 \!=\!\psi _{i(t)}^2\!=\!\frac{(1\!-\!\psi _{i(t)}^0)}{2}$.
% $\mathbb{T}_{thr}$ can be determined by the security requirements {\cite{trust_parameters}}.

% \subsection{Trust Model}
% The paper comprehensively evaluates the node trust value considering direct and indirect factors, 
% avoiding the single assessment factor and insufficiently reasonable calculation.
% In detail, $\mathbb{T}_{u}(t)$ denotes total trust value of UAV $u$ at time step $t$ and
%  is the addition of direct trust $\mathbb{T}^{\text{\tiny{D}}}_{u}(t)$,  indirect trust $\mathbb{T}^{\text{\tiny{I}}}_{u(t)}$, 
%  and initial trust $\mathbb{T}_{u^0}$, i.e.,
% \begin{equation}
%     \mathbb{T}_{u}(t) =\psi _{0}\mathbb{T}_{u}(0)+ \psi _{1} \mathbb{T}^{\text{\tiny{D}}}_{u}(t) +\psi_{2} \mathbb{T}^{\text{\tiny{I}}}_{u}(t), \forall  u \in \mathcal{U}, t\in T,
% \end{equation}
% where $\psi _{0}$, $\psi_{1}$, and $\psi _{2}$ denote the weights of $\mathbb{T}_{u}(0)$,
% $\mathbb{T}^{\text{\tiny{D}}}_{u}(t)$, and $\mathbb{T}^{\text{\tiny{I}}}_{u}(t)$, respectively, and $\psi _{0}+\psi _{1}+\psi _{2}\!=\!1$.

% Further, combining the demand forwarding rate $\mathbb{T}^{\text{\tiny{D1}}}_{u(t)}$, 
% trusted interaction degree $\mathbb{T}^{\text{\tiny{D2}}}_{u(t)}$, 
% and probe message receiving rate $\mathbb{T}_{u(t)}^{\text{\tiny{D3}}}$, 
% the direct trust is comprehensively calculated as
% \begin{equation}
%     \mathbb{T}^{\text{\tiny{D}}}_{u(t)} =\backepsilon_{1} \! \mathbb{T}^{\text{\tiny{D1}}}_{u(t)} +\backepsilon_{2}\! 
%     \mathbb{T}^{\text{\tiny{D2}}}_{u(t)}+ \backepsilon_{3} \! \mathbb{T}_{u(t)}^{\text{\tiny{D3}}}, \forall  u \in \mathcal{U}, t\in T,
% \end{equation}
% in which $\backepsilon_{1}$, $\backepsilon_{2}$, and $\backepsilon_{3}$ indicate the weights of 
% $\mathbb{T}^{\text{\tiny{D1}}}_{u(t)}$, $\mathbb{T}^{\text{\tiny{D2}}}_{u(t)}$, and $\mathbb{T}_{u(t)}^{\text{\tiny{D3}}}$, respectively. 
% Specifically, the $\mathbb{T}_{u(t) }^{\text{\tiny{D1}}}$ is designed as the radio 
% of total transmitted demands $\sum_{k=1}(t)\varepsilon^{tr}_{u^k}$ to total received demands 
% $\sum_{k=1}(t)\varepsilon^{re}_{u^k}$ by UAV $u$ at time step $t$. 

%     \begin{equation}
%         \mathbb{T}_{u(t) }^{\text{\tiny{D1}}}=\frac{\sum\limits_{k=1}(t)\varepsilon^{tr}_{u^k}}{1+\sum\limits_{k=1}(t)\varepsilon^{re}_{u^k}}, \forall u \in \mathcal{U}, t \in T.
%     \end{equation}  
% Considering the interaction with trusted nodes, $\mathbb{T}_{u(t)}^{\text{\tiny{D2}}}$ is 
%     \begin{equation}
%         \mathbb{T}_{u(t)}^{\text{\tiny{D2}}}=f^{\mathsf{T} }_{u(t)} \times e^{-f^{\mathsf{N} }_{u(t)}}, \forall u \in \mathcal{U}, t \in T.
%     \end{equation}  
%     Where, $f^{\mathsf{T} }_{u(t)}$ and $f^{\mathsf{N}}_{u(t)}$ denote the interaction frequency of UAV $u\in\mathcal{U}$ 
%     with trusted nodes and non-trusted nodes, respectively.

%     The $\mathbb{T}_{u(t)}^{\text{\tiny{D3}}}$ indicates the probability of 
%     successfully reaching the receiver for probe messages, and is defined as
%     \begin{equation}
%         \mathbb{T}_{u(t)}^{\text{\tiny{D3}}}=\frac{\varTheta(t-\Im,t)}{\Im/\ell},
%     \end{equation}  
%     where $\varTheta(t-\Im,t)$ is the number of probe messages actually received by the evaluation UAV during 
%     time window $\Im $ and $\ell $ is the probing period. $\Im/\ell$ is the theoretical number of the received probe messages, 
%     i.e., the number of probe messages sent by the evaluated UAV $u$.

% To mitigate this limitation by fully utilizing the knowledge of the network, 
% the indirect trust evaluation is obtained from the trusted neighboring nodes and calculated 
% \begin{equation}
%     \mathbb{T}^{\text{\tiny{I}}}_{u(t)}\!=\!\sum\limits_{k\in \Gamma_{u(t)} }\! 
%     \frac{\mathbb{P} _{k(t)}}{\mathbb{P}_{k(t)}\!+\!\mathbb{N} _{k(t)}}, \mathbb{T}_{k(t)}\!\geqslant\!\mathbb{T}_{thr} ,\forall u \!\in\! \mathcal{U}, t\in T.
% \end{equation}
% Here, $\mathbb{P}_{k(t)}$ and $\mathbb{N} _{k(t)}$ are the positive and negative recommendation of UAV $k$ to UAV $u$, respectively.
% $\mathbb{T}_{thr}$ is the threshold for determining the trusted nodes.

% $\mathbb{T}_{u(t)}$ denotes total trust value of UAV $u$ at time step $t$ and is the addition of direct and indirect trust, i.e.,
% \begin{equation}
%     \mathbb{T}_{u(t)} =\psi _{0}\mathbb{T}_{u^0}+ \psi _{1} \mathbb{T}^{\text{\tiny{D}}}_{u(t)} +\psi_{2} \mathbb{T}^{\text{\tiny{I}}}_{u(t)}, \forall  u \in \mathcal{U}, t\in T,
% \end{equation}
% where $\mathbb{T}_{u^0}$ indicates the initial trust value for UAV $u$. 
% $\psi _{0}$, $\psi_{1}$, and $\psi _{2}$ are hyperparameters, denoting the weights of $\mathbb{T}_{u^0}$,
% $\mathbb{T}^{\tiny{D}}_{u(t)}$, and $\mathbb{T}^{\tiny{I}}_{u(t)}$, respectively, and $\psi _{0}+\psi _{1}+\psi _{2}\!=\!1$.

% Meanwhile, in the UAV network, the security of the trust manager is significantly considered during routing. 
% However, centralized manager always relies on third-party authentic centers, which are susceptible to diverse attacks, 
% such as DOS, DDos, which can cause the entire network to break down. 
% To overcome the challenge posed by the above security threat, it is necessary to design the distributed and trusted 
% management schemes, to defend against malicious attacks. 
% In particular, the blockchain is a distributed ledger and consists of a chain of blocks, 
% in which transaction details and records are stored and hard to be tempered with.
% Therefore, blockchain technology is introduced to provide a distributed and reliable manager 
% of trust values, to ensure the security of routing environment in LAINs.

\vspace{0.2cm}
\subsection{Blockchain Model}
To manage the mobility of UAVs, a lightweight blockchain model is proposed.
% In detail, when there exists a new UAV applies to join the LAIN, 
% which is required for authentication from the blockchain. 
Additionally, to maintain the sustainability and reliability of routing, 
the joining and exiting of UAVs need to be recorded and updated via the blockchain.

\subsubsection{Role Selection}
In the lightweight blockchain, the set $\mathcal{U}$ of UAVs is divided into the sets of full nodes 
$\mathcal{U}_f= \{1, 2,  \cdots, u_f \}$ and light nodes $\mathcal{U}_l= \{1, 2, \cdots, u_l \}$, respectively.
In detail, as shown in Fig. {\ref{fig:Network_of_UAV}}, 
cluster head UAVs are selected as full nodes due to the sufficient resources,
while the other UAVs act as light nodes in LAINs. 
In particular, the full nodes have the full blockchain ledger and are responsible for the blockchain consensus, 
including broadcasting and verification of transactions. 
The light nodes can only store the header of blocks and are in charge of generating local transactions and relaying transactions from other UAVs.

\subsubsection{PBFT-based Consensus Process}
We apply the practical Byzantine fault tolerance (PBFT) method, 
which can ensure the success of the consensus process when the number of failure nodes is less than one third. 
% However, , the random selection of the primary node may cause the entire consensus process to fail when it is the malicious node. 
% Moreover, due to the larger load on primary nodes, selecting capable nodes is significant for the effectiveness and reliability of the consensus. 
For the effectiveness and reliability of the PBFT consensus, 
% due to the larger load on the primary node, 
it is significant to select consensus UAVs with the most abundant resources as the primary node, 
while other consensus UAVs operate as non-primary (replica) nodes. 

\subsubsection{Transaction Generation and Broadcasting}
The transactions waiting for the consensus are generated periodically and include the status of UAVs, 
i.e., the queue buffer, location, and information of neighboring nodes.
Then, all generated transactions are broadcasted to the entire network  via the Gossip protocol for verifying. 
After verification, the transactions are added to the transaction pool of the blockchain and then synchronized to the 
entire blockchain. Once a consensus is reached, the data transaction are recorded in the blockchain with tamper-proof.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.8\linewidth]{PBFT-12.10.pdf}
%     \vspace{-0.3cm}
%     {\caption{\label{fig:PBFT}The consensus process of the PBFT. }}
%     \vspace{-0.3cm}
% \end{figure}

% Fig. {\ref{fig:PBFT}} depicts the U-PBFT based consensus process and the delay is discussed as follows.
% The U-PBFT based consensus process is discussed as follows.
% \begin{itemize}
%     \item Firstly, the primary packs the validated transaction into a block
%     and then broadcasts the \textit{pre-prepare} message to 
%     non-leader consensus UAVs. 
%     \item In the \textit{prepare} stages, each non-primary  consensus UAV verifies
%     the received \textit{pre-prepare} message and then broadcasts the \textit{prepare} 
%     message to other consensus UAVs. Furthermore, each consensus UAV  
%     compares the received \textit{prepare} message with the \textit{pre-prepare} message. 
%     % It is noted that 
%     % We know that in the PBFT protocol, when the full node receives a valid signature greater than or equal to 2f.
%     \item In the \textit{commit} phase, if the consensus UAV receives more 
%     than or equal to $2n$ valid \textit{prepare} messages, they broadcast \textit{commit} messages 
%     to the other consensus UAVs for verification. If each consensus UAV receives $2n+1$ \textit{commit} 
%     messages, the consensus is reached. 
% \end{itemize}
% We consider blockchain messages to have the highest priority and therefore do not consider queuing delays.
% We assume the number of consensus nodes is $K$, and the number of malicious nodes is $f<{K/3}$. 
 
% We consider only the costs of the cryptographic operations, including generating signatures, verifying signatures, and generating or verifying MACs, 
% with costs of $\epsilon_s$, $\epsilon_v$, and $\epsilon_m$ cycles, respectively.
% % indicate the number of CPU cycles required to sign a transaction or block, verify a signature, and create or verify an MAC, respectively.

% In the phase of collecting the transactions, the primary collects routing information from other nodes via the consensus nodes and then verifies.
% In detail, light UAVs sends its own information to the nearest surrounding full nodes as request after transmitting demands.
% Then, each consensus UAV generates a transaction according to the received information from surroundings.
% Particularly, the transactions are signed by the private key of consensus UAVs, 
% and then they are packaged and forwarded to the primary node with a message authentication code (MAC). 

% At this step, the delay cost of consensus nodes is a fixed value $T_g$, 
% and the delay of the primary node in verifying all the packaged transactions is $K(\epsilon_v+\epsilon_m)$. 
% One $\epsilon_v+\epsilon_m$ is for verifying the request message, 
% and the $(K-1)(\epsilon_v+\epsilon_m)$ CPU cycles are utilized for verifying 
% the signatures and MACs of the transactions originating from the $K-1$ UAVs. 
% Therefore, the delay of this step can be given by
% \begin{equation}
%     T_1=\frac{K(\epsilon_v+\epsilon_m)}{\partial _{p(t)}} + T_g.
% \end{equation}
% where ${\partial _{p(t)}}$ is computation resource assigned by the primary node for the block consensus.

% % \item When the primary node receives the message from the consensus nodes, it will broadcast the message to other consensus nodes.
% In the Pre-prepare phase, the primary node first packages the validated transactions into a block and then generates a signature for the block 
% and $K-1$ MACs for the $K-1$ replica nodes individually. Hence, the delay of the primary node is
% \begin{equation}
%     T_{2,1}=\frac{\epsilon_s+(K-1)\epsilon_m}{\partial _{p(t)}}.
% \end{equation}
% % Subsequently, each replica UAV verifies the MAC of the block, the signature, and the transactions included in the pre-prepare message

% Subsequently, each replica UAV consumes $\epsilon_v + \epsilon_m$ CPU cycles for verifying the pre-prepare message 
% and $K(\epsilon_v + \epsilon_m)$ CPU cycles for verifying the signature and the MAC of the $K$ transactions. 
% Suppose that each replica UAV $j$ allocates $f_{j(t)}$ CPU cycles for the blockchain consensus, and then the delay is
% \begin{equation}
%     T_{2,2}=\max_{j\in\mathcal{U}_c}\frac{(K+1)(\epsilon_\nu+\epsilon_m)}{\partial _{j(t)}}.
% \end{equation}
% Therefore, the total delay of the pre-prepare step is 
% \begin{equation}
%     \begin{aligned}
%     T_{2} =T_{2,1}+T_{2,2}.
%     % &=\frac{\epsilon_s+(K-1)\epsilon_m}{f_{p(t)}}\\ &+\max_{j\in\mathcal{U}_c}\frac{(K+1)(\epsilon_\nu+\epsilon_m)}{f_{j(t)}}
% \end{aligned}
% \end{equation}

% In the Prepare, since the primary node only needs to verify $2\lceil J\rceil+1$ MACs and signatures of the received prepare messages, 
% the calculation amount is $(2\lceil J\rceil+1)(\epsilon_v + \epsilon_m)$ CPU cycles, and the delay of the primary node is
% \begin{equation}
%     T_3^p=\frac{(2\lceil J\rceil+1)(\epsilon_\nu+\epsilon_m)}{\partial _{p(t)}}.
% \end{equation}

% Compared with the primary node, replica nodes consume extra $\epsilon_s + (K- 1)\epsilon_m$ CPU cycles 
% to generate a signature for the prepare message and $K-1$ MACs for other $K-1$ full nodes.
% Hence, the delay of each replica node $j$ at this step is
% \begin{equation}
%     T_{3,j}^{r}=\frac{(2\lceil J\rceil+1)(\epsilon_\nu+\epsilon_m)+\epsilon_s+(K-1)\epsilon_m}{\partial _{j(t)}}.
% \end{equation}
% Based on the above analysis, the delay of the step is
% \begin{equation}
%     T_3=\max\{T_3^p,T_{3,j}^{r}\},j\in\mathcal{U}_c,
% \end{equation}
%    where $\mathcal{U}^{\mathrm{non}}$ is the set of all the replica nodes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              

% After receiving $2\lceil J\rceil+1$ consistent prepare messages, every node broadcasts a commit message to all the other nodes. 
% Each node must accumulate at least $2\lceil J\rceil+1$ consistent commit messages from other nodes.
% At this step, each node generates one signature for the commit message and $K-1$ MACs 
% for the other $K-1$ full nodes. Besides, each full node verifies $2\lceil J\rceil+1$ signatures and MACs. 
% Therefore, the total delay of this step is
% \begin{equation}
%     T_4\!=\!\frac{\epsilon_s \!+\!(K\!-\!1)\epsilon_m\! +\! (2\lceil J\rceil+1)(\epsilon_v \!+\! \epsilon_m)}
%     {\min\left\{\partial^p(t), \partial _j^{r}(t)\right\}},\mathrm{~}j\!\in\!\mathcal{U}_{c}.
% \end{equation}

% In the Reply pahse, any node that has received at least $2\lceil J\rceil+1$ commitments from the other full nodes will replicate the block locally 
% and regard it as genuine. Then each full node dispatches a reply message to the client.
% At this step, each node should generate a signature for the relay message and an MAC for the client, 
% which requires $\epsilon_s + \epsilon_m$ CPU cycles. Therefore, the delay of this step is
% \begin{equation}
%     T_5=\max\left\{\frac{\epsilon_s+\epsilon_m}{\partial ^p(t)},\frac{\epsilon_s+\epsilon_m}{\partial _j^{np}(t)}\right\}, j\in\mathcal{U}_{c}.
% \end{equation}

% In the above consensus process, there is no overlap between the adjacent steps. 
% Therefore, the overall consensus delay $T_c^b(t)$ can be given by
% \begin{equation}
%     T_c^b=T_1+T_2+T_3+T_4+T_5.
% \end{equation}

% Apart from the consensus delay, both the generation delay and propagation delay are essential for creating a block. 
% In detail, the latency in block generation is denoted as $T_{B(t)}^g$, i.e.,
% \begin{equation}
%     T_{B(t)}^g=\frac{S_{B(t)}}{\partial ^g_{B(t)}}, 
% \end{equation}
% and we consider the block and message transmission delay between all UAVs are the same, 
% so the propagation delay $T_p^b$ during the consensus process could be regarded as a constant.
% In summary, the creation latency is  
% \begin{equation}
%     T^b(t)=T^g_{B(t)}+T^p_B+T^c_{B(t)},
% \end{equation}
% which satisfies
% \begin{equation}{\label{blockchaindelay}}
%     T_{B(t)}\leqslant T_{B(t)}^{min}.
% \end{equation}



% Specifically, the blockchain stores the trust values agreed  
% through a consensus algorithm among the selected high-trust UAVs, which are 
% decentralized and tamper-proof.
% The blockchain is a distributed and immutable ledger, 
% which enables distributed nodes to trade with each other
% and maintain a consistent and tamper-proof ledger without
% a centralized controller. As a partially decentralized system, 
% the consortium blockchain is better suited for UAV networks 
% than public blockchain and private blockchain,
% to create the secure and reliable communication environment.
% Generally, UAVs are vulnerable to be attacked, since they are 
% characterized by the complex application environment and high 
% mobility. In addition, any attacked UAVs may perform 
% malicious activities in the network, leading to incorrect information 
% being broadcast and the degradation of system performance. 
% To minimize the damage of malicious UAVs, the blockchain-based trust management 
% mechanism are proposed. Specifically, the abnormal behaviors of UAVs are analyzed 
% in the following and the trust values are calculated via the designed node trust 
% evaluation mechanism. The blockchain stores the trust values agreed  
% through a consensus algorithm among the selected high-trust UAVs, which are 
% decentralized and tamper-proof.
% which includes the basic topology information and the recognized abnormal activities about neighbor UAVs. 
% As known, the blockchain provides data immutability wherein it cannot be tampered with by the malicious nodes.
% To caught and record the exceptions, consensus mechanism 
% Besides, general UAV networks are unable to tackle malicious behaviors efficiently.
% Accordingly, 
% the caught and recorded abnormal behaviors by the blockchain consensus 
% due to its unique consensus mechanism and smart contract technologies. 
% Then, the trust values are recorded in the blockchain after
% the trust evaluation.
% Moreover, no node can repudiate its action as the blockchain
% provides traceability in the trust evaluation process. Therefore,
% the trust value of each UAV is calculated to remove selfish and
% malicious nodes from the network. The trust value of each UAV
% is compared with a predefined threshold and then malicious
% and legitimate nodes are classified considering this threshold,
% motivated by {\cite{tang2022blockchain}}. 
% To detect malicious UAVs in the network, we design a consensus 
% mechanism based on the blockchain technology.
% to alleviate the increased routing delay associated with such insecure environment.


\subsection{Delay Model}
\vspace{0.05cm}
As shown in Fig. {\ref{fig:Network_of_UAV}}, in LAINs, the  E2E  routing delay consists of the total
transmission delay on the multi-hop path from the source UAV to destination UAV.
Since the delay is constrained by data transmission rate $G$, it is essential to 
analyze the channel characteristics of both ground-to-air and air-to-air wireless communication links.
% For the simplicity and clarity, the Definition 1 is first presented.
% Definition 1: $X_{n m}(t)$ denotes the set of variants, detailed as $X\!=\!\{G,L,B,P^{tr},\sigma,\eta \}$. 
% Besides, $X_{n m}(t)\!=\!X_{i u}(t) (i\in \mathcal{I},u\in \mathcal{U})$, 
% $X_{nm}(t)\!=\!X_{u \kappa}(t) (u \! \in \! \mathcal{U}, \kappa \!\in\! \Gamma_{u(t)})$, and
% $X_{n m}(t)\!=\!X_{u b}(t) (u\!\in\! \mathcal{U}, b\!\in\! \mathcal{B})$ indicates the variant from SD $i$ to UAV $u$, 
% UAV $u$ to UAV $\kappa$, and UAV $u$ to BS $b$, respectively. 

Regard to demand $r$, binary variable $\zeta_{n}^{r}(t) \!\in\! \{0,1\}$ clarifies 
the transmission status, i.e.,
\begin{equation}{\label{zeta-demands}}
    \zeta_{n}^{r}(t)\!=\!
    \left\{
        \begin{aligned}
            &1, \!\text{ if }\!  r \! \text { is on node }  n  \in \mathcal{I}\cup \mathcal{U}\text { at time step }\! t,\\
            &0, \!\text{ otherwise}.
        \end{aligned}
    \right.
\end{equation}
Besides,  binary variable $\eta_{n m}^{r}(t) \!\in\! \{0,1\}$ denotes whether demand $r$ 
passes  link $e_{n m}$ ($n  \in \mathcal{I}\cup \mathcal{U},m  \in \mathcal{U}\cup \mathcal{B}$), i.e.,
\begin{equation}{\label{eta-link}}
    \eta_{n m}^{r}(t)\!=\!
    \left\{
        \begin{aligned}
            &1, \!\text{ if }\!  r \! \text { is transmitted via }\! e_{n m}\! \text { at time step }\! t,\\
            &0, \!\text{ otherwise}.
        \end{aligned}
    \right.
\end{equation}
Further, $L_{n m}(t)$ is the path loss between nodes $n \in \mathcal{I} \cup \mathcal{U}$ and $m \in \mathcal{U} \cup \mathcal{B}$
and remains constant within time step $t$, i.e., 
\begin{equation}{\label{PLAG}}
    \begin{aligned}
        &L_{n m}(t)=20\log \left(\frac{4\pi  \lambda   }c d_{n m}(t)\right)\\
        &+\omega\left[{\Pr}_{n m}(t) \left(\eta_{n m}^\mathrm{LoS}(t)-\eta_{nm}^\mathrm{NLoS}(t)\right) +\eta_{n m}^\mathrm{NLoS}(t)\right],
    \end{aligned}
\end{equation} 
where $\eta_{n m}^\mathrm{LoS}(t)$ and $\eta_{nm}^\mathrm{NLoS}(t)$  
represent the additional path losses under LoS and non-LoS (NLoS) propagations, respectively. 
When $\omega=1$, $L_{n m}(t)$ is  the path loss  from $n\in \mathcal{I}$ to $m\in \mathcal{U}$ or $n\in \mathcal{U}$ to $m\in \mathcal{B}$.
While $\omega=0$, $L_{n m}(t)$ indicates the path loss between UAVs. 
$\lambda  $ represents the carrier frequency, and $c$ is the speed of light.
Besides, ${\Pr}_{n m}(t)$ indicates the probability that  there exist line of sight (LoS) links between SDs/BSs and UAVs, i.e.,
\begin{equation}{\label{P}}
    {\Pr}_{n m}(t)\!=\!\frac1{1\!+\!\varrho _1\!\exp\left\{\!-\!\varrho_2 \!\left[ \! \frac{180}{\pi}\!\arctan \! \left( \! \frac{h_{n m}(t)}{xy_{n  m}(t)} \! \right)\!-\!\varrho _1 \! \right] \!\right\}},
\end{equation} 
in which $\varrho_1$ and $\varrho_2$ are the constant parameters {\cite{channel_model_PL}}.


Since LAINs are characterized by high mobility and unstable data traffic fluctuations,
we introduce a queue buffer for each node $n \in \mathcal{I} \cup \mathcal{U}$ to alleviate the network congestion.
In particular, for node $n$, the amount of demands received at time step $t\!-\!1$ is $\varepsilon_{n}^{re}(t\!-\!1)$. 
At time step $t$, the queued demand set, queue length, maximum queue capacity, 
and the number of transmitted demands of node $n$ are denoted as 
$\mathcal{C}_{n}(t)=\{r , \zeta_{n}^{r}(t)\!=\!1, \forall r \!\in\! R\}$, $C_{n}(t)$, $C_{n}^{max}$, and $\varepsilon_{n}^{tr}(t)$, respectively.
In detail,
\begin{align}{\label{re_tr}}
    \left\{\begin{aligned}
    &\varepsilon_{n}^{re}(t\!-\!1)\!=\!\sum_{r\in R} \sum_{{m}  \in \mathcal{I}  \cup \mathcal{U} } \eta^r_{{m}n}(t\!-\!1), 0\!\leq\! \varepsilon_{n}^{re}(t\!-\!1)\!\leq\!C_{n}^{max},\\
    &C_{n}(t)=\sum_{r\in R}\zeta_{n}^{r}(t), 0\leq C_{n}(t)\!\leq \!C_{n}^{max}, C_{n}(t)\!=\!\left\lvert \mathcal{C}_{n}(t)\right\rvert, \\
    &\varepsilon_{n}^{tr}(t)\!=\!\sum_{r\in \mathcal{C}_{n}(t)} \sum_{{m}  \in  \mathcal{U}\cup \mathcal{B}  } \eta^r_{n {m}}(t),\varepsilon_{n}^{tr}(t)\!=\! C_{n}(t).
\end{aligned}\right.
\end{align}
% 无人机采用并行传输的方式传输请求,我们采用自适应带宽分配方案,缩小统一时隙不同数据包传输时延差距。
Here, the UAV leverages the parallel transmission for demands, 
indicating that UAVs forward all demands received from the last time step.
Besides, the adaptive channel bandwidth allocation scheme is designed 
to narrow the transmission delay gap of different demands in one time step.
Hence, at time step $t$, the allocated bandwidth $B^r_n(t)$ is calculated based on the size of demand $r \in \mathcal{C}_{n}(t)$, i.e.,
\begin{equation}{\label{equ:BW}}
    B^r_n(t)\!= \!\frac{\mathcal{L}^{r}}{\sum\limits_{k  \in \mathcal{C}_{n}\!(t)}\!\mathcal{L}^{k}} B_n(t), 
    \forall n \!\in\! \mathcal{I} \! \cup \!\mathcal{U},r \!\in \!\mathcal{C}_{n}(t), t \!\in \!T,
\end{equation}
where $ B_n(t)$ is the total bandwidth of node $n$ at time step $t$.
Based on Shannon theory, at time step $t$, transmission rate $G^r_{n m}\!(t)$ for demand $r$ from nodes $n\!\in\! \mathcal{I} \! \cup \!\mathcal{U}$ 
to $m\!\in\! \mathcal{U} \! \cup \!\mathcal{B}$ is 
\begin{equation}{\label{Channel-Rate}}  
    G_{n m}^r(t)\!=\!B^r_n(t)\log_{2}\!\left(\!1\!+\!
    \frac{P^{tr}_{n m}(t) \cdot 10^\frac{-{L_{n m}(t)}}{10}}{\sigma^{2}_{n m}(t)}\!\right)\!, r \in \mathcal{C}_{n}(t),
\end{equation}
where $P^{tr}_{n m}(t)$ and $\sigma^{2}_{n m}(t)$
indicate the transmission power and noise power between nodes $n$ and $m$, respectively. 
% Besides, due to limited communication resources, 
% the total amount of demands passing $e(n,\! m) \!\in \! \mathcal{E}$ at time step $t$ should satisfy
% \begin{equation}\label{R_L}
%    \sum_{r\in R} \eta_{n(t) m(t)}^{r} \mathcal{L}^{r} \leqslant \tau G_{n(t) m(t)},t \in T, 
% \end{equation}
% in which $\eta_{n(t) m(t)}^{r}$ is a binary variable denoting whether demand $r$ 
% passes the link $e(n, m)$ at time step $t$,
% 
% Therefore, the delay of one-hop between UAVs $i$ and $j$ is as follows.
% Among them, the propagation delay is calculated as 
% $\mathcal{T}^{prop}_{i(t) j(t)}=d_{i(t) j(t)}/c$ at time step $t$, 
% in which $d_{i(t) j(t)}$ and $c$ are the distance between UAVs $i$ and $j$ and 
% the speed of light, respectively. While it is much smaller than the other delay,
% the value of $\mathcal{T}^{prop}_{i(t) j(t)}$ is negligible. 
% Thus, we consider the major delay of routing consists of the transmission delay, 
% processing delay, and queue delay in the UAV network.
% Furthermore, considering that the process of signals and computation
% on the UAV are usually separated, the data transmission and the computation 
% are able to be performed simultaneously. 
% \subsubsection{Processing Delay ($\mathcal{T}^{proc}$)}
% In light of {\cite{JiaHiera}}, let $\iota_{i}$ denote 
% the consumption of computing resources on UAVs to handle $1$ bit data for 
% the received data, i.e., the CPU cycle. Particularly, the process involves 
% checking for bit errors, deciding the next hop UAV, and recognizing the destination UAV.    
% Hence, the delay cost by the UAV $i$ to process data $p_{i(t)}^{m}$ at time step $t$ is 
% \begin{equation}{\label{proc-delay}}
%     \mathcal{T}^{proc, p_{i(t)}^{m}}_{i(t)}=\frac{\mathcal{L}^{m}_{i(t)}}{\mathcal{C}_{i}/\iota_{i}}=\frac{\mathcal{L}^{m}_{i(t)}\iota_{i}}{\mathcal{C}_{i}}, \forall i \in U,
% \end{equation}
% where $\mathcal{C}_{i}$ indicates the computation capacity of UAV $i$.
Then, the transmission delay for demands from nodes $n$ to $m$ is
\begin{equation}{\label{trans-delay1}}
    \begin{aligned}
         \mathcal{T}^{tr,r}_{n  m}(t) = & \max_{r \in R}  \frac{\mathcal{L}^{r}}{G^r_{n  m}(t)} \eta^{r}_{n  m}(t),\\
     &\forall r \in  R, n  \in  \mathcal{I}\cup \mathcal{U}, m  \in  \mathcal{U}\cup\mathcal{B}, t \in  T.
    \end{aligned}
\end{equation}
% 
% \subsubsection{Process Delay ($\mathcal{T}^{proc,r}$)}
% In light of {\cite{JiaHiera}}, let $\iota_{i}$ denote 
% the consumption of computing resources on UAVs to handle $1$ bit data for 
% the received demand, i.e., the CPU cycles. In particularly, the process involves 
% checking for bit errors and deciding the next hop and the destination node.    
% Hence, the delay cost by UAV $i$ to process demand $r$ is 
% \begin{equation}{\label{total-delay}}
%     \mathcal{T}^{proc, r}_{i(t)}=\frac{\mathcal{L}^{r}}{\mathcal{C}_{i}/\iota_{i}} \eta^{r}_{i(t) u(t)}=\frac{\mathcal{L}^{r}\iota_{i}}{\mathcal{C}_{i}}\eta^{r}_{i(t) u(t)}, \forall i \in U,
% \end{equation}
% where $\mathcal{C}_{i}$ indicates the computation capacity of UAV $i$.
% 
% 
% 
% 
% In practice, the value of $\varepsilon_{i(t)}^{out}$ cannot exceed 
% the queue capacity $C_{i(t)}$ at time step $t$, i.e., $\varepsilon_{i(t)}^{out}\leq C_{i(t)}$. 
% In detail, if the queue $C_{i}({t})$ is empty, the change of the queue length only depends on 
% $\varepsilon_{i}^{in}(t)$ due to $0\leq \varepsilon_{i}^{out}\leq C_{i}(t)$, 
% denoting the length can only be increased. 
% Similarly, the change of the queue length only depends on $\varepsilon_{i}^{out}(t)$ when the queue $C_{i}(t)$ is full.
% the values of $C_{i(t)}$, $\varepsilon_{i(t)}^{re}$, and $\varepsilon_{i(t)}^{tr}$ are nonnegative,  and 
% Additionally, $C_{u(t)}$ is calculated by adding $\Delta C_{u(t)}$ to 
% the queue length at time step $t-1$, i.e.,
% \begin{equation}
%     C_{u(t)}=C_{u^{t-1}}+\Delta C_{u(t)}.
% \end{equation}
% Based on the above analysis, 
% when there exists demand $r \in R$ arriving at UAV $u$ with $C_{u(t)}$, 
% the queue delay of $r$ for transmitting to next-hop UAV $j$ is indicated as
% \begin{equation}{\label{queue-delay}}
%     \mathcal{T}^{que,r}_{u(t) j(t)}=\sum\limits_{r\in \mathcal{C}_{u(t)}}\frac{\eta^{r}_{u(t) k(t)} \mathcal{L}^r }{G_{u(t) k(t)}},
%  \end{equation}
% where $\mathcal{C}_{u(t)}=\{r_u^{q},q=1,\cdots,C_{u(t)}\}$ is the queued demand set of UAV $u$ at time step $t$, 
% and $|\mathcal{C}_{u(t)}|=C_{u(t)}$.
% Hence, the sum of one-hop delay for transmitting demand ${r}$ 
% from UAV $u$ to UAV $j$ at time step $t$ is 
% Besides, the value of $\mathcal{T}^{r}_{n(t) m(t)}$ from nodes $n$ to $m$ cannot 
% exceed the maximum tolerated delay $\mathcal{T}_{one}^{max}$ for one-hop, i.e.,
% \begin{equation}{\label{delay_constraint}}
%     \mathcal{T}^{r}_{n(t) m(t)} \leq \mathcal{T}_{one}^{max}.
% \end{equation}
When the routing path $\mathcal{P}^{r}_{ib}$ for transmitting demand $r$ 
from source SD $i$ to destination BS $b$ 
is determined, E2E delay $\mathcal{T}^{r}$ can 
be calculated as 
% Therefore, the E2E delay from source UAV $\mathtt{s} \in \mathcal{U}$  to destination UAV $\mathtt{d}\in \mathcal{U}$ is indicated as 
\begin{equation}
    \mathcal{T}^{r}\!=\!\underset{t\in T}{\sum} \underset{{e_{n m}\in \mathcal{P}_{ib}^r}}{\sum}\mathcal{T}^{tr,r}_{n  m}(t), \forall r\!\in\! R, n \!\in \!\mathcal{I}\cup \mathcal{U}, m\! \in\! \mathcal{U}\cup\mathcal{B}.
\end{equation}
\vspace{0.1cm}
\subsection{Problem Formulation}

% The demand $r$ from source UAV $ \mathtt{s} \in \mathcal{U}_\mathtt{s}$ can 
% only be received by one another UAV 
% $j$, i.e.,
% \begin{equation}\label{F1}
%     \sum_{j(t) \in \mathcal{U}_\mathtt{r} \cup \mathcal{U}_\mathtt{d}}\eta^{r}_{\mathtt{s}(t) j(t)}=1, 
%     \forall r \in R, t \in T.
% \end{equation} 
% Recall that $\eta^{r}_{\mathtt{s}(t) j(t)} \in \{0,1\}$ denotes 
% whether demand $r$ via link $e({\mathtt{s}, j})\in \mathcal{E}$, 
% 1 if passing and 0 otherwise.

% Similar to the source UAVs, 
% the destination UAV $\mathtt{d} \in \mathcal{U}_\mathtt{d}$ 
% can only receive demand $r$ from one another UAV $i$, i.e.,
% \begin{equation}\label{F4}
%     \sum_{i(t) \in \mathcal{U}_\mathtt{s} \cup \mathcal{U}_\mathtt{r}}\eta^{r}_{i(t) \mathtt{d}(t)}=1, 
%     \forall r \in R, t \in T.
% \end{equation} 
% With respect to a middle UAV $j \in \mathcal{U}_{r}$, the flow conservation 
% should be satisfied:
% \begin{align}{\label{F2}}
%     \!\left\{\!\begin{aligned}
%             &\sum_{i(t) \in \mathcal{U}_{\mathtt{s}}\cup \mathcal{U}_\mathtt{r}} 
%             \eta^{r}_{{i(t)} {j(t)}}= 
%             \sum_{i(t) \in \mathcal{U}_\mathtt{r} \cup \mathcal{U}_{\mathtt{d}}}
%             \eta^{r}_{{j(t)} {i(t)}}+
%             \eta^{r}_{{j(t)} {j^{t+1}}},\\
%             &\qquad\qquad\qquad\qquad\quad\forall r \in R,  j\in \mathcal{U}_\mathtt{r}, t=1,\\
%             &\sum_{i(t) \in \mathcal{U}_{\mathtt{s}}\cup \mathcal{U}_\mathtt{r}} 
%             \eta^{r}_{{i(t)} {j(t)}} + \eta^{r}_{{j^{t-1}} {j(t)}}  =  
%             \sum_{i(t) \in \mathcal{U}_\mathtt{r} \cup \mathcal{U}_{\mathtt{d}}}
%             \eta^{r}_{{j(t)} {i(t)}} + 
%             \eta^{r}_{{j(t)} {j^{t+1}}},\\
%             &\qquad\qquad\forall r \in R,  j\in \mathcal{U}_\mathtt{r}, t\in \{2,\cdots,T-1\},\\
%             &\sum_{i(t) \in \mathcal{U}_{\mathtt{s}}\cup \mathcal{U}_\mathtt{r}} 
%             \eta^{r}_{{i(t)} {j(t)}}+\eta^{r}_{{j^{t-1}} {j(t)}}= 
%             \sum_{i(t) \in \mathcal{U}_\mathtt{r} \cup \mathcal{U}_{\mathtt{d}}}
%             \eta^{r}_{{j(t)} {i(t)}},\\
%             &\qquad\qquad\qquad\qquad\quad\forall r \in R,  j\in \mathcal{U}_\mathtt{r}, t=T.
%         \end{aligned}
%             \right.
% \end{align}
% \end{multline}
% Further, when $t=1$, the value of $\eta^{r}_{{j^{t-1}} {j(t)}}$ is $0$ in ({\ref{F3}}).
% and when $t=T$, the value of $\eta^{r}_{{j(t)} {j^{t+1}}}$ is $0$ in ({\ref{F3}}).
% Besides, a demand can select only one routing path, i.e.,
% \begin{align}{\label{F3}}
%     \left\{\begin{aligned}
%         &\sum_{j(t) \in \mathcal{U}_\mathtt{r} \cup \mathcal{U}_{\mathtt{d}}}
%         \eta^{r}_{{i(t)} {j(t)}}+
%         \eta^{r}_{{i(t)} {i^{t+1}}}= 1,\\
%         &\qquad\qquad \forall r \in R,  i\in \mathcal{U}_\mathtt{r}, t\in \{1,\cdots,T-1\},\\
%         &\sum_{j(t) \in \mathcal{U}_\mathtt{r} \cup \mathcal{U}_{\mathtt{d}}}
%         \eta^{r}_{{i(t)} {j(t)}}= 1, \forall  r \in R,  i\in \mathcal{U}_\mathtt{r}, t=T.
%     \end{aligned}
%     \right.
%  \end{align}
% Moreover, when $t=T$, the value of $\eta^{r}_{{i(t)} {i^{t+1}}} $ is $0$ in ({\ref{F4}}).

The objective is to minimize the total E2E delay of LAINs with the mobility of nodes, 
and the corresponding optimization problem is formulated as
% In this article, our objective is to achieve efficient transmission during 
% routing by balancing the distance, energy consumption, and delay. 
% Therefore, we consider jointly optimizing the distance 
% factor $f_1$, energy factor $f_2$ and delay factor $f_3$ of the UAV nodes.
% In detail, the joint optimization function is defined as follows
\begin{equation}{\label{optimal}}
    \begin{aligned}
    \mathscr{P}0:\;&\underset{{\boldsymbol{\eta,\zeta}}}{\textrm{min}}\;
    \mathcal{T}^{r}\\
       \textrm{s.t.}\;
        &\text{(\ref{distance_min}), (\ref{distance_max}), (\ref{zeta-demands}), (\ref{eta-link}), (\ref{re_tr})},\\
        &\sum_{m  \in \mathcal{U} \cup \mathcal{B} }\!\eta^{r}_{n m}(t)\!=\!1, \forall r \!\in\! R, t \!\in\! T,e_{n m}\! \in \mathcal{E},\\
        &\forall  n\in \mathcal{I} \cup\mathcal{U}, m \in \mathcal{U}\cup \mathcal{B}, 
    \end{aligned}
\end{equation}
where $\boldsymbol{\eta}=\{\eta_{n m}^{r}(t),\forall t\in T, e_{n m}\in \mathcal{E}, 
n \in \mathcal{I} \cup \mathcal{U},m \in \mathcal{U}\cup \mathcal{B}, r \in R\}$, 
and $\boldsymbol{\zeta}=\{\zeta_{n}^{r}(t),\forall t\in T, n \in \mathcal{I} \cup \mathcal{U}, r \in R\}$.
% in which $n,m \notin \mathcal{U}_\mathtt{f}$ represents that demand $r\in R$ avoids being transmitted by malicious UAVs in the network. 
Besides, the demand $r$ from node $ n \!\in\! \mathcal{I} \cup \mathcal{U}$ can 
only be received by one another node $m \!\in \!\mathcal{U}\cup \mathcal{B}$.
It is observed that $\mathscr{P}0$ is in the form of ILP and 
NP-hard to deal with {\cite{Lancia2018}}. 
% Therefore, in the next part we propose the feasible solutions. 






% Therefore, in the following section, we design the efficient routing algorithm based on the MADDQN.
% Firstly, the distance factor $f_1$ is expressed as
% \begin{equation}
%     f_{1}=\chi \frac{\sqrt{(x_{j(t)}-x_{d(t)})^2,(y_{j(t)}-y_{d(t)})^2,
%     (z_{j(t)}-z_{d(t)})^2}}{\sqrt{(x_{i(t)}-x_{d(t)})^2,(y_{i(t)}-y_{d(t)})^2,
%     (z_{i(t)}-z_{d(t)})^2}}\eta_{i(t)j(t)}^{p_{i(t)}^{m}}
% \end{equation}
% where $\chi\in \{1,-1\}$, and $\chi$ is negative when the next hop UAV $j(t)$ is 
% further away from the destination than UAV $i(t)$ and vice versa. 
% Secondly, the energy factor $f_2$ of UAV $j(t)$ is defined as 
% the ratio of the residual energy $E_{j(t)}^{res}$ of the UAV 
% to the initial energy $E_{j(t)}^{init}$, i.e.,
% \begin{equation}
%     f_{2}= \frac{E_{j(t)}^{res}}{E_{j(t)}^{init}}\eta_{i(t)j(t)}^{p_{i(t)}^{m}},
% \end{equation}
% in which a larger $f_3$ indicates the lower energy consumption of UAV ${j(t)}$.
% Thirdly, $f_3$ represents the delay factor. Then, we introduce ${T}_{base}$ 
% as a base to standardize and normalize the value of ${T}_{i(t) j(t)}$. 
% The delay between UAV ${i(t)}$ and UAV ${j(t)}$ can be expressed as follows
% \begin{equation}
%     f_3=\frac{{T}_{base}-{T}_{i(t) j(t)}}{{T}_{base}}\eta_{i(t)j(t)}^{p_{i(t)}^{m}}.
% \end{equation}

\vspace{0.5cm}
\section{Problem Formulation and Algorithm Design}{\label{Sec:GATDRL}}
\vspace{0.1cm}
\subsection{Dec-POMDP based Reformulation}
\vspace{0.1cm}
Since each UAV has a local observation rather than global observation, 
$\mathscr{P}0$ is reformulated as a Dec-POMDP, to cater for the dynamically changing network environment. 
Each UAV in LAINs is regarded as an independent agent and makes its own routing decision 
that sends a demand to an alternative next UAV. Hence, the set of all agents is equal to UAV set $ \mathcal{U}$.
At each time step $t$, agent $u\in \mathcal{U}$ observes local state $o_{u}(t)$ of the environment 
and executes action $a_{u}(t)$ according to the observable state. 
Then, agent $u$ receives an immediate reward $\mathcal{R}_{u}(t+1)$, 
and the environment is transfered to next observation state $o_{u}({t+1})$.
The tuple $\left\langle o_{u}(t),a_{u}(t),\mathcal{R}_{u}(t),o_{u}({t+1}),f_{u}(t)\right\rangle$ 
indicates the transition experience of agent $u$ and is explained in detail.
\begin{itemize}
    % The goal of each drone agent is to efficiently route carried data packets (with different destination nodes)  to their destinations through collaboration.
    \item State space $\mathcal{S}$: At time step $t$, the observable state $o_{u}(t)$ of agent $u$
    includes the available information of the current UAV and neighboring UAVs, detailed as
    \begin{equation}
        \begin{aligned}
        o_{u}(t)\!=\!\{\Theta_{u}(t), \mathcal{C}_{u}(t), \Theta_{\kappa}(t),\mathcal{C}_{\kappa}(t)\}, 
        \kappa\!\in\!\Gamma_{u}(t).
        \end{aligned}
    \end{equation}
   Wherein, $\Theta_{u}(t)$ and $\Theta_{k}(t)$ indicate the locations of UAV $u$ and neighbor UAV $\kappa$, respectively. 
   $\mathcal{C}_{u}(t)$ and $\mathcal{C}_{\kappa}(t)$ are the set of queued demands on UAVs $u$ and $\kappa$, respectively.
    The queued demand set includes the information tuple $\varUpsilon^r$ of each demand $r$.
   The observations of all agents are aggregated into joint state $\bm{s}(t)$ in time step $t$, 
   denoted as $\bm{s}(t)=\{o_{u}(t), u\in \mathcal{U}\}$,
   and the state space is indicated as $\mathcal{S} = \{\bm{s}(t)| t\in T\}$.
% It is noted that the queue length of UAVs is empty at the beginning of each time step, 应该加上的，因为有优化空间，根据时延先后顺序
    \item Action sapce $\mathcal{A}$: Agent $u$ makes decisions for each carried demand independently, 
    and the set $a_{u}(t)= \{a_{u}^r(t), r \!\in \!\mathcal{C}_{u}(t)\}$ represents the actions 
    for demand $r \!\in \!\mathcal{C}_{u}(t)$ at time step $t$.
    Wherein, each sub-action $a_{u}^r(t)$ denotes the next-hop neighboring node 
    selected by UAV $u$ to relay demand $r$, i.e.,
    \begin{equation}
        \begin{cases}
            a_{u}^r(t) \in \{\Gamma_{u}(t)\},u \in \mathcal{U}_\mathtt{s} \cup \mathcal{U}_\mathtt{r},\\
            a_{u}^r(t) \in \{ \Gamma_{u}(t), Z _u(t)\},  u \in \mathcal{U}_\mathtt{d},
        \end{cases}    
    \end{equation}
    where $Z _u(t)$ is the set of BSs connected with UAV $u \in \mathcal{U}_\mathtt{d}$ at time step $t$. 
    If the destination BS $b$ of demand $r \!\in\! \mathcal{C}_u(t)$ connects to UAV $u \!\in\!\mathcal{U}_\mathtt{d}$, 
    the demand is directly transmitted to destination $b$ by UAV $u$.
    On the contrary, the demand is relayed by neighboring UAVs.
    The actions of all agents are aggregated as $\bm{a}(t)=\{a_{u}(t), u\in \mathcal{U}\}$ in time step $t$,
    and the action space is $\mathcal{A} = \{\bm{a}(t)| t\in T\}$.
    \item Reward $\mathcal{R}$:  $\mathcal{R}_u(t)\!=\!\{\mathcal{R}_{u}^r(t)|r \!\in\! \mathcal{C}_{u}(t)\}$, 
    where $\mathcal{R}_{u}^r(t)$ is the reward that agent $u$ obtains after transmitting demand $r$ to neighboring node 
$\kappa$ at time step $t$, i.e.,
% \begin{equation}
%     \mathcal{R}_{u}(t)=\{\mathcal{R}_{u}^r(t), \forall r \in R \},
% \end{equation}
% and 
\begin{equation}{\label{equ:reward}}
    \mathcal{R}^{r}_{u}(t)=\frac{1}{\mathcal{T}^{tr,r}_{u\kappa}(t)} \eta_{u \kappa}^r(t), \forall r \in \mathcal{C}_u(t), \kappa \in \Gamma_{u}(t).
\end{equation}
    \item Transition flag $\bm{f}$: $\bm{f}(t)\!=\!\{f^r(t)| r \!\in\! \mathcal{C}_{u}(t) \}$, where $f^r(t)$ indicates whether demand $r$ arrives at destination BS $b \!\in\! \mathcal{B}$, defined as
    \begin{equation}
        f^r{(t)}\!=\!
        \begin{cases}
        \!1,  \text{if }a_u^r{(t)} \text{ is the destination BS }b, \\
        \!0,  \text{otherwise.} 
        \end{cases}
    \end{equation}
    \item Discount factor $\bm{\gamma}$: $\bm{\gamma}=\{\gamma_u| u\!\in\! \mathcal{U}\}$, 
    in which $\gamma_u$ is designed to calculate the cumulative reward. 
    A larger $\gamma$ indicates decisions focusing on the long-term reward.
\end{itemize}

% The agents interact with the network environment to learn a reward-maximum policy. In this paper, 
% cooperation among the agents is achieved either via the communication between neighboring nodes. 
% In the next section, we will first introduce the framework of the RL algorithm.
The policy $\pi_{u}^r(t)$ leads agent $u$ to select action $a_{u}^r(t)$ for demand $r$
under observation $o_{u}(t)$ at time step $t$.
$\bm \pi_u(t)=\{\pi_{u}^r(t), \forall r \!\in\! \mathcal{C}_u(t)\}$ indicates the joint policy of all demands on agent $u$. 
$\bm \Pi(t)=\{\bm\pi_{u}(t), \forall u \in \mathcal{U}\}$ indicates the policy of all agents. 
According to the Dec-POMDP and specific policy $\bm \Pi(t)$, 
we can obtain the routing path for all demands. 
Therefore, $\mathscr{P}0$ is transformed to find the optimal 
policy $\bm \Pi^{\star}(t)=\{\bm\pi_{u}^{\star}(t), \forall u\!\in\! \mathcal{U}\}$, 
and then the improved MADRL-based routing method is designed to 
obtain $\bm \Pi^{\star} =\{\bm \Pi^{\star} (t)| t \in T\}$  for minimizing the total E2E delay.
% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=0.88\linewidth]{algorithm4.pdf}
%     \textcolor{black}{\caption{\label{fig:consensus_update} BTMM-MADDQN algorithm 
%     framework for trusted routing in the UAV network.}}
%     \vspace{-0.2cm}
% \end{figure*}

% GATDRL enables the local observations of the routers to be transformed to some more 
% abstract and relational representations, and therefore facilitates the routing decision making.
% the parameter updates are exchanged only between neighboring agents without the orchestration 
% of a central controller.
% \subsection{DRL}
% The MADDQN is a Q-learning-based algorithm, which mainly 
% constructs and maintains a Q-table containing the values of all state-action pairs. 
% Formally, the Q-value function is defined as the expected 
% total reward for taking action $a_{u}(t)$ in observation $o_{u}(t)$ for agent $u$ at time step $t$, i.e.,
% \begin{equation}
%     Q(o_{u}(t),a_{u}(t))\!= \!\mathbb{E}\!\left[\!\sum_{k=0}^{\infty} \gamma_u^k \mathcal{R}_{u}({t\!+\!k\!+\!1}) \! \mid \! o_{u}(t)\!=\!o, a_{u}(t)\!=\!a \!\right]\!,
% \end{equation}
% where $\mathbb{E}[\cdot]$ denotes the expected value.  
% % $\mathcal{R}_{i^{t+k+1}}$ is the immediate reward received at time step $t+k+1$.
% Through the Q-table, agent $u$ can obtain optimal policy ${\bm{\pi}^{\star}_u}$  
% in the process of continuous interactions with the environment.
% In time step $t$, the policy $\bm{\pi}^{\star}_{u}$ is
% \begin{equation}
%     \bm{\pi}^{\star}_{u}=\{\textrm{arg } \underset{{\pi_{u}}}{\textrm{max}}\;Q^{\star}(o_{u}(t),a^r_{u}(t)), \forall r \in \mathcal{C}_{u}(t) \}.
% \end{equation}
% Further, the following formula iteratively
% updates the Q-value function $Q(o_{u}(t), a_{u}(t)) $ via the Bellman equation, i.e.,
% \begin{multline}
%         Q(o_{u}(t), a_{u}(t)) \leftarrow (1-\alpha_{u})  Q(o_{u}(t), a_{u}(t))  + \\
%         \alpha_u \left[ \mathcal{R}_{u}({t+1}) +  \gamma_u \max_{a^{\prime}_{u}(t)} Q(o_{u}({t+1}), a^{\prime}_{u}(t))\right], 
% \end{multline}
% where $\alpha_u$ is the learning rate that controls the 
% size of update steps. $Q(o_{u}({t+1}), a^{\prime}_{u}(t))$ 
% is the Q-value function of agent $i$ for taking action $a^{\prime}_{u}(t)$ 
% under the next observation $o_{u}({t+1})$, 
% which is transformed by performing action $a_{i(t)}$ in current observation $o_{u}(t)$
% with reward $\mathcal{R}_{u}({t+1})$ in time step $t$. 
% The term $y=\mathcal{R}_{u}({t+1}) + \gamma_u \max_{a^{\prime}_{u}(t)} Q(o_{u}({t+1}), a^{\prime}_{u}(t))$ 
% represents the Q-target.
\subsection{SHERB-MADDQN-based Routing Algorithm}
% In the multiple sources and multiple destinations dynamic scenario, 
% to improve the learning efficiency of routing strategies, the adaptive SHERB-MADDQN-based routing algorithm is designed.  
In dynamic scenarios with multiple sources and destinations,
to improve the learning efficiency of routing strategies, the adaptive SHERB-MADDQN-based routing algorithm is designed.  
In detail, the experience buffer of each agent is softly constructed 
by embedding the state information of the destination BS in the reward.
% To effectively deal with the complex issue of multiple destination routing in UAV networks,
Thus, the reward in ({\ref{equ:reward}}) is reformulated as 
\begin{equation}
    \begin{aligned}
    \mathcal{R}_{u}^r(t)=\frac{1}{\mathcal{T}^{tr,t}_{u\kappa}(t)+\varsigma} \cdot& \frac{d_{u\kappa}(t)}{d_{u\kappa}(t)+d_{\kappa b}(t)} \eta_{u \kappa}^r(t),\\
    &r \in  \mathcal{C}_{u}(t), \kappa \in \Gamma_{u}(t), t\in T,
    \end{aligned}
\end{equation}
where $d_{u\kappa}(t)$ and $d_{\kappa b}(t)$ denote distances
from UAV $u$ to neighboring UAV $\kappa$, and from UAV $\kappa$ to destination BS $b$, respectively.
$\varsigma$ is a hyperparameter to balance the benefits from the delay and  distance.
It is noted that $d_{u\kappa}(t)$ is positively related to the reward, 
since a larger value of $d_{u\kappa}(t)$ indicates a fewer hop counts required, 
saving time in queuing for transmission.
Meanwhile, ${d_{u\kappa}(t)+d_{\kappa b}(t)}$ represents the total transmission distance 
from the selected next hop $\kappa$ to UAV $u$ and BS $b$.
If $d_{u\kappa}(t)+d_{\kappa b}(t)$ is closer to the straight shortest distance between UAV $u$ and BS $b$, 
agent $u$ may obtain the greater value of rewards, and vice versa.
% It enables the classification learning of demands with different destinations, 
Moreover, compared with the hard-HERB (HHERB)-based method that constructs 
a hierarchical data structure to store the experience, 
the SHERB can mitigate the problem of sparse experience samples, 
improving the sample utilization efficiency and generalization ability of strategies.
% In the paper, ERB each agent $u$ maintains a 
% $\mathcal{D}_u=\{( o_{u}(t), a_{u}^r(t), \mathcal{R}_{u}^r({t+1}), o_{u}({t+1}))\vert r\in \mathcal{C}_u(t)\}$.

Furthermore, when the dimensions of state and action spaces are large, it is tricky to maintain the Q-table in Q-learning. 
Besides, the deep Q-network (DQN)-based algorithm may cause a large deviation  
caused by overestimating the Q-target value. 
Hence, by combining double Q-learning with DQNs, DDQN algorithms are proposed to approximate 
Q-value functions via deep neural networks (DNNs) and decouple the action selection 
and calculation of Q-target values {\cite{van2016deep}}. 
% It is theoretically proved the DDQN-based method can avoid the overestimation .
% Besides, agent $u$ equip each $\mathcal{D}_u$ with an independent DDQN network,
% which allows each network to focus on the value function fitting for specific demands, 
% avoiding policy interference. 
% The network takes the observation of the agent $u$ and the destination node $b$ of the demand as inputs, 
% and outputs the Q-value of the action corresponding to this destination node.
Further, for the DDQN, there exist two DNNs, i.e., 
the online network with parameter $\theta_{u}$ 
and the target network with parameter $\theta^{-}_{u}$ of each agent $u$.
Through constantly updating the weight $\theta_{u}$ of online networks,
loss function $L(\theta_{u})$ is trained and then minimized. 
The experience replay buffer (ERB) of agent $u$ is designed to store the historical experience and denoted as 
$\mathcal{D}_u\!=\!\{(o_{u}(t), a_{u}^r(t), \mathcal{R}_{u}^r({t+1}), o_{u}({t+1}))\vert r \!\in\! \mathcal{C}_u(t)\}$.
By randomly sampling $D$ transition tuples from $\mathcal{D}_u$,
$L(\theta_{u})$ is typically computed as the mean squared error between Q-value function
$Q(o_{u}(t), a_{u}(t);  \theta_{u})$ and Q-target $y_{u}(t)$, i.e.,
\begin{algorithm}[t!]
    \caption{{\label{algorithm-MADDQN}}SHERB-MADDQN-based routing algorithm}
    \begin{algorithmic}[1]
    \REQUIRE {$\mathcal{I}$, $\mathcal{U}$, $\mathcal{B}$, $\mathcal{E}$, $R$, ${\bm{\alpha}}$, and ${\bm{\gamma}}$ }.
    \ENSURE Optimal policy ${\bm{\Pi^{*}}}$.
    \STATE\textbf{Initialization:}\label{initialize} Initialize the network environment, hyper-parameters, 
    ERB set $\bm {\mathcal{D}}$, and the online 
    and target network parameters $ \theta_u $  and $ \theta_u^{-} $ for each agent $u \in \mathcal{U}$, respectively.
    \FOR{each episode} {\label{episode}}
    \FOR{$t = 1, \dots, T$}
    \FOR{$u = 1,\dots, U$} % 遍历每个无人机智能体
    \STATE {\label{episode-initi}} The observation of agent $u$ is set as $o_{u}(t)$.
    \STATE {\label{Allocate-BW}} Allocate the bandwidth based on queued demands in $\mathcal{C}_u(t)$ via (\ref{equ:BW}). 
    \FOR{$r = 1, \dots, |\mathcal{C}_u(t)|$}{\label{FOR-demands}} % 遍历无人机$j$携带的每个数据包
        \STATE Select action $a_{u}^r(t)$ for demand $r$ under observation $o_{u}(t)$ 
        using an $\epsilon$-greedy policy.
        \STATE Execute $a_{u}^r(t)$, and obtain reward $\mathcal{R}_{u}^r(t\!+\!1)$.
    \ENDFOR{\label{ENDFOR-demands}}
   
     \IF{$|\mathcal{D}_u| > D$} {\label{sample}}
        \STATE Randomly select $D$ samples from $\mathcal{D}_u$.
        \STATE {\label{target}} Compute Q-target value $y_{u}(t)$ via (\ref{Q-target}).
        \STATE {\label{update-theta}} Update $\theta_u$ via the gradient descent in (\ref{theta-update}). 
        \STATE {\label{update-theta-}} Periodically update target network parameter $\theta_u^{-}$ via (\ref{target-undate}) every $\mathcal{W}$ steps.
    \ENDIF 
    \ENDFOR
    \STATE {\label{update-environment}} Update the environment, 
    and set observation $o_{u}(t)\leftarrow o_{u}({t + 1})$ for all agents in $\mathcal{U}$.
    \STATE {\label{Store-E}}Store transition $( o_{u}(t), a_{u}^r(t), \mathcal{R}_{u}^r(t\!+\!1), o_{u }({t\! + \!1}))$.
     of each demand $r$ into corresponding $\mathcal{D}_u$.
    % \STATE {\label{update-observation}} .
    \ENDFOR
    \ENDFOR
    \end{algorithmic}
\end{algorithm}
\begin{equation}{\label{loss}}
    L(\theta_{u}) = \mathbb{E}_{\xi \thicksim \mathcal{D}_{u}} \left[ \left( y_{u}(t)  
    - Q(o_{u}(t), a_{u}(t);  \theta_{u}) \right)^2 \right],
\end{equation}  
where tuple $\xi$ is a transition data of $\mathcal{D}_{u}$, and $y_{u}(t)$ is
\begin{equation}{\label{Q-target}}
    \begin{aligned}
         &y_{u}(t)  =  \mathcal{R}_{u}({t+1}) +  \\
          &\gamma_u Q(o_{u}({t+1}), \arg\max_{a^{\prime}_{u}(t)} Q(o_{u}({t+1}), a^{\prime}_{u}(t);  \theta_{u}^b)|\theta^{-}_{u}).
    \end{aligned}
\end{equation}
Besides, the gradient of $L(\theta_{u})$ is denoted as $\nabla_{\theta_{u}}L(\theta_{u})$,   
which is used to  update $\theta_{u}$ via the gradient descent, i.e.,
\begin{equation}{\label{theta-update}}
    \theta_{u} \leftarrow \theta_{u} - \alpha_{u} \nabla_{\theta_{u}} L(\theta_{u}).
\end{equation}
Wherein, $\alpha_{u}$ is the learning rate that controls the size of update steps.
In every $\mathcal{W}$ steps, parameter $\theta^{-}_{u}$ is periodically updated 
to match the parameter of online network $\theta_{u}$ for stabilizing training 
and improving the convergence, i.e.,
\begin{equation}{\label{target-undate}}
    % \theta_{i}^{-}\leftarrow \ell\cdot \theta_{i}+ (1-\ell)\cdot \theta_{i}^{-}.
    \theta_{u}^{-}\leftarrow \tau \theta_{u} +(1-\tau)\theta_{u}^{-},
\end{equation}
where $\tau$ is the soft update coefficient.

% In the paper, each agent $u$ maintains a ERB ${\mathcal{D}}_u$, where
% each sub-buffer $\mathcal{D}_u^b$ noly stores the experience of the destination BS $b$, 
% $\mathcal{D}_u^b=\{( o_{u}(t), a_{u}^r(t), \mathcal{R}_{u}^r({t+1}), o_{u}({t+1}))\vert r\in \mathcal{C}_u(t), b =\mathtt{d}^r \}$.
% Besides, agent $u$ equip each $\mathcal{D}_u^b$ with an independent DDQN network,
% which allows each network to focus on the value function fitting for specific demands, 
% avoiding policy interference. 
% The network takes the observation of the agent $u$ and the destination node $b$ of the demand as inputs, 
% and outputs the Q-value of the action corresponding to this destination node.
% Further, for the DDQN network of BS $b$, there exist two DNNs, i.e., 
% the online network with parameter $\theta_{u}^b$ 
% and the target network with parameter $\theta^{b,-}_{u}$ of each agent $u$.
% By constantly updating the weight $\theta_{u}^b$ of online networks,
% the loss function $L(\theta_{u}^b)$ of agent $u$ is minimized  
% and typically computed as the mean squared error between Q-value function
% $Q(o_{u}(t), a_{u}(t);  \theta_{i}^b)$ and Q-target $y_{u}^{b}(t)$ 
% via randomly sampling $B$ historical experience transitions from $\mathcal{B}_{u}^b$, i.e.,
% \begin{equation}{\label{loss}}
%     L(\theta_{u}^b) = \mathbb{E}_{\xi \thicksim \mathcal{B}_{u}^b  } \left[ \left( y_{u}^{b}(t)  
%     - Q(o_{u}(t), a_{u}^b(t);  \theta_{u}^b) \right)^2 \right],
% \end{equation}  
% and $y_{u}^{b}(t)$ is
% \begin{equation}{\label{Q-target}}
%     \begin{aligned}
%          &y_{u}^{b}(t)  =  \mathcal{R}_{u}^b({t+1}) +  \\
%           &\gamma Q(o_{u}({t+1}), \arg\max_{a^{\prime}_{u}(t)} Q(o_{u}({t+1}), a^{\prime}_{u}(t);  \theta_{u}^b)|\theta^{b,-}_{u}).
%     \end{aligned}
% \end{equation}
% where tuple $\xi   \! = \!(o_{u}(t), a_{u}(t), \mathcal{R}_{u}({t+1}), o_{u}({t+1}))$ is a 
% transition data stored in replay pool $\mathcal{B}_{u}^b$, 
% which is designed to store the historical experience of agent $u$ of destination BS $b$.

% Besides, the gradient of loss functions is denoted 
% as $\nabla_{\theta_{u}}L(\theta_{u})$,   
% which is leveraged to  update $\theta_{u}$ 
% via the gradient descent, i.e.,
% \begin{equation}{\label{theta-update}}
%     \theta_{u}^b \leftarrow \theta_{u}^b - \alpha_{u} \nabla_{\theta_{u}^b} L(\theta_{u}^b).
% \end{equation}
% Every $\mathcal{W}$ steps, parameter $\theta^{b,-}_{u}$ is periodically updated 
% to match the parameter of online network $\theta_{u}^b$ for stabilizing training 
% and improving the convergence, i.e.,
% \begin{equation}{\label{target-undate}}
%     % \theta_{i}^{-}\leftarrow \ell\cdot \theta_{i}+ (1-\ell)\cdot \theta_{i}^{-}.
%     \theta_{u}^{b,-}\leftarrow \tau \theta_{u}^b +(1-\tau)\theta_{u}^b.
% \end{equation}
% \begin{algorithm}[t!]
%     \caption{{\label{algorithm-MADDQN}}MADDQN-based routing algorithm}
%     \begin{algorithmic}[1]
%     \REQUIRE {$\mathcal{U}$, $R$, ${\bm{\alpha}}$, ${\bm{\gamma}}$, and $\mathcal{E}$}.
%     \ENSURE Optimal policy ${\bm{\pi^{*}}}$.
%     \STATE\textbf{Initialization:} {\label{initialize}}Initialize the UAV network environment, 
%     hyper-parameters, and experience replay pool set $\bm {\mathcal{B}}$.
%     \FOR{each episode} {\label{episode}}
%     \FOR{$t=1, \dots, T$}
%     \FOR{$i=1,\dots, N$}
%     \STATE {\label{episode-initi}}The observation of agent $i$ is set as $o_{i(t)}$.
%     \STATE {\label{o_a}}Agent $i$ selects an action $a_{i(t)}$ under observation $o_{i(t)}$ using an $\epsilon$-greedy policy.
%     \STATE {\label{a_o}}Execute $a_{i(t)}$, and obtain reward $\mathcal{R}_{i^{t+1}}$ and next observation $o_{i^{t+1}}$.
%     \STATE {\label{store}}Store the transition $( o_{i(t)}, a_{i(t)}, \mathcal{R}_{i^{t+1}}, o_{i^{t+1}})$ 
%     in the experience replay pool ${\mathcal{B}_i}$.
%     \STATE {\label{update-s}} Set $ o_{i(t)}\leftarrow o_{i^{t+1}}$.
%     \IF{$|\mathcal{B}_{i}|>B$} {\label{sample}}
%     \STATE Randomly select $B$ samples from the experience replay pool $\mathcal{B}_{i}$.
%     \ENDIF
%     \STATE {\label{target}} Compute the Q-target value $y_{i(t)}^{\text{\tiny{DDQN}}}$ for 
%     each agent $i$ via ({\ref{DDQN-Q-target}}).
%     \STATE {\label{update-theta}} Perform the gradient descent to update $\theta_{i}$ by ({\ref{theta-update}}). 
%     \STATE {\label{update-theta-}} Periodically update the target network parameter $\theta^{-}_{i}$ via ({\ref{target-undate}}) every $\mathcal{W}$ steps.
%     \ENDFOR
%     \ENDFOR
%     \ENDFOR
%     \end{algorithmic}
% \end{algorithm}

The detail of the proposed SHERB-MADDQN-based routing method is shown in Algorithm {\ref{algorithm-MADDQN}}.
Firstly, the algorithm initializes the network environment,
hyper-parameters, ERB set $\bm{\mathcal{D}}$, and the parameters of DNNs, respectively ({line \ref{initialize}}).
At the beginning of each episode, the observation of agent $u$ is initialized as $o_{u}(t)$ (lines {\ref{episode}}-{\ref{episode-initi}}).
Then, according to (\ref{equ:BW}), the bandwidth of agent $u$ is allocated according to queued demands in $\mathcal{C}_u(t)$ (line \ref{Allocate-BW}).
Based on $o_{u}(t)$, each agent $u$ selects sub-action $a_{u}^r(t)$ for demand $r$ via an $\epsilon$-greedy policy, 
and then executes $a_{u}^r(t)$ to obtain reward $\mathcal{R}_{u}^r({t+1})$ (lines {\ref{FOR-demands}}-{\ref{ENDFOR-demands}}). 
If the number of transition tuples in $\mathcal{D}_{u}$ is larger than mini-batch $D$, $D$ samples are randomly selected to calculate 
Q-target value $y_{u}(t)$ via (\ref{Q-target}) (lines {\ref{sample}}-{\ref{target}}). 
Additionally, the DNN performs a gradient descent step to update $\theta_{u}$ (line {\ref{update-theta}}).
The target network parameter $\theta_{u}^{-}$ is periodically updated according to ({\ref{target-undate}}) 
every $\mathcal{W}$ steps (line {\ref{update-theta-}}).
At time step $t$, when all agents finish the actions of all demands, the environment is updated.
Further, each agent $u \!\in \! \mathcal{U}$ obtains next observation $o_{u}({t \!+ \!1})$ to update observation $o_{u}(t)$ (line \ref{update-environment}).
Besides, the transition $( o_{u}(t), a_{u}^r(t), \mathcal{R}_{u}^r(t\!+\!1), o_{u }({t\! + \!1}))$ 
of each demand $r$ is stored into corresponding $\mathcal{D}_u$ for training (line \ref{Store-E}).
% Set $o_{u}(t)\leftarrow o_{u}({t + 1})$ for all agents in $\mathcal{U}$. 
% Besides, the observation $o_{u}(t)$ of agent $u$ is correspondingly updated by $o_{u }({t+1})$ (line \ref{update-observation}).



\section{Simulation Results\label{sec:Simulation Results}}
In this section,  a couple of simulations are conducted via Python. 
% The specific parameters are listed in Table {\ref{table1}} {\cite{channel_model_PL}}. 
Specifically, nodes of LAINs are distributed in the area within a 15km $\times$ 5km range, 
the altitude range of UAVs is within [0.2, 0.4]km. 
UAVs are initialized by the ground control center at the beginning of  missions.
Besides, the size of demands from SDs is randomly set within [400, 600]kbits.
Other parameters are set as: $d_{min}\!=\!$ 10m,  $d_{u,max}\!=\!$ 100m, 
$\sigma_{ij}^{2}\!=\!-$110dBm, $\lambda\!=\!$ 2.4Ghz, $c\!=\!3 \times 10^{8}$m/s, $P^{tr}\!=\!$ 40dBm, 
$C^{max}_{i}\!=\!$ 50, $B_{u}\!=$ 2MHz,
$\varrho_1\!=\!$ 5.0188, $\varrho_2\!=\!$ 0.3511, 
$\eta_{n m}^\mathrm{LoS}\!=\!$ 0.1dB, and
$\eta_{n m}^\mathrm{LoS}\!=\!$ 21dB {\cite{JiaHiera,}}. 


% Fig.{\ref{fig:Delay}}

% Fig.{\ref{fig:Step}}

\begin{figure}[t]
    \vspace{-0.3cm}
    \centering
    \includegraphics[width=0.7\linewidth]{Rewards.pdf}
 
        \caption{\label{fig:Rewards}Comparisons of the four algorithms in terms of the accumulative reward during the training process. 
       \vspace{-0.3cm}
    } 
    
\end{figure}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{Loss.pdf}
    \caption{\label{fig:Loss}Comparisons of the four algorithms in terms of the convergence performance during the training process. 
    } 
    \vspace{-0.3cm}
\end{figure}

\begin{figure}[t]
    \centering
            \vspace{-0.3cm}
    \includegraphics[width=0.7\linewidth]{Delay.pdf}
    \caption{\label{fig:Delay}Comparisons of the four algorithms in terms of average E2E delay. 
    } 
        \vspace{-0.3cm}
\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{Step.pdf}
    \caption{\label{fig:Step}Comparisons of the four algorithms in terms of  average hop counts. 
    } 
        \vspace{-0.3cm}
\end{figure}




% \begin{figure*}[t]
%     \vspace{-0.2cm}
%     \centering
%     % 设置子图说明居中
%     % \captionsetup[subfloat]{justification=centering,singlelinecheck=false}
%     % % 设置大图说明左对齐
%     % \captionsetup[figure]{justification=raggedright,singlelinecheck=false}
%     \subfloat[\textcolor{black}{ }]{\centering
%     \includegraphics[width=0.33\linewidth]{Loss.pdf}}
%     % \hspace{0.01\linewidth}
%     \subfloat[\textcolor{black}{}]{\centering
%     \includegraphics[width=0.33\linewidth]{Delay.pdf}}
%     \subfloat[\textcolor{black}{}]{\centering
%     \includegraphics[width=0.33\linewidth]{Step.pdf}}
%     \caption{Comparisons of the four algorithms with different metrics. 
%     (a) Convergence performances of the average loss value. 
%     (b) Average E2E delay with different demand numbers.
%     (c) Average hop counts with different demand numbers.}
%     \label{fig:lr-number-demand}
%     \vspace{-0.4cm}
% \end{figure*}



To demonstrate the performance of Algorithm 1, different metrics are evaluated 
by comparing with SHERB-MADQN, HHERB-MADDQN, and HHERB-MADQN algorithms in Figs. {\ref{fig:Rewards}}-{\ref{fig:Step}}.
Specifically, in Fig. {\ref{fig:Rewards}}, the accumulative rewards are provided to evaluate the convergence performance.
It can be observed that all four algorithms converge with different performances.
In the first 2,000 episodes, rewards are not satisfactory. 
As the number of episodes increases, rewards increase and converge at the specific values.
Besides, the rewards of SHERB-MADRL-based methods are larger compared to the rewards of HHERB-MADRL-based algorithms, 
due to the higher learning efficiency of the proposed SHERB.
Meanwhile, the convergence value of the proposed SHERB-MADDQN algorithm is larger than the SHERB-MADQN algorithm. 
Hence, according to the designed (\ref{equ:reward}) where rewards are negative, the proposed algorithm may have less delay for routing. 
% In Fig. {\ref{fig:lr-number-demand}}, the SHERB-MADDQN is compared with 
% other three algorithms with regard to the convergence performance of training losses, average E2E delay, and rouitng hops. 
% Specifically, in Fig. {\ref{fig:lr-number-demand}}(a), the loss functions of all four algorithms converge.
% For the proposed SHERB-MADDQN, the convergence speed is faster and the curve fluctuation of loss functions has a narrower range.
% Moreover, the loss value of the proposed method is smaller compared to other algorithms when the curve converges, 
% indicating a more stable and effective training process.
% The E2E delay for transmitting demands is evaluated in Fig. {\ref{fig:lr-number-demand}}(b).
% It is observed that as the demands grow, the E2E delay of the data transmission 
% increases of all algorithms, due to the limited resources of the bandwidth. 
% Nevertheless, the delay of the SHERB-MADDQN algorithm decreases by 24.09\%, 20.49\%, and 22.56\% 
% than the delay of SHERB-MADQN, HHERB-MADDQN, and HHERB-MADQN algorithms, respectively.
% Fig. {\ref{fig:lr-number-demand}}(c) shows the performance of hop counts and the demand numbers. 
% Specifically, with the increasing demands, the average hop counts of all algorithms grow, 
% due to the increased congestion of networks.
% Nevertheless, the SHERB-based algorithm requires fewer hop counts for transmitting demands, 
% benefiting from the better algorithm performance.
% In short, simulation results demonstrate that the proposed algorithm performs better during routing.
In Fig. {\ref{fig:Loss}}, the loss functions of all four algorithms converge.
For the proposed SHERB-MADDQN, the convergence speed is faster and the curve fluctuation of loss functions has a narrower range.
Moreover, the loss value of the proposed method is smaller compared to other algorithms when the curve converges, 
indicating a more stable and effective training process.

The E2E delay for transmitting demands is evaluated in Fig. {\ref{fig:Delay}}.
It is observed that as demands grow, the E2E delay of the data transmission 
increases  for all algorithms, due to the limited resources of the bandwidth. 
Nevertheless, the delay of the SHERB-MADDQN algorithm decreases by 24.09\%, 20.49\%, and 22.56\% 
than the delay of SHERB-MADQN, HHERB-MADDQN, and HHERB-MADQN algorithms, respectively.
Fig. {\ref{fig:Step}} shows the performance of hop counts under different demand numbers. 
Specifically, with the increasing demands, the average hop counts of all algorithms grow, 
due to the increased congestion of networks.
Nevertheless, the SHERB-based algorithm requires fewer hop counts for transmitting demands, 
benefiting from the better training performance of the algorithm.
In short, simulation results demonstrate that the proposed algorithm performs better during routing.
% 9.1、13.2、11.18。
% 第一组数据相较于第 2 组数据的增降百分比: [0.0, 0.0, -0.54, -24.09, -12.5]
% 第一组数据相较于第 3 组数据的增降百分比: [-1.52, -15.45, -15.79, -20.49, -2.72]
% 第一组数据相较于第 4 组数据的增降百分比: [-12.19, -1.22, -6.32, -22.56, -8.28]
\section{Conclusions\label{sec:Conclusions}}
In this work, we characterize the routing process of multiple sources and destinations in zero-trust LAINs, with the joining and exiting of UAVs.
Additionally, the blockchain technique is introduced to manage the mobility and verify identities, 
enhancing the reliability and safety during routing. 
Besides, the routing problem is formulated to minimize the total E2E delay with multi-constraints. 
Further,  we reformulate the routing problem into a Dec-POMDP to deal with the challenge of obtaining global information in LAINs 
characterized by the high dynamic, distributed topology.
Then, to improve the learning efficiency of the MARL, a SHERB-MADDQN-based algorithm is proposed via 
embedding the observed state into rewards. 
Simulation results in LAINs demonstrate that the designed SHERB-MADDQN algorithm outperforms 
in the delay, convergence, and loss value of training performances than other algorithms.

\bibliographystyle{IEEEtran}
\bibliography{ref2}

\end{document}
