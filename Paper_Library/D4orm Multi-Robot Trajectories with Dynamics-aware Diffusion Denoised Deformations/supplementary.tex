\input{images_supp/obstacles_transpose}
\appendix
We now present some additional studies with \textsc{D4orm} to showcase our ability to handle general target assignment scenarios (not only antipodal points on a circle/sphere), scaling up to more number of robots, and handling more complex workspaces that contain obstacles.
\newline{}

\medskip\noindent\textbf{Generic Target Assignment.}
To validate that the success of our proposed method does not depend on exploiting biases or patterns in the problem, we test it on $30$ random configurations with $\{8\ldots 16\}$ 2D holonomic robots.
The environments have random initial and target positions, all generated within a square of size \( D \times D \), with \( D \) as the diameter of the circle with antipodal points used in previous experiments.
\cref{fig:time_cmp_random_16} (left) shows a solution instance for 16 robots.
We also observe in \cref{fig:time_cmp_random_16} (right) that the method works reliably for all environments and is generally faster; the average time required to generate the first feasible solution for 16 robots is about \SI{1}{\second}, which is less than the circle with antipodal points scenario ($\approx\SI{2}{s}$).
This is because some of the trajectories do not interfere with each other due to geometric relationships in the random scenario, and are therefore often much easier to deconflict.

\input{images_supp/random}

\medskip\noindent\textbf{Presence of Obstacles.}
We also tested our method in environments with obstacles, which can be easily addressed by a slight modification of the reward function of \cref{eqn:generic-reward}.
In particular, for each state in the trajectories, we add a binary penalty term for whether the robot collides with any obstacle.
\cref{fig:obstacles} shows that \textsc{D4orm} is capable of handling obstacles.
Meanwhile, as the workspace becomes more complex due to the addition of obstacles, the time required to obtain the first feasible solution increases, and \textsc{D4orm} also encounters failures where a few robots are sacrificed for collision in order to achieve a high team reward.
Dealing with obstacle-rich environments in a more systematic way (as opposed to a na\"{i}ve binary penalty) is an interesting future direction.
