\begin{figure*}[!t]
    \centering
    \begin{subfigure}{0.9\textwidth}
        \centering
        % \includesvg[width=0.9\textwidth]{figs/steps_wrt_II.svg}
        \includegraphics[width=0.9\textwidth]{figs/steps_wrt_II.png}
        \vspace{-3mm}
    \end{subfigure}
    % \hfill
    \vspace{-3mm}
    \begin{subfigure}{0.9\textwidth}
        \centering
        % \includesvg[width=0.9\textwidth]{figs/capa_wrt_II.svg}
        \includegraphics[width=0.9\textwidth]{figs/capa_wrt_II.png}
    \end{subfigure}
    % \vspace{-3mm}
    \caption{Effect of idle incentive $R_{II}$ on operation effectiveness and capability usage with (a) no reassignment (b) medium reassignment and (c) high reassignment penalty $T_{RP}$. The performance evaluation includes 500 realizations, and each bar plot shows the mean and the standard error.}
    \label{fig:idle_effect}
\end{figure*}

We analyze the teaming behaviors of the proposed HTLM Dec-POMDP framework in a disaster relief operation scenario. The operation has a team of 5 agents and 2 disaster sites. At each site, there are two different but conditionally dependent tasks: extinguishing fire and rescuing people from the burning site (4 tasks in total). The demand/severity level for each task is within the range of $[0,4]$. At the beginning of the operation, all tasks start with the severity level of 4, and the operation is considered complete when the severity levels of all tasks are 0. Each agent is equipped with two task-specific attributes (firefighting and rescue) and two perception-related attributes (sensing and communication). The joint capability level for each attribute is within the range of $[0,5]$, and it is assumed that joint capability is computed as the addition of the capabilities of the agents assigned to the same task and capped at level 5. Higher task-specific capabilities would reduce the task demand with higher probabilities, and task levels would not increase once they reach level 0. The dependency between tasks is also modelled in task transition probabilities, where the probability for rescuing demand to reduce is 0 when fire level is high ($>2$) no matter how capable the agents are. An agent is only able to observe the task level at the assigned task, making the problem partially observable. Higher sensing and capabilities would help agents perceive the environment more accurately, and the observed information broadcasted by the agents with higher communication capabilities would be trusted more. Here, the sensing and communication capabilities for all agents are set to level 3 (moderately high accuracy) since perception accuracy is not the focus of this study. With a proper designed reward function, agents would reduce the task demands efficiently by cooperating on the same task or simultaneously working on different tasks. Meanwhile, without compromising the operation effectiveness, agents' load is reduced by appropriate idling behaviors and avoiding extra capability usage and unnecessary assignments.

\subsection{Effect of Idle Incentive and Reassignment Penalty on Load Management}
\label{sec:R_LM_effect}
In real operations, constantly engaging or being heavily loaded in task execution would increase the risk exposure and reduce the capability of task-handling for agents, which might cause unexpected deficiencies in operations. Training with the proposed HTLM Dec-POMDP framework and the proper designed reward functions allows agents to make intelligent decisions with their preferences and to be prepared for additional/unexpected task loads. In this study, we investigate the impact of varying levels of idle incentive and reassignment penalty in reward functions on team performance and load reduction. We assume that agents have distinct capability levels in firefighting and rescue as shown in Table~\ref{tb:agent_capa}, capabilities do not change throughout the operation, and agents use the same decision model and reward function. As described in Section~\ref{sec:preference}, for $R_{II}$, agents receive positive reward when idling and negative reward if the capability level is 2-level higher than the believed severity level of the assigned task, reflecting penalty on unnecessary assignment. For the task reassignment penalty $T_{RP}$, agents receive negative reward if being reassigned to a task at a different location. While the reward functions can be adjusted by agents to model their preferences in operations, this study focuses on the change in the reward magnitude given to the team instead of the difference in reward functions among the agents.

\begin{figure*}[!t]
    \centering
    % \includesvg[width=0.85\textwidth]{figs/perf_wrt_rp.svg}
    \includegraphics[width=0.85\textwidth]{figs/perf_wrt_rp.png}
    \vspace{-3mm}
    \caption{Effect of reassignment penalty $T_{RP}$ on operation effectiveness (a) and load conservation (b), (c). Bar plots show the mean and the standard error for each performance metric evaluated using 500 realizations.}
    \label{fig:reassign_effect}
\end{figure*}

\begin{table}[ht]
\caption{Capabilities for a Heterogeneous Team}
\centering
    \begin{tabular}{|c|c|c|}
         \hline
         Agent ID & Firefighting & Rescue \\
         \hline
         1 & 3 & 1\\
         2 & 3 & 2\\
         3 & 2 & 0\\
         4 & 0 & 1\\
         5 & 1 & 1\\
         \hline
    \end{tabular}
\label{tb:agent_capa}
\end{table}


We train the team of agents with 6 different combinations of idle incentive $R_{II}$ and reassignment penalty $T_{RP}$, and evaluate the trained agents with two performance metrics as shown in Fig.~\ref{fig:idle_effect} with and without $R_{II}$ under (a) no, (b) medium, and (c) high reassignment penalty $T_{RP}$. 
% When there is no $R_{II}$ and $T_{RP}$, the agents replicate the behaviors learned by HT Dec-POMDP \cite{HT-DEC-POMDP}. 
The agents are evaluated in 500 operation trials, and each operation has 30 steps. The first performance metric is operation effectiveness in terms of the steps taken to complete all tasks. When training with no and medium $T_{RP}$, team effectiveness remains at the same level and is not affected by the idling behaviors induced by idle incentive. When $T_{RP}$ is too high, agents are less willing to move and an additional idle incentive further decreases the effectiveness. The second metric is the unused capability per agent per step. Whenever an agent decides to idle, the capability of the agent is considered as unused. On average, each agent has total task-handling capability level 2.8 (1.8 in firefighting and 1 in rescue) as indicated in Table \ref{tb:agent_capa}, and most of the capability $\approx 71\%$ is saved throughout an operation compared to $\approx 2.5\%$ when there is no idle incentives as shown in Fig. \ref{fig:idle_effect}. The amount of unused capability without $R_{II}$ is not always 0 because of the randomness and agent's exploratory behavior during training.

Next, we showcase the impact of reassignment penalty $T_{RP}$ on load management in Fig.~\ref{fig:reassign_effect} by fixing the amplitude of idle incentive. Giving more reassignment penalty during training incentivizes agents to reduce reassignment or overall traversing cost if the penalty is the distance between two task locations. Agents are trained using different levels of reassignment penalty (no, medium and high), and in evaluation, three metrics are investigated: (a) operation effectiveness, (b) team idle count before completion, and (c) team reassignment count before completion (Fig.~\ref{fig:reassign_effect}). For training with medium $T_{RP}$ levels, the team ends up with more idling behaviors and less frequent reassignment before completing all tasks without compromising the operation effectiveness compared to no $T_{RP}$ penalty case (Fig. \ref{fig:reassign_effect}(a)). When $T_{RP}$ is too high during training, agents prefer to stay at the same task or stay idling, but operation effectiveness cannot be guaranteed.


To visualize the learned agent behaviors in our proposed HTLM Dec-POMDP, we demonstrate the intelligent task allocation decisions made by two agents in the team shown in Fig.~\ref{fig:idle_behavior} and compare to the decisions trained with no idle incentive or reassignment penalty shown in Fig.~\ref{fig:reg_behavior}. With the help of idle incentive and reassignment penalty, agent task load is reduced by idling when its capability is not needed and when all tasks are completed. Agent 1 with firefighting capability of 3 gets assigned to fire tasks when fire levels are above 1 and idles when fire level is 1 (steps 7 and 8). At steps 2, 7, and 8, Agent 5 with both firefighting and rescue capability of 1 stays idle, letting other agents work on the remaining tasks. Furthermore, the reassignment count for both Agent 1 and 5 is only 1 (step 3 for Agent 1 and Agent 5 in Fig.~\ref{fig:idle_behavior}), while the reassignment count is 2 for both agents trained with no $T_{RP}$ (steps 6, 8 for Agent 1 and step 4, 5 for Agent 5 in Fig.~\ref{fig:idle_behavior}).


\subsection{Agent Importance}
Before training a team of agents for an operation, it is complicated to decide which agents should be chosen as team members. Random team composition based on agent capabilities might cost additional training time if the selected agents are not capable enough to accomplish tasks efficiently or cost too much capability usage if they are all being deployed. The proposed HTLM Dec-POMDP framework could provide insights on team formation and agent importance in terms of their trained behaviors and available capabilities. Identifying the importance of agents could help selecting team members and inferring the team resilience when one of the trained agents is lost or not performing well in the team. A metric for agent importance depending on capability usage and task urgency is proposed in the following equations:

\begin{equation}
    \label{eq:imp}
    \zeta=\sum_{k=1}^K\omega_k u_k,
\end{equation}

\begin{equation}
    \label{eq:capa_usage}
    u_k=\frac{1}{E}\sum_{i=1}^{E}c_k\textbf{1}(\pi^*=a_k|i),
\end{equation}

\begin{equation}
    \label{eq:task_weight}
    \bar{\omega}_k=\sum_{i=1}^{E}\sum_{j=1}^{N}\textbf{1}(\pi_j^*=a_k|i),
\end{equation}

\begin{equation}
    \label{eq:task_weight2}
    \omega_k=\frac{\bar{\omega}_k}{\sum_{k=1}^K \bar{\omega}_k}.
\end{equation}

\begin{figure}[!t]
    % \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figs/behave_noiirp.png}
        \vspace{-6mm}
        \caption{Decisions of Agent 1 and 5 trained with no $R_{II}$ and no $T_{RP}$}
        \label{fig:reg_behavior}
    \end{subfigure}
    \hfill
    \vspace{3mm}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figs/behave_idle.png}
        \vspace{-6mm}
        \caption{Decisions of Agent 1 and 5 trained with $R_{II}$ and medium $T_{RP}$}
        \label{fig:idle_behavior}
    \end{subfigure}
    \caption{Demonstration of task allocation in an operation, where agents are trained (a) with no $R_{II}$ and no $T_{RP}$, and (b) with $R_{II}$ and medium $T_{RP}$. Black lines indicate agent decisions for the first 15 steps, and color blocks represent the actual severity levels for each task ranging from 0 to 4.}
    \label{fig:agent_behavior}
\end{figure}

Here, the importance metric $\zeta:=f(U,W|C,\pi^*,n_s)$ for each agent is defined as a function of its capability usage on each task type $U=[u_1,\dots,u_K]$ depending on its available task-specific capabilities $C=[c_1,\dots,c_K]$ and the task urgency weight $W=[\omega_1,\dots,\omega_K]$, where $K$ is the number of task types in an operation. The importance is estimated through $E$ simulated operation episodes and the trained optimal agent policy $\pi^*$ (i.e. task allocation decisions). The capability usage for each task type $u_k\in U$ is computed as the average capability used in $E$ episodes as shown in Eq. (\ref{eq:capa_usage}), where $a_k$ indicates the agent is allocated to task type $k\in{1,\dots,K}$. However, tasks have different dynamics, and some tasks are harder to resolve than others. Taking our fire and rescue operation as an example, for each step, fire severity can only be reduced by one level at most, and multiple people can be rescued only when the fire level is low, which naturally makes firefighting tasks harder and more urgent. Capability usage only accounts for the resource needed for each task, but an important agent would spend more capability on more urgent tasks. Instead of making arbitrary weights for task urgency, we assume that the task allocated more frequently is more urgent. With a team of $N$ agents and $E$ episodes, the estimated task urgency weight is computed as Eq. (\ref{eq:task_weight}) and normalized using Eq. (\ref{eq:task_weight2}). Then, the importance for each agent is calculated using Eq. (\ref{eq:imp}).

\begin{table}[hb]
\caption{Agent Importance for Three Teams}
\centering
\begin{subtable}[b]{0.48\textwidth}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
         \hline
         Agent & $C_{fire}$ & $C_{rescue}$ & $U_{fire}$ & $U_{rescue}$ & $\zeta$\\
         \hline
         1 & 3 & 1 & 21.19 & 0.04 & 13.90\\
         2 & 3 & 2 & 16.92 & 3.18 & 12.18\\
         3 & 2 & 0 & 13.26 & 0 & 8.69\\
         \textbf{4} & 0 & 1 & 0 & 7.17 & \textbf{2.47}\\
         5 & 1 & 1 & 3.64 & 3.32 & 3.57\\
         \hline
    \end{tabular}
    \vspace{-2mm}
  \caption{Heterogeneous Team $\omega_{fire}=0.66, \omega_{rescue}=0.34$}
  \label{tb:heter_imp}
\end{subtable}
  \hfill
\vspace{2mm}
\begin{subtable}[b]{0.48\textwidth}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
         \hline
         Agent & $C_{fire}$ & $C_{rescue}$ & $U_{fire}$ & $U_{rescue}$ & $\zeta$\\
         \hline
         \textbf{1} & 3 & 1 & 3.44 & 0 & \textbf{2.58}\\
         2 & 3 & 1 & 22.38 & 0 & 16.75\\
         3 & 1 & 1 & 10.80 & 0 & 8.08\\
         4 & 2 & 2 & 3.70 & 4.26 & 3.84\\
         5 & 2 & 2 & 8.99 & 9.42 & 9.10\\
         \hline
    \end{tabular}
    \vspace{-2mm}
  \caption{Semi-Heterogeneous Team $\omega_{fire}=0.75, \omega_{rescue}=0.25$}
  \label{tb:semiheter_imp}
\end{subtable}
    \hfill
\vspace{2mm}
\begin{subtable}[b]{0.48\textwidth}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
         \hline
         Agent & $C_{fire}$ & $C_{rescue}$ & $U_{fire}$ & $U_{rescue}$ & $\zeta$\\
         \hline
         1 & 2 & 1 & 17.91 & 1.49 & 12.49\\
         2 & 2 & 1 & 12.68 & 4.05 & 9.84\\
         \textbf{3} & 2 & 1 & 2.52 & 3.20 & \textbf{2.74}\\
         4 & 2 & 1 & 12.17 & 3.00 & 9.15\\
         5 & 2 & 1 & 14.60 & 2.99 & 10.77\\
         \hline
    \end{tabular}
    \vspace{-2mm}
  \caption{Homogeneous Team $\omega_{fire}=0.67, \omega_{rescue}=0.33$}
  \label{tb:homo_imp}
\end{subtable}
\label{tb:agent_imp}
\end{table}

In this analysis, we use the same operation scenario with $h=30$ steps, consisting of two task types (fire and rescue) at two locations and five agents. The importance score is ranging from 0 if the agent always idles to $c_kh$ if all agents always work on the same task type. In addition to a team of five agents with heterogeneous capabilities as described in Table \ref{tb:agent_capa}, a semi-heterogeneous team and a homogeneous team are considered. The available capabilities $(C_{fire},C_{rescue})$, used capabilities $(U_{fire},U_{rescue})$, and the importance $\zeta$ of each agent for three teams are summarized in Table \ref{tb:agent_imp}. The agent with the least importance score for each team is highlighted in bold.

\begin{figure}[!t]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{figs/imp_heter.png}
        \label{fig:semi_imp}
    \end{subfigure}
    \hfill
    \vspace{-4mm}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \caption{Heterogeneous Team}
        \includegraphics[width=1\textwidth]{figs/imp_semihomo.png}
        \label{fig:semi_imp}
    \end{subfigure}
    \hfill
    \vspace{-4mm}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \caption{Semi-Heterogeneous Team}
        \includegraphics[width=1\textwidth]{figs/imp_homo.png}
        \label{fig:homo_imp}
    \end{subfigure}
    \hfill
    \vspace{-4mm}
    \begin{subfigure}{0.48\textwidth}
        \centering
        \caption{Homogeneous Team}
    \end{subfigure}
    \vspace{-5mm}
    \caption{Operation effectiveness comparison between having all agents (blue) and inactivating the least important agent (red) for (a) Heterogeneous Team, (b) Semi-Heterogeneous Team, (c) Homogeneous Team. Each histogram shows 200 realizations with the mean completion step indicated.}
    \label{fig:imp_compare}
\end{figure}

To validate the agent importance, without re-training the agents, we set one of the agents in a team to always idle and evaluate the operation effectiveness described as completion step compared to having all agents. Fig. \ref{fig:imp_compare} suggests that the operation effectiveness is not affected after inactivating the the least important agent indicated in Table \ref{tb:agent_imp} for all three teams. Inactivating the most important agent for all teams would lead to operation failure (i.e. unable to accomplish tasks within 30 steps). It is worth noting that the agent importance metric is not simply the indicator of its capability but depends also on the learned decision process during the training in interaction with other agents. Consequently, agents with the same capability might have different importance (Table \ref{tb:homo_imp}) and agents with higher capabilities might be the least important and unnecessary to execute any tasks (Table \ref{tb:semiheter_imp}). Hence, the agent importance is the metric for the significance of the agent in a learned team collaboration. We have demonstrated that the importance metric for agents trained with the HTLM Dec-POMDP framework could help to infer which agent is more significant in collaboration, how much capability could be saved without affecting the operation effectiveness, and consequently how much additional demand can be handled by the team by fully activating all agents. 

%reviewer1major5
Although this study focuses on fire suppression and rescue operations, the formulation is general enough to model different types of task dynamics  and various team compositions ranging from homogeneous to heterogeneous teams. The formulation could be generalized to autonomy applications in different fields including but not limited to warehouse management and task scheduling in manufacturing.

% (i.e. fire and rescue tasks are individually modeled but can be dependent on teach other, and task levels can suddenly increase to simulate unforeseen events)