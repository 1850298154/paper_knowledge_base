
In this section, we review the related literature in the fields of multi-agent and multi-robot simulation, highlighting the core gaps of each field. Furthermore, we compare the most relevant simulation frameworks with VMAS in \autoref{tab:simulator_comparison}. 

\textbf{Multi-agent reinforcement learning environments}. A significant amount of work exists in the context of MARL to address the issues of multi-robot simulation for learning hard coordination strategies. Realistic GPU-accelerated simulators and engines have been proposed. Isaac~\cite{makoviychuk2021isaac} is a proprietary NVIDIA simulator used for realistic robotic simulation in reinforcement learning. Instead of using environment vectorization to accelerate learning, it uses concurrent execution of multiple training environments in the same simulation instance. Despite of this, its high-fidelity simulation makes it computationally expensive for high-level MARL problems. Brax~\cite{brax2021github} is a vectorized 3D physics engine introduced by Google. It uses the Jax~\cite{jax2018github} library to achieve environment batching and full-differentiability. However, computational issues occur when scaling the number of simulated agents, leading to stalled environments with just 20 agents. There also exist projects for single-agent vectorized environments~\cite{gymnax2022github,envpool}, but the complexity of extending these to the multi-agent domain is non-trivial.

The core benchmark environments of the MARL literature focus on high-level inter-robot learning. Multiagent Particle Environments (MPE)~\cite{lowe2017multi} are a set of enviroments created by OpenAI. They share VMAS's principles of modularity and ease of new scenario creation, without providing environment vectorization. \text{MAgent}~\cite{zheng2018magent} is a discrete-world environment supporting a high number of agents. Multi-Agent-Learning-Environments~\cite{jiang2021multi} is another simplified discrete-world set of environments with a range of different multi-robot tasks. Multi-Agent-Emergence-Environments~\cite{baker2019emergent} is a customizable OpenAI 3D simulator for hide-and-seek style games. Pommerman~\cite{DBLP:journals/corr/abs-1809-07124} is a discretized playground for learning multi-agent competitive strategies.
SMAC~\cite{samvelyan19smac} is a very popular MARL benchmark based on the Starcraft 2 videogame. Neural-MMO~\cite{suarez2019neural} is another videogame-like set of environments where agents learn to survive in large populations. Google Research Football~\cite{kurach2020google} is a football simulation with a suite of scenarios that test different aspects of the game.
Gym-pybullet-drones~\cite{panerati2021learning} is a realistic PyBullet simulator for multi-quadricopters control. Particle Robots Simulator~\cite{shen2022deep} is a simulator for particle robots, which require high coordination strategies to overcome actuation limitations and achieve high-level tasks. Multi-Agent Mujoco~\cite{peng2021facmac} consists in multiple agents controlling different body parts of a single Mujoco~\cite{todorov2012mujoco} agent. While all these environments provide interesting MARL benchmarks, most of them focus on specific tasks. Furthermore, none of these environments provide GPU vectorization, which is key for efficient MARL training. We present a comparison between VMAS and all the aforementioned environments in \autoref{tab:simulator_comparison}.

\textbf{Multi-robot simulators}. Video-game physics engines such as Unity and Unreal Engine grant realistic simulation that can be leveraged for multi-agent robotics. Both make use of the GPU-accelerated NVIDIA PhysX. However, their generality causes high overheads when using them for robotics research.
% their use in research environments comes with a high overhead due to their generality---the tools themselves are not tailored towards robotics research. Furthermore, they incorporate complex simulations which require significant computational resources.
Other popular physics engines are Bullet, Chipmunk, Box2D, and ODE. These engines are all similar in their capabilities and prove easier to adopt due to the availability of Python APIs. Thus, they are often the tool of choice for realistic robotic simulation. However, because they do not leverage GPU-accelerated batched simulation, these tools lead to performance bottlenecks in MARL training.

The most widely known robotic simulators are Gazebo~\cite{koenig2004design} and Webots~\cite{michel2004cyberbotics}. Their engines are based on the ODE 3D dynamics library. These simulators support a wide range of robot models, sensors, and actuators, but suffer from significant performance loss when scaling in the number of agents. Complete simulation stall is shown to occur with as few as 12 robots~\cite{8088134}. For this reason, Argos~\cite{Pinciroli:SI2012} has been proposed as a scalable multi-robot simulator. It is able to simulate swarms in the thousands of agents by assigning parts of the simulation space to different physics engines with different simulation goals and fidelity. Furthermore, it uses CPU parallelization through multi-threading. Despite these features, none of the simulators described are fast enough to be usable in MARL training. This is because they prioritize realistic full-stack multi-robot simulation over speed, and they do not leverage GPU acceleration for parallel simulations. 
This focus on realism is not always necessary in MARL. In fact, most collective coordination problems can be decoupled from low-level problems relating to sensing and control. When these problems can be efficiently solved independently without loss of generality, fast high-level simulation provides an important tool. This insight is the key factor motivating the holonomicity assumption in VMAS.



\begin{table}[t]
\caption{Comparison of multi-agent and multi-robot simulators and environments.}
\label{tab:simulator_comparison} 
\resizebox{\linewidth}{!}{%
\begin{tabular}{r c c c c c c c c c c c}
\hline\noalign{\smallskip}
 & \rotatebox{0}{Vector$^a$} & \rotatebox{0}{State$^b$} & \rotatebox{0}{Comm$^c$} & \rotatebox{0}{Action$^d$} & \rotatebox{0}{PhysEng$^e$} & \rotatebox{0}{\#Agents$^f$} & \rotatebox{0}{Gen$^g$} & \rotatebox{0}{Ext$^h$} & \rotatebox{0}{MRob$^i$} & \rotatebox{0}{MARL$^j$} & \rotatebox{0}{RLlib$^k$} \\
\toprule

Brax~\cite{brax2021github} & \cmark  & C & \xmark & C & 3D & $<10$ & \cmark & \cmark & \xmark & \xmark &\xmark\\
MPE~\cite{lowe2017multi}  & \xmark  & C & C+D & C+D & 2D & $<100$ & \cmark & \cmark & \xmark & \cmark &\cmark\\
MAgent~\cite{zheng2018magent} & \xmark  & D & \xmark & D & \xmark & $>1000$ & \xmark & \xmark & \xmark & \cmark &\cmark\\
MA-Learning-Environments~\cite{jiang2021multi} & \xmark  & D & \xmark & D & \xmark & $<10$ & \cmark & \xmark & \cmark & \cmark &\xmark\\
MA-Emergence-Environments~\cite{baker2019emergent} & \xmark  & C & \xmark & C+D & 3D & $<10$ & \xmark & \xmark & \xmark & \cmark &\xmark\\
Pommerman~\cite{DBLP:journals/corr/abs-1809-07124} & \xmark  & D & \xmark & D & \xmark & $<10$ & \xmark & \xmark & \xmark & \cmark &\xmark\\
SMAC~\cite{samvelyan19smac}  & \xmark  & C & \xmark & D & \xmark & $<100$ & \xmark & \cmark & \xmark & \cmark & \cmark\\
Neural-MMO~\cite{suarez2019neural} & \xmark  & C & \xmark & C+D & \xmark & $<1000$ & \xmark & \cmark & \xmark & \cmark & \cmark \\
Google research football~\cite{kurach2020google} & \xmark  & C & \xmark & D & 2D & $<100$ & \xmark & \cmark & \xmark & \cmark &\cmark\\
gym-pybullet-drones~\cite{panerati2021learning} & \xmark & C & \xmark & C & 3D & $<100$ & \xmark & \cmark &\cmark & \cmark &\cmark \\
Particle robots simulator~\cite{shen2022deep} & \xmark  & C & \xmark & C+D & 2D & $<100$ & \xmark & \cmark & \cmark & \cmark &\xmark\\
MAMujoco~\cite{peng2021facmac} & \xmark  & C & \xmark & C & 3D & $<10$ & \xmark & \xmark & \xmark & \cmark &\xmark\\

\midrule

Gazebo~\cite{koenig2004design} &  \xmark & C & C+D & C+D & 3D & $<10$  & \cmark & \cmark & \cmark & \xmark & \xmark\\
Webots~\cite{michel2004cyberbotics} & \xmark  & C & C+D  & C+D & 3D & $<10$  & \cmark & \cmark & \cmark &\xmark  & \xmark \\
ARGOS~\cite{Pinciroli:SI2012} & \xmark & C & C+D & C+D & 2D\&3D & $<1000$ & \cmark & \cmark &\cmark & \xmark &\xmark \\

\midrule

VMAS & \cmark  & C & C+D & C+D & 2D & $<100$ & \cmark & \cmark & \cmark & \cmark &\cmark\\

\bottomrule
\end{tabular}}\\

$^a$ Vectorized\\
$^b$ Continuous state (C) or discrete state/grid world (D)\\
$^c$ Continuous communication (C) or discrete communication (D) inside the simulator\\
$^d$ Continuous actions (C) or discrete actions (D)\\
$^e$ Type of physics engine\\
$^f$ Number of agents supported\\
$^g$ General purpose simulator: any type of task can be created\\
$^h$ Extensibility (API for creating new scenarios)\\
$^i$ Contains multi-robot tasks\\
$^j$ Made for Multi-Agent Reinforcement Learning (MARL)\\
$^k$ Compatible with RLlib framework~\cite{liang2018rllib}
\end{table}