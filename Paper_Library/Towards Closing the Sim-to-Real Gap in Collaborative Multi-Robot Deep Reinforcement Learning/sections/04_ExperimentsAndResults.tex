
% 20200628T124652: Normal
% 20200629T211808: IF5
% 20200629T183036: IF15
% 20200629T202018: IF25

% 20200628T173606: IV5 
% 20200628T182701: IV15
% 20200628T191601: IV25

% 20200628T204434: OF5
% 20200629T165257: OF15
% 20200628T222909: OF25

% 20200628T231804: OV5
% 20200629T060207: OV15
% 20200629T070507: OV25

% 20200629T135403: IF15BigNoise
% 20200629T145641: OF15BigNoise

% 20200629T101439: OFMN25
% 20200629T110510: IFMN25

\begin{figure*}
    \centering
    \begin{minipage}{0.49\textwidth}
        \begin{subfigure}[t]{0.99\textwidth}
            \centering
            \setlength{\figureheight}{0.8\textwidth}
            \setlength{\figurewidth}{\textwidth}
            \small{\input{fig_latex_v2/20200628T124652}}
            \caption{Base scenario with common perturbation-free environments.}
            \label{fig:base}
        \end{subfigure}
    \end{minipage}
    \begin{minipage}{0.49\textwidth}
        \begin{subfigure}[t]{0.49\textwidth}
            \centering
            \setlength{\figureheight}{0.8\textwidth}
            \setlength{\figurewidth}{\textwidth}
            \scriptsize{\input{fig_latex_v2/20200629T211808}}
            \caption{IF5}
            \label{fig:IF5}
        \end{subfigure}
        \begin{subfigure}[t]{0.49\textwidth}
            \centering
            \setlength{\figureheight}{0.8\textwidth}
            \setlength{\figurewidth}{\textwidth}
            \scriptsize{\input{fig_latex_v2/20200629T183036}}
            \caption{IF15}
            \label{fig:IF15}
        \end{subfigure}
        \begin{subfigure}[t]{0.49\textwidth}
            \centering
            \setlength{\figureheight}{0.8\textwidth}
            \setlength{\figurewidth}{\textwidth}
            \scriptsize{\input{fig_latex_v2/20200629T202018}}
            \caption{IF25}
            \label{fig:IF25}
        \end{subfigure}
        \begin{subfigure}[t]{0.49\textwidth}
            \centering
            \setlength{\figureheight}{0.8\textwidth}
            \setlength{\figurewidth}{\textwidth}
            \scriptsize{\input{fig_latex_v2/20200628T173606}}
            \caption{IV5}
            \label{fig:IV5}
        \end{subfigure}
    \end{minipage}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v3/20200630T111226}}
        \caption{IV15}
        \label{fig:IV15}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200628T191601}}
        \caption{IV25}
        \label{fig:IV25}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v3/20200630T120538}}
        \caption{OF5}
        \label{fig:OF5}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200629T165257}}
        \caption{OF15}
        \label{fig:OF15}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200628T222909}}
        \caption{OF25}
        \label{fig:OF25}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v3/20200630T131604}}
        \caption{OV5}
        \label{fig:OV5}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200629T060207}}
        \caption{OV15}
        \label{fig:OV15}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \setlength{\figureheight}{0.8\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200629T070507}}
        \caption{OV25}
        \label{fig:OV25}
    \end{subfigure}
    \caption{Simulation results where we show the training in perturbance-free environment, and 12 cases where we analyze the effect of a modified environment (fixed and variable perturbances on both sensing and actuation) on 5, 15 and 25 agents. The total number of agents is 30 in all cases. The legend is common across all graphs and has been omitted in subfigures (b) through (m) to improve readability.}
    \label{fig:main_results}
\end{figure*}

\section{Experimentation and Results}
\label{sec:results}

In this section, we describe the training parameters utilized through our simulations, and the ways in which the environments have been modified to introduce disturbances in both sensors and actuators. We then present the results of multiple simulations where different numbers of agents have been trained in different environments but treated equally from the point of view of the collaborative learning process.

\subsection{Training Method}

The maximal number of steps in one episode is set to 1200, and the maximum number of steps for the whole training process is set to 4 million. If the gripper contacts the object or approaches it at a very small distance (0.008\,m), the episode will be terminated. The final score for this episode is thus calculated by summing all the rewards obtained in all the steps until termination.

The initial reward is set as -1000 for each step if the distance is larger than 1\,m. However, if the distance between the finger on the gripper and the object is smaller than 1\,m, the reward is computed as $reward_{raw} = -10\cdot distance$. Moreover, we also add the cost of each step, in order to encourage the gripper to approach the target as soon as possible. The cost of each step is set as 1. Therefore, the final reward for this step is hence: $ reward_{final} = -10\cdot distance - 1$, where the distance is given in meters. If the gripper finally contacts its target or approach it in a threshold, we give it a significantly larger reward (1000) to help the model learn faster and clearly.

In total, in our simulations, we utilize 30 agents parallelized on the GPU processes to produce experience data based on a vectorized environment. Therefore, these agents can represent a multi-robot system learning a collaborative RL task. We give different settings on individual environments to manually simulate the possible perturbations that robots find in real-world scenarios. 


\subsection{Calibration and Accuracy Noises}

To emulate the practical noises and errors that robots could encounter when training an RL algorithm, we consider the following four types of perturbations, for each of which we generate a different environment to expose a variable number of robots to: fixed input errors on all the nine elements by $0.005\,m$, uniformly distributed sensing errors in the interval $[0.005\,m, 0.01\,m]$, fixed output errors modifying the gripper actuators by an offset of $0.005\,m$ on the $x$ axis, and uniformly distributed output errors in the interval $[0.005\,m, 0.01\,m]$. It should be noted that the uniform distributed errors on input and output could be different in each step, which can be regarded as inaccurate sensing errors, or reduced repeatability in the actuation of real robots.

Moreover, in order to further analyze how more extreme cases affect the collaborative learning process, we also consider fixed disturbances on larger magnitude (0.015\,m on all the values for the sensing error and 0.015\,m on the x-axis for the actuation error) as well as scenarios where the noise is different for each of the agents exposed to the modified environment (in the interval 0.005\,m to 0.025\,m for 25 agents).

\subsection{Simulation Results}

Figure~\ref{fig:main_results} shows the results of our simulations. The notation describing each subfigure is as follows: \{I,O\}: representing the input (sensing) and output (actuation) perturbances, \{F,V\}: representing fixed and variable perturbances, and \{5, 15, 25\}: representing the number of agents exposed to the modified environment where the perturbances occur.

\begin{figure*}
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \setlength{\figureheight}{0.5\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200629T135403}}
        \caption{IF15 - Large perturbations}
        \label{fig:IF15BigNoise}
    \end{subfigure}
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \setlength{\figureheight}{0.5\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200629T145641}}
        \caption{OF15 - Large perturbations}
        \label{fig:OF15BigNoise}
    \end{subfigure}
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \setlength{\figureheight}{0.5\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v2/20200629T101439}}
        \caption{OF25 - Each agent exposed to a different environment}
        \label{fig:OFMN25}
    \end{subfigure}
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \setlength{\figureheight}{0.5\textwidth}
        \setlength{\figurewidth}{\textwidth}
        \footnotesize{\input{fig_latex_v3/20200630T161240}}
        \caption{IF25 - Each agent exposed to a different environment}
        \label{fig:IFMN25}
    \end{subfigure}
    \caption{Simulation results with an extra 4 scenarios analyzed: two of them where we consider perturbations of larger magnitude, and two more where we consider that each of the agents in a modified environment is affected differently.}
    \label{fig:more_results}
\end{figure*}

Comparing perturbations in the sensors versus perturbations in the actuators, we see an overall more robust performance against adversarial elements in the sensing part. In Figures~\ref{fig:IF5} to~\ref{fig:IF25}, we see that the network always converges and we only see more unstable behaviour when there is a large fraction of agents suffering of variable sensing errors (50\% and 83\%). When we compare the effect of constant or fixed perturbations against variable ones, we notice that variable perturbations induce less stable convergence. This can be to some extent explained by the fact that there are no large subsets of agents being exposed to a common environment.

For small fixed perturbations affecting actuation (output disturbances), we have seen that the agents are able to converge towards a working policy. In the cases where 5 or 25 of the agents are affected, this was expected as there is a majority (25) of agents, in both cases, that work in exactly the same way, and a small subset (5) that work in a slightly different way (but still the same within that subset). When this fixed perturbation is introduced to half of the agents, then we have two subsets of the same size operating in different ways, but again consistently across each of the subsets. In this case, we have seen that for a small magnitude in the perturbation, the agents still converge on a policy that works for both subsets. As the difference between the operation of the agents in these two subsets diverges, the performance of the system as a whole drops significantly. Nonetheless, we have observed that the case were half of the agents have a common fixed perturbation of small magnitude the system is able to converge even when the initial conditions are disadvantageous. 

In order to analyze the effect of perturbations with larger magnitude as well as fixed perturbations in both sensing and actuation that vary across the robots exposed to a modified environment, we have analyzed four more cases shown in Fig.~\ref{fig:more_results}. In Figures~\ref{fig:IF15BigNoise} and~\ref{fig:OF15BigNoise}, we analyze how perturbations with larger magnitude affect the learning process, with half of the agents being affected as the worst-case scenario. We see that the trend from the previous results is followed, with the network being able to converge to a common policy when a constant error is added to the sensors interface, but not when the disturbances affect to the actuators. Finally, Figures~\ref{fig:OFMN25} and~\ref{fig:IFMN25} show that when there are no differentiated subsets of agents with a common behaviour and the perturbations are different across a large number of agents, then the system is not able to converge.


