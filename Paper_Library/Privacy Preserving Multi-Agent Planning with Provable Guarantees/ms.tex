\documentclass[twoside,11pt]{article}
\usepackage{jair, theapa, rawfonts}
\usepackage{amsthm,amsmath}
\usepackage{aliascnt,cleveref}
\usepackage[noend]{algorithmic}
\usepackage{algorithm}
\usepackage[usenames]{color} % Only used in comment commands
\usepackage{xcolor}
\usepackage{url}
\usepackage{graphicx}
%\usepackage[normalem]{ulem} %DIF PREAMBLE
%
%\ifnum\draft=1
	%\newcommand{\CHANGED}[1]{\textcolor{blue}{#1}}
	%\newcommand{\TODO}[1]{\textcolor{red}{TODO: #1}}
	%
	%%\newcommand{\CHANGED}[1]{{\protect\color{blue}\uwave{#1}}}
	%\newcommand{\DELETED}[1]{{\protect\color{red}\sout{#1}}}
%\else
	%\newcommand{\CHANGED}[1]{#1}
	%\newcommand{\TODO}[1]{}
	%\newcommand{\DELETED}[1]{}
%\fi

\newcommand{\red}[1]{{\color{red} #1}}
\renewcommand{\algorithmiccomment}[1]{/* #1 */}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicforall}{\textbf{for each}}

%\jairheading{1}{1993}{1-15}{6/91}{9/91}
\ShortHeadings{PP MAP with Provable Guarantees}
{Beimel and Brafman}
\firstpageno{1}

\crefname{algorithm}{Algorithm}{Algorithms}
\crefname{clm}{Claim}{Claims}
%\newtheorem{notation}[theorem]{Notation}

\crefname{notation}{Notation}{Notations}
%\iffalse
%\newtheorem{theorem}{Theorem}[section]
\crefname{theorem}{Theorem}{Theorems}
%\spnewtheorem{theorem}[theorem]{Theorem}{\bf}{\em}
%\newtheorem{claim}[theorem]{Claim}
\crefname{claim}{Claim}{Claims}
%\spnewtheorem{clm}[theorem]{Claim}{\bf}{\em}
%\newtheorem{proposition}[theorem]{Proposition}
\crefname{proposition}{Proposition}{Propositions}
%\newaliascnt{lemma}{theorem}
%\newtheorem{lemma}[theorem]{Lemma}
%\aliascntresetthe{lemma}
%\crefname{lemma}{Lemma}{Lemmas}
%\spnewtheorem{lemma}[theorem]{Lemma}{\bf}{\em}
%\newtheorem{definition}[theorem]{Definition}
\crefname{definition}{Definition}{Definitions}

%\spnewtheorem{dfn}[theorem]{Definition}{\bf}{\em}
%\newtheorem{define}[theorem]{Definition}
%\newtheorem{cor}[theorem]{Corollary}
\crefname{cor}{Corollary}{Corollaries}


%\theoremstyle{definition}

%\spnewtheorem{cor}[theorem]{Corollary}{\bf}{\em}
%\newtheorem{obs}[theorem]{Observation}
\crefname{obs}{Observation}{Observations}
%\spnewtheorem{obs}[theorem]{Observation}{\bf}{\em}
%\newtheorem{example}[theorem]{Example}
\crefname{example}{Example}{Examples}
%\newtheorem{construct}[theorem]{Construction}
\crefname{construct}{Construction}{Constructions}



%\spnewtheorem{construct}[theorem]{Construction}{\bf}{\em}
%\newtheorem{theorem}{Theorem}
%\newtheorem{question}{Question}
\crefname{question}{Question}{Questions}

\newtheorem{remark}{Remark}
\crefname{remark}{Remark}{Remarks}
%\fi
\renewcommand{\Cref}[1]{\cref{#1}}
\definecolor{ToDoColor}{rgb}{0.1,0.2,1}
\newcommand{\todo}[1]{\textbf{\color{ToDoColor} TODO: #1}}
\newcommand{\anote}[1]{\textbf{\color{ToDoColor} Amos's note: #1}}
\newcommand{\rnote}[1]{\textbf{\color{ToDoColor} Ronen's note: #1}}
\newcommand{\astar}{\textsc{a*}}
\newcommand{\mafs}{{\sc{mafs}}}
\newcommand{\smafs}{{\sc{secure mafs}}}
\newcommand{\masas}{\textsc{mad-a*}}
\newcommand{\mastrips}{\textsc{ma-strips}}
\newcommand{\pp}{\textsc{pp-mas}}
\newcommand{\strips}{\textsc{strips}}
\newcommand{\hdastar}{\textsc{hda*}}
\newcommand{\mafd}{\textsc{ma-fd}}
\newcommand{\ppastar}{\textsc{pp-a*}}
\newcommand{\prune}{\rho}
\newcommand{\enqueue}{\operatorname{enqueue}}
\newcommand{\dequeue}{\operatorname{dequeue}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\eff}{\mathrm{eff}}
\newcommand{\PST}{\mathrm{PST}}
\newcommand{\ST}{\mathrm{ST}}
%\newcommand{\Sim}{{\sc Sim}}\
\newcommand{\algname}[1]{\mbox{\sc #1}}
\newcommand{\Sim}{\algname{Sim}}
\newcommand{\view}{\operatorname{\rm view}}

\newcommand{\set}[1]{\{#1\}}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

\newcommand{\commentout}[1]{}


%Summary of meetings with Amos
%
%1. Assumption: public actions only
%2. Define notion of equivalent problems
%   a. you suggested two problems in which the tree of public states is the same. The tree is defined as the tree corresponding to the full search space of the problem, where states are projected to public variables only.
%		This still has to be defined cleanly.
%   b. another option is when the DAG is the same
%3. Find algorithms that send the same information given equivalent problems
%   a. For tree-equivallence: you suggested emulating all possible computations and checking to see what is feasible next
%   b. We need to check whether secure mafs also has this property.
%4. We should give examples of classes of equivalent problems
%
%
%Basic assumption: we are willing to expose the global tree = the projection of the real tree to the global variables.
%Thus, two domains are equivalent if they have the same global tree.
%
%Last time we discussed the algorithm in which agents recompute their local state based on the path so far,
%and then decide what next states are possible. Agents send only the global state.
%
%This time we considered variants that are more similar to forward search.
%
%First take: Agents expand all children, and combine children that are identical, except for their local state.
%They send a state with an ID of their local state. This ID corresponds to the list of local states that have the same non-local component.
%
%It was pretty straightforward to see that this works if we allow IDs that correspond to local states that come from sibling states.
%
%Then, we said that it can also work if we combine states that are at the same level, but are not siblings.
%The claim is that the DAG that corresponds to this is a function of our tree.
%
%	NOTE1: this variant is less natural, as it requires that the agents not only expand all the children of every node at once,
%	but that they expand all the children of every sibling of that node. This is not the case in search algorithms.
%	
%	NOTE2: If we can generate states incrementally and not report on states that should be combined, this would work well.
%	It is ok if we generate all children of a state in batch, and then move to the next state. I think that this is not a problem, as we can
%	define clear criteria for ordering states.
%
%Finally, we discussed the option of combining states across level. The reason for this being OK is not clear to me.


\begin{document}

\title{Privacy Preserving Multi-Agent Planning with Provable Guarantees}

\author{\name Amos Beimel \email beimel@cs.bgu.ac.il\\
       \name Ronen Brafman \email brafman@cs.bgu.ac.il \\
       \addr Ben-Gurion University of the Negev,\\
       Be'er Sheva, Israel}

% For research notes, remove the comment character in the line below.
% \researchnote

\maketitle


\begin{abstract}
In privacy-preserving multi-agent planning, a group of agents attempt to cooperatively solve a multi-agent planning problem while maintaining private their data and actions. Although much work was carried out in this area in past years,
its theoretical foundations have not been fully worked out. Specifically, although algorithms with precise privacy guarantees
exist~\cite{Yao82b,GMW87}, even their most efficient implementations are not fast enough on realistic instances,
%they are of theoretical interest only, 
whereas for practical algorithms no meaningful privacy guarantees exist.
\smafs~\cite{Brafman15}, a variant of the multi-agent forward search algorithm~\cite{nissim2014distributed}  
is the only practical algorithm to attempt to offer more precise guarantees, but only in very limited settings and with proof sketches only. 
In this paper we formulate a precise notion of secure computation for search-based algorithms and prove that \smafs\ has this property in all domains. We also provide a proof of its completeness.
\end{abstract}

\input{introduction}

\section{The Model}
\label{model}



\mastrips~\cite{Brafman200828}  is a minimal extension of \strips\ to multi-agent domains.
A \strips\ problem is a  4-tuple $\Pi = \langle P,A,I,G \rangle$, where 
\begin{itemize}
\item
$P$ is a finite set of primitive propositions, which are essentially the state variables; a {\em state\/} is a truth assignment to $P$.
\item
$I$ is the initial state. 
\item
$G$ is the set of goal states. 
\item
$A$ is a set of actions.
%usually described by the subset of propositions in $P$ that are assigned the value {\em true\/}.  $I\subseteq P$ is
%the initial state, i.e., $p$ is assigned {\em true} in the initial state iff $p\in I$. $G\subseteq P$ is the set goals. It is not necessarily a single state,
%and $s$ is a goal state iff $s\models G$.
Each action $a$ has the form $a=\langle \pre(a),\eff(a) \rangle$, where  $ \pre(a)\subset P$ is the set of preconditions of $a$
and  $ \eff(a)$ is a set of literals, denoting the effects of action $a$. We use $a(s)$ to denote the state attained by applying $a$ in $s$. The state $a(s)$ is well defined iff $s\models \pre(a)$. In that case, $a(s)\models p$ (for $p\in P$) iff $p\in \eff(a)$ or $s\models p$ and $\neg p\not\in \eff(a)$.
\end{itemize}
A {\em plan\/} $\pi = a_1,\ldots, a_m$ is a solution to $\Pi$ iff $a_m(\cdots a_1(s)\cdots)\models G$.

An \mastrips\ problem is  a \strips\ problem in which the action set $A$ is partitioned among a set $\Phi=\{\varphi_i\}_{i=1}^{k}$ of
agents.  Formally, $\Pi = \langle P,\{A_i\}_{i=1}^{k},I,G \rangle$, where $P,I,G$ are as above, and $A_i$ is the set of actions of $\varphi_i$.



%In different planning contexts, one  might seek special types of solutions. For example, in the context of planning games \cite{BrafmanDET09}, \emph{stable} solutions are sought. Our focus here is on cooperative multi-agent systems where agents try to generate a solution plan, together.
%The agents may have various optimization criteria in mind, seeking a cost-optimal solution, or a make-span optimal solution, or some sort of fair solution that minimizes the maximal cost per agent. We will not concern ourselves with this aspect of the problem, but rather, we will focus on how the agent can succeed in generating a plan without revealing too much private information to each other.

%A \textit{private} proposition of agent $\varphi$ is required and affected only by the actions of $\varphi$. An action is \textit{private} if all its preconditions and effects are private. All other actions are classified as \textit{public}. That is, $\varphi$'s private actions affect and are affected only by $\varphi$'s actions, while its public actions may require or affect the actions of other agents. For ease of the presentation of our algorithms and their proofs, we assume that all actions that achieve a goal condition are considered \textit{public}. Our methods are easily modified to remove this assumption.

%We note that while the notion of private\slash public is natural to the \mastrips\ encoding, it can easily be applied in models having multi-valued variables. For example, in SAS+, where each variable may have multiple values, the analogous of a (boolean) proposition in \mastrips\ is a $\langle \mathrm{variable},\mathrm{value} \rangle$ pair. Such a pair is considered private if it is required, achieved or destroyed only by the actions of a single agent. Consequently, actions which require, achieve or destroy only private $\langle \mathrm{variable},\mathrm{value} \rangle$ pairs are considered private. For clarity and consistency with previous work we use \mastrips\ notation when discussing the theoretical aspects of our work. However, the examples given, as well the practical framework we present for MA planning, use the more concise multi-valued variables SAS+ encoding.

Work on privacy-preserving multi-agent planning seeks algorithms that generate good, or possibly optimal plans while not disclosing private information about their actions and the variables that they manipulate. For this to be meaningful, one has to first define what information is private and what information is not. Here we focus on the standard notion of private actions and private propositions. Thus, each action $a_i\in A_i$ is either {\em private} to agent $\varphi_i$ or {\em public}. Similarly, each proposition $p$ is either private to some agent $\varphi_i$ or public. To make sense, however, $p$ can be private to agent $\varphi_i$ {\em only\/} if $p$ does not appear in the description of an action $a_j\in A_j$ for $j\neq i$. Similarly, $a_i$ can be
private to  $\varphi_i$ only if all propositions in $a_i$'s preconditions are either public or private to $\varphi_i$
and all propositions in $a_i$'s 
effects are private to $\varphi_i$.

Hence, a {\em privacy preserving \mastrips\ problem} (\pp) is defined by as a set of
local planning problems:
$\Pi=\{\Pi_i : i=1,\ldots,k\}$
where 
$\Pi_i = \langle P_i^{\mathrm{prv}},P^{\mathrm{pub}},A_i^{\mathrm{prv}},A_i^{\mathrm{pub}},I_i,I^{\mathrm{pub}},G \rangle$. Here, $I^{\mathrm{pub}}$ is the value of $P^{\mathrm{pub}}$ in the initial state, and
the
goal is shared among all agents and
involves public propositions only. Furthermore, any action $a\in A_i^{\mathrm{prv}}$  involves private propositions only. 
We use $A_i$ to denote $A_i^{\mathrm{prv}}\cup A_i^{\mathrm{pub}}$.
A solution for a \pp\ problem is the sequence of all the public actions in a solution for the
\mastrips\ problem. 

We note that  a more refined notion of privacy was suggested in~\cite{,}. While we believe that the ideas discussed in this paper
can be extended to this setting, we leave this for future work.

Recall that in classical planning, we assume that the world state is fully observable to the acting agent and actions are deterministic. The multi-agent setting shares these assumptions, except that full observability is w.r.t.~the primitive propositions in 
$P_i^{\mathrm{prv}}\cup P^{\mathrm{pub}}$.


An issue that often arises is whether private goals should be allowed, or should all goals be public. Public goals make it easier for all agents to detect goal achievement, and have been assumed in most past work. As there is a simple reduction from private to public goals, albeit one that makes public the fact that all private goals of an agent have been achieved, we will maintain the assumption that all goal propositions are public.


Next, we define the notion of a \emph{public projection}. The \textit{public projection} $\pi_{\mathrm{proj}}(a)$ of an action
$a\in A_i$, $a=\langle \pre(a),\eff(a) \rangle$, is defined
as  $\pi_{\mathrm{proj}}(a)=\langle \{ p\in P^{\mathrm{pub}} | p\in\pre(a) \},\{\ell\in P^{\mathrm{pub}} | \ell\in\eff(a)\} \rangle$. That is, the same action, but with its private propositions removed.
Accordingly, $\pi_{\mathrm{proj}}(a)$ for $a\in A_i^{\mathrm{prv}}$ is empty. 
The \textit{public projection} $\pi_{\mathrm{proj}}(s)$ of a state is the partial assignment obtained by projecting $s$ to $P^{\mathrm{pub}}$.

Now, we define 
% the public projection of $\Pi_i = \langle P_i^{prv},P^{pub},A_i^{prv},A_i^{pub},I_i,I^{pub},G \rangle$ to be
% $\pi_{proj}\Pi_i = \langle P^{pub},\{\pi_{proj}(a) | a\in A_i^{pub}\},\pi_{proj}(I_i),G \rangle$. And the 
$\pi_{\mathrm{proj}}(\Pi)$, the
public projection of 
$\Pi=\{\Pi_i : i=1,\ldots,k\}$ to be 
the \strips\ planning problem:
$\langle P^{\mathrm{pub}},\{\pi_{\mathrm{proj}}(a):a\in A^{\mathrm{pub}}_i,1\leq i \leq k\},I^{\mathrm{pub}},G\rangle$.




%todo Example. Ronen.

The \emph{search-tree} induced by a planning problem plays a key role in our definition of privacy in distributed forward search planning.

\begin{definition}
The search tree associated with an MA planning problem $\Pi=\langle P,\{A_i\}_{i=1}^{k},I,G \rangle$, denoted by $\ST(\Pi)$, is a tree inductively defined below, where 
every node is labeled by a state and is either private to some agent or public, and every edge is labeled by an action.  
The root is labeled by $I$, and is public. The children of a node $v$ labeled by a state $s$ are defined as follows:
\begin{itemize}
\item
If $v$ is public, then for every $a$ applicable in $s$ there is a child labeled by  $a(s)$. %(Duplicate states are ignored).   
\item
If $v$ is private to $\varphi_i$, then for every $a\in A_i$ applicable in $s$ there is a child labeled by  $a(s)$.
\item In both cases, the node $a(s)$ is public if $a$ is public, and $a(s)$ is  private to $\varphi_i$
if $a$ is private to $\varphi_i$.
\item The edge from $s$ to $a(s)$ is labeld by $a$.
\end{itemize}
We will also assume the existence of some lexicographic ordering over states which defines
the order of the children of a node. We assume that public variables appear before private variables in this order.
\end{definition}

Next we define a concept of the public projection of a search tree. First, we project all states into their public parts.
Then, we connect every public node to its closest public descendants, remove all private nodes, and remove duplicate
children in the resulting tree. Formally:
\begin{definition}
The \emph{public-projection of the search
tree of $\Pi$} (denoted $\PST(\Pi)$) is a  tree, defined below, whose nodes are labeled by assignments to the public variables of $\Pi$
and edges are labeled by public actions. 
Each node in $\PST(\Pi)$ corresponds to a list of public nodes in the search-tree $ST(\Pi)$, where the public states of all the nodes in the list are the public state of the node in $\PST(\Pi)$ (this list is used only to construct $\PST(\Pi)$ from $\ST(\Pi)$ and is not part of $\PST(\Pi)$).
The tree is inductively defined. 
\begin{itemize}
\item
The root of $\PST(\Pi)$ 
corresponds to the root of $\ST(\Pi)$ and is labeled by $I^{\mathrm{pub}}$. 
\item
Let $w$ be a node in $\PST(\Pi)$, with public state $s$, that corresponds to  public nodes $v_1,\dots,v_k$ in the search tree $\ST(\Pi)$. Denote the (public and private) states of $v_1,\dots,v_k$ by $s_1,\dots,s_k$ respectively. We define the children of  $w$
in two stages:
\begin{itemize}
\item
First, for every $i\in\set{1,\dots,k}$ and every public descendants  $v'$ of $v_i$ such that 
all internal nodes in the path from $v_i$  to $v'$ are private, i.e., 
the labels of the edges on the path from $v_i$ to $v'$ are actions $a_1,\ldots,a_\ell$ such that $a_1,\ldots,a_{\ell-1}$ are private actions and $a_\ell$ is a public action,
we construct a child $w'$.
We label the edge from $w$ to $w'$ by the last actions on this path, namely, by $a_\ell$.
The public state of $w'$ is the public state in $a_k(\cdots a_2(a_1(s_i)))$ and we associate 
$v'$ to $w'$.
\item
 We remove duplicated children. That is, if $w_1$ and $w_2$ are children of $w$ such that the actions labeling the edges $(w,w_1)$ and $(w,w_2)$ are the same and the public states of $w_1$ and $w_2$ are the same, then we merge $w_1$ and $w_2$ and associate all the nodes associated to them to the merged node. We repeat this process until there are no children that can be merged. 
\end{itemize}
\end{itemize}
\end{definition}

%Intuitively, \red{the private tree} is the tree obtained from the original search-tree by connecting every public node
%to its nearest public descendants, combining identical children, and projecting the state into its public variables.
%In a distributed system of fully-cooperative agents privacy is not an issue, and so the distinction between private and public actions is not essential, although it can be exploited for computational gains~\cite{Brafman200828}. However, there are settings in which agents collaborate on a specific task, but prefer not to reveal private information about their local states, their private actions, and the cost of these private actions.
%They wish only to make their public interface known -- i.e., the public preconditions and effects of their actions.

%This setting is the planning equivalent to the area of distributed CSPs, where agents must coordinate (e.g., schedule a meeting) while keeping certain constraints and private variables private. We will refer to algorithms that plan without revealing this information as \emph{privacy preserving} (distributed) planning algorithms. More specifically, in a privacy-preserving algorithm the only information available about an agent to others is its set of public actions, projected onto public propositions. This can be viewed as the interface between the agents. Information about an agent's private actions and private aspects of a public action are known to the agent only.




%\section{Lossless Projection}
%We now introduce two domain transformations, one lossy, and one lossless. They will serve as two ends of the spectrum of privacy.
%
%The {\em lossless projection\/} of a planning domain transforms the original set of actions by compiling away private actions.
%A conceptually simple (though inefficient) way of doing this is by generating for every agent and for every pair of partial assignments $\tau,
%\tau'$ such that $\tau'$ extends the set of precondition of one of the agent's public actions, a macro whose preconditions are $\tau$ and
%effects are $\tau'$. Macros with weaker preconditions but identical effects can be removed.
%agent's private variables, a macro that achieves
%The new domain is obtained by applying the following transformation repeatedly, until all private actions are removed.
%If $a_{pr}\in A_i$ is the private action of agent $\varphi_i$ selected next, define:
%$$ A_i := A_i \cup \{a_{pr}\cdot a | a\in A_i \mbox{ is public and }a_{pr}\mbox{ does no negate a precondition of }a\}\setminus
%\{a_{pr}\}$$
%
%Note that the newly generated actions are all public, by definition. Thus, after performing this process for all private actions,
%the resulting domain contains public actions only, although it may contain private variables.
%
%\begin{claim}
%A \mastrips\ planning problem $\Pi$ is solveable iff its lossless projection is solveable.
%\end{claim}
%There is a problem here because of the order induced on actions by the order in which actions are removed.
%
%A different form of projection, called the public projection, was introduced in~\cite{}. It basically contains all non-private actions, stripped of their private preconditions and effects. Formally for an action $a$, define $a^{pub}$ to be ...
%Now define the set of actions.
%Do this analogously in the case of the lossless, defining a new planning problem. Consider also what happens to the initial state.


\section{Privacy Guarantees}
The main property of interest from a solution algorithm to
a \pp\ planning problem, aside from soundness and completeness, is the level of privacy it preserves.
The main privacy-related question one asks regarding a \pp\ algorithm  is whether coalitions of agents participating in the planning algorithm will be able to gain information about the private propositions and actions of other agents.

In what follows we work under the following assumptions:
\begin{itemize}
\item Agents are {\em honest, but curious\/}. This is a well known assumption in secure multi-party computation (see, e.g.,~\cite{LindellP10}).
According to this assumption, which we believe applies to many real-world interactions among business partners and ad-hoc teams,
the agents perform the algorithm as specified, but are curious enough to collude and try to learn what they can about the other agents without acting maliciously. (Alternatively, consider malicious agents that  eavesdrop on the communication among agents, but are not part of the team, so they cannot intervene.) 
%\item There are no private communication channels (\rnote{why do we care about this}
\item The algorithm is synchronous. That is agent operate with a common clock, and send messages in rounds and
these messages are immediately delivered without corruption or delay.
\item Perfect security, that is, even an unbounded adversary cannot learn any additional information beyond the leakage function (defined below).
\end{itemize}


To date, most work was satisfied with algorithms that never explicitly expose private information, typically by encrypting this information prior to
communicating it to other agents. Consequently, we say that an algorithm is {\em weakly private\/} if the names of private actions and
private state variables and their values are never communicated explicitly.

However, the fact that information is not explicitly communicated is not sufficient. Consider, for example an algorithm in which agents share with each other their complete domains, except that the names of private actions and state variables are obfuscated by (consistently) replacing each with some
arbitrary random string. This satisfies the requirement of weak privacy, but provides the other agents with a complete model that is isomorphic to the real model. For example, imagine a producer who expects exclusivity from its suppliers. With this scheme, the producer will not know the real names of other customers of its suppliers,
but it will certainly learn of their existence. Similarly, a shipping company may not want to have others learn about the size of its fleet, or the number of workers it employs.

At the other extreme we have {\em strong privacy\/}. We say that an algorithm is {\em strongly private\/} if no coalition of agents can deduce from the information
obtained during a run of this algorithm any information that it cannot deduce from the public projection of the planning problem,
the private information the coalition has (i.e., the initial states and the actions of the agents in the coalition), and
the public projection of ``its solution''. As we are considering search problems, where many 
solutions can exists, the traditional privacy definition for functions does not apply. The problem is that the solution chosen by the algorithm can leak information (e.g., 
an algorithm that returns the lexicographically first solution leaks no previous solutions exists). See \cite{BeimelCNW08} for a discussion on this problem and a suggestion of a definition of privacy for search problems.

Furthermore, strong privacy is likely to be very difficult to achieve and to prove unless stronger cryptographic methods are introduced. With
the latter, it will be
possible to develop algorithms that are strongly private, but, at least
with our current knowledge, this is likely to come at substantial computational cost that will render them not practical for the size of inputs we would like to consider.
Weak privacy, on the other hand, seems too weak in most cases, and provides no real guarantee, as it is not clear what information is deducible from the algorithm. 

Given this state of affairs, where in the existing algorithms strong privacy is not as practical as desired, whereas weak privacy tells us little, if anything, about the information that might be leaked, it is
important to provide tools that will specify the privacy guarantees of existing and new algorithms.
Here we would like to suggest a type of privacy ``lower-bound'' in the form of an indistinguishability guarantee. More specifically, given a function $\beta$ defined on planning domains, we say that an algorithm is \emph{$\beta$-indistinguishable},
if a coalition of agents participating in the planning algorithm  solving a problem $\Pi$ cannot distinguish between the current domain and any other domains $\Pi'$ such that $\beta(\Pi) = \beta(\Pi')$. We provide two equivalent definitions of privacy. 

We define the view of the of a set of agents $T$, denoted $\view_T(x)$, 
in an execution of a deterministic algorithm with inputs $x=(x_1,\dots,x_n)$
as all the information it sees during the execution,
namely,  %the public information $\pi_{\mathrm{proj}}(\Pi)$, 
the inputs of the agents in $T$ (namely, $(x_i)_{i\in T}$)
and the messages exchanged during the execution of the algorithm.

\begin{definition}
\label{def:ind-dist}
Let $\beta:\set{0,1}^*\rightarrow \set{0,1}^*$ be a (leakage) function. We say that a deterministic algorithm is \emph{$\beta$-indistinguishable} if for every set $T$ of agents and for every two inputs
$x=(x_1,\dots,x_n)$ and $y=(y_1,\dots,y_n)$ such that $x_i=y_i$ for every $i \in T$ and $\beta(x)=\beta(y)$ the view of $T$ is the same,
i.e., $\view_T(x)=\view_T(y)$.
\end{definition}

\begin{definition}
\label{def:ind-sim}
Let $\beta:\set{0,1}^*\rightarrow \set{0,1}^*$ be a (leakage) function. We say that a deterministic algorithm is \emph{$\beta$-indistinguishable} if there exists a simulator $\Sim$ such that for every set $T$ of agents and for every input
$x=(x_1,\dots,x_n)$ the view of  $T$ is the same as the output of the simulator that is given $(x_i)_{i\in T}$ and $\beta(x)$, i.e., $\Sim(T,(x_i)_{i\in T},\beta(x))=\view_T(x)$.
\end{definition}

In \cref{def:ind-sim}, the simulator is given the inputs of the agents in $T$ and $\beta(x)$ -- the output of the leakage function applied to the inputs of all agents. The simulator is required to produce all the messages that were exchanged during the algorithm.
If such simulator exists, then all the information that the adversary can learn from the execution of the algorithm is implied by the inputs of the parties in $T$ and $\beta(x)$. 


\begin{claim}
The two definitions are equivalent.
\end{claim}
\begin{proof}
Assume that an algorithm is $\beta$-indistinguishable according to \cref{def:ind-sim}. 
Let 
$x=(x_1,\dots,x_n)$ and $y=(y_1,\dots,y_n)$ be two inputs
such that $x_i=y_i$ for every $i \in T$ and $\beta(x)=\beta(y)$.
Thus, 
%\begin{equation}
$\Sim(T,(x_i)_{i\in T},\beta(x))=\Sim(T,(y_i)_{i\in T},\beta(y)).$
%\end{equation} 
Therefore, by \cref{def:ind-sim},
$\view_T(x)=\Sim(T,(x_i)_{i\in T},\beta(x))=\Sim(T,(y_i)_{i\in T},\beta(y))=\view_T(y)$.

Assume that an algorithm is $\beta$-indistinguishable according to \cref{def:ind-dist}. Let 
$x=(x_1,\dots,x_n)$ be any input. We define a simulator for the algorithm.
Given $T,(x_i)_{i\in T},\beta(x)$ we construct a simulator $\Sim$ as follows:
\begin{itemize}
\item
Finds inputs $(y_i)_{i \notin T}$
such that $\beta(y)=\beta(x)$, where $y_i=x_i$ if $i \in T$.
\item
Outputs $\view_T(y)$. 
\end{itemize}
By \cref{def:ind-dist}, $\view_T(x)=\view_T(y)$, thus,
$\Sim(T,(x_i)_{i\in T},\beta(x))=\view_T(x)$, as required in \cref{def:ind-sim}.
\end{proof}
%\anote{We should choose one of the above two definitions.}


Note that the simulator is not given the output of the function computed by the algorithm, information that is implied by the messages exchanged in the algorithm. 
The simulator can compute the view of $T$, hence the output, from the information it gets.
This implies that the leakage $\beta(x)$ (together with $(x_i)_{i\in T}$) determines the output of the algorithm. This is an important feature of our definition, as we consider search problems where there can  be many possible outputs. The output that an algorithm returns might leak information on the inputs (see~\cite{BeimelCNW08}), and it is not clear how to compare the privacy provided by two algorithms returning different solutions. Our definition bypasses this problem as it explicitly specifies the leakage.   

In this paper, we will focus on a particular function $\beta$ that returns the public projection of the
problem's search tree. That is, the algorithms we will consider will have the property that a set of agents
cannot distinguish between two problem instances whose public projection and their PST are identical.
We will refer to this as {\em PST-indistinguishable security}.


%For this we propose the following definitions: Let {\cal P} be a class of planning domains with an identical public projection.
%We say that  algorithm {\cal A} is  {\em private with respect to {\cal P} and agent $\varphi_i$\/} if all other agents learn the same
%information about $\varphi_i$'s private actions and private variables in any execution of {\cal A} on any problem in  {\cal P}.
%We say that  algorithm {\cal A} is  {\em one-run private with respect to {\cal P} and agent $\varphi_i$\/} if all other agents learn the same
%information about $\varphi_i$ given any single execution of {\cal A} on any problem in  {\cal P}.
%To see the difference, suppose that {\cal A} is a probabilistic algorithm that may behave differently in different runs on the same inputs.
%If {\cal A} is  private with respect to {\cal P} and agent $\varphi_i$ then the distribution over information gained by different runs of {\cal A}
%must be identical on all problems in {\cal P}. If {\cal A} is  one-run private with respect to {\cal P} and agent $\varphi_i$ then if a run of {\cal A} on
%a problem $\pi\in{\cal P}$ yields some information, there must be a run of {\cal A} on
%a problem $\pi\in{\cal P}$ that yields the same information. Thus, when the algorithm is executed once on a problem, the other agents cannot
%rule out any other problem in {\cal P}. Finally, when {\cal A} is probabilistic, we can strengthen the last definition and say that
% {\cal A} is  {\em one-run private with respect to {\cal P} and agent $\varphi_i$ with probability $p$} if for every two problems $\pi, \pi' \in{\cal P}$
% the probability that a single execution of {\cal A} will yield the same information to some other agent is at least $p$.

A recently proposed example of privacy w.r.t.\ a class of domains is {\em cardinality preserving privacy}~\cite{MaliahSS17} where the idea is that agents cannot 
learn the number of values of a some variable, such as the number of locations served by a track.
(Defining this formally requires using multi-valued variable domains.)
Another notion of privacy recently introduced is \emph{agent privacy}~\cite{FaltingsLP08} in which agents are not aware
of other agents with whom they do not have direct interactions -- i.e., agents that require or affect
some of the variables that appear in their own actions.  This notion is more natural when such interactions
are explicitly modelled using the notion of subset-private variables~\cite{Bonisoli14}.
These notions seem more ad-hoc and weaker than our definition of privacy.
 We will not discuss these notions in this paper.


\section{A PST-Indistinguishable Algorithm}

The goal of this section is to show that \smafs\ is PST-Indistinguishable. We will do it by gradually refining a very simple (and inefficient) algorithm to obtain an algorithm that is essentially identical to \smafs, which, as shown by~\cite{MaliahSB16}, is quite efficient in practice, and thus the first algorithm to be both practical and have clear theoretical guarantees. 
This gradual progression will make the proofs and ideas simpler.

\subsection{A Simple Algorithm}
We start with a very simple algorithm, which we shall call PST-Forward Search.
The algorithm simply constructs $\PST(\Pi)$ -- the public-projection of the search
tree of $\Pi$. 
The search progresses level by level in the public-projection of the  search tree. In a given level of the tree, each agents $\varphi_i$: (1) computes the children of all the nodes in $\PST(\Pi)$, where a child of a node results from a sequence of private actions followed by a single public action by the agent, 
and (2) sends the public state of each child (as well as a description of the path to the child) to all other agents (removing duplicates). 
The PST-Forward Search algorithm is described in \cref{alg:simple-search}. 
In this algorithm, the agents maintain a set $Q_{d}$ for every level $d$ in the tree, 
which will contain all nodes in level $d$.
Every element in the set is a node represented as a pair $(\vec{s},\vec{a})$, where $\vec{s}=(s_0,\dots,s_m)$ is a sequence of public states such that $s_0=I^{\mathrm pub}$ and $\vec{a}=(a_1,\dots,a_m)$ is a sequence of public actions.
Such a pair describes a path in the PST from the root to the node in level $d$.
To find the actions that an agent can apply from a node, it needs to compute the possible private states of that node,
as this information is not contained in the message it received. To do this\red{,} the agent reconstructs its private
state, as described in Algorithm {\bf compute-private-states}. This is, of course, highly inefficient, but has the
desired privacy property.

%\vspace{-5pt}
%\begin{algorithm}
%\caption{Simple Private Search Algorithm}
    %\label{alg:simple-search}
%\begin{algorithmic}[1]  %[n] = every n'th line is numbered
%\STATE Each agent holds a copy of the same prefix $T$ of $\PST(\Pi)$. 
%\STATE Initialization: Each agent holds the root of the tree labeled by $I^{\mathrm{pub}}$.
%\WHILE{goal has not been achieved}
 %\STATE Let $v$ be the next node in a BFS tour of $T$ and $s$ be its state. 
 %\FOR{$i=1$ \TO $n$ }
  %\STATE Agent $\varphi_i$ reconstructs its private state $s_i$ in $v$ starting from $I_i$ and updating it according to its actions on the path from the root to $v$.
	%\FORALL{sequences $a_1,\dots,a_k$ in $A_i$ applicable from $s,s_i$, where $a_1\dots,a_{k-1}$ are private and $a_k$ is public}
		%\STATE Agent $\varphi_i$  computes $s',s'_i \gets a_k(a_{k-1}(\cdots a_1(s,s_i)))$.
		%\STATE Agent $\varphi_i$ sends $a_1,\dots,a_k,s'$ to all other agents.
		%\STATE All agents add a new node $w$ as a child of $v$ in the tree. 
		%\STATE The state of $w$ is $s'$ and the label of the edge between $v$ and $w$ is $a_1,\dots,a_k$. 
		%\STATE If $s'$ satisfies the goal, then output the actions on the path from the root to $w$ and halt.
	%\ENDFOR
	%\ENDFOR
%\ENDWHILE
%\end{algorithmic}
%\end{algorithm}

\begin{algorithm}
\caption{PST Forward Search}
    \label{alg:simple-search}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
%\STATE Each agent holds a copy of the same prefix $T$ of $\PST(\Pi)$. 
\STATE {\bf initialization:} $d \gets 0$; for $i \in \set{1,\dots,n}$ set $Q_{0}=\set{(I^{\mathrm{pub}},\epsilon)}$.\\
// $Q_d$ will contain the states at level $d$ of the PST. Each agent maintains a copy of it.
%Each agent holds the root of the tree labeled by $I^{\mathrm{pub}}$.
\WHILE{goal has not been achieved}
   \STATE $d\gets d+1$; for every $i \in \set{1,\dots,n}$ agent $\varphi_i$ sets $Q_{d}\gets\emptyset$ and $C_i\gets \emptyset$.
   \FOR{$i=1$ \TO $n$ }
	    \STATE Agent $\varphi_i$ does the following:
      \FORALL{$(\vec{s},\vec{a})\in Q_{d-1}$}
         \STATE let $s$ be the last state in $\vec{s}$.
         \STATE executes $PS\gets $\textbf{ compute-private-states}$(i,\vec{s},\vec{a})$.
				
  	     \FORALL{private state $ps \in PS$}
				\FORALL{sequence $a_1,\dots,a_\ell$ of actions of $\varphi_i$ applicable from $s,ps$, where $a_1\dots,a_{\ell-1}$ are private and $a_\ell$ is public }
		        \STATE computes $(s',ps') \gets a_\ell(a_{\ell-1}(\cdots a_1((s,ps))))$ and $C_i \gets C_i \cup \set{((\vec{s},s'),(\vec{a},a_\ell))}.$
		     
	       \ENDFOR
				\ENDFOR
	    \ENDFOR
			\STATE sends $C_i$ to all agents (where the elements of $C_i$ are sent according to some canonical order).
		  \STATE each agent $\varphi_j$ updates its copy: $Q_{d}\gets Q_{d} \cup C_i$.
      \IF{the last state $s'$ in some $((\vec{s},s'),(\vec{a},a_\ell)) \in C_i$ satisfies the goal}
				\STATE	all agents output $(\vec{a},a_\ell)$ and halt. 
			\ENDIF
	\ENDFOR
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{compute-private-states$(i,\vec{s}=(s_0,\dots,s_m),\vec{a}=(a_1,\dots,a_m))$}
    \label{alg:CompPrivate}
\begin{algorithmic}[1]
\STATE\COMMENT{The algorithm reconstructs the possible private states of agent $\varphi_i$
			  starting from $I^{\rm pub},I_i$ and updating it according to the states is $\vec{s}$ and the actions of $\varphi_i$ in $\vec{a}$.} 
\STATE let $PS_0\gets\set{I_i}$.
   \FOR{$j=1$ \TO $m$}
	 \IF{$a_j$ is not an action of $\varphi_i$}
	    \STATE{$PS_j\gets PS_{j-1}$.}
			\ELSE
			\STATE $PS_j\gets \emptyset$.
			\FORALL{$ps \in PS_{j-1}$ and  sequence of private actions 
			$a'_1,\dots,a'_{\ell}$ in $A_i$ such that $a'_1,\dots,a'_{\ell},a_j$ is applicable from $s_{j-1},ps$}
			  \STATE let $(s',ps') \gets a_j(a'_{\ell}(\cdots a'_1((s_j,ps))))$.
				\red{
				\IF{$s'=s_j$}
					\STATE{$PS_j\gets PS_j\cup \set{ps'}$.}
				\ENDIF
				}
			\ENDFOR
	 \ENDIF
   \ENDFOR
	\RETURN{$PS_m$.}
\end{algorithmic}
\end{algorithm}
%Initially all agents start with a single element in their open list: the public
%projection of the initial state and the empty action sequence. 
%At each step, the agent 1) removes the first element from its open list, 2) generates all private states consistent with this projected state and its associated action sequence (see below), 3) for every projected state
%and private state consistent with it, it expands this state using all possible actions sequences containing and ending with a single
%public action, 4) projects the resulting states back to their public part and augments their action sequence
%with the public action is performed, 5) orders the projected state based on some lexicographic order. Having done this to all elements of its open list, it sends the resulting state/actions pairs and updates its open list with them.

%To generate all private states consistent with the project state and the action sequence (step 2), the agent recreates its past work. That is, it takes the initial state, applies the prefix of relevant actions
%in the sequence up to, but not including, its first action. At this point, it recreates the work it did to
%apply this first action, which could be diverse sequences of private actions. Using these sequences it recreates the (possibly many) private states obtained after applying the  action sequence. It continues with this simulation process until the end of the associated action sequence, and now has all the possible values of its private state that could occur with this action sequence.


In  \cref{alg:simple-search}, the messages sent correspond exactly to the PST nodes, 
and therefore, two domains with an identical PST will yield identical messages. To enable an exact simulation, we need to specify the order in which each agent sends the possible sequences of children in a given level; we assume that this is done in some canonical order. We supply the formal proof of privacy in the next claim.
\begin{claim}
\cref{alg:simple-search}, the simple private search algorithm, is a PST-indistinguishable secure algorithm.
\end{claim}
\begin{proof}
The simulator, given the PST $T$, traverses the tree level by level, 
in each level $d$ it goes over all agents $\varphi_i$ starting from $\varphi_1$ and ending at 
$\varphi_n$, and for each agent $\varphi_i$ it sends the nodes of level $d$ resulting from an action of $\varphi_i$,  where for each node it sends the public states and the actions on the path from the root to the node. The order of sending the nodes is as in the algorithm, according to the fixed canonical order.  
\end{proof}

\subsection{Using IDs}

%Next, observe that since the expansion is level by level, an agent will receive at some point,
%all nodes at the same level of the PST. Suppose that they generated the same public projection
%$s_p$ from two different siblings. They need not send this twice, but instead, can send $s_p$
%with all the associated action sequences. Again, there is no problem reproducing the different cases,
%from these sequences. Thus, we can allow agents to send the same projected state with a set
%of action sequences. 
%
%\rnote{It seems to me that this would work also in the following case. The agent generated $s_p$ 
%at level $k$. Later it generates $s_p$ again at level $k'>k$. It can now associate with
%$s_p$ the sequences corresponding to the states at level $k$ and at level $k'$. This is a function
%of the tree. However, if we assume that the agents first completes a level
%of the tree, sends everything and then continue, then it is not clear how this could occur.
%}

Next, we present an optimization of \cref{alg:simple-search}, which eliminates the need to compute private states, and merges some nodes in the tree, reducing the communication complexity of the algorithm. 
We call this version: PST-ID Forward Search.

%We next explain how we can avoid computing the possible private states for each node. 
Notice that only actions of $\varphi_i$ change the local state of $\varphi_i$. 
There are two approaches to use this observation.
In one approach,  for each node that is sent, the agent sending the node can locally keep  a list containing its possible local states in that node. When an agent wants to  compute  the children of some node, it looks for its last action in the path to the node and retrieves its possible local states after that action. 
%
%Consider the path information associated with each node in the PST sent in \cref{alg:simple-search}.
%To recreate its local state, the agent needs only to know its own actions in the sequence and the pubic states before each such state is executed --
%the actions of the other agents affect the public variables only, and it already knows their  values.
%Thus, instead of associating action sequences with each project state, we can associate a vector of action sequences,
%one per each agent. Since each agent cares only about its component of this vector, it can replace this action
%sequence with a unique ID -- maintaining the correspondence between the ID and its actions in its memory.
%Again, throughout, PST-indistinguishability is maintained, as the information sent is a function of the
%the PST. 
In the second approach, which we use, each agent associates the possible local states with a unique id and keeps the possible local states associated with this id.  Each time  an agent sends a node in the tree, it sends the public state of the node as well as the $n$ ids, encoding the local states of each agent. Notice that each id is not a function of these local states, but only of the particular PST node with which it is associated. When an agent wants to compute the children of a node resulting from its actions, it does the following: 
\begin{itemize}
\item
It retrieves all private states associated with its id in this state.  
\item
It expands the public state  and each possible private state using all possible actions sequences containing and ending with a single public action.
\item
For every  node reached, it generates a new id and associates
with it its local state in the states generated with this projected state,
keeping the ids of all other agents associated with the original node.
\item 
It orders the nodes based on some lexicographic order.
\item
It sends these nodes,  with their public states and their associated ids, in this order to all agents. 
\end{itemize}

Note that the above algorithm sends at each stage a vector consisting of a public state and an id for
each agent. As this id encodes the private state(s) of the agent, we can think of the message as representing the state, with its private components encoded.  The agent does not need to send neither the actions leading to the new node nor the father of the new node. Furthermore,
if two (or more) children  of a node have the same public state, the agent does not need to send them twice;
it can send one public state, together with the ids of the other agents taken from the original node, and one new id for the agent associated with  all its possible private states associated with any one of these children.  We go one step further,  merging all nodes generated by an agent in level $d$ (possibly with different fathers) if they have the same public state and the same ids for all other agents.


The formal description of the algorithm appears in \cref{alg:less-simple-search}.
The algorithm that recovers a solution after the goal has been reached is described in \cref{alg:recover-solution}.
 
\begin{algorithm}
\caption{PST-ID Forward Search}
    \label{alg:less-simple-search}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
%\STATE Each agent holds a copy of the same prefix $T$ of $\PST(\Pi)$. 
\STATE {\bf initialization:} $d \gets 0$; for every $i \in \set{1,\dots,n}$ agent $\varphi_i$ sets  $id_i\gets 0$, $Q_{0}\gets \set{(I^{\mathrm{pub}},0,\dots,0)}$, and $PS_{i}[0]\gets \set{I_i}$. \\
//$PS_{i}[j]$ denotes the local states $\varphi_i$ associated with the id $j$.
%Each agent holds the root of the tree labeled by $I^{\mathrm{pub}}$.
\WHILE{goal has not been achieved}
   \STATE $d\gets d+1$; for every $i \in \set{1,\dots,n}$ agent $\varphi_i$ sets $Q_{d}\gets \emptyset$ 
	and $E_i\gets \emptyset$.
   \FOR{$i=1$ \TO $n$ }
	    \STATE agent $\varphi_i$ does the following:
      \FORALL{$(s,j_1,\dots,j_n)\in Q_{d-1}$}
            \FORALL{private state $ps\in PS_{i}[j_i]$ }
  	        \FORALL{sequence $a_1,\dots,a_\ell$ of actions of $\varphi_i$  applicable from $s,ps$, where $a_1\dots,a_{\ell-1}$ are private and $a_\ell$ is public }
		           \STATE $(s',ps') \gets a_\ell(a_{\ell-1}(\cdots a_1((s,ps))))$ 
							 \STATE $E_i\gets E_i \cup \set{(s',j_1,\dots,j_{i-1},j_{i+1},\dots,j_n,ps')}$.
						\ENDFOR
	       \ENDFOR
			\ENDFOR
			\STATE agent $\varphi_i$ sorts the elements of $E_i$, first by the public state,  then by the $n-1$ ids, and then by the private state. Let $((s^1,j_1^1,\dots,j^1_{i-1},j^1_{i+1},\dots,j_n^1,ps^1)$ 
			$\dots,(s^t,j_1^t,\dots,j^t_{i-1},j^t_{i+1},\dots,j_n^t,ps^t))$ be the sorted elements of $E_i$.
			%\STATE $C_i\gets\set{(s^1,j_1^1,\dots,j^1_{i-1},id_i,j^1_{i+1},\dots,j_n^1)}$ and $PS_{i}[id_i]\gets \set{ps^1}$.
			\FOR{$u=1$ \TO $t$}
			   \IF{$u > 1$ \AND $s^{u-1} =s^u $ \AND $(j_1^{u-1},\dots,j^{u-1}_{i-1},j^{u-1}_{i+1},\dots,j^{u-1}_n)=
				(j_1^u,\dots,j^u_{i-1},j^u_{i+1},\dots,j_n^u)$}
				    \STATE $PS_{i}[id_i]\gets PS_{i}[id_i] \cup \set{ps^u}$.
				 \ELSE
				    \STATE $id_i\gets id_i+1$.
						\STATE $C_i\gets C_i \cup \set{(s^u,j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)}$ and $PS_{i}[id_i]\gets \set{ps^u}$.
				 \ENDIF
			\ENDFOR
			\STATE $\varphi_i$ sends $C_i$ to all agents (where the elements of $C_i$ are sent according to some canonical order).
		  \STATE each agent $\varphi_j$ updates: $Q_{d}\gets Q_{d} \cup C_i$.
		\ENDFOR
		\IF{the state $s$ in some element in $Q_{d}$ satisfies the goal}
				\STATE the agents execute $sol \gets $ {\bf recover-solution},   output $sol$,  and halt.
    \ENDIF 
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\cref{alg:recover-solution} described below returns a solution to the planning problem, i.e., a sequence of public actions on a path from the root of the PST to a node in level $d$ that satisfies the goal. 
Clearly, this sequence of actions should be computed from the information computed by the algorithm so far.  
Furthermore, to guarantee privacy, this sequence of actions should be determined by the PST (that is, a simulator can generate it from the PST). In \cref{alg:recover-solution} we choose it in a specific way that is fairly efficient (especially, if the agents keep additional information during \cref{alg:less-simple-search}). 


In \cref{alg:recover-solution},  we say that 
$s_{d'-1},j_{1,{d'-1}},\dots,j_{n,{d'-1}} \in Q_{d'-1}$ 
leads to $s_{d'},j_{1,{d'}},\dots,j_{n,{d'}} \in Q_{d'}$ by agent $\varphi_i$ if
there exist private states $ps_{d-1}\in PS_{i}[j_{d'-1}],ps_d\in PS_{i}[j_{d'}]$, and a sequence of actions $a_1,\dots,a_\ell$ of agent $\varphi_i$ such that $a_1,\dots,a_{\ell-1}$ are private and $a_\ell$ is public and 
$a_1,\dots,a_{\ell}$ are applicable from $s_{d'-1},ps_{d'-1}$ and lead to $s_{d'},ps_{d'}$.

\begin{algorithm*}
\caption{recover-solution}
    \label{alg:recover-solution}
\begin{algorithmic}[1]
\STATE let $s_d,j_{1,d},\dots,j_{n,d}$ be the first element in $Q_{d}$ that satisfies the goal.
\STATE \COMMENT{recall that all agents have a copy of $Q_d$.} 
\FOR{$d'=d$ {\bf downto } 1 }
\STATE let $\varphi_i$ be the agent performing the last action leading to $s_{d'},j_{1,{d'}},\dots,j_{n,{d'}}$.
\STATE agent $\varphi_i$ finds the first element  $s_{d'-1},j_{1,{d'-1}},\dots,j_{n,{d'-1}} \in Q_{d'-1}$ 
leading to $s_{d'},j_{1,{d'}},\dots,j_{n,{d'}}$.
\STATE let $a_{d'}$ be the last action in  a sequence of actions 
leading from  $s_{d'-1},j_{1,{d'-1}},\dots,j_{n,{d'-1}}$ to $s_{d'},j_{1,{d'}},\dots,j_{n,{d'}}$
(if there is more than one such action, choose the lexicographically first action).
\STATE agent $\varphi_i$ sends $s_{d'-1},j_{1,{d'-1}},\dots,j_{n,{d'-1}}$ and $a_{d'}$ to all other agents. 
\ENDFOR
\RETURN $a_1,\dots,a_d$.
\end{algorithmic}
\end{algorithm*}

\begin{claim}
\label{c:less-simple}
\cref{alg:less-simple-search}, the PST-ID Forward Search algorithm, is a PST-indistinguishable secure algorithm.
\end{claim}
\begin{proof}
We construct a simulator proving that \cref{alg:less-simple-search} is a PST-indistinguishable secure algorithm. We first supply a high level description of the simulator.
The simulator, given the PST $T$, traverses the tree level by level and simulates the algorithm. For some level $d$, it goes over the agents from agent $\varphi_1$ to $\varphi_n$ and for each agent it produces a list $C_i$ as the agent would have sent, using the nodes in 
level $d$ resulting from an action of $\varphi_i$. Recall that each element in $C_i$ is a public state and a list of $n$ ids. To produce these ids (and to know which nodes should be merged), for every vertex $w$ in level $d$  the simulator computes a label, denoted by $L(w)$, that contains $n$ ids; this label is computed using the label of the father of a node $w$, denoted by $f(w)$. The labels of $w$ and $f(w)$ are the same except for the $i$th id, which is carefully computed to simulate \cref{alg:less-simple-search}.
After reaching  the first level in which there is a node satisfying the goal, the simulator, using the PST tree, reconstructs the solution that  
%\Crefrange{alg:less-simple-search}{alg:recover-solution} return.
\Cref{alg:recover-solution} returns.

The simulator is formally described  in \cref{sim:less-simple-search}.
The input in \cref{sim:less-simple-search} is a PST $T$\red{;} we denote its root  by $root$.
It can be easily proved by induction that the simulator computes the same messages as \cref{alg:less-simple-search}.
\end{proof}

\begin{algorithm}
%\floatname{algorithm}{Simulator}
\caption{Simulator for \cref{alg:less-simple-search} -- The  PST-ID Forward Search Algorithm}
    \label{sim:less-simple-search}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
%\STATE Each agent holds a copy of the same prefix $T$ of $\PST(\Pi)$. 
\REQUIRE A PST tree $T$
\STATE {\bf initialization:} $d \gets 0$; for every $i \in \set{1,\dots,n}$  set  $id_i\gets 0$, $Q_{0}\gets ((I^{\mathrm{pub}},0,\dots,0))$.
%Each agent holds the root of the tree labeled by $I^{\mathrm{pub}}$.
\WHILE{goal has not been achieved}
   \STATE $d\gets d+1$; for every $i \in \set{1,\dots,n}$ set $Q_{d}\gets \emptyset$,
	  $C_i\gets \emptyset$, and $\tilde{E}_i\gets \emptyset$.
	 \STATE $L[root]=(0,\dots,0)$.
   \FOR{$i=1$ \TO $n$ }
      \FORALL{node $w$ in level $d$ s.t.~the edge $(f(w),w)$ is labeled by an action of $\varphi_i$}
			\STATE let $L(f(w))=(j_1,\dots,j_n)$ and $s'$ be the state of node $w$.
      \STATE $\tilde{E}_i\gets \tilde{E}_i \cup \set{(s',j_1,\dots,j_{i-1},j_{i+1},\dots,j_n,w)}$.
			\ENDFOR
		\STATE sort the elements of $\tilde{E}_i$, first by the public state, then by the $n-1$ ids, and then by $w$. 
		\STATE let $((s^1,j_1^1,\dots,j^1_{i-1},j^1_{i+1},\dots,j_n^1,w^1),$ 
			$\dots,(s^t,j_1^t,\dots,j^t_{i-1},j^t_{i+1},\dots,j_n^t,w^t))$ be the sorted elements of $\tilde{E}_i$.
		%\STATE $C_i\gets\set{(s^1,j_1^1,\dots,j^1_{i-1},id_i,j^1_{i+1},\dots,j_n^1)}$.
		\FOR{$u=1$ \TO $t$}
			   \IF{ $u=1$ \OR $s^{u-1} \neq s^u $ \OR $(j_1^{u-1},\dots,j^{u-1}_{i-1},j^{u-1}_{i+1},\dots,j^{u-1}_n) \neq
				(j_1^u,\dots,j^u_{i-1},j^u_{i+1},\dots,j_n^u)$}
			    \STATE $id_i\gets id_i+1$.
					\STATE $C_i\gets C_i \cup \set{(s^u,j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)}$.
				 \ENDIF
				\STATE $L(w^u)\gets (j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)$.
		\ENDFOR
		\STATE send $C_i$ on behalf of $\varphi_i$ to all agents (where the elements of $C_i$ are sent according to some canonical order).
		\STATE for every $j \in \set{1,\dots,n}$ set $Q_{d}\gets Q_{d} \cup C_i$.
	\ENDFOR
	\IF{ the state $s$ in some element in $Q_d$ satisfies the goal}
				\STATE execute $sol \gets $ {\bf sim-recover-solution},   output $sol$,  and halt.
  \ENDIF 
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\begin{algorithm*}
\caption{sim-recover-solution}
    \label{sim:recover-solution}
\begin{algorithmic}[1]
\STATE let $s_d,j_{1,d},\dots,j_{n,d}$ be the first element in $Q_{d}$ that satisfies the goal
and $W_d$ be all nodes $w$ in level $d$ whose public state is $s$ and whose label $L(w)$ is
$j_{1,d},\dots,j_{n,d}$.
%\STATE \COMMENT{As $Q_{1,d}=\cdots = Q_{n,d}$, all agents know these values.} 
\FOR{$d'=d$ {\bf downto } 1 }
\STATE let $F_{d'-1}\gets \set{f(w)|w \in W_{d'}}$.
\STATE let $s_{d'-1},j_{1,d'-1},\dots,j_{n,d'-1}$ be the first element in
$\set{(s(v),L(v)|v \in F_{d'-1}}$ (where $s(v)$ is the public state in the node $v$). 
\STATE let $a_{d'}$ be the lexicographically first action labeling an edge from a node
$v \in F_{d'-1}$ such that  $s(v)=s_{d'-1}$ and  $L(v)=j_{1,d'-1},\dots,j_{n,d'-1}$
to a node in $W_{d'}$.
\STATE let $W_{d'-1}$ be all nodes in $F_{d'-1}$ such that  $s(v)=s_{d'-1}$,   $L(v)=j_{1,d'-1},\dots,j_{n,d'-1}$ and there exists an edge from them to a node in $W_{d'}$ labeled by the action $a_{d'}$.
\STATE Send the message $s_{d'-1},j_{1,d'-1},\dots,j_{n,d'-1}$  and $a_{d'}$.
\ENDFOR
\RETURN $a_1,\dots,a_d$.
\end{algorithmic}
\end{algorithm*}

\subsection{Merging More Nodes}
In PST-ID Forward Search, an agent merged two nodes if they were in the same level, they had the same public state, and the ids of the other agents were the same. The simple case when two nodes were merged is if they had the same parent and there were two sequences of actions ending with the same public state (if the last action in these sequences is the same, then they are already merged in the PPT). There are somewhat more complicated scenario when nodes are merged. For example, suppose that in some public state $s$ and private state 
$ps$ in level $d$, agent $\varphi_i$ can apply two sequences of public actions $a_1,a_2$ and $a_3,a_4$, and both sequences result in the same public state $s'$. Then, the resulting two nodes are in the same level $d+2$ and they will be merged. However, suppose that also action $a_5$ is applicable in the state $s,ps$ and results in state $s'$ (in level $d+1$). The resulting node is not in the same level and the previous nodes are not merged with the new node.
As a result, the current algorithm will send two nodes that are identical in every respect, except for its id.
One key motivation for the original \smafs\ algorithm was to prevent this situation and never send two nodes
that differ only in the private state of the sending agent.

There is a simple (though probably inefficient) way of overcoming this. For this observe that, under the 
assumption that an agent will never send two states that differ only in its own id, the only way two
states $s',s''$ generated by an agent $\varphi_i$ can be identical is if they have a common ancestor $s$, 
and $s'$ and $s''$ were generated by applying actions of $\varphi_i$ only. As in the above example, these
could be sequences containing different numbers of public actions, and hence at different levels of the PST.
However, once a public action is applied by some other agent $\varphi_j$, its id will change, and hence $s'$ and $s''$ will
differ on $\varphi_j$'s id. Given this observation, it is easy to modify PST-ID FS to have the property that
an agent $\varphi_i$ never sends two nodes that are identical in all but (possibly) its id, which we call
PST-ID-E Forward Search. Whereas in PST-ID FS an agent will send each state obtained by applying
exactly one public action, in PST-ID-E, the agent expands the entire local sub-tree below a node in its open list.
That is, it will consider state reachable by applying more than one (of its) public actions. This could be a large 
sub-tree, of course, but under the assumption that all variables have finite-domains, it is finite and with appropriate
book keeping (maintaining a closed list) can be constructed in finite time. Thus, the only change is in line 8 of~\cref{alg:less-simple-search},
where the new line is
\begin{quote}
{\bf for each} sequence $a_1,\dots,a_\ell$ of actions of $\varphi_i$  applicable from $s,ps$, where $a_1\dots,a_{\ell-1}$ are {\em public or private} and $a_\ell$ is public {\bf do}.
\end{quote}


\begin{claim}
\label{c:psd-id-e}
The PST-ID-E Forward Search algorithm is a PST-indistinguishable secure algorithm.
\end{claim}
\begin{proof}
This follows immediately from the proof of~\cref{c:less-simple} using the following observation:
Take the PST, and add to it additional edges between every node and all its descendants that
are reachable using public actions of the same agent only. Now, use the simulator for PST-ID FS
on this modified tree.
\end{proof}

Note that given the modified tree in the proof above, it is possible to recover the original ordering by 
simply taking into account the number of public actions that were applied in the path from the initial
state to the current state.

\begin{claim}
\label{c:psd-id-e-differ}
In the PST-ID-E Forward Search algorithm, an agent never sends two states $s,s'$ that differ only in its own id.
\end{claim}
\begin{proof}
Consider two states $s,s'$ sent by an agent $\varphi_i$ during the run of the algorithm. Let the level of a state denote
the number of times (plus 1) a public action was applied in the path to this state by an agent such that this agent did not apply
the previous public action on the path.
First, assume that $s,s'$ have a common ancestor such that all actions on the paths from this ancestor to
$s$ and $s'$ are of the same agent $\varphi_i$. In this case, if they are identical in all other respects, 
an id that contains both their private states is formed, and only one state is sent.
Suppose that $s,s'$ do not have such ancestor.  Consider the sequence of states sent by agents on the paths from the root to $s$ and $s'$.
At some points, these states differ, and hence the id of the agent that sent the states will differ too. But from this point on,
the ids of all sending agent must change.
\end{proof}




\subsection{Heuristic Search}
So far, the algorithms we described expanded nodes in breadth-first manner, and followed some canonical
ordering within each level. PST-ID-E also fits this view, when levels are defined such that the level increases
only when a public action is applied by an agent who did not apply the last public action.
However, the privacy guarantees do not rest on this property. 
In principle, the PST can be traversed in any order, and all the above results are correct provided the
traversal ordering is a function of the PST only. Thus, for example, any heuristic search algorithm can be used, provided the heuristic
depends on the history of the public part of the state only, or on the current public state.
This follows trivially from the fact that a simulator that has access to the PST can simulate any such ordering.



\subsection{\smafs}




We are now ready to describe a PST-indistinguishable secure algorithm that is essentially 
a synchronous, breadth-first version of  \smafs~\cite{Brafman15}. 
\smafs\ is similar to PST-ID Forward Search (i.e., a message is sent after the application of a public action),
except that an agent never sends two states that differ only in its own private state -- in our case, its own id. 
The PST-ID-E algorithm has this property, but requires that an agent first explore its entire sub-tree.


To prevent resending identical states (modulo its own id), in \smafs\ the agent must maintain a list of states sent so far. Whenever it wishes to send a state $s$ with local state $ps$, it first checks if the state $s$ was sent before. If it was, it simply updates the id associated with $s$ to include $ps$.

\begin{figure}[ht]
\centerline{
\includegraphics[width=0.5\textwidth,height=7cm]{FigExample1.pdf}}
\caption{\label{fig:example1}An example for \smafs.} 
\end{figure}

However, this change alone is insufficient to maintain completeness. See Figure~\ref{fig:example1} for illustration of the following example. Consider some state $s$ that is
being expanded by $\varphi_i$. Suppose that the non-private part of the state is identical in  $s'=a_2(a_1(s))$ and $s$, but the local state is different. Here $a_1,a_2$ are  public actions of $\varphi_i$ that only change the private state of $\varphi_i$.
Let $a_3$ be a public action of another agent $\varphi_j$ and $a_4$ an action of $\varphi_i$. 
We claim that $\varphi_i$ may never generate $a_4(a_3(s'))$, although, as we shall see, it should. 
To see this, note that $\varphi_i$ will receive $a_3(s)$ from $\varphi_j$ and will  expand it
%Suppose that $a_6$ is not applicable in $a_5(s'')$ because of $\varphi_i$'s local state there, but that it is applicable in $a_5(s')$. 
before it generates $s'=a_2(a_1(s))$. 
Now, suppose that $a_4$ cannot be applied in $a_3(s)$ because of $\varphi_i$'s local state, but it can be applied in $a_3(s')$. Eventually, $\varphi_i$ will generate
$s'=a_2(a_1(s))$. However, it will not send it to $\varphi_j$. It will simply update the id associated with
$s$ to include the local state of $s'$. Since $s$ was already expanded, it will not attempt to re-expand it, and will miss the state $a_4(a_3(s'))$. 


%However, this change alone is insufficient to maintain completeness. Consider some state $s$ that is
%being expanded by $\varphi_i$. Suppose that the non-private part of the state is identical in  $s'=a_3(a_2(a_1(s)))$ and $s''=a_4(s)$, but the local state is different. Here $a_1,a_2,a_3,a_4$ are all actions of $\varphi_i$.
%Let $a_5$ be a public action of another agent $\varphi_j$ and $a_6$ an action of $\varphi_i$. 
%We claim that $\varphi_i$ may never generate $a_6(a_5(s'))$, \red{although, as we shall see, it should}. 
%To see this, note that $\varphi_i$ will receive $a_5(s'')$ from $\varphi_j$ and will  expand it
%%Suppose that $a_6$ is not applicable in $a_5(s'')$ because of $\varphi_i$'s local state there, but that it is applicable in $a_5(s')$. 
%before it generates $s'=a_3(a_2(a_1(s)))$. 
%Now, suppose that $a_6$ cannot be applied in $a_5(s'')$ because of $\varphi_i$'s local state, but it can be applied in $a_5(s')$. Eventually, $\varphi_i$ will generate
%$s'=a_3(a_2(a_1(s)))$. However, it will not send it to $\varphi_j$. It will simply update the id associated with
%$s''$ to include the local state of $s'$. Since $s''$ was already expanded, it will not attempt to re-expand it, and will miss the state $a_6(a_5(s'))$. 


To address this issue, \smafs\ must re-expand states previously expanded when their id is modified.
Specifically, in the above example, when we modify the id of $a_2(a_1(s))$, \smafs\ will 
add $a_3(s')$ (with the appropriate ids) to a local queue and later see that $a_4$ is applicable from this state. 

\begin{algorithm}
\caption{\smafs}
    \label{alg:smafs}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\STATE {\bf initialization:} $d \gets 0$; $Q_{0}\gets \set{(I^{\mathrm{pub}},0,\dots,0)}$; for every $i \in \set{1,\dots,n}$ agent $\varphi_i$ sets  $id_i\gets 0$, $PS_{i}[0]\gets \set{I_i}$,
and $LQ_{i,d'}\gets\emptyset$ for every $d'$.
\WHILE{goal has not been achieved}
   \STATE $d\gets d+1$; for every $i \in \set{1,\dots,n}$ agent $\varphi_i$ sets $Q_{d}\gets \emptyset$, $C_{i,d}\gets\emptyset$, %,  $LQ_{i,d+1}\gets\emptyset$, 
	and $E_i\gets \emptyset$.
   \FOR{$i=1$ \TO $n$ }
	    \STATE agent $\varphi_i$ does the following:
%ronen changed d-1 to d-2 in LQ	    
      \FORALL{$(s,j_1,\dots,j_n)\in Q_{d-1} \cup LQ_{i,d-1}$}
            \FORALL{private state $ps\in PS_{i}[j_i]$ }
						\IF{$(s,j_1,\dots,j_n)$ and $ps$ where not evaluated previously by $\varphi_i$}
  	        \FORALL{sequence $a_1,\dots,a_\ell$ of actions of $\varphi_i$  applicable from $s,ps$, where $a_1\dots,a_{\ell-1}$ are private and $a_\ell$ is public }
		           \STATE  $(s',ps') \gets a_\ell(a_{\ell-1}(\cdots a_1((s,ps))))$.
		           \IF {$(s',j_1,\dots,j_{i-1},j_{i+1},\dots,j_n,ps')$ was not generated before}
							 \STATE $E_i\gets E_i \cup \set{(s',j_1,\dots,j_{i-1},j_{i+1},\dots,j_n,ps')}$.
							 \ENDIF
						\ENDFOR
					\ENDIF
	       \ENDFOR
			\ENDFOR
			\STATE agent $\varphi_i$ sorts the elements of $E_i$, first by the public state, and then by the $n-1$ ids, and then by the private state. Let $((s^1,j_1^1,\dots,j^1_{i-1},j^1_{i+1},\dots,j_n^1,ps^1)$ 
			$\dots,(s^t,j_1^t,\dots,j^t_{i-1},j^t_{i+1},\dots,j_n^t,ps^t))$ be the sorted elements of $E_i$.
			%\STATE $C_i\gets\set{(s^1,j_1^1,\dots,j^1_{i-1},id_i,j^1_{i+1},\dots,j_n^1)}$ and $PS_{i}[id_i]\gets \set{ps^1}$.
			\FOR{$u=1$ \TO $t$}
			   \IF{there exist $d' < d$ and $id$ such that $(s^u,j_1^u,\dots,j^u_{i-1},id,j^u_{i+1},\dots,j_n^u) \in C_{i,d'}$ % Q_{d'}$
				}	
						\STATE update $PS_{i}[id]\gets PS_{i}[id] \cup \set{ps^u}$.
						%ronen -- added "was not created by i"
						\FORALL{$(s,j_1,\dots,j_{i-1},j_{i+1},\dots,j_n)$ s.t. $(s,j_1,\dots,j_{i-1},id,j_{i+1},\dots,j_n) \in Q_{d''}$ for some $d'' <d$}
%						   \STATE Updates $LQ_{i,d} \gets LQ_{i,d} \cup \bar{s}$.
%						 \FORALL {$\bar{s'}$ that is a child of $\bar{s}$ not created by $\varphi_i$}
						   \STATE \label{line:LQ} update $LQ_{i,d+(d''-d')} \gets LQ_{i,d+(d''-d')} \cup \set{(s,j_1,\dots,j_{i-1},id,j_{i+1},\dots,j_n)}$.
%						   \STATE Updates $LQ_{i,d+1} \gets LQ_{i,d+1} \cup \bar{s'}$.
%						\ENDFOR
						\ENDFOR
			   \ELSIF{$u >1$ \AND  $s^{u-1} =s^u $ \AND $(j_1^{u-1},\dots,j^{u-1}_{i-1},j^{u-1}_{i+1},\dots,j^{u-1}_n)=
				(j_1^u,\dots,j^u_{i-1},j^u_{i+1},\dots,j_n^u)$}
				    \STATE $PS_{i}[id_i]\gets PS_{i}[id_i] \cup \set{ps^u}$. //Collects ids of similar states in a level
						\label{step:PSi}
				    \ELSE  
				    \STATE update $id_i\gets id_i+1$
				    %\STATE Updates $C_{i}\gets C_{d} \cup \set{(s^u,j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)}$,
						% and $PS_{i}[id_i]\gets \set{ps^u}$.
						\STATE update $C_{i,d}\gets C_{i,d} \cup \set{(s^u,j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)}$,
						 and $PS_{i}[id_i]\gets \set{ps^u}$.
				    \ENDIF
			\ENDFOR
			\STATE agent $\varphi_i$ sends $C_{i,d}$ to all agents (where the elements of $C_{i,d}$ are sent according to some canonical order).
		  \STATE each agent $\varphi_j$ updates: $Q_{d}\gets Q_{d} \cup C_{i,d}$.
		\ENDFOR
		\IF{the state $s$ in some element in $Q_{d}$ satisfies the goal \label{line:finds}} 
				\STATE the agents execute $sol \gets $ {\bf recover-solution},   output $sol$,  and halt.
    \ENDIF 
\ENDWHILE
\end{algorithmic}
\end{algorithm}
The pseudo-code for \smafs\ appears in~\cref{alg:smafs}. At each level we generate a number of lists of states:
The set $C_{i,d}$ contains the new states that agent $\varphi_i$ created in level $d$; these states are sent to all agents. The set $Q_d$ contains the new states created in level $d$ by some agent,
that is $Q_d=\cup_{1\leq i \leq n} C_{i,d}$.
Furthermore, the set $LQ_{i,d}$ will contain states that were generated
by $\varphi_i$, but are not being sent because a similar state was sent earlier. These lists are initially empty.
In round $d$, each agent $\varphi_i$ expands all states in $Q_{d-1}$ and in $LQ_{i,d-1}$ using any sequence
of private actions followed by a single public action. It collects all these states into $E_d$. 
This list is sorted and all its elements are processed in order. 
For each element, agent $\varphi_i$ checks if this state did not appear before in the states it created (namely, in $C_{i,d'}$ for some $d' <d$), and if
a similar state $s'$ that differs only in $\varphi_i$'s private state appeared earlier.
If the latter is the case, let $id$ denote the id of agent $\varphi_i$ in $s'$.
We now go over all states in previous $Q_t$'s that have the id $id$, and add them to an appropriate $LQ$ list.
The list selected reflects the number of public actions that were applied to reach them from $s'$.



\commentout{
\begin{algorithm}
%\floatname{algorithm}{Simulator}
\caption{Simulator for \smafs}
    \label{sim:smafs}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
%\STATE Each agent holds a copy of the same prefix $T$ of $\PST(\Pi)$. 
\REQUIRE A PST tree $T$
\STATE Initialization: $d \gets 0$; for every $i \in \set{1,\dots,n}$  set  $id_i\gets 1$, $Q_{i,0}\gets ((I^{\mathrm{pub}},0,\dots,0))$,
$E_{i}=\{\}$.
%Each agent holds the root of the tree labeled by $I^{\mathrm{pub}}$.
\WHILE{goal has not been achieved}
   \STATE $d\gets d+1$; for every $i \in \set{1,\dots,n}$ set $Q_{i,d}\gets \emptyset$,
	  $C_i\gets \emptyset$, and $\tilde{E}_i\gets \emptyset$.
	 \STATE $L[root]=(0,\dots,0)$.
   \FOR{$i=1$ \TO $n$ }
      \FORALL{node $w$ in level $d$ s.t. the edge $(f(v),w)$ is labeled by an action of $\varphi_i$}
			\STATE Let $L(f(v))=(j_1,\dots,j_n)$ and $s'$ be the state of node $w$.
      \STATE $\tilde{E}_i\gets \tilde{E}_i \cup \set{(s',j_1,\dots,j_{i-1},j_{i+1},\dots,j_n,w)}$.
			\ENDFOR
		\STATE Sort the elements of $\tilde{E}_i$, first by the public state, then by the $n-1$ ids, and then by $w$. 
		\STATE Let $((s^1,j_1^1,\dots,j^1_{i-1},j^1_{i+1},\dots,j_n^1,w^1),$ 
			$\dots,(s^t,j_1^t,\dots,j^t_{i-1},j^t_{i+1},\dots,j_n^t,w^t))$ be the sorted elements of $\tilde{E}_i$.
		%\STATE $C_i\gets\set{(s^1,j_1^1,\dots,j^1_{i-1},id_i,j^1_{i+1},\dots,j_n^1)}$.
		\FOR{$u=1$ \TO $t$}
			   \IF{ $u=1$ \OR $s^{u-1} \neq s^u $ \OR $(j_1^{u-1},\dots,j^{u-1}_{i-1},j^{u-1}_{i+1},\dots,j^{u-1}_n) \neq
				(j_1^u,\dots,j^u_{i-1},j^u_{i+1},\dots,j_n^u)$}
			    \STATE $id_i\gets id_i+1$.
					\STATE $C_{i,d}\gets C_{i,d} \cup \set{(s^u,j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)}$.
				 \ENDIF
				\STATE $L(w^u)\gets (j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)$.
		\ENDFOR
		\STATE Send $C_i$ on behalf of $\varphi_i$ to all agents (where the elements of $C_i$ are sent according to some canonical order).
		\STATE For every $j \in \set{1,\dots,n}$ set $Q_{j,d}\gets Q_{j,d} \cup C_i$.
	\ENDFOR
	\IF{ the state $s$ in some element in $Q_{1,d}$ satisfies the goal}
				\STATE Execute $sol \gets $ {\bf sim-recover-solution},   output $sol$,  and halt.
  \ENDIF 
\ENDWHILE
\end{algorithmic}
\end{algorithm}
}

Observe that \smafs\ enjoys the property that an agent $\varphi_i$ will never send two states that differ only in its
own id.

\begin{algorithm}
%\floatname{algorithm}{Simulator}
\caption{Simulator for \cref{alg:smafs} -- \smafs}
    \label{sim:smafs}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
%\STATE Each agent holds a copy of the same prefix $T$ of $\PST(\Pi)$. 
\REQUIRE A PST tree $T$
\STATE {\bf initialization:} $d \gets 0$; for every $i \in \set{1,\dots,n}$  set  $id_i\gets 1$, $Q_{0}\gets ((I^{\mathrm{pub}},0,\dots,0))$.
%Each agent holds the root of the tree labeled by $I^{\mathrm{pub}}$.
\WHILE{goal has not been achieved}
   \STATE $d\gets d+1$; for every $i \in \set{1,\dots,n}$ set $Q_{d}\gets \emptyset$,
	  $C_{i,d}\gets \emptyset$, and $\tilde{E}_i\gets \emptyset$.
	 \STATE $L[root]=(0,\dots,0)$.
   \FOR{$i=1$ \TO $n$ }
      \FORALL{node $w$ in level $d$ s.t.~the edge $(f(w),w)$ is labeled by an action of $\varphi_i$}
			\STATE let $L(f(w))=(j_1,\dots,j_n)$ and $s'$ be the state of node $w$.
      \STATE $\tilde{E}_i\gets \tilde{E}_i \cup \set{(s',j_1,\dots,j_{i-1},j_{i+1},\dots,j_n,w)}$.
			\ENDFOR
		\STATE sort the elements of $\tilde{E}_i$, first by the public state, then by the $n-1$ ids, and then by $w$. 
		\STATE let $((s^1,j_1^1,\dots,j^1_{i-1},j^1_{i+1},\dots,j_n^1,w^1),$ 
			$\dots,(s^t,j_1^t,\dots,j^t_{i-1},j^t_{i+1},\dots,j_n^t,w^t))$ be the sorted elements of $\tilde{E}_i$.
		%\STATE $C_i\gets\set{(s^1,j_1^1,\dots,j^1_{i-1},id_i,j^1_{i+1},\dots,j_n^1)}$.
		\FOR{$u=1$ \TO $t$}
		 \IF{ there exists $d'< d$ and $id$ such that $(s^u,j_1^u,\dots,j^u_{i-1},id,j^u_{i+1},\dots,j_n^u) \in C_{i,d'}$}
				\STATE $L(w^u)\gets (j_1^u,\dots,j^u_{i-1},id,j^u_{i+1},\dots,j_n^u)$.
				\ELSE
			   \IF{ $u=1$ \OR $s^{u-1} \neq s^u $ \OR $(j_1^{u-1},\dots,j^{u-1}_{i-1},j^{u-1}_{i+1},\dots,j^{u-1}_n) \neq
				(j_1^u,\dots,j^u_{i-1},j^u_{i+1},\dots,j_n^u)$}
			    \STATE $id_i\gets id_i+1$.
					\STATE $C_{i,d}\gets C_{i,d} \cup \set{(s^u,j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)}$.
				 \ENDIF
				\STATE $L(w^u)\gets (j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j_n^u)$.
			\ENDIF
		\ENDFOR
		\STATE send $C_{i,d}$ on behalf of $\varphi_i$ to all agents (where the elements of $C_{i,d}$ are sent according to some canonical order).
		\STATE for every $j \in \set{1,\dots,n}$ set $Q_{d}\gets Q_{d} \cup C_{i,d}$.
	\ENDFOR
	\IF{ the state $s$ in some element in $Q_{d}$ satisfies the goal}
				\STATE execute $sol \gets $ {\bf sim-recover-solution},   output $sol$,  and halt.
  \ENDIF 
\ENDWHILE
\end{algorithmic}
\end{algorithm}


\bibliography{cites}
\bibliographystyle{theapa}

\end{document}





{
%\red{
\begin{claim}
\label{clm:smfas1} 
Let $w$ be a node on level $d$ of $\PST(\Pi)$ then there are 
$id_1,\dots,id_n$ such that for every 
node in $\ST(\Pi)$ corresponding  to $w$ in which the public state is $s$ and the private states are $ps_1,\dots,ps_n$. Then,  
\begin{itemize}
\item 
either $s,id_1,\dots,id_n \in Q_d$  and in step $d$ of \smafs\  $ps_i \in PS[id_i]$ for every $1 \leq i \leq n$, or
\item
for every child $x$ of $w$ such that the action on the edge $(w,x)$ is of agent $\varphi_i$,
there exists a $d' \leq d$ such that $s,id_1,\dots,id_n \in LQ_{i,d'}$
and in step $d'$ of \smafs\  $ps_i \in PS[id_i]$. 
\end{itemize}
\end{claim}
\begin{proof}
We prove the claim by induction on $d$. The basis is $d=0$. The only node in level $0$ of $\PST(\Pi)$  is the root and the only node in $\ST(\Pi)$ is the node with public state $I^{\rm pub}$ and private states $I_1,\dots,I_n$. By the initialization of \smafs, $(I^{\rm pub},0,\dots,n) \in Q_0$ and $I_i \in PS_i[0]$ for every $1 \leq i \leq n$ as required.


  
For the induction step, let $w$ be a node in level $d$ of $\PST(\Pi)$. Let $v$ be its parent, 
$a_d$ be the action labeling the edge $(v,w)$ and $\varphi_i$ be the agent performing this action. 
Furthermore, let $id^v_1,\dots,id^v_n$ be the ids guaranteed by the induction hypothesis for $v$.

Consider any path in $\ST(\Pi)$ that ends in a node of $\ST(\Pi)$ that corresponds to $w$, $s,ps_1,\dots,ps_n$ the state of this nodes, and $s_v,ps_{v,1},\dots,ps_{v,n}$ the state of the node in $\ST(\Pi)$ that corresponds to $v$ on this path.

\begin{description}
\item[
Case I: $s_v,id_{v,1},\dots,id_{v,n} \in Q_{d-1}$.]
In this case $\set{(s,id_{v,1},\dots,id_{v,i-1},id_{v,i+1},\dots,id_{v,n},ps)} \in E_i$.


First assume that there does not exist $d' < d$ and $id$ such that $$(s,id_{v,1},\dots,id_{v,i-1},id,id_{v,i+1},\dots,id_{v,n}) \in C_{i,d'}.$$ In this case, agent $\varphi_i$ creates some $id_i$, adds $s,id^v_1,\dots,id^v_{i-1},id_i,id^v_{i+1}\dots,id^v_n$ to $C_{i,d}$ (and, therefore, to $Q_d$),
and adds $ps$ to $PS_i[id]$. 

Second, assume that there  exist $d' < d$ and $id$ such that $$(s,id_{v,1},\dots,id_{v,i-1},id,id_{v,i+1},\dots,id_{v,n}) \in C_{i,d'}.$$ In this case, agent $\varphi_i$ adds $ps_i$ to $PS_i[id]$
and adds $(s,id_{v,1},\dots,id_{v,i-1},id,id_{v,i+1},\dots,id_{v,n})$ to $LQ_{i,d}$. Furthermore,

Explain why holds for $i'\neq i$.

\item[
Case I: $s_v,id_{v,1},\dots,id_{v,n} \in LQ_{d'}$ for some $d'\leq d-1$.]
\end{description}
We next consider a sequence of actions ending with a public action and containing $d$ public actions $a_1,\dots,a_d$ for some $d \geq 1$. For every $0 \leq \ell \leq d$, let  $s^\ell,ps^\ell_1,\dots,ps^\ell_n$ be the state after the actions in the prefix of the sequence ending with $a_\ell$.
Let $0 \leq \ell_0 \leq d-1$ be the maximal index such that there exist $n$ indices $id^{\ell_0}_1,\dots,id^{\ell_0}_n$ such that $ps^{\ell_0}_i \in PS_i[id^{\ell_0}_i]$ for every $1 \leq i \leq n$ and  $s,id_1,\dots,id_n \in Q_{\ell_0}$. 

First assume that $\ell_0=d-1$. Let $\varphi_i$ be the agent that performs the last action $a_d$ in the sequence. 
Thus, $ps^{d}_{i'}=ps^{d-1}_{i'} \in PS_{i'}[id^{d-1}_{i'}]$ for every $i'\neq i$. 
By the code of \smafs, agent $\varphi_i$ adds $s^d,id^{d-1}_1,\dots,id^{d-1}_{i-1},id^{d-1}_{i+1},\dots,id^{d-1}_{n},ps_i^d$ to $E_i$.

If 
there does not exist a $d' < d$ and an $id$ such that $s^d,id^{d-1}_1,\dots,id^{d-1}_{i-1},id,id^{d-1}_{i+1},\dots,id^{d-1}_{n} \in C_{i,d'}$, then for some $id_i$ agent $\varphi_i$ adds $ps^d_i$ to $PS_i[id_i]$ and adds $s^d,id^{d-1}_1,\dots,id^{d-1}_{i-1},id_i,id^{d-1}_{i+1},\dots,id^{d-1}_{n}$ to $C_{i,d'}$ and, hence, to $Q_i$. 

If 
there exist a $d' < d$ and an $id$ such that $s^d,id^{d-1}_1,\dots,id^{d-1}_{i-1},id,id^{d-1}_{i+1},\dots,id^{d-1}_{n} \in C_{i,d'}$,
agent $\varphi_i$ adds $ps^d_i$ to $PS_i[id]$ and adds $s^d,id^{d-1}_1,\dots,id^{d-1}_{i-1},id_i,id^{d-1}_{i+1},\dots,id^{d-1}_{n}$  to $LQ_{i,d}$. Furthermore, by the induction hypothesis,...
\end{proof}

We next prove that every ``state'' generated in step $d$ of \smafs\ is a state generated by a plan containing $d$ public actions.
 
\begin{claim}
\label{clm:smfas2}
If $(s,j_1,\dots,j_n) \in Q_d \bigcup \cup_{1\leq i \leq n} LQ_{i,d}$ and  there exist $ps_1,\dots,ps_n$ such that 
in step $d$ of the algorithm $ps_k \in PS_\ell[id_{j_k}]$ for every $1 \leq k \leq n$, then there exists a plan in $\Pi$ containing $d$ public actions and resulting in the state $s,ps_1,\dots,ps_n$.  
\end{claim}
\begin{proof}
The proof is by induction on $d$. The basis for $d=0$ is trivial as the only tuple in   
$Q_0 \bigcup \cup_{1\leq i \leq n} LQ_{i,0}$  is $(I^{\rm pub},0,\dots,0)$ and the only private state in $PS_i[0]$ is $I_0$.

For the induction step, first assume that $(s,j_1,\dots,j_n) \in Q_d$, thus it was added 
by some agent $\varphi_i$ and there exist some $j'_i$, a public state $s'$,  a private state $ps'_i \in PS_i[j'_i]$, and a sequence of actions $a_1,\dots,a_\ell$ of $\varphi_i$ that are applicable from $s',ps'_i$ and resulting in $s,ps_i$ such that $(s',j_1,\dots,j_{i-1},j'_i,j_{i+1}\dots,j_n) \in Q_{d-1} \cup LQ_{i,d-1}$.   Since the actions of $\varphi_i$ do not change the private states of other agents, $ps_k \in PS_j[j_{k}]$ at step $d-1$ of the algorithm.

\red{THIS MIGHT NOT BE TRUE IN OUR ALGORITHM SINCE A DIFFERENT AGENT MIGHT HAVE CHANGED $PS_j[j_{k}]$  IN A DIFFERENT SEQUNCE OF ACTIONS}.

Thus, by the induction hypothesis, there exists a plan in $\Pi$ containing $d$ public actions and resulting in the state $s,ps_1,\dots,ps_{i-1},ps'_i,ps_{i+1},p\dots,ps_n$ containing $d-1$public actions. Adding $a_1,\dots,a_\ell$ to this plan results in a plan satisfying the induction hypothesis.

Next assume that $(s,j_1,\dots,j_n) \in  LQ_{i,d}$ for some $i$. Let's look at the events in which $(s,j_1,\dots,j_n)$ was added to $LQ_{i,d}$:
\begin{itemize}
\item 
 In step 6 of \smafs, there was some $(s',j_1^u,\dots,j_n^u) \in Q_e \cup LQ_{i,e}$, a sequence of actions $a_1,\dots,a_\ell$ resulting in a public state $s^u$ and private state $ps^u$ of  $\varphi_i$. 
\item 
In step 15 of \smafs, there exists some $e'<e$  such that $$(s'^u,j_1^u,\dots,j^u_{i-1},j_i,j^u_{i+1},\dots,j_n^u) \in C_{i,e'}.$$
\item
In step 17 of  \smafs, there exists $e''$ such that $d=e+(e'-e'')$ and $(s,j_1,\dots,j_n) \in  LQ_{i,d}$.
\end{itemize}
By the induction hypothesis, there is a node $w$ in level $e'$ in $\PST(\Pi)$ that corresponds to $(s',j_1^u,$ $\dots,j^u_{i-1},j_i,j^u_{i+1},$ $\dots,j_n^u)$, denote this node by $w$.
Since $(s',j_1^u,$ $\dots,j^u_{i-1},j_i,j^u_{i+1},$ $\dots,j_n^u)$ is in $C_{i,e'}$,
step $e'$ is the first in which the id $j_i$ was created for agent $\varphi_i$ and all tuples containing $j_i$ as the id of $\varphi_i$ were generated from $(s',j_1^u,$ $\dots,j^u_{i-1},j_i,j^u_{i+1},$ $\dots,j_n^u)$. 


%The key issue is that only actions of $\varphi_i$ are applied to state in $LQ_{i,d}$.
%Hence, we potentially lose children of nodes in $LQ_{i,d}$ obtainable using
%actions of other agents.
%
%The proof is by  induction on $d$ and is immediate for $d=1$.
%Next, suppose that $s_d$ appears in level $d$ of the PST. 
%Let $s_{d-1}$ be its parent in the PST. By the inductive assumption,
%it is in $Q_{d-1}\cup  \cup_{i\in\{1,\ldots n\}}LQ_{i,d-1}$. 
%If $s_{d-1}\in Q_{d-1}$ then the claim clearly holds for $s_d$.
%Similarly, if $s_d$ is a child of $s_{d-1}$ using actions of $\varphi_i$,
%it will be generated in Line 9 in any case.
%
%So it remains to consider the case where $s_d$ is a child of $s_{d-1}$,
%$s_{d-1}\in LQ_{i,d-1}$ and $s_d$ is obtained from it via some sequence 
%of actions (ending with a single public action) of  some $\varphi_j$ for $j\neq i$.
%Since $s_{d-1}\in LQ_{i,d-1}$, we know that there exists some 
%$s_{d_0}$ for some $d_0<d-1$ that was generated by $\varphi_i$ such that both 
%$s_{d_0}$ and $s_{d-1}$ have the same id for $\varphi_i$, and some $d'\leq d'' < d_0$
%and state $s_{d'}\in Q_{d'}$ and $s_{d''}\in Q_{d''}$ such that $s_d'$ is identical to
%$s_{d_0}$ (except for the agent's id) and $s_{d''}$ is identical to $s_{d-1}$ (except for
%the agent's local state), and $d-1=d_0+(d''-d')$. 
%We know that $s_d$ is identical, except for the agent's local state, to a child $s_{d''+1}$ 
%of $s_{d''}$ in the PST. If  $d''+1<d$, then the algorithm would have inserted $s_{d''+1}$ with an appropriate id
%into $LQ_{i,d}$ (since $d = d_0+(d''+1-d')$).
%Note that this implies that the entire sub-tree of $s_{d_0}$ obtained by applying actions by other agents will
%be in some $LQ_{d*,i}$, provided the sequence of actions is no longer then $d_0-d'-1$. 
%But then, notice that the condition of Line 14 will also apply to those added children.
%They will be able to add elements that correspond to sequences of length $d_0-d$ from $s_{d_0}$ and
%their children will be able to elements that correspond to sequences of length $d_0-d+1$ from $s_{d_0}$,
%and so on, provided no action of $\varphi_i$ was applied (in which case, the id would change).
%In particular, in our case, we know that $s_d$ is a descendent of $s_{d_0}$ obtained w/o any actions by $\varphi_i$,
%and so we are done.
\end{proof}
}
\begin{theorem}
\label{t:psd-id-e}
\smafs\ is a PST-indistinguishable secure algorithm.
\end{theorem}
\begin{proof}
A simulator for \smafs\ appears in \cref{sim:smafs}.
It is similar to the simulator for PSD-ID FS, except that it maintains
a list of states sent by each agent and does not send a state if the same state
(except for the sending agent's id) has been sent before. By

By \cref{clm:smfas1,clm:smfas2}, algorithm \smafs\ sends tuples corresponding to nodes in $\PST(\Pi)$ exactly as  \cref{sim:smafs} does.   
\end{proof}

%\begin{remark}
%In Algorithm \smafs, we add $(s,j_1,\dots,j_{i-1},id,j_{i+1},\dots,j_n)$  to $LQ_{i,d}$. This means that the possible private states of $\varphi_i$ in this node is $PS_i(id)$ and many children of this node that were generated previously are generated again in the next level and inserted 
%to the local list. This waists computation of the agents, but does not add communication. To optimize the computation, we will  associate with the node $(s^u,j_1^u,\dots,j^u_{i-1},id,j^u_{i+1},\dots,j_n^u)$ only private states that were not in $PS_i(id)$ in previous levels. Since the technical details are tedious, we will not formally write this optimization.
%\end{remark}

%\subsection{Correctness}
%\begin{theorem}
%Algorithms PST-Forward Search, PST-ID FS, PST-ID-E FW, and \smafs\  are sound and complete.
%\end{theorem}
%\begin{proof}
%For all the algorithms prior to \smafs, soundness and completeness is immediate because we are essentially
%developing the PST level by level. 
%Soundness follows from the fact that every state is generated by applying some sequence of actions.
%Completeness follows from the fact that all the algorithms fully explore the PST, and the fact that the goal condition is public. (It is not difficult to see that private goals would be detected, too).
%
%For \smafs\, the proof follows from the proof of Theorem~1: since the simulator sends only and
%all public states that appear in the PST then we know that a goal will be detected by \smafs\
%iff one exists in the PST.
%\end{proof}
%

\commentout{
The next two claims prove the correctness of the algorithm, that is, it finds a plan satisfying the goal if and only if such plan exists.
\begin{claim}
If there exists a path from the initial state to a state satisfying the goal, % of length $h$, 
then \cref{alg:smafs} finds a (possibly different) path from 
the initial state to a state satisfying the goal. % with $d <h$.
\end{claim}
\begin{proof}
We prove by induction on $d$ that for every $(s,id_1,\dots,id_n)\in Q_{i,d} \cup LQ _{i,d}$ and for every
$ps_1\in PS_i[id_1],\dots, ps_n\in PS_i[id_n]$ there is a plan staring from the initial state $(I^{\rm pub},I_1,\dots,i_n)$ and ending at the state
$(s,ps_1,\dots,ps_n)$. Within each level, the induction is done according to the order that the $(n+1)$-tuples are inserted into  $Q_{i,d} \cup LQ _{i,d}$ and the updates to $PS_i[id]$.

The base $d=0$ is trivial as $Q_{i,d} \cup Q _{i,d}=\set{(I^{\rm pub},0,\dots,0)}$,  $PS_1[0]=\set{I_1},\dots,PS_n[0]=\set{I_n}$, and the empty plan satisfies the claim.

There are two cases for the step:
\begin{itemize}
\item If $(s,id_1,\dots,id_n) \in Q_{i,d}$, then $(s,id_1,\dots,id_n)\in C_{i'}$ for some agent $\varphi_{i'}$. Thus, $(s,id_1,\dots,id_{i'-1},id_{i'+1},\dots,id_n,ps_{i'})\in E_{i'}$
and there exists $s^0,id^0_{i'},ps^0_{i'}$ 
and a sequence of actions $a_1,\dots,a_\ell$ of agent $\varphi_{i'}$ such that 
$ps^0_{i'} \in id^0_{i'}$,  
$$(s^0,id_1,\dots,id_{i'-1},id^0_{i'},id_{i'+1},\dots,id_n) \in Q_{i',d-1} \cup LQ_{i',d-1}$$ and 
$(s,ps) \gets a_\ell(a_{\ell-1}(\cdots a_1((s^0,ps^0))))$.
By the induction hypothesis there is a plan starting at $(I^{\rm pub},I_1,\dots,i_n)$ and ending at 
$(s^0,ps_1,\dots,ps_{i'-1},ps^0_{i'},ps_{i'+1},\dots,ps_n)$; this plan together with $a_1,\dots,a_\ell$ satisfies the induction hypothesis. 
%Notice that this case is also valid to step \ref{step:PSi} of the algorithm, where only $PS_i[id_i]$ is updated.
\item If $(s,id_1,\dots,id_n) \in LQ_{i,d}$, then $(s,id_1,\dots,id_n) \in Q_{i,d''}$ for some $d'' < d$ and there exist $(s^u,j_1^u,\dots,j^u_{i-1},j^u_{i+1},\dots,j^u_n,ps^u) \in E_i$
and $d' <d $ such that  
$$(s^u,j_1^u,\dots,j^u_{i-1},id_i,j^u_{i+1},\dots,j^u_n) \in Q_{i,d'}.$$
If $ps^u\neq ps_i$, then the induction hypothesis is implied by the step when $ps_i$ was added to $PS_i[id]$ (either when $id$ was first used by $\varphi_i$ or in prior steps when $(s,id_1,\dots,id_n)$ was added to the local list). 
 
Therefore, there exists $s^0,id^0_{i},ps^0_{i}$ 
and a sequence of actions $a_1,\dots,a_\ell$ of agent $\varphi_{i}$ such that 
$ps^0_{i} \in id^0_{i}$,  
\begin{equation}
\label{eq:inQorLQ}
(s^0,j^u_1,\dots,j^u_{i-1},id^0_{i},j^u_{i+1},\dots,j^u_n) \in Q_{i,d'-1} \cup LQ_{i,d'-1}
\end{equation}
 and 
$(s^u,ps_i) \gets a_\ell(a_{\ell-1}(\cdots a_1((s^0,ps^0_i))))$.
This implies that agent $\varphi_i$  changes its id to $id_i$ only if the state is $s^u$ and the other ids are  $j^u_1,\dots,j^u_{i-1},j^u_{i+1},\dots,j^u_n$. As the tuple $(s,id_1,\dots,id_n)$ contains $id_i$, there path to this tuple passes through $s^u,j^u_1,$ $\dots,j^u_{i-1},id_i,j^u_{i+1},$ $\dots,j^u_n$ and all actions after this tuple are actions of agents $\varphi_j$ where $j\neq i$. Furthermore, every plan reaching $(s,id_1,\dots,id_n)$ is of the above format.
By the induction hypotheses, for every $ps'_i$ that was in $PS_i[id]$ prior to the insertion of $ps_i$ there is a plan $\pi$ starting from the initial state and ending at the state $s,ps_1,\dots,ps_{i-1},ps'_i,ps_{i+1},\dots,ps_n$. Partition this plan to its prefix $\pi_{\rm pref}$until it passes via the tuple $s^u,j^u_1,$ $\dots,j^u_{i-1},id_i,j^u_{i+1},$ $\dots,j^u_n$ and its suffix $\pi_{\rm suf}$ after this tuple, and let $s^u,ps^u_1,\dots,ps^n_n$ be the state in this plan when it passes via this tuple.
By the induction hypothesis and~(\ref{eq:inQorLQ}), there is a plan $\pi_1$ starting from the initial state and ending at the state $s^u,ps^u_1,\dots,p^u_{i-1},ps^0_i,ps^u_{i+1}\dots,ps^n_n$.
The plan $\pi_1,a_1,\dots,a_\ell,\pi_{\rm suf}$ is a plan starting from the initial state and ending at the state $s,ps_1,\dots,ps_n$ as required by the induction hypothesis. Note that since $a_1,\dots,a_\ell$ are actions of $\varphi_i$ and the actions in $\pi_{\rm suf}$ are actions of other agents, this plan is legal.
\end{itemize}
\end{proof}  

\begin{claim}
If \cref{alg:smafs} finds in line  \ref{line:finds}  
a state $s$  satisfying the goal in level $d $,
then in the PST there exists a path from the initial state to the state $s$ of length  $h \leq d$.
\end{claim}  
}
%\begin{remark}
%In \cref{alg:smafs}, we add $(s,j_1,\dots,j_{i-1},id,j_{i+1},\dots,j_n)$  to $LQ_{i,d}$. This means that the possible private states of $\varphi_i$ in this node is $PS_i(id)$ and many children of this node that were generated previously are generated again in the next level and inserted 
%to the local list. This waists computation of the agents, but does not add communication. To optimize the computation, we will  associate with the node $(s^u,j_1^u,\dots,j^u_{i-1},id,j^u_{i+1},\dots,j_n^u)$ only private states that were not in $PS_i(id)$ in previous levels. Since the technical details are tedious, we will not formally write this optimization.
%\end{remark}
%Finally, suppose that at some point  agent $\varphi_1$ generates a state $s'$ such that in the past, $\varphi_1$ sent a similar state $s$,such that $s$ that is identical to $s'$ except for the value of its own ID. The agent need not send this state again, but can simply update the ID to reflect a larger set of local states. 
%
%This modification raises two issues:  1) Does this impact PST-indistinguishability? 2) Does this impact
%completeness. Regarding the former: as long as we continue to work layer by layer, ordering elements based
%on their lexicographic order, the resulting sequence of messages is identical for identical trees. 
%Regarding the latter, the problem is as follows: state $s$ was generated in the past by
%agent $\varphi_1$, sent to some other agent $\varphi_2$, who generated state $s_1$ and returned this state to $\varphi_1$.  Agent 
%$\varphi_1$  could
%not apply some action $a$ at $s_1$ because its local state was inappropriate. If the new
%state $s'$, which is identical to $s$ except for the local state of $\varphi_1$, is sent to $\varphi_2$,
%it would be able to apply exactly the same actions it applied in $s$. Hence,
%it would generate a state $s'_1$ that is the same as $s_1$, except for $\varphi_1$'s local state.
%It may be the case that in $s'_1$ action $a$ is applicable.
%However, because the $\varphi_1$ did not send $s'$ to $\varphi_2$, but only updated its local state, $\varphi_2$ will never generate $s'_1$, and $\varphi_1$ will never generate $a(s'_1)$. In order to preserve completeness, the agent that generated $s'$, must now
%recreate the entire sub-tree that corresponds to state $s$ with $s'$, instead. 
%
%To do this, we must assume that agents  maintain a copy of their part of
%the PST so far. In a sense, we take a step back, and assume that with each ID, not only is the local
%state maintained, but also the sequence of one's own public actions. In this sequence the agent also
%keeps track of at which point other agents inserted actions (what actions they inserted is not important).
%Now, when the agent generates state $s'$ that is identical to $s$, except for the local state of the agent, the agent can retrieve all states $s_i$ which are descendants of $s$, generating the equivalent
%state $s'_i$. It odes this as follows: First, it updates the IDs associated with $s'_i$ to reflect
%the local states in $s'_i$. Second, it can check whether actions that were not applicable earlier are applicable in $s'_i$, apply them, and generate the relevant new state. If needed, it will now send
%these news states to other agents. This will alter the order of state expansions and messages, but
%in an identical manner in all domains with the same PST.
 %
%\rnote{asynchronous version -- suppose that computation is asynchronous, but given that an agent starts to develop a state, it applies all its available actions, and sends the resulting state. It seems that any changes in the order of execution are now dependent only on the channels and the computation speed of  agents, and would thus be identical for identical PSTs.}


\vskip 0.2in
\bibliography{cites}
\bibliographystyle{theapa}
\end{document}
\section{Multi-Agent Forward Search}
\label{FSalgorithm}

We now present two multi-agent planning algorithms: multi-agent forward search (\mafs) and a modification of \mafs\
called secure-\mafs~\cite{Brafman15}(\smafs). \mafs\ is a a distributed variant of forward search. It is actually an algorithm schema, since it does not specify the precise search algorithm
used, which could, in fact, be different for different agents. It basically defines the search space of each agent, and how search states are shared. For a more
detailed description of its finer points, please see~\cite{nissim2014distributed}.


\subsection{MAFS}
\label{the-algorithm}


Algorithms \ref{alg:forward-search}-\ref{alg:expand} depict the \mafs\ algorithm for agent $\varphi_i$.
In \mafs, a separate search space is maintained for each agent. Each agent maintains an \textit{open list} of states that are candidates for expansion and a \textit{closed list} of already expanded states. It expands the state with the minimal $f$ value in its open list. When an agent expands state $s$, {\em it uses its own operators only.} This means two agents expanding the same state will generate \textit{different} successor states.

Since no agent expands all relevant search nodes, messages must be sent between agents, informing one agent of open search nodes relevant to it expanded by another agent. Agent $\varphi_i$ characterizes state $s$ as relevant to agent $\varphi_j$ if $\varphi_j$ has a public operator whose public preconditions (the preconditions $\varphi_i$ is aware of) hold in $s$, and the creating action of $s$ is public. In that case, Agent $\varphi_i$ will send $s$ to Agent $\varphi_j$.

%\vspace{-5pt}
\begin{algorithm}
\caption{\mafs\ for agent $\varphi_i$}
    \label{alg:forward-search}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\STATE Initialization
\WHILE{did not receive \textbf{true} from a solution verification procedure}
	\FORALL{messages $m$ in message queue}
		\STATE \textbf{process-message($m$)}
	\ENDFOR
	\STATE $s\leftarrow$ \textbf{extract-min}(open list) \label{line:extract_min}
	\STATE \textbf{expand($s$)}
\ENDWHILE
\end{algorithmic}
\end{algorithm}
%\vspace{-10pt}
\begin{algorithm}
\caption{process-message($m=\langle s,g_{\varphi_j}(s),h_{\varphi_j}(s)\rangle$)}
    \label{alg:process-message}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\IF{$s$ is not in open or closed list \textbf{or} $g_{\varphi_i}(s)>g_{\varphi_j}(s)$  } %\STATE \COMMENT{$g_i(s)$ is agent $i$'s current $g$ value for $s$}
	\STATE add $s$ to open list \textbf{and} calculate $h_{\varphi_i}(s)$
	\STATE $g_{\varphi_i}(s)\leftarrow g_{\varphi_j}(s)$
	\STATE $h_{\varphi_i}(s)\leftarrow \max(h_{\varphi_i}(s),h_{\varphi_j}(s))$\label{line:update-h}
\ENDIF
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
\caption{expand($s$)}
    \label{alg:expand}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\STATE move $s$ to closed list
\IF{$s$ is a goal state}
	\STATE broadcast $s$ to all agents \label{line:broadcast1}
	\STATE initiate verification of $s$ as a solution	\label{line:broadcast2}
	\RETURN
\ENDIF
\FORALL{agents $\varphi_j \in \Phi$}\label{line:sending-forloop}
	\IF{the last action leading to $s$ was public \textbf{and} $\varphi_j$ has a public action for which all public preconditions hold in $s$} \label{line:relevant}%\textbf{or} the last action leading to $s$ achieved a goal proposition }
		\STATE send $s$ to $\varphi_j$	\label{line:send}
	\ENDIF
\ENDFOR
\STATE apply $\varphi_i$'s successor operator to $s$ \label{line:succ}
\FORALL{successors $s'$}\label{line:successors-forloop}
	\STATE update $g_{\varphi_i}(s')$ and calculate $h_{\varphi_i}(s')$
	\IF{$s'$ is not in closed list \textbf{or} $f_{\varphi_i}(s')$ is now smaller than it was when $s'$ was moved to closed list}
		\STATE move $s'$ to open list \label{line:move-to-open-list}
	\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}





Since no agent expands all relevant search nodes, messages must be sent between agents, informing one agent of open search nodes relevant to it expanded by another agent. Agent $\varphi_i$ characterizes state $s$ as relevant to agent $\varphi_j$ if $\varphi_j$ has a public operator whose public preconditions (the preconditions $\varphi_i$ is aware of) hold in $s$, and the creating action of $s$ is public. In that case, Agent $\varphi_i$ will send $s$ to Agent $\varphi_j$.

The messages sent between agents contain the full state $s$, i.e.\ including both public and private variable values, as well as the cost of the best plan from the initial state to $s$ found so far, and the sending agent's heuristic estimate of $s$.
 When agent $\varphi$ receives a state via a message, it checks whether this state exists in its open or closed lists. If it does not appear in these lists, it is inserted into the open list. If a copy of this state with higher $g$ value exists, its $g$ value is updated, and if it is in the closed list, it is reopened. Otherwise, it is discarded. Whenever a received state is (re)inserted into the open list, the agent computes its local $h$ value for this state, and then can choose between\slash combine the value it has calculated  and the $h$ value in the received message. If both heuristics are known to be admissible, for example, the agent could choose the maximal of the two estimates, as is done in Line \ref{line:update-h} of Algorithm \ref{alg:process-message}.

Once an agent expands a \emph{solution} state $s$, it sends $s$ to all agents and awaits their confirmation. For simplicity, and in order to avoid deadlock, once an agent either broadcasts or confirms a solution, it is not allowed to create new solutions. If a solution is found by more than one agent, the one with lower cost is chosen, and ties are broken by choosing the solution of the agent having the lower ID. When the solution is confirmed by all agents, the agent initiates the trace-back of the solution plan. This is also a distributed process, which involves all agents that perform some action in the optimal plan. The initiating agent begins the trace-back, and when arriving at a state received via a message, it sends a trace-back message to the sending agent. This continues until arriving at the initial state. When the trace-back phase is done, a terminating message is broadcasted and the solution is outputted.

%As we will see, this general and simple scheme -- apply your own actions/operators only and send relevant generated nodes to other agents -- can be used to distribute other search algorithms. However, there are various subtle points pertaining to message sending and termination that influence the correctness and efficiency of the distributed algorithm, which we discuss later.


%To better demonstrate the flow of the algorithm, consider the example given in Figure \ref{fig:example}. In this example,  we have two agents who must cooperate in order to achieve the goal. The agents' actions are described on the left-hand side, where every node in the graph depicts an action, and an edge $(u,v)$ indicates that $u$ either achieves or destroys a precondition of $v$. There are two public actions $a_5,a_8$, which affect\slash depend on the only public variable, $v_4$, while the rest of the actions are private. In the initial state, all variable values are zero (i.e., $I=0000$), and the goal is $G=\{v_4=2\}$. When the agents begin searching, each applies its own actions only. Therefore, agent 2 quickly exhausts its search space, since as far as it's concerned, state $0020$ is a dead end. Agent 1 generates its search space, until it applies public action $a_5$, which results in state $s=2201$. $s$ is then sent to agent 2, since all the public preconditions of $a_8$ hold in $s$ (Line \ref{line:relevant} of Algorithm \ref{alg:expand}). Upon receiving $s$, agent 2 continues applying its actions, eventually reaching the goal state, which is then broadcasted.


\begin{figure*}[t]
  \caption{Description of the actions of an example planning problem, its reachable search space, and the search space generated by \mafs. Actions are represented as $<\textit{pre},\textit{eff}>$ and states are denoted by the values of variables $v_1,v_2,v_3,v_4$ respectively (For example, $1122$ denotes the state where $v_1=1,v_2=1,v_3=2,v_4=2$.).}
\label{fig:example}
%\vspace{-97pt}
\hspace{-40pt}
  \centering
    %\includegraphics[width=1.025\textwidth]{example_original.pdf}
\hspace{-40pt}
%\vspace{-95pt}
\end{figure*}


\section{Secure \mafs}
\label{Sec:properties}

\mafs\ does not require agents to know private information of other agents,
nor is such information provided to them explicitly. Although agents see the private state of other agents, it is encrypted, and they cannot and need not manipulate it. Thus, it is weakly private. However, agents are exposed to more information than the projected public actions of other agents and the solution plan because they receive many intermediate states during the search process. From this information, it may be possible, in principle, to deduce private information. For example, from the complete search tree, even with encrypted private states, an agent may be able to deduce that the state of an agent is identical in two different search states based on the public parts of the sub-tree rooted at them. Thus, it could deduce the number of private variables of other agents. And maybe, potentially, construct a model of the transitions possible between them.

In reality, agents are not exposed to the entire search space, as only a small portion of it is explored typically, some states are not sent to them, and
it may not be easy to deduce that one state is a parent of another state.  However, this observation is neither a proof nor a guarantee that \mafs\
maintains privacy. Thus, it is desirable to devise algorithms for which such guarantees are provable.

Secure \mafs\ (\smafs) is a conceptually simple variant of \mafs\ that aims to improve privacy by ensuring an agent never sends others multiple states that differ only
in the value of its private state. The basic assumption behind this property is that if an agent always sees one (encrypted) private state associated
with the public aspects of a non-private state, it can learn nothing from this private component. We describe the algorithm below, and then shows it
soundness and completeness.

\subsection{\smafs}

%To provide such guarantees we would like to revise MAFS to have the following property:
%the information observed by an agent is the same regardless of the set of private variables, private actions of other agents, and the private preconditions and
%effects of their public actions. If this property holds, we can immediately conclude that this information is private, as an agent
%cannot deduce this information from the information it observes.
%
%While we we cannot provide this property precisely. If in one model it is possible to get from some state $s$ to some state $s'$, whereas
%in another model, it is impossible to get from any state that is identical to $s$ in terms of its public propositions to any state that is identical to $s'$
%in terms of its public propositions, then agents will be able to see this information, and


%Let's consider more closely the nature of the information available to an agent. As a starting point, let us assume that the entire search tree is explored by the algorithm. Each agent, sees only part of this search tree because it only sees states it generated using its own actions and states that were sent to it by other agents.%Thus, consider the search tree explored. The projected search tree (with respect to agent $\varphi$) is obtained from this search tree if we filter out from it states that were not exposed. For simplicity, we shall assume that the initial state is known to all agents.%
%\footnote{One can start with an artificial initial state and assume that every agent has an action that generates the real initial state, projected to its variables.}
%We obtain the projected search tree by going top down from the initial state and removing from it any state $s$ that was not sent to $\varphi$, connecting the
%parent of $s$ with all children of $s'$.

%Our first observation is the following: an agent is not aware of the existence of propositions that are not private to it that always have the same value in states that it receives. As an example, consider the logistics domain with a truck in each city and an airplane serving the airports of the cities. The truck has many locations in which it can stop, however, the plane will only see states in which a truck dropped or picked up a package in the airport -- these are the only actions that the truck can perform that impact variables that are private to it. Thus, the set of states it can obtain during search is identical, regardless of the number of locations the truck has besides the airport. This is because the location of the truck during the relevant pickup and drop actions has to be in the airport.
%
%One would think that the same would hold regarding local packages, that is, packages that are shipped from and to the same city. However, states that are identical except for the location of such packages, for example, are visible to other agents. For example, the truck agent could be in the airport with the private package in it or with the private package at the source, or with the  private package in the destination, and these would be different states. Of course, the states are encrypted, but conceivably, the agent could identify them as different. All that it could conclude from them is that the agent has certain private variables. While this level of privacy would often suffice, we suggest a modification to the MAFS algorithm that will expose no information about the private variables of an agent. This modification will also reduce the number of messages sent.

The basic idea behind \smafs\ is as follows:  the effect of $\varphi_i$'s action on the components of the state that are not private to $\varphi_j$ is the same, regardless of $\varphi_j$'s private state. Thus, if $\varphi_j$ knows the effect of $\varphi_i$'s action on a state $s_1$, it knows its effect on a similar state $s_2$ that differs only in its private state. To exploit this, whenever agent $\varphi_i$ sends a state to other agents, it also sends a macro
actions that encapsulates the sequence of actions applied by $\varphi_i$ on the previous state produced by a public action.  This allows $\varphi_j$ to emulate these actions on similar states. In particular, given two states that differ only in $\varphi_j$'s private state (and hence, have the same
assignment to variables of $\varphi_i$, $\varphi_j$ can emulate the transitions induced by $\varphi_j$'s action.

More precisely, we make the following modifications to the pseudo code of \mafs:
(1) When agent $\varphi_i$ expands a state $s$ in its open list such that $s$ was sent by agent $\varphi_j$,
$\varphi_i$ will send $\varphi_j$ a macro for every sequence $a_1,\ldots a_m$ that was applied to $s$ such that
$a_1,\ldots a_{m-1}$ are private to $\varphi_i$ and $a_m$ is public. This added macro generation and sending appears in lines
10-16 of {\em secure expand}. Since messages can now be either states or macros,  {\em secure process-message\/} must be modified accordingly
to handle each case appropriately.


Given these macros, we need a few  slight modifications to achieve our goal of never transmitting two states that differ only in the private state of an agent. (1) The agent must maintain a {\em sent-list\/} of sent messages. This list contains all states it sent to other agents.
(2) When the agent wants to send a state to other agents, it first checks if a similar state that differs only in its private variable values appears in
the {\em sent-list\/}. If it does, the state should not be sent. Both of these changes are obtained by replacing {\em send\/} with the {\em virtual-send\/}
routine.

These two steps ensure the desired property. However, they can lead to incompleteness because a macro that is applicable at state $s$ may arrive after it was expanded by the agent. This implies that the state obtainable by applying the macro to state $s$ may not be generated at all. Therefore, in addition to (1) and (2) above, we must all add the following steps: (3) Every state that was not sent in (2) is kept in an {\em unsent-list\/}.  (l.2 of {\em virtual-send\/})
(4) Whenever an agent obtains a new macro, it applies it to all states in the {\em unsent-list\/} to which it is applicable (l.9 of {\em secure process-message\/})
and adds it to its list of actions, to be used in future applications (l.10 of {\em secure process-message\/}).

The modified psuedo-code  appears below.

Finally, we note that since a private state is never sent twice with the same non-private state, the agent can freely encrypt its private part. In fact,
its encryption could be the non-private part itself. Thus, no information about the private state of an agent is ever communicated explicitly.
It will be useful to assume the following:
\[\mbox{ Two states }s\neq s'\mbox{sent by }\varphi_i\mbox{ will have different encrypted private state.}\]
That is, even if the original private state was identical, its encryption is different if some other part of the state is different.

\begin{algorithm}
\caption{\smafs\ for agent $\varphi_i$ (outer loop identical to \mafs)}
    \label{alg:forward-search-1}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\WHILE{did not receive \textbf{true} from a solution verification procedure}
	\FORALL{messages $m$ in message queue}
		\STATE \textbf{process-message($m$)}
	\ENDFOR
	\STATE $s\leftarrow$ \textbf{extract-min}(open list) \label{line:extract_min-1}
	\STATE \textbf{expand($s$)}
\ENDWHILE
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{secure process-message($m$)}
    \label{alg:secure-process-message}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\IF{$m=\langle s,g_{\varphi_j}(s),h_{\varphi_j}(s)\rangle$) (i.e., a state was sent)}
\IF{$s$ is not in open or closed list \textbf{or} $g_{\varphi_i}(s)>g_{\varphi_j}(s)$  } %\STATE \COMMENT{$g_i(s)$ is agent $i$'s current $g$ value for $s$}
	\STATE add $s$ to open list \textbf{and} calculate $h_{\varphi_i}(s)$
	\STATE $g_{\varphi_i}(s)\leftarrow g_{\varphi_j}(s)$
	\STATE $h_{\varphi_i}(s)\leftarrow max(h_{\varphi_i}(s),h_{\varphi_j}(s))$\label{line:update-h-1}
\ENDIF
\ENDIF
\IF{$m=a_{macro}$}
\FORALL{states $s$ in {\em unsent-list\/}}
	\IF{$s\models pre(a_{macro})$)}
		\STATE Add $a_{macro}(s)$ to open
		\STATE Add $a_{macro}$ to $A_i$
	\ENDIF
\ENDFOR
\ENDIF
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
\caption{secure expand($s$)}
    \label{alg:secure-expand}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\STATE move $s$ to closed list
\IF{$s$ is a goal state}
	\STATE broadcast $s$ to all agents \label{line:broadcast1-1}
	\STATE initiate verification of $s$ as a solution	\label{line:broadcast2-1}
	\RETURN
\ENDIF
\IF{the last action leading to $s$ was public  \textbf{or} a macro}
	\FORALL{agents $\varphi_j \in \Phi$}\label{line:sending-forloop-1}	
		\IF{$\varphi_j$ has a public action for which all public preconditions hold in $s$} \label{line:relevant-1}%\textbf{or} the last action leading to $s$ achieved a goal proposition }
			\STATE virtual-send($s$,$\varphi_j$)	\label{line:virtual-send}
		\ENDIF
	\ENDFOR
\ENDIF
\IF{the last action $a_{last}$ leading to $s$ was public}
	\STATE Let $s_{ancestor}$ be the earliest ancestor of $s$ generated by a public action
	\STATE Let $a_1,\ldots,a_k(=a_{last})$ be the actions such that $a_k(\cdots(a_1(s_{ancestor}))\cdots)=s$
	\STATE Create a macro $a_{macro}$ from $a_1,\ldots,a_k=a_{last}$ [Note that $a_k$ is the only public action in this sequence]
	\STATE Remove any preconditions of $a_{macro}$ on $\varphi_i$'s private variables replacing them by its encoded private state at $s'$
	\IF{$s_{ancestor}$ was sent to the agent by $\varphi_j$}
			\STATE send $a_{macro}$ to $\varphi_j$
	\ENDIF
\ENDIF
\STATE apply $\varphi_i$'s operators and macros to $s$ \label{line:succ-1}
\FORALL{successors $s'$}\label{line:successors-forloop-1}
	\STATE update $g_{\varphi_i}(s')$ and calculate $h_{\varphi_i}(s')$
	\IF{$s'$ is not in closed list \textbf{or} $f_{\varphi_i}(s')$ is now smaller than it was when $s'$ was moved to closed list}
		\STATE move $s'$ to open list \label{line:move-to-open-list-1}
	\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}
\begin{algorithm}
\caption{virtual-send($s,\varphi_j$)}
    \label{alg:virtual-send}
\begin{algorithmic}[1]  %[n] = every n'th line is numbered
\IF {sent-list contains a state $s'$ that differs from $s$ in the agent's private variables only}
	\STATE add $s$ to unsent-list
\ELSE
	\STATE send $s$ to $\varphi_j$
	\STATE add $s$ to sent-list
\ENDIF
\end{algorithmic}
\end{algorithm}




\subsection{Soundness and Completeness}
We now prove the correctness of the algorithm.

\begin{lemma}
\smafs\ is sound.
\end{lemma}
\begin{proof}
A simple inductive argument shows that states generated are reachable from the initial state.
States are only generated by applying actions or actions sequences (macros) to other
states. Since the open list is initialized with the initial state, all such states are reachable.
We note that the use of macros leads to much simpler proofs than in the original formulation of
\smafs.

Next, goals are public, and so their identification is easy, and can be done by any agent.
Finally, tracing back the plan is analogous to the centralized case, except that it is done in
a distributed manner, where the token passes from $\varphi_j$ to $\varphi_i$ when $\varphi_j$
reaches a state $s$ that was sent to it by $\varphi_i$
\end{proof}

%To simplify the remaining proofs we assume, without loss of generality, that there are public actions only.
%This can be achieved by replacing every set $A_i$ with all legal sequences of private actions followed by a single public action, all from $A_i$. There is no loss of generality because no information is exchanged following private actions,
%and a pubic goal is reachable iff it is reachable via a sequence of actions in which a private action by an agent is always followed by
%another action (private or public) by the same agent.
%% Computationally, this is not a very good idea, as it can increase the number of actions considerably. But for the theoretical treatment of this section, this simplifies our analysis with no loss of generality.




\begin{lemma}[Completeness]

If $\Pi$ is solvable then \smafs\ will find a solution, provided each agent will eventually expand every node in its open list untill a solution is found.
\end{lemma}
\begin{proof}
Let $\pi$ be some solution to $\Pi$.
Without loss of generality (this follows from the results of~\cite{NBJAIR}) in $\pi$ every private
action of an agent $\varphi_i$ is followed by another action (private or public) of $\varphi_i$.
Moreover, since the goal is public, any private action at the end of the plan can be removed without affecting its correctness
(it affects private variables only). Thus, we can also assume that $\pi$ ends with a public action.
Let $\bar{a_1},\ldots,\bar{a_m}$ be a partitioning of $\pi$ into subsequences (possibly of length 1)
such that each $\bar{a_i}$ contains exactly one public action which appears last in this subsequence.
By the above, $\bar{a_i}$ contains actions of a single agent only.

We will prove the following stronger claim:
\begin{claim}
If $s$ is reachable via a sequence of action sequences as above, then $s$ will appear in the
open list of some agent (unless a goal is found earlier).
\end{claim}
\begin{proof}
By induction on $m$, the  number of above subsequences required to reach $s$.

For $k=0$, the initial state is inserted initially to all open lists.

Next,  consider a sequence of length $k+1$ of subsequences that reaches $s$. Let $s'$ be the
state reached via $\bar{a_1},\ldots,\bar{a_k}$, the first $k$
subsequences, and assume that the actions in $\bar{a_k}\in A_i$
and the actions in $\bar{a_{k+1}}\in A_j$.
By the inductive assumption, we know that $s'$ will appear in the open list of the agent that generates it, i.e., $\varphi_i$.
We need to show that either (1) $\varphi_i$ will send $s'$ to $\varphi_j$, in which case $\varphi_j$ will eventually apply the actions in $\bar{a_{k+1}}$,
or that (2) $\varphi_j$ has sent or will send $\varphi_i$ a macro that is equivalent to $\bar{a_{k+1}}$, in which case this
macro will be applied to $s'$ by $\varphi_i$ at some point, generating $s$.

Since $s'$ is in $\varphi_i$'s open list, and by our assumption the public preconditions of $\bar{a_{k+1}}$ must hold
at $s'$, $\varphi_i$ will virtual-send $s'$ to $\varphi_j$. If it actually sends $s'$, we are done, as $\varphi_j$ will eventually
apply the relevant actions. Otherwise, $s'$ will be inserted into the {\em unsent\/} list. This implies that some state $s''$ that
is identical to $s'$, except for the private variables of $\varphi_i$, was sent earlier. Note that $\bar{a_{k+1}}$ is applicable
in $s''$ because $\varphi_i$'s private variables cannot appear in the preconditions of actions in $\bar{a_{k+1}}$.
Consequently, $s''$ was sent to $\varphi_j$. Since $\bar{a_{k+1}}$ is applicable at $s''$, at some point it would be applied,
and the macro that corresponds to it would be generated (l.~16) and sent to the $\varphi_i$. If $s'$ was already in
the {\em unsent\/} list when the macro was received, $\varphi_i$ would generate $s$ and insert it into its open list.
Otherwise, $s'$ has not been expanded yet. When it will be expanded, $\varphi_i$ will apply the macro that corresponds to
$\bar{a_{k+1}}$, and $s$ will be inserted into its open list. Note that, the macro generated by $\varphi_j$ will not require any
preconditions that are private to agents other than $\varphi_j$. However, by our assumption, the private variables of $\varphi_j$
in $s'$ and $s''$ are identical, as are all public variables, and therefore it will be applicable.
\end{proof}
If $s$ appears in the open list of some agent, it will eventually expand it, under our assumption, and the solution will have been found.
\end{proof}

Given a state $s$, we use $s_{-i}$ to denote the partial assignment that is identical to $s$ on all state variables that are {\em not}
private to agent $\varphi_i$. That is $s$, with the private variables of $\varphi_i$ projected out.
We now prove the following uniqueness property which will be useful for our privacy analysis:
\begin{lemma}[Uniqueness]
\label{l:unique}
During the run of \smafs\, an agent $\varphi_i$ will never receive two states $s\neq s'$ such that $s_{-i}=s'_{-i}$.
\end{lemma}
\begin{proof}
%First, we prove that no agent receives two states $s,s'$ such that $s=s'$. Let agent $\varphi_j$ be the first agent to receive a state twice.
%Let $s$ be that state. $s$ could not have been sent by the same agent because \smafs\ monitors for this case.
%Hence, it was sent by two different agents. Note that both agents sent a state that had identical value to agent $\varphi_i$'s private variables.
%Hence, these states must be descendants of the same state, $s_{parent}$ that was sent to them by $\varphi_i$ (Recall our assumption about the encryption
%of private states. Each encrypted private state is sent once only). This means that both agents developed $s_{parent}$ using their actions and reached
%an identical state. Hence, they did not change the value of their own private variables in
%the process (otherwise, the other agent could not generate this state). However, our assumption of unique encryption
%stipulates that the private state of the agent is never the same in two states sent by the agent. So the private states of these agents in $s_{parent}$
%and the state they sent ($s,s'$) must be different, and so $s\neq s'$.

Assume, to the contrary, that agent $\varphi_l$ is the first agent to receive  two states, $s,s'$ such that $s_{-i}=s'_{-i}$.
These states could not have been sent by $\varphi_i$, as {\em virtual-send\/} ensures this.
These two states could not have been sent to $\varphi_l$ by another agent $\varphi_k$, such that $k\neq i$ since if $s\neq s'$ but $s_{-i}=s'_{-i}$
then the private state of $\varphi_k$ is identical in $s,s'$, contrary to our assumptions about unique state encoding (which must follow from
$s_{-k}\neq s'_{-k}$).

Thus, $s,s'$ were sent to $\varphi_l$ by two different agents $\varphi_j$ and $\varphi_k$, respectively.
The private values of $\varphi_j$ and $\varphi_k$ are identical in $s$ and $s'$. Let $s_a$ and $s'_a$ be the ancestors to $s$ and $s'$ respectively
from which $s$ and $s'$ were obtained by applying actions of a single agent only. In particular, this implies that private value of $\varphi_j$ in
$s$ and $s'_a$ are identical. But this is impossible. The private value of $\varphi_j$ in $s'_a$ is derived from its private value in the closest ancestor $s'_{ancestor}$ of $s'_a$ sent by $\varphi_j$ (or from the initial state). By our unique encryption assumption, it cannot be the case that $\varphi_j$ sent
two states, $s$ and $s'_{ancestor}$ in which its private state was encrypted identically.

\end{proof}

We end with a note on optimality. {\sc mad-a*}~\cite{NB12} is a special instance of \mafs\ that guarantees that the resulting plan will be cost-optimal.
The main issue in it is distributed solution detection which essentially ensures that no agent has in its open list a better state than the proposed goal,
nor is there some such state that is in transmission. In the case of \smafs\ there can also be macros in transmission, which would later on yield new states.
For these macros to lead to a better solution, there must be some current state with an $f$ value better than the goal state found.
More problematic is the potential existence of states that were not sent, that is, states in the {\em unsent-list\/} that have a lower $f$ value than the
corresponding earlier state sent. One particular example is state re-expansion. That is, state $s$ such that $s=s'$, $s$ was sent, and $f(s')<f(s)$.%
\footnote{For \smafs\, re-expansion is just a special instance of $s_{-i}= s'_{-i}$. Of course, some optimizations can be applied, e.g., ignore it if its $f$ value
is no lower than the previous expansion.}
Thus, the solution detection algorithm must be take into account the possibility that a better solution reachable from that state exists.
It is possible that due to the high $f$ value of $s$, other agent did not explore path leading from it to a better solution, when $s'$ is used instead.
For these agents to explore these path, the value of this state needs to be modified. This could be done, for example, by resending the original state with
a new value. We leave the precise formulation and analysis of a more secure version of {\sc mad-a*} as an open problem for future work.



\section{Privacy Guarantees}
We now introduce our main proof technique which is based on  a type of search tree, which we call the {\em $i$ projected-out search tree}.

The forward search tree $G^{\Pi}$ associated with a planning task $\Pi$ is a well known concept.  Its root node is the initial
state, and for every node containing state $s$, its children correspond to all states obtained by applying all applicable actions to $s$.
The children's order is algorithm dependent -- it corresponds to the order by which the children will be expanded. (Note, that this does not
imply that the children are expanded one after the other, in a breadth-first manner).
Leaf nodes are goal states that satisfy the optimization criteria (e.g., in satisficing planning, all goal states;
in optimal planning, goal states with optimal $f$ value) and dead-ends. In principle, the states in the tree can be generated in any topological order,
but the use of a particular search algorithm restricts the order further.

In the context of \mafs, this definition must be slightly modified to take into account the restriction that following a private action by $\varphi_i$,
only another action by $\varphi_i$ may follow. Consequently, we say that a node is \emph{private} to $i$ if the action that generated it is private to $\varphi_i$.
A node is \emph{public} if the action that generated it was public. The root node is public. Now, the definition of $G^{\Pi}$ is altered so that
the children of a node that is private to $i$ and contains $s$ are $\{a(s) | a\in A_i\}$, i.e., nodes that contain states obtained by applying an action of
$\varphi_i$ at $s$. If $s$ is a public node, its children are $\{a(s) | a\in A\}$.

We define the $i$ {\em projected-out search tree}, $G^{\Pi}_{-i}$, to be very similar excepts that levels correspond to consecutive actions by $\varphi_i$
are flattened, each state $s$ is replaced by $s_{-i}$, and duplicates are removed.
First, we defined the flattened out version of $G^{\Pi}$, $G^{\Pi}_{i-flat}$, which is defined as follows.
We refine the definition of a public node to be either \emph{public}, or \emph{public to $i$}.
The root node is public.
The children of a node $s$ that is public to $i$ are $\{a(s)| a\in A\setminus A_i\}\cup \{\pi(s)| \pi\mbox{ is a sequence of action from }A_i\}$.
The nodes in $\{a(s)| a\in A\setminus A_i\}$ are classified as either public or private to $j$, as defined above.
The nodes in $\{\pi(s)| \pi\mbox{ is a sequence of action from }A_i\}$ are private to $i$ if the last action in $\pi$ is private to $i$,
and are public to $i$ otherwise. If $s$ is private to $j\neq i$, then its children are $\{a(s) | a\in A_j\}$, as above.
If $s$ is private to $i$, it has no children. If $s$ is public to $i$, its children are $\{a(s)| a\in A\setminus A_i\}$, that is all states that can be obtained by
applying an action by another agent. Again, these children are classified are either public or private to $j$ as in the case of $G^{\Pi}$.

The above definition simply ensures that nodes obtained by applying a sequence of actions from $A_i$ to some state are all siblings.
Now, we can define $G^{\Pi}_{-i}$ to be the result of replacing every state $s$ that is private to $i$ or public to $i$ (i.e., was generated by $\varphi_i$)
by $s_{-i}$ and removing duplicates.


\begin{lemma}
The $i$ projected-out search tree is well defined.
\end{lemma}
\begin{proof}
Potentially, duplicates could appear in different parts of the tree, leading to multiple ways of removing them.
We now show that this is not possible. That is, duplicates can only occur among siblings in $G^{\Pi}_{-i}$, which implies that there is only one possible
$i$ projected-out search tree.

We do this in three steps: First, we show that it is not possible for agents other than $\varphi_i$ to
generate two different states $s,s'$ such that $s_{-i}=s'_{-i}$. Next, we show that such $s,s'$ cannot be generated by $\varphi_i$ and
$\varphi_j$ for some $j\neq i$. Finally, we show that $\varphi_i$ can generate two states $s\neq s'$ such that $s_{-i}=s'_{-i}$ only if they are both descendants of some common ancestor $s_a$, and are obtained from $s_a$ by applying a sequence of actions of $\varphi_i$ only, that contains a single public action.
\begin{claim}
An agent $\varphi_i$ running \mafs\ cannot receive two messages containing states $s,s'$ such that $s_{-i}=s'_{-i}$.
\end{claim}
\begin{proof}
First, we note that such $s,s'$ cannot be sent by an agent $\varphi_j$ ($j\neq i$). If the states are identical, the $s_{-j}=s'_{-j}$ and so $\varphi_j$
will send the first one generated only. If the states $s_{-j}\neq s'_{-j}$ then by our unique encoding assumption, $\varphi_j$ will use a different private-state
encoding, implying $s_{-i}\neq s'_{-i}$.

Next, suppose that $s,s'$ were sent by $\varphi_j,\varphi_k$, respectively. Since $s_{-i}=s'_{-i}$, the private state of $\varphi_j$ in both states must be identical.
Given our unique private state assumption, there must exist some state $\hat{s}$ that is an ancestor of both states. $s$ must have been obtained from
$\hat{s}$ using $\varphi_j$'s action only, while $s'$ is the result of actions by additional agents, ending with those of $\varphi_k$. But given the unique private
state assumption, $\varphi_j$ would use a different private state in $s$ than in $\hat{s}$, contradicting $s_{-i}=s'_{-i}$.
\end{proof}

\begin{claim}
An agent $\varphi_i$ running \mafs\ cannot receive a message containing a state $s$ such that $s_{-i}=s'_{-i}$ and $s'$ was generated by $\varphi_i$.
\end{claim}
\begin{proof}
Denote  the agent sending $s$ by $\varphi_j$. The private state of $\varphi_j$ in $s,s'$ is identical.
But this can only be possible if $s,s'$ have some common ancestor $\hat{s}$ such that from $\hat{s}$ to $s,s'$ no state was sent by $\varphi_j$.
So this implies that $\hat{s}=s$, and that $s'$ was by applying some actions to $s$ by agents other than $\varphi_j$.
If all the actions applied from $\hat{s}=s$ to $s'$ are by $\varphi_i$, this implies that $s$ was sent twice to $\varphi_i$, which is impossible.
Hence, some other agent $\varphi_k$ was involved in the process. That agent sent one of the descendants of $s$ to $\varphi_i$, and given the unique
private state assumption, must have changed its private state in the process. Hence the private state of $\varphi_k$ in $s$ and $s'$ is different,
and so $s_{-i}\neq s'_{-i}$.
\end{proof}

\begin{claim}
If $\varphi_i$ generates two states $s,s'$ such that $s_{-i}=s'_{-i}$ then $s,s'$ are descendants of a common ancestor $s_a$ obtained by
applying a sequence of private actions followed by at most one public action, all of which are in $A_i$.
\end{claim}
\begin{proof}
THE PROBLEM IS EXEMPLIFIED BY MOVE VS PICKUP AND PUTDOWN. THEY GENERATE THE SAME STATE. SO THEY ARE IDENTICAL.
HOWEVER, THEY ARE NOT SIBLINGS.
MAYBE WE SHOULD CHANGE TO "AN I-PROJECTED" RATHER THAN "THE I-PROJECTED" BUT IF IT IS NOT THE SAME, THE PARTICULAR PROJECTED TREE COULD GIVE A HINT. OR, WE WOULD HAVE TO SOMEHOW SHOW THAT THERE IS A FLATTER STRUCTURE THAT CAPTURES THE MESSAGES OBTAINED. MAYBE A PARTIAL ORDER?
All states have a common ancestor, the initial state. Let $s_a$ be the closest common ancestor of $s,s'$. From arguments made in the
proof of the previous claims, we know that no other agent is involved in the sequence of actions from $s_a$ to $s$ and to $s'$.
As long as private actions are applied to $s_a$, the resulting states are all identical, except for $\varphi_i$'s private state.
If a public action is applied, the public state could change, but different public actions may have identical effect on the public variables.

Suppose that $\varphi_i$ can generates two states $s,s'$ such that $s_{-i}=s'_{-i}$ but the condition above is not satisfied.
Let $s,s'$ be the earliest states with this property, where by earliest we mean that there are no two states with this property such that
$s$ and $s'$ are descendants of any of these states. (Note that, in principle, there may be multiple earliest pairs such as this, which is fine.)
Let $\bar{s}$ be their closest common ancestor (which is, at the worst case, the initial state). To reach at least one of $s,s'$ from $\bar{s}$ some
other agent must apply actions from $\bar{s}$ in at least one of $s,s'$. W.l.o.g, let $\varphi_j$ ($j\neq i$) be the last agent to apply an action on the path
from $\bar{s}$ to $s$. $\varphi_j$ must send the resulting state (or one of its descendants) $\hat{s}$ to $\varphi_i$.
By our unique private encoding assumption, the  encoding of $\varphi_j$'s private state in $\hat{s}$ and $\bar{s}$ must be different.
At this point, there are two options: $s'$ was obtained by the application of a different action of $\varphi_j$, with the resulting state
being $\hat{s}'$ which implies that it either differs from  $\hat{s}$ in the public variables and therefore, also by the encoding of the private variables (because these states are sent as two different messages). Note that if $\hat{s}'=\hat{s}$ then a single message is sent, and it will be the closest ancestor, not $\bar{s}$.
Or, $s'$ did not require the application of an action by $\varphi_j$, in which case, again, by unique private state encoding, it will have a different private state
for $\varphi_j$.
\end{proof}
Given our claim above, the choice of which duplicate state is removed will not impact the search tree, as all states that are obtained from
a state $s$ expanded by $\varphi_i$ using its own actions only will appear as children of $s$ in the $i$ projected-out search tree. This follows from the
fact that private actions change only private variables, and hence have no impact on the $i$ projected-out state.
\end{proof}

Our basic observation is that the $i$ projected-out search tree together with the order by which its nodes are expanded provides an upper bound on the
information that an agent can learn during the course of a run of the \smafs\ algorithm. That is, given this information, an agent
can deduce all the information it receives about $\varphi_i$ during the run of the algorithm. This implies that
if two domains have the same $i$ projected-out search tree, and this tree is expanded in the same order, then agents running \smafs\ cannot distinguish between these two algorithms.

%Throughout the rest of this paper, unless noted otherwise, we shall assume the existence of two agents only. In terms of privacy analysis, this is equivalent to the assumptions that all agents other than $\varphi_i$ may share information in order to learn about $\varphi_i$. If we can guarantee privacy under this assumption of collusion, then if the agents do not collude, they can only learn less.

\begin{theorem}
\label{t:tree}
Let $\Pi$ and $\Pi'$ be two planning problems. If $G^{\Pi}_{-i} = G^{\Pi'}_{-i}$ and $A_i$ contains unit cost public actions only, zero-cost private actions,
and the heuristic value of a node depends only on its non-private component, then agents other than $\varphi_i$ cannot distinguish between an execution of \smafs\ on $\Pi$ and $\Pi'$
\end{theorem}
\begin{proof}
$G^{\Pi}_{-i} = G^{\Pi'}_{-i}$ implies that the search-tree is identical, except for, possibly, the various private parts (and multiplicity) of
states with identical non-private part. Given our assumption on $g$ and $h$, the expansion order of this tree depends only on
the non-private component of the states, which is identical in both cases. Messages are sent based on the non-private part only,
so in both cases, $\varphi_i$ will send identical messages and identical macros.
Since the other agent sees the same messages and generates the same states (their state generation is not influenced by the private variables of $\varphi_i$,
they will send identical messages in both cases, and so the executions will appear identical to all agents other than $\varphi_i$.
%(Formally, by induction on the number of messages involved in the generation of a state).
PROOF IS INSUFFICIENT. WE ARE IGNORING THE MACROS.
\end{proof}
Our essential claim here is that the agents generate the same messages (states, macros), and send them in the same order.
First, we note that macros are a by-product of the state sent.
To ensure that the order is identical

LOOKS LIKE WE DON'T NEED TO REQUIRE COST 1 PUBLIC ACTIONS, BUT WE NEED TO ENSURE THAT THE PRIVATE ACTIONS IN DIFFERENT DOMAINS WILL NOT AFFECT THE EXPANSION ORDER. IF THE HEURISTIC DOES NOT DEPEND ON THEM, IT IS NOT CHANGED BY THEIR APPLICATION, AND THE COST DOES NOT CHANGE EITHER. WE WILL NEED TO ASSUME THAT THE ALGORITHM WILL GENERATE NODES THAT
ARE NO BETTER THAN EARLIER NODES (CONSISTENT HEURISTIC) BUT ALSO THAT THE EXPANSION IS SUCH THAT IF I EXPANDEDED
A NODE I WILL EXPAND ANOTHER NODE IF ITS F VALUE IS THE SAME. THAT IS, WE SOMEHOW NEED TO TRY TO SHOW THAT NODES ARE GENERATED IN THE SAME ORDER. NOTE THAT IT IS POSSIBLE FOR TWO AGENTS TO GENERATE THE SAME STATE BY APPLYING PUBLIC
ACTIONS ONLY THAT HAVE THE SAME EFFECT, BUT NO EFFECT ON THE PRIVATE STATE. HOWEVER, BY OUR ASSUMPTION, THE PRIVATE
STATE IS NEVER THE SAME, SO THIS CANNOT HAPPEN.

 CONSIDER PROVING FIRST THAT IS NODES ARE GENERATED IN THE SAME ORDER, THEN WE CANNOT DISTINGUISH.


NEED TO DO VIRTUAL SEND TO THE MACRO TOO -- OTHERWISE ONE MAY SEE TWO PRIVATE STATES FOR THE SAME PUBLIC STATE?
NEED TO CHECK IF THIS IS NECESSARY. PERHAPS THE MACRO DOES NOT INCLUDE PROBLEMATIC INFORMATION.
THE ASSUMPTION OF DIFFERENT PRIVATE STATES IS GOING TO LEAD TO PROBLEMS IN THE MACRO GENERATION.
THE AGENT IS UNLIKELY TO BE ABLE TO APPLY THE MACRO AGAIN!

NEED TO VERIFY THE MACROS RELATION TO THE STATE AND THAT THEY DO NOT REVEAL INFORMATION.

ESSENTIALLY, WHAT MATTERS IS THE ORDER BY WHICH THE AGENT SENDS MESSAGES.
IF THE SEARCH TREE IS THE SAME, THEN PERHAPS WE CAN FORCE IT TO SEND MESSAGES IN THE SAME ORDER?
ESSENTIALLY, THE MESSAGES DEPEND ON EXPANSION ORDER. IN THAT CASE,  WE COULD SEND THE MESSAGES WHEN THE CHILDREN ARE
GENERATED. ALTERNATIVELY, LAZY EVALUATION WOULD ASSOCIATE THE SAME VALUE FOR THE CHILDREN WITH THE PARENT.




Theorem~\ref{t:tree} provides a tool for proving strong privacy. As an example, consider the case of
independent private variables. Formally, $v$ is an {\em independent private\/} variable of $\varphi_i$ if
$v$ is a private variable of $\varphi_i$ and if $v$ appears in a precondition of $a$ then all
the variables that appear in $a$'s description are private, and all its effects are on independent private variables.
For example, suppose that the truck doesn't only deliver goods, but the driver sells drugs on the side, having actions
of buying and selling them at various places. The action of selling/buying a drug at a location has no effect on public variables, nor on
private variables that can impact public variables.

Given a set of variables, the actions in the domain  induced by the removal of these variables contain  the original
actions, except for those in which the removed variables appear as preconditions and/or effects. In our example, if we
remove the variable {\em has-drugs(agent)}, the actions of selling and buying drugs are also removed.

\begin{lemma}
\label{L:independent}
Let $\Pi$ be a planning problem and let $R$ be a set of independent private variables of $\varphi$.
Agents other than $\varphi_i$ cannot distinguish between an execution of \smafs\ on $\Pi$ and $\Pi_{-R}$, the problem obtained by removing $R$,
assuming $R$ does not influence $h$.
\end{lemma}
\begin{proof}
The addition or removal of private independent variables does not influence $G^{\Pi}$.
It simply leads to additional public actions (when we compile away private actions) that differ only in their effect on the variables in $R$.
Since the value of variables in $R$ does not influence our ability to apply any of the other actions,
$G^{\Pi}_{-i} = G^{\Pi_{-R}}_{-i}$.
\end{proof}

We illustrate the utility of the above techniques by showing that
\smafs\ is strongly private for logistics.
We say that a location is public if more than one agent can reach it.
%The following was claimed informally for \mafs\ in~\cite{NBJAIR}.

\begin{lemma}
Under the above assumptions, \smafs\ is strongly private for logistics.
\end{lemma}
\begin{proof}
The public information in logistics is whether or not a package is in a public location.
Thus, consider  two planning problems $\Pi$ and $\Pi'$ that have the same set of packages, the same set of public locations, and, initially,
identical locations for packages that are in locations that are not private to $\varphi_i$.
We claim that $G^{\Pi}_{-i} = G^{\Pi'}_{-i}$.
To see this, note that  two states that differ only in the location of packages that are in places private to $\varphi_i$ have
the same sub-tree, projected to ${-i}$ under the assumption that every private location is reachable from every other
private location. Thus, from Theorem~\ref{t:tree} it follows that agents cannot distinguish between these domains.
\end{proof}
Suppose, further, that logistics is augmented with public actions that are executable in a private location.
For example, suppose the amount of fuel of an agent is public, and agents can fuel in private locations.
The above result remains true. On the other hand, consider a, somewhat contrived,
logistics variant in which certain private locations are reachable from some other private locations only by passing through some
public locations, and that trucks must unload their cargo when passing in a public location.
In that case, $G^{\Pi}_{-i} \neq G^{\Pi'}_{-i}$, and we would not be able to apply Theorem~\ref{t:tree}.
Thus, we see that our strong privacy proofs are sensitive to the specifics of the domains.
Finally, note that in all proofs above, we assume that the agents are honest but curious, and these proofs are correct even if
all agents collude, combining their information.
%The above case shows why it is difficult to prove general strong privacy results, such as Lemma~\ref{L:independent}.

We now briefly, and informally, consider two other domains. The {\em satellites\/} domain is strongly private, both for \mafs\ and \smafs\ because
no satellite supplies or destroys preconditions of actions of another satellite, and the only public actions are actions that achieve a sub-goal.
The only information one agent can learn about another agent when this property holds is whether or not it is able to achieve a sub-goal.
Private sub-goals can be modelled by adding a proposition such as {\em private-sub-goals-achieved} and an action that achieves it with the set of private sub-goals as its (private) preconditions, and the above remains true. The {\em rovers\/} domain is more similar to {\em logistics\/}. Agents can block or free a shared resource, the channel, required for communication, and
some of the sub-goals are achievable by multiple agents. Because of the shared channel, all communication actions are public. Private information includes the location of the agent, the state of its internal instruments, the existence of such instruments, and what information the agent has
acquired.  We claim that this information is strongly private in \smafs\ in the following sense. If an agent can move between locations freely, without requiring intermediate public actions (which implies that it can collect information in whatever order it wishes), the projected search trees of two planning problems in which the agents have identical capabilities, that is, they can acquire the same information (pictures, soil samples, etc.), are identical. Thus, external agents cannot differentiate between them.
%The state of internal instruments and their existence is strongly private in the sense that
%an external agent cannot distinguish between two domains in which the agent can communicate the information directly, or where it has to collect it via some process -- this follows from Theorem~1. If an agent can move between locations freely, without requiring intermediate public actions, the location parameter is also strongly private. That is, external agents cannot differentiate between a problem in which the agent needs to visit locations physically to obtain information, and a domain in which it can somehow obtain this information without moving.

\section{Search Trees}
Regular and i-projected search tree. Discuss order of expansion.
Show that regular search-tree is equivalent to lossless projection. What can we say about encrypted messages in MAFS? Is that equivalent to lossless projection?

\section{Proving Privacy}
same search tree -- strong privacy for MAFS
same i-projected search tree -- strong privacy for secure MAFS

\section{Heuristics}
Discuss impact of heuristics on the search trees.
Consider projection heuristics and related requirements.

\section{Advanced}
Eps-greedy?

Speculative: What happens if agents do not know what public actions exists, but rather, what public variables can be affected (is this equivalent). What if they don?t know the public actions that are in the plan, only the state of the public variables.


\section{Discussion}


\subsection{Secure Multi-Party Computation}
Secure Multi-Party Computation \cite{Yao82b,Yao86} is a subfield of Cryptography which relates closely to distributed planning, as well as to distributed problem solving in general. The goal of methods for secure multi-party computation is to enable multiple agents to compute a function over their inputs, while keeping these inputs private. More specifically, agents $\varphi_1,\dots,\varphi_n$, having \emph{private} data $x_1,\dots,x_n$, would like to jointly compute some function $f(x_1,\dots,x_n)$, without revealing any information about their private information, other than what can be reasonably deduced from the value of $f(x_1,\dots,x_n)$.


While in principle, it appears that these techniques can be extended to our setting of distributed planning, their complexity quickly becomes unmanageable. For example, a common approach for secure multiparty computation uses cryptographic circuits. When solving the shortest path problem (e.g., network routing, Gupta et al., 2012\nocite{GuptaSPSSFRS12}), the size of the circuits created is polynomial in the size of the graph. In our setting the function $f$ computes a shortest path in the implicit graph induced by the descriptions of the agents' actions. As this graph is exponential in the problem description size, it quickly becomes infeasible to construct these circuits given time and memory limitations. While it is true that planning is NP-hard and forward search algorithms do, in general, require exponential time/memory, the purpose of heuristic search is to reduce the search space and to solve large problems in low-polynomial time. Requiring the construction of exponential-sized circuits {\em a-priori}  contradicts the goal of efficiency and feasibility. Another difference between our model and the ones used for secure multiparty computation, is that these methods assume that some ($\geq 1$) of the agents are honest, and the other agents are adversaries which are determined to uncover the private information.
In distributed planning, the distinction between honest agents and adversaries is not as clear-cut. Despite faithfully participating in the distributed protocol, all agents might benefit from discovering other agents' private information (e.g., competing companies or contractors), and therefore can all be viewed as adversaries where privacy is concerned. Therefore, the assumptions usually made for secure multiparty computation regarding the limited number of adversaries do not fit our models as well.


\subsection{Privacy}
\label{sec:discussion_privacy}
Work in distributed CSPs \cite{YokooSH02,SilaghiM04} identified that although a key motivation for distributed computation is preservation of agent privacy, some private information may leak during the search process. For example, in DisCSP each agent has a single variable, and there exist both binary and unary constraints. Binary constraints are public since more than one agent knows of their existence, while unary constraints are considered private information. In meeting scheduling, an agent has a single variable whose values are possible meeting time slots. A binary constraint could be an equality constraint between the values of two variables belonging to different agents, while a unary constraint represents slots in which the agent cannot hold meetings. During search, whenever an agent sends some assignment of its variable to other agents, they can deduce that that value has no unary constraint forbidding it. If this value does not end up being assigned in the solution, the agent revealed some private information that could not have been deduced from only viewing the solution. In the field of DisCSPs, there has been work focusing of how to \emph{measure} this privacy loss \cite{FranzinRFW04,MaheswaranPBVT06}, as well as work on analyzing how much information specific algorithms lose \cite{GreenstadtPT06}. More recently, further work has emerged on how to alter existing DisCSP algorithms to handle stricter privacy demands \cite{GreenstadtGS07,LeauteF09}.

Given a model of a distributed system such as \mastrips, it is natural to ask how to search for a solution. The best known example of distributed search is that of distributed CSPs \cite{YokooDIK98}, and various search techniques and heuristics have been developed for it \cite{MeiselsBook}. Planning problems can be cast as CSP problems (given some bound on the number of actions), and the first attempt to solve \mastrips\ problems was based on a reduction to distributed CSPs. More specifically, Brafman and Domshlak  introduced the \textit{Planning as CSP+Planning} methodology for planning by a system of cooperative agents with private information. This approach separates the public aspect of the problem, which involves finding public action sequences that satisfy a certain distributed CSP, from the private aspect, which ensures that each agent can actually execute these public actions in a sequence. Solutions found are locally optimal, in the sense that they minimize $\delta$, the maximal number of public actions performed by an agent. This methodology was later extended to the first fully distributed MA algorithm for \mastrips\ planning, \textit{Planning-First} \cite{NissimBD10}. \textit{Planning First} was shown to be efficient in solving problems where the agents are very loosely coupled, and where $\delta$ is very low. However, it does not scale up as $\delta$ rises, mostly due to the large search space of the distributed CSP. Recently, a distributed planner based on partial order planning was introduced \cite{TorrenoOS12}, which outperforms Planning First, effectively solving more tightly coupled problems. Both methods are privacy preserving, but do not guarantee cost-optimal solutions.

In our model of distributed planning, things are a bit different. To consider privacy loss during search, first we must examine what type of information could leak during  distributed search. Our model considers the private preconditions of public actions, private actions, and private
action costs as private information which the agents do not want to disclose. %Consider a software company which has a public action ``release product'', but does not want to disclose that the preconditions for that action are \emph{doneQA} and \emph{prepareNextVersion}, as well as the cost of achieving these preconditions.

We begin by discussing the cost of private actions. When running \masas, messages sent by the agents contain $g$-values, or the currently minimal cost of arriving at a state. Given this information throughout the search procedure, the agents can deduce an upper bound on the minimal cost of applying public action $a$, given a \emph{public} state $s$. Consider an example of a system consisting of two agents $\varphi_{1,2}$. During the search procedure, $\varphi_1$ sends public state $s$ to $\varphi_2$ multiple times, each with different private states, which are indistinguishable to $\varphi_2$, by applying methods discussed in Section \ref{sec:privacy}. Upon receiving $s$, $\varphi_2$ continues searching until applying public action $a$, and then sending the resulting state $s'$ back to $\varphi_1$, which can now compute $g(s')-g(s)$, or the total (including private) cost of applying $a$. If $\varphi_1$ minimizes this value for every $s'$, it can now deduce an upper bound on the minimal cost of applying $a$ given public state $s$.

Another possible leak of information can be the existence of private actions or private preconditions of public actions. These affect whether or not a public action can be applied at certain states. When running \mafs, the first bit of information which can easily be deduced is whether a public action is applicable in some reachable state. Clearly, if an agent sends a state for which the creating operator is public action $a$, then other agents now know that there exist some reachable state in which $a$ is applicable. However, this information is apparent from
the public description of public actions, and hence is not private.

However, there exists a potentially more serious leak of information. Given all the knowledge accumulated during the search process, agents can attempt to recreate some model of other agent's private states, and the possible transitions between these private states. For example, given every public state, agents can see which actions were applicable and which actions where not applicable. If the actions are different, agents can deduce that the states are different. This information can later be used in order to reconstruct a model of the agent's private state using techniques for learning with hidden values or techniques for learning hidden states. Of course, there is no guarantee that this information will be correct or useful, obtaining it requires collaboration between different agents (that need to share which public states they received from the agent), and algorithms for learning in the context of hidden variables/states can be weak. Nevertheless, clearly some information could leak.

The discussion above indicates that careful investigation of information leaks and development of algorithms that have better privacy guarantees is an important avenue for future research. First, it would be interesting to see work that empirically investigates the significance of privacy loss. For example, our empirical results indicate that many problems can be solved quickly using distributed forward search, without expanding too many nodes. Is it possible to build reasonable models of agent's private states in such cases?

Second, one can develop variants of current algorithms that have stronger privacy preserving properties.
For example, consider the problem of inferring upper bounds on the cost the minimal cost of applying action $a$ in public state $s$. In general, private actions which achieve preconditions of a public action do not have to be applied immediately before \emph{that} public action -- an agent can perform some of the private actions required for a public action before a previous public action. In other words, an agent can ``distribute'' the private cost of a public action between different ``segments'', or parts of the plan between two public actions, making the cost of the first action appear higher and the cost of the second action lower, although with some potential impact on optimality.
In the case of non-optimal search, $g$-values are not disclosed, so this is not an issue.

The above example illustrates a general idea: one can trade-off efficiency for privacy. A similar tradeoff is explored in the area of {\em differential privacy}~\cite{Dwork06}. There, some noise is inserted into a database before statistical queries are evaluated, such that the answer to the statistical query is correct to within some given tolerance, $\epsilon$, yet one cannot infer information about a particular entry in the database (e.g., describing the medical record of an individual). Similarly, in our context, one can consider algorithms in which agents refrain from sending certain public states with some probability, or send it with some random delay, or even possibly, generate bogus, intermediate public states. Such changes are likely to have some impact on running time and solution quality, and these tradeoffs would be interesting to explore.

We believe that as this area matures, much like in the area of DisCSP, more attention will be given to the problem of precise quantification of privacy and privacy loss. Our work brings us closer to this stage. It offers algorithms for distributed search that start to match that of centralized search, and perhaps more importantly, a general methodology for distributed forward search that respects the natural distributed structure of the system,
%(i.e., where agents need only apply their own operators)
that can form a basis for such  extensions.



\vskip 0.2in
\bibliography{cites}
\bibliographystyle{theapa}

\end{document}






