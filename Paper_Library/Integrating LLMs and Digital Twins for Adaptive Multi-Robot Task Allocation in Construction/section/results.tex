\section{Case Study}

To validate the proposed framework, a case study is conducted to verify the system workflow and evaluate module capabilities. A BIM model is employed in this study as the digital environment for evaluating LLM performance. Rhino is used as the BIM platform, which offers intuitive user interface to edit attribute data and can be interfaced with other applications. Fig. \ref{fig:construction_scene} shows the initial BIM model, which represents the current state of the construction site. The robotic system leverages the BIM model and the extracted task list to identify work zones and dynamically allocate tasks. The robotic agents receive task assignments based on priority, dependencies, and spatial constraints, ensuring an optimized workflow. Human workers can interact with the system by updating task priorities, modifying scheduling constraints, or assigning specific tasks to robots based on evolving site conditions. As robotic agents complete their tasks, the BIM model is updated in real-time, reflecting changes in the construction progress.

\begin{figure}[t]%% placement specifier
%% Use \includegraphics command to insert graphic files. Place graphics files in 
%% working directory.
\centering
\includegraphics[width=0.48\textwidth]{Paper_Figures/Figure4.png}
%% Use \caption command for figure caption and label.
\caption{Scene of the construction site}\label{fig:construction_scene}
%% https://en.wikibooks.org/wiki/LaTeX/Importing_Graphics#Importing_external_graphics
\end{figure}

The physical site is simulated in Gazebo, with inter-robot communication established through ROS. Fig. \ref{fig:simulation} demonstrates an example scenario of the simulation, where two robots transfer window frames to windows of corresponding sizes: red frame strips for wider windows and blue strips for narrower ones.
 It is important to note that the robots are not expected to handle all tasks independently, but rather to complete or assist with specific tasks, with human workers often remaining essential to the process.
Once a robot transfers and places the frame strips on the ground near a window, the associated transfer task is completed, and a human worker installs the frame on the wall. The actions of human workers are not modeled; instead, the world state is updated, and the frames are teleported onto the wall. Following installation, the simulation updates the building state specifications and transmits the relevant information to the digital twin for incorporation into the BIM data.

\begin{figure*}[tb]%% placement specifier
%% Use \includegraphics command to insert graphic files. Place graphics files in 
%% working directory.
\centering%% For centre alignment of image.
\includegraphics[width=0.8\linewidth]{Paper_Figures/construction_simulation.png}
%% Use \caption command for figure caption and label.
\caption{Simulation of the task allocation and completion}\label{fig:simulation}
%% https://en.wikibooks.org/wiki/LaTeX/Importing_Graphics#Importing_external_graphics
\end{figure*}



Since the robot trajectory planners and communication framework can be seamlessly applied to similar mobile robots in real-world settings, this simulation is used to assess the practicality of the proposed framework in actual applications.







\subsection{Digital twin demonstration}

The digital twin is developed using Unity, with a project template designed to automatically generate interactive digital twins from different BIMs, eliminating the need for manual setup each time \cite{wang2024enabling}. This template includes five key components: (1) robot emulators for robot state synchronization; (2) BIM object templates for digital model visualization; (3) site information templates for site data rendering; (4) user interface elements for user supervision and intervention; and (5) BIM update functions. A screenshot of the digital twin interface and the robot status tracker is shown in Fig. \ref{fig:dt_interface}.

The robot emulators are created by subscribing to robot descriptions from ROS through the ROS\# library \cite{siemens2025rossharp}. Robot URDF files and meshes, stored in ROS, are retrieved and stored in Unity as game objects. These game objects represent the hierarchical structure of each robot: links are structured as children of their respective parent links, allowing dynamic transformation updates based on real-time state data. A dedicated script is attached to each robot emulator to subscribe to robot states (i.e., arm joint states and base locations and orientations), enabling continuous pose synchronization.

"Prefab" game object templates are used to visualize BIM components. For each component in BIM, a prefab object template is instantiated in the Unity scene. The mesh of the instantiated object is automatically set to the component mesh received from the BIM to replicate the site environment. The script attached to the template can change the name, layer, material, and state of the instantiated object according to its BIM attributes. For example, the objects that have not yet been constructed are rendered as hidden or transparent in the digital twin. This BIM-Unity communication is established with Rhino.Inside, which is an open-source plugin to run Rhino and its API inside other applications on the Windows operating system.

For the site information, this case study specifically focuses on the construction materials. Monitoring the states of materials is essential in construction projects for supply management and task scheduling. Additionally, due to their large size and weight, these materials pose significant safety considerations during robot manipulation. Both the resting and active materials are tracked. Locations of the materials resting on site are detected by robots and instantiated in the digital twin as game objects. For materials being manipulated, they are attached as a child to the end effector or moving platform of the corresponding robot based on their attachment offsets. Therefore, they can move with the robot during operation.

In addition, the user interface elements are created. The digital twin is initiated with two buttons on the top-left corner for users to access the task status tracker and the robot status tracker. Once the "Task Status" button is clicked, a panel shows up with text inside displaying a comprehensive task list along with the status of each task (i.e., uninitiated, ongoing, or completed). The initial task list is received from the BIM at project initiation. As construction progresses, task statuses are updated via messages received from ROS. Similarly, the "Ongoing" button provides the users with a summary of the current task each robot is performing, shown as task IDs, followed by high-level task descriptions, also via messages received from ROS. An example of robot status tracker is demonstrated in Fig. \ref{fig:dt_interface}. At the bottom-right corner of the UI, two additional buttons are used to collect user inputs. The keyboard button pops up a text input field for typing, while the voice button transcribes spoken input to text with the transcription API from OpenAI. The text collected is then passed to the LLM module for further processing and interpretation.

 
\begin{figure*}[t]
\centering
\includegraphics[width=0.7\textwidth]{Paper_Figures/InterfaceFigure.png}
\caption{Screenshot of digital twin interface}\label{fig:dt_interface}
\end{figure*}



\subsection{Construction tasks and robot capabilities}
Typical construction tasks, such as element delivery, window installation, wall drilling, HVAC duct installation, wiring, wall painting, and site inspections, are used to showcase the capabilities of the methodologies developed in this study. The assumed durations and dependencies of these tasks are detailed in Table \ref{tab:task_durations_dependencies}. Additionally, seven types of robots with varying capabilities, as outlined in Table \ref{tab:robot_capabilities}, are considered alongside these construction-related tasks. For instance, robots equipped with a cargo container can assist with material transport and element delivery tasks. Robots with an Indoor Air Quality (IAQ) sensor can help with site inspections, particularly in monitoring environmental conditions.


\begin{table}[h!]
% \centering
% \footnotesize % Increase font size to make it readable
\setlength{\tabcolsep}{5pt} % Set space between columns
\caption{Durations and dependencies of the construction tasks*}
\begin{tabular}{p{0.5cm}|p{0.95cm}|p{1cm}|p{3.6cm}|p{1cm}} % Adjust column widths as needed
    \toprule
    \textbf{Task} & \textbf{Pred.} & \textbf{Duration} & \textbf{Description} & \textbf{Robot} \\
    \midrule
    \(T_{1}\) & - & 0.25 & Move Electrical Conduit & \(R_1\) \\
    \(T_{2}\) & - & 0.25 & Move Window Frame & \(R_1\) \\
    \(T_{3}\) & - & 0.25 & Move Window & \(R_1\) \\
    \(T_{4}\) & - & 0.25 & Move Duct Structural Materials & \(R_1\) \\
    \(T_{5}\) & - & 0.25 & Move Duct & \(R_1\) \\
    \(T_{6}\) & - & 0.5 & Drill Wall & \(R_4\) / \(R_2\) \\
    \(T_{7}\) & \(T_{1}\), \(T_{6}\) & 1 & Install Electrical Conduit & \(R_5\) / \(R_2\) \\
    \(T_{8}\) & \(T_{2}\) & 1 & Install Window Frame & \(R_4\) / \(R_2\) \\
    \(T_{9}\) & \(T_{3}\), \(T_{8}\) & 0.5 & Install Window & \(R_3\) \\
    \(T_{10}\) & \(T_{4}\) & 2 & Duct Structural Framing & \(R_4\) / \(R_2\) \\
    \(T_{11}\) & \(T_{5}\), \(T_{10}\) & 2 & Install HVAC Duct & \(R_4\) / \(R_2\) \\
    \(T_{12}\) & \(T_{7}\) & 2 & Install Wiring & \(R_5\) / \(R_2\) \\
    \(T_{13}\) & \(T_{12}\) & 1 & Wall Painting & \(R_6\) \\
    \(T_{14}\) & - & 0.5 & Construction Site Inspection & \(R_7\) \\
    \bottomrule
\end{tabular}
\label{tab:task_durations_dependencies}
\\
\textit{*Note: Durations are in hours. ``Pred.'' denotes predecessor.}
\end{table}


\begin{table}[h!]
\centering
\scriptsize % Use a smaller font size
\caption{Robot capabilities and quantities}

\begin{tabular}{l|c|c|c|c|p{0.3cm}|p{0.35cm}|p{0.3cm}}
    \toprule
    \textbf{Robot} & \(R_{1}\) & \(R_{2}\) & \(R_{3}\) & \(R_{4}\) & \(R_{5}\) & \(R_{6}\) & \(R_{7}\) \\
    \textbf{Number} & [1,4] & [1,2] & [1,2] & [1,2] & [1,2] & [1,2] & [1] \\
    \midrule
    Cargo container & 1 & & & & & & \\
    High-payload & & 1 & 1 & 1 & & & \\
    Suction-based gripper & & & 1 & & & & \\
    Precise parallel gripper & & 1 & & & 1 & & \\
    Normal parallel gripper & & 1 & & 1 &  & & \\
    Sprayer & & & & & & 1 & \\
    Camera & & & & & & & 1 \\
    IAQ sensors & & & & & & & 1 \\
    \bottomrule
\end{tabular}
\label{tab:robot_capabilities}
\end{table}



\subsection{LLM performance analysis}

To evaluate the LLMs' ability to interpret constraints of varying complexity, we constructed a test set consisting of 500 descriptive narrative samples. Each sample includes one or more types of constraint and parameter changes as defined in Table \ref{tab:constraint_changes}. The dataset is evenly divided into five groups based on the number of changes described in each sample. For example, the first group contains 100 samples, each involving a single change. The second group includes 100 samples with two randomly selected changes, and so on, up to the fifth group, which contains samples with five randomly selected changes. We then define three metrics to comprehensively evaluate the LLMs' performance, including (1) Constraint Accuracy, (2) Parameter Accuracy, and (3) Correct Rate. Constraint Accuracy measures how accurately the LLM identifies the categories of changes, as defined and labeled from 1 to 5 in Table \ref{tab:constraint_changes}. Parameter Accuracy evaluates the accuracy of specific extracted values or attributes given each constraint, such as task duration or robot change. Finally, the Correct Rate assesses the proportion of cases in which the LLM provides entirely accurate responses across all evaluated constraints and parameters.

The evaluation of the selected LLMs’ performance across five task difficulty levels is presented in Fig. \ref{fig:llm_performance} and Table \ref{tab:llm_performance}. The results reveal a consistent pattern that Constraint Accuracy remains consistently high (around 100\%) across all LLMs, demonstrating their robust capacity to accurately interpret and classify task relationships, even as task complexity increases. 



\begin{figure*}[tb]
\centering
\includegraphics[width=0.95\linewidth]{Paper_Figures/llm_performance.png}
\caption{Performance evaluation of selected LLMs across five complexity levels using Constraint Accuracy, Parameter Accuracy, and Correct Rate.}\label{fig:llm_performance}
\end{figure*}




Regarding Parameter Accuracy, GPT-4.1, GPT-4.1-mini, and GPT-4o outperform Anthropic’s Claude models and GPT-4o-mini across five complexity levels.  In particular, GPT-4.1 and GPT-4o maintain consistently high accuracy scores (typically above 95\%) across difficulty levels. In contrast, Claude models achieve moderate Parameter Accuracy (generally between 70\% and 80\%). This pattern suggests that Claude and GPT4o-mini models encounter difficulties extracting precise details, such as task durations and robot types, from complex textual descriptions.


In terms of the Correct Rate metric, which provides a more integrated assessment, GPT-4.1 achieves the highest Correct Rates across all difficulty levels (consistently above 95\%), underscoring its comprehensive understanding and robust performance in combined reasoning tasks. GPT-4o and GPT-4.1-mini also show commendable Correct Rates at lower complexity but exhibit noticeable performance drops at higher difficulty. The other three selected LLMs, Claude-Haiku, Claude-Sonnet, and GPT-4o-mini models display substantial reductions in Correct Rate, especially at higher complexity levels, often falling below 40\%.



Overall, the evaluation identifies OpenAI's GPT-4.1 models as the top performers across all assessed metrics, consistently achieving nearly 98\% accuracy with narrower confidence intervals across all five complexity levels. This indicates that GPT-4.1 offers superior precision and reliability in handling intricate construction scheduling analyses compared to other evaluated models. While GPT-4o models also deliver strong performance, they exhibit noticeable limitations as task complexity increases. These findings are promising for construction project scheduling as they illustrate the capability of advanced LLMs, particularly GPT-4.1, to reliably automate and accurately manage complex scheduling tasks.


\begin{table}
\centering
\caption{Average performance across all difficulty levels}
\begin{tabular}{l|c|c|c}
\toprule
\textbf{Model} & \textbf{Constraint Acc.} & \textbf{Parameter Acc.} & \textbf{Correct Rate} \\
\midrule
claude\_haiku & 96.2\% & 74.9\% & 45.4\% \\
claude\_sonnet & 96.5\% & 77.9\% & 51.4\% \\
gpt4o\_mini & 96.2\% & 79.3\% & 53.8\% \\
gpt4o & 99.5\% & 98.2\% & 93.4\% \\
gpt4.1\_mini & 98.9\% & 96.1\% & 88.8\% \\
gpt4.1 & 99.8\% & 99.2\% & 97.6\% \\
\bottomrule
\end{tabular}
\label{tab:llm_performance}
\end{table}

\subsection{Optimization results}

To evaluate the performance and efficiency of formulated task allocation algorithms in construction tasks, we randomly vary the number of available robots for each type according to the number ranges specified in Table \ref{tab:robot_capabilities}. In addition, we vary the number of tasks as outlined in Table \ref{tab:task_durations_dependencies} by generating either one or two sets from the groups \(\{T_{1}, T_{6}, T_{7}, T_{12}, T_{13}\}\), \(\{T_{2}, T_{3}, T_{8}, T_{9}\}\), and \(\{T_{4}, T_{5}, T_{10}, T_{11}\}\). Tasks within the same group are selected together to maintain the task dependencies. Overall, 1000 test scenarios with different combinations of robots and tasks were created to evaluate the proposed framework (row 1 in TABLE \ref{tab:task_allocation_evaluation}).

To simulate scenarios with additional time window constraints (row 2 in TABLE \ref{tab:task_allocation_evaluation}), we randomly select between one and three tasks and impose a condition that these tasks must start after a randomly chosen period of 2 to 4 hours, reflecting scheduling conflicts. For scenarios with task conflict constraints (row 3 in TABLE \ref{tab:task_allocation_evaluation}), we enforce that tasks in the set \(\{T_{6}, T_{7}, T_{8}, T_{9}, T_{12}, T_{13}\}\) cannot be performed concurrently, as they require collaboration with a single available worker for these tasks. Similarly, we generated 1024 test scenarios incorporating various combinations of robots and tasks with either the time window or task conflict constraints. To evaluate the replanning optimization (row 4 in TABLE \ref{tab:task_allocation_evaluation}), the plan created without time constraints is used as the original plan, and additional time window constraints are introduced during replanning. The updated plan should leverage the original plan while satisfying the time constraints and accounting for the penalty associated with deviations from the original plan.

\begin{table}[htbp]
  % \centering
  \caption{Evaluation of the task allocation algorithm*}
    \begin{tabular}{c|c|c|c|c|c|c}
    \toprule
    \multirow{3}[2]{*}{} & \multirow{3}[2]{*}{Tasks} & \multirow{3}[2]{*}{Robots} & Max   & Max   & Max   & Avg \\
          &       &       & \# of & \# of & Time  & Time \\
          &       &       & Vars  & Cons. & (sec) & (sec) \\
    \midrule
    Original & 14-27 & 15    & 345   & 377   & 3.40  & 0.13 \\
    Time window & 14-27 & 15    & 345   & 379   & 1.26  & 0.05 \\
    Task conflicts & 14-27 & 15    & 345   & 378   & 23.76 & 0.48 \\
    Replanning & 14-27 & 15    & 372   & 406   & 0.08  & 0.02 \\
    \bottomrule
    \end{tabular}%
  \label{tab:task_allocation_evaluation}%
  \\

  \textit{*The table displays only the maximum and average values across task scenarios. ``Vars.'' and ``Cons.'' denote variables and constraints, respectively.}
\end{table}%

\begin{figure*}[tb]%% placement specifier
%% Use \includegraphics command to insert graphic files. Place graphics files in 
%% working directory.
\centering%% For centre alignment of image.
\includegraphics[width=0.7\linewidth]{Paper_Figures/schedule.png}
%% Use \caption command for figure caption and label.
\caption{Example of the optimized task allocation and schedule}\label{fig:schedule}
%% https://en.wikibooks.org/wiki/LaTeX/Importing_Graphics#Importing_external_graphics
\end{figure*}


The integer programming-based task allocation is applied to the generated test scenarios. Table \ref{tab:task_allocation_evaluation} summarizes the number of tasks, robots, decision variables, and constraints in each scenario, along with the corresponding computational times to find the optimal solution. According to the table, on average, the optimal solutions are found within under one second, demonstrating the efficiency of our task allocation formulation.

Fig. \ref{fig:schedule} presents an example of task allocation results. Following these results, we ran the simulation, and the scene at the snapshot time was captured as shown in the Fig. \ref{fig:simulation} and Fig. \ref{fig:dt_interface}. In this scenario, the robot fleet includes two robots of type R1, two of type R2, and one each of types R3, R6, and R7. These robots are assigned to complete one set of wall installation and painting tasks, one set of electrical wiring tasks, one set of HVAC duct installation tasks, two sets of window installation tasks, and a site inspection. The optimal completion time for the schedule is calculated to be 5.25 hours.


In addition to the initial plan, a replanned scenario is also illustrated. We present a scenario in which, at 0.2 hours into the schedule, the workers realize that the structural materials required for the HVAC duct installation are unavailable due to delivery delays and will not arrive until 0.5 hours. This disruption necessitates a reallocation of tasks. Applying the replanning framework described in Section \ref{sec:method-replanning}, the system minimally adjusts the initial plan to accommodate the disturbance. Considering the penalties for deviating from the original schedule, the updated plan reassigns R1 to execute task T5 followed by T4, reversing the original task order (as shown in Fig. \ref{fig:schedule}).


% \begin{table}[htbp]
%   % \centering
%   \caption{Evaluation of the task allocation algorithm*}
%     \begin{tabular}{c|c|c|c|c|c}
%     \toprule
%           & Tasks & Robots & Vars. & Cons. & Time (sec) \\
%     \midrule
%     Original & 27 & 15    & 345 & 377 & 0.053 \\
%     Time window & 27 & 15    & 345 & 379 & 0.047 \\
%     Task conflicts & 27 & 15    & 345 & 378 & 0.095 \\
%     Replanning & 27 & 15    & 372 & 406 & 0.105 \\
%     \bottomrule
%     \end{tabular}%
%   \label{tab:task_allocation_evaluation}%
%   \\

%   \textit{*The table displays only the maximum values across task scenarios. ``Vars.'' and ``Cons.'' denote variables and constraints, respectively.}
% \end{table}%



% \begin{table}[htbp]
%   \centering
%   \caption{Evaluation of the task allocation algorithm*}
%     \begin{tabular}{c|c|c|c|c|c}
%     \toprule
%           & Tasks & Robots & Vars. & Cons. & Time (sec) \\
%     \midrule
%     Original & 14-27 & 7-15    & 67-345 & 72-377 & 0.004-0.053 \\
%     Time window & 14-27 & 7-15    & 67-345 & 74-379 & 0.005-0.047 \\
%     Task conflicts & 14-27 & 7-15    & 67-345 & 73-378 & 0.005-0.095 \\
%     \bottomrule
%     \end{tabular}%
%   \label{tab:task_allocation_evaluation}%
%   \\
%   \textit{*Note: Vars. and Cons. stand for variables and constraints, respectively.}
% \end{table}%


