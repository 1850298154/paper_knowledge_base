% \vspace{-0.05in}
\section{Limitation and Future Work}
% \vspace{-0.05in}

While our experiments focus on the two-agent setting, the method itself, as described in section \ref{sec:method}, is not limited to such cases. Due to space constraints, we leave evaluation in broader multi-agent settings to future work.
Besides, the current algorithm follows a structured debate-style interaction, where the LLMs follow a predefined sequence of steps. 
A promising direction is to leverage advanced LLMs to understand the objective of PeerGuard and adapt defense strategies without predefined steps.


% \vspace{-0.05in}
\section{Conclusion} \label{sec:conclusion}
% \vspace{-0.05in}

In this paper, we present automatic defense debate which leverage the reasoning ability of LLM in various multi-agent systems to defend against potential backdoor attacks, improving MAS safety. High attack success rate in all agents of MAS press need to defense against these vulnerabilities. Our experiments illustrate that debates between agents in the system, and scrutinizing the inconsistency within each other's reasoning procedure, can improve MAS safety. 

% \textbf{Limitations. }However, there are great room for improvement of our method. Further experiments on more datasets that are not mentioned in this paper should be demonstrating generalizability of the proposed method. Though agents are debating without manual intervention, pre-designed templates are required to serve as Chain-of-Scrutiny pattern to better utilize its reasoning capabilities for inspection of the consistency. We believe in the future, template-free reasoning procedure will be initiated for multi-agent systems defense. 


