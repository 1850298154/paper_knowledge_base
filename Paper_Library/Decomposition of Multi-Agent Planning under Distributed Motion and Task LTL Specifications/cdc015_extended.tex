%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document


\usepackage{graphicx}     
\usepackage{url} 
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{color}
\usepackage{cite}


\usepackage{pgf}
\usepackage{tikz}
\usetikzlibrary{arrows,automata,positioning}


\let\proof\relax
\let\endproof\relax
\usepackage{amsthm}
\newtheoremstyle{exampstyle}
  {0.1cm} % Space above
  {0.1cm} % Space below
  {\it} % Body font
  {} % Indent amount
  {\bfseries} % Theorem head font
  {.} % Punctuation after theorem head
  {.5em} % Space after theorem head
  {} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{exampstyle} \newtheorem{lemma}{Lemma}
\theoremstyle{exampstyle} \newtheorem{remark}{Remark}
\theoremstyle{exampstyle} \newtheorem{proposition}{Proposition}
\theoremstyle{exampstyle} \newtheorem{assumption}{Assumption}
\theoremstyle{exampstyle} \newtheorem{corollary}{Corollary}
\theoremstyle{exampstyle} \newtheorem{definition}{Definition}
\theoremstyle{exampstyle} \newtheorem{theorem}{Theorem}
\theoremstyle{exampstyle} \newtheorem{problem}{Problem}
\theoremstyle{exampstyle} \newtheorem{example}{Example}



\newcommand{\T}{\mathcal{T}} %transition system
\newcommand{\A}{\mathcal{A}} %automaton
\newcommand{\B}{\mathcal{B}} %Buchi automaton
\newcommand{\BA}{B\"uchi automaton }
\renewcommand{\P}{\mathcal{P}} %product automaton
\newcommand{\R}{\mathcal{R}} %rabin automaton
\newcommand{\init}{\mathit{init}}
\newcommand{\pref}{\mathit{pref}}
\newcommand{\currs}{\mathfrak{s}}
\newcommand{\currq}{\mathfrak{q}}
\newcommand{\dur}{\Delta}
\newcommand{\wait}{\mathit{wait}}
\newcommand{\sync}{\mathit{sync}}
\newcommand{\nosync}{\mathit{nosync}}
\newcommand{\stay}{\mathit{stay}}
\newcommand{\Sync}{\mathit{Sync}}
\newcommand{\TS}{{\T=(S,s_{\init},{A} ,T, \AP, L)}}
\newcommand{\TSi}{{\T_i=(S_i,s_{\init,i},{A_i} ,T_i, \AP_i, L_i)}}
\newcommand{\Lab}{\mathcal{L}}

\newcommand{\irrelevant}{\Epsilon_i}
\newcommand{\Dep}{\mathit{Dep}}
\newcommand{\trans}{\mathfrak{t}}

\newcommand{\LTLX}{LTL$_{\setminus \Next}$ }

\newcommand{\N}{\mathcal{N}}
\newcommand{\M}{{M}}
\newcommand{\model}{\mathcal{M}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\D}{{D}}
\renewcommand{\O}{\mathcal{O}}
\newcommand{\Ser}{\Sigma} %services
\newcommand{\Sers}{\mathbf{\Sigma}}
\newcommand{\AP}{\Pi} %atomic propositions
\newcommand{\APs}{\mathbf{\Pi}}
\newcommand{\Lang}{\mathcal{L}} %language
\newcommand{\Set}{\mathsf{S}} %set
\newcommand{\Spec}{\mathbf{\psi}}

\newcommand{\Epsilon}{\mathcal{E}}

\renewcommand{\i}{\iota}

\newcommand{\Nat}{\mathbb{N}} %natural numbers
\newcommand{\Real}{\mathbb{R}}

%LTL
\newcommand{\prop}{\pi}
\newcommand{\Next}{\mathsf{X}}
\newcommand{\Until}{\mathsf{U}}
\newcommand{\Always}{\mathsf{G}}
\newcommand{\Event}{\mathsf{F}}
\newcommand{\true}{\mathit{true}}
\newcommand{\false}{\mathit{false}}

\renewcommand{\epsilon}{\varepsilon}

\newcommand{\ie}{{i.e.,~}}
\newcommand{\eg}{{e.g.,~}}

\newcommand{\progressive}{\varpi}
\newcommand{\move}{\mathit{move}}
\newcommand{\service}{\mathit{service}}
\newcommand{\h}{h}
\renewcommand{\H}{H}
\newcommand{\parti}{\mathit{P}}

%\renewcommand{\alph}{\Sigma}
\newcommand{\Alpha}{\mathbf{\Sigma}}
\renewcommand{\mod}{\mathrm{\, mod \, }}
\newcommand{\suc}{\mathit{succ}}
\newcommand{\dist}{\mathrm{dist}}
\newcommand{\proj}{\mathrm{proj}}

\newcommand{\jana}[1]{{\color{magenta}  #1}}
\newcommand{\gray}[1]{{\color{black!50}  #1}}
\newcommand{\blue}[1]{{\color{blue}  #1}}
\newcommand{\new}[1]{ #1}

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Decomposition of Multi-Agent Planning under Distributed Motion and Task LTL Specifications 
}

%\author{ \parbox{3 in}{\centering Huibert Kwakernaak*
%         \thanks{*Use the $\backslash$thanks command to put information here}\\
%         Faculty of Electrical Engineering, Mathematics and Computer Science\\
%         University of Twente\\
%         7500 AE Enschede, The Netherlands\\
%         {\tt\small h.kwakernaak@autsubmit.com}}
%         \hspace*{ 0.5 in}
%         \parbox{3 in}{ \centering Pradeep Misra**
%         \thanks{**The footnote marks may be inserted manually}\\
%        Department of Electrical Engineering \\
%         Wright State University\\
%         Dayton, OH 45435, USA\\
%         {\tt\small pmisra@cs.wright.edu}}
%}

\author{Jana Tumova and Dimos V. Dimarogonas% <-this % stops a space
\thanks{This work was supported by EU STREP RECONFIG, European Unionâ€™s Horizon 2020 Research and Innovation Programme under the Grant Agreement No.644128 (AEROWORKS), Swedish Research Council (VR), and H2020 European Reasearch Council (ERC) Starting Grant BUCOPHSYS. The authors are with the ACCESS Linnaeus Center, School of Electrical
Engineering, KTH Royal Institute of Technology, Stockholm,
Sweden and with the KTH Centre for
Autonomous Systems. Email:
        {\tt\small tumova@kth.se, }%
        {\tt\small dimos@kth.se}.}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

The aim of this work is to introduce an efficient procedure for discrete multi-agent planning under local complex temporal logic behavior specifications. While the first part of an agent's behavior specification constraints the agent's trace and is independent, the second part of the specification expresses the agent's tasks in terms of the services to be provided along the trace and may impose requests for the other agents' collaborations. To fight the extreme computational complexity of centralized multi-agent planning, we propose a two-phase automata-based solution, where we systematically decouple the planning procedure for the two types of specifications. At first, we only consider the former specifications in a fully decentralized way and we compactly represent each agents' admissible traces by abstracting away the states that are insignificant for the satisfaction of their latter specifications. Second, the synchronized planning procedure uses only the compact representations. The satisfaction of the overall specification is guaranteed by  construction for each agent. An illustrative example demonstrating the practical benefits of the solution is included.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Automated synthesis of correct-by-design controllers complying with complex behavior specifications has recently found a wide support in formal verification methods and temporal logics. A number of the suggested solutions build on a hierarchical approach\cite{hadas09TL, marius-tac2008, nok-hscc2010, kavraki-ram}, where the dynamics of the system is abstracted into a finite, discrete transition system, a discrete plan that meets the specification is synthesized and next translated into a controller for the original system.
This work focuses on a multi-agent version of the above problem, and particularly on the second step of the hierarchical approach. 
We consider a {heterogeneous} team of agents (e.g., robots), that are assigned a behavior specification each, comprising of the requirements on the sequence of states they go through (e.g., the robots' trajectories) and the services they provide (e.g., loading an object). The agents' tasks are though not completely independent; in order to achieve their task a collaboration of the other agents might be required (e.g., helping to load a heavy object). 
Our aim in this paper is to efficiently synthesize a strategy for each agent, such that all requirements are met. As a specification language, we use Linear Temporal Logic (LTL), for its resemblance to natural language~\cite{hadas-icra2012}, and expressive power. The goal is viewed from the bottom-up perspective, where we introduce the notion of local specification satisfaction based on the individual agents' own viewpoints. %The desired discrete plans comprise not only of the agents' discrete steps to be taken, but also their synchronizations. 



Multi-agent planning from temporal logic specification has been explored in several recent works. %~\cite{loizou-cdc2005,marius-cdc2011,sertac-ijnc2010,yushan-tr2012,alphan-ijrr2013,meng-cdc2013}. 
Planning for a team of robots from a global LTL specification was addressed, e.g., in~\cite{loizou-cdc2005,marius-cdc2011}.
 The authors in~\cite{sertac-ijnc2010} considered LTL  for vehicle routing and in~\cite{lygeros-ecc2013} for search and rescue missions. A decentralized control of a robotic team from local LTL specification with communication constraints is proposed in~\cite{dimos-cdc12, meng-cdc14}. In contrast to our work, the agents therein do not impose any constraints on the other agents' behavior. %hus, the focus of the paper is different to ours.
In~\cite{yushan-tr2012,alphan-ijrr2013}, a top-down approach to LTL planning is investigated; the team is given a global specification and an effort is made to decompose the formula into independent local specifications that can be treated separately. 
In~\cite{meng-ijrr2015}, bottom-up planning from LTL specifications is considered, and a partially decentralized solution is proposed that decomposes the group into clusters of dependent agents.
To cope with the state space explosion, in~\cite{ acc14, automatica} we have proposed a receding horizon approach to multi-agent planning.

In this paper, we take into account an extension of the previous problem, where besides the high-level \emph{tasks} in terms of services to be provided, the agents' behaviors are limited by additional temporal logic constraints, allowing to express safety, surveillance, sequencing, or reachability properties of their traces, which we call \emph{motion} specifications for simplicity.
We propose to decouple the planning for the former and the latter parts of the specification. The main idea is to build local synchronized product automata for each of the agents' motion separately and reduce their size before creating the global product. %Namely, we propose to systematically remove states and actions that are not significant for the collaboration before proceeding with the task planning. 
The contribution of this paper can thus be summarized as the introduction of an efficient, bottom-up control strategy synthesis for multi-agent systems from local LTL motion and task specifications. The designed strategy allows the agents to execute their finite plans to a large extent independently, in an asynchronous manner. % As a result, although each agent follows its finite plan, the real collective team behavior might deviate from the planned one due to different time durations of agents' discrete steps. Our algorithm is adaptive in that sense that even if the real behavior of the team is not as planned, the event-based synchronization and replanning still guarantees the satisfaction of all the missions. This feature can be especially beneficial in heterogeneous multi-robot motion and task planning problems, where individual robots traveverse their common environment at different speeds.

% receding horizon approach to multi-agent planning. The idea is to translate infinite horizon planning into an infinite sequence of finite horizon planning problems similarly as in \cite{nok-hscc2010}, where the authors leverage the same idea to cope with uncertain elements in an environment in single-robot motion planning. 
%{To guarantee the satisfaction of the formula, we use an attraction-type function that guides the individual agents towards a progress within a finite planning horizon; similar ideas were used in~\cite{dennis-rh2,dennis-rh,maja} for a single-agent LTL planning to achieve a locally optimal behavior.}

 %We follow the hierarchical approach to robot controller synthesis as outlined above and we narrow our attention to the second step of the approach, i.e., to generating discrete plans. 
%The application of the algorithm that we propose is, however, not restricted to discrete systems: For the first step of the hierarchical approach, numerous methods for discrete modeling of robotic systems can be used (see,~\eg\cite{hadas09TL, marius-tac2008, nok-hscc2010, lavalle} and the references therein); moreover, for the third step, low-level controllers exist that can drive a robot from any position within a region to a goal region (see, \eg\cite{Belta-TAC06}). {The agents can, but do not have to, mutually synchronize after the execution of their respective discrete steps. The desired discrete plans thus comprise not only of the agents' discrete steps to be taken, but also their synchronizations. Besides the satisfaction of all agents' missions, our goal is to avoid unnecessary synchronization in order to improve the team performance.}
 
%, and LTL control strategy synthesis.
%{In this paper, we consider an alternative definition of LTL to describe the desired tasks. Particularly, we perceive atomic propositions, over which LTL formulas are built, as offered services rather than undetachable inherent properties of the system states. For instance, given that a state is determined by the physical location of an agent, we consider atomic propositions of form ``in this location, data can be gathered'', or ``there is a recharger in this location" rather than ``this location is dangerous''. %In other words, the agent is given the option to decide whether an atomic proposition $\prop \in L(s)$ is in state $s$ satisfied or not. In contrast, $\prop \in \AP$ is never satisfied in state $s$, such that $\prop \not \in L(s)$. The LTL specifications are then interpreted over sequences of executed services along traces instead of the words produced by the traces.
%The formula is then interpreted over the sequences of services that were provided, not the sequences of states that the agents went through. 
%Instead of evaluation of the specification as a conjunction of LTL formulas over the whole team behaviors, we propose the notion of satisfaction of an LTL formula from local perspective. This way, the problem of finding a collective team behavior is decomposed into several subproblems, enabling us to avoid the straightforward, but expensive fully centralized planning.


%To our best knowledge, such an approach has not been taken to address the distributed multi-agent planning problem and its extreme computational demands before. In our solution, we repetitively build a finite discrete plan fragment, i.e., several next steps to be taken and services to be provided by the individual agents, using ideas from automata-based verification. We discuss the correctness of the solution and find assumptions, under which the proposed iterative algorithm leads to provable eventual satisfaction of the desired specifications. The solution was designed under the assumption that the agents synchronize after every discrete step, however we show that it is enough to synchronize and recompute the finite plan fragments only upon certain events. This allows the agents to execute their finite plans to a large extent independently, in an asynchronous manner. As a result, although each agent follows its finite plan, the real collective team behavior might deviate from the planned one due to different time durations of agents' discrete steps. Our algorithm is adaptive in that sense that even if the real behavior of the team is not as planned, the event-based synchronization and replanning still guarantees the satisfaction of all the missions. This feature can be especially beneficial in heterogeneous multi-robot motion and task planning problems, where individual robots traveverse their common environment at different speeds. }

%{This paper builds on our earlier work~\cite{acc14}. In addition, it relaxes the earlier assumptions that the agents synchronize after every single discrete step of theirs and introduces the event-based synchronization and replanning.}


%\subsection{Related Work}

%Multi-agent planning from temporal logic specification has been explored in several recent works. %~\cite{loizou-cdc2005,marius-cdc2011,sertac-ijnc2010,yushan-tr2012,alphan-ijrr2013,meng-cdc2013}. 
%{Planning from computational tree logic was considered in~\cite{quo-icra2004}, whereas in~\cite{loizou-cdc2005,marius-cdc2011}, the authors focus on planning behavior of a team of robots from a single, global LTL specification. 
 %A fragment of LTL has been considered as a specification language for vehicle routing problems for unmanned aerial vehicles in~\cite{sertac-ijnc2010}, and a general reactivity LTL fragment has been used in~\cite{lygeros-ecc2013} to express search and rescue missions. A decentralized control of a robotic team from local LTL specification with communication constraints is proposed in~\cite{dimos-cdc12}. However, the specifications there are truly local and the agents do not impose any requirements on the other agents' behavior. Thus, the focus of the paper is significantly different to ours.
 
%As opposed to our approach, in~\cite{yushan-tr2012,alphan-ijrr2013}, a top-down approach to LTL planning is considered; the team is given a global specification and an effort is made to decompose the formula into independent local specifications that can be treated separately for each robot.

%In~\cite{meng-ijrr2015}, bottom-up planning from LTL specifications is considered, and a partially decentralized solution is proposed that takes into account only clusters of dependent agents instead of the whole group. A huge challenge of the previous approach is its extreme computational complexity. To cope with this issue, in this paper, we propose a receding horizon approach to multi-agent planning. The idea is to translate infinite horizon planning into an infinite sequence of finite horizon planning problems similarly as in \cite{nok-hscc2010}, where the authors leverage the same idea to cope with uncertain elements in an environment in single-robot motion planning. 
%{To guarantee the satisfaction of the formula, we use an attraction-type function that guides the individual agents towards a progress within a finite planning horizon; similar ideas were used in~\cite{dennis-rh2,dennis-rh,maja} for a single-agent LTL planning to achieve a locally optimal behavior.}

%\subsection{Contribution}

{The rest of the paper is structured as follows. In Sec.~\ref{sec:prelims}, we fix necessary notation. Sec.~\ref{sec:pf} formalizes the problem statement. In Sec.~\ref{sec:solution}, the details of the solutions are provided. An illustrative example is given in Sec.~\ref{sec:experiment}. % serves to demonstrate the benefits of the proposed solution.%, and we conclude and outline several directions for future research in Sec.~\ref{sec:summary}.}

\section{NOTATION AND PRELIMINARIES}
\label{sec:prelims}
%\subsection{Notation}
Given a set $\Set$, let %$|\Set|$, 
$2^\Set$,
% and $2^{\Set +}$
and $\Set^\omega$
denote %the cardinality of~$\Set$, 
the set of all subsets of $\Set$, 
%the set of all nonempty subsets of $\Set$, 
and the set of all infinite sequences of elements of $\Set$, respectively. %A finite and infinite sequence of elements of $\Set$ is called a finite and infinite word over $\Set$, respectively. 
The $i$-th element of the sequence $w$ is $w(i)$, and a \emph{subsequence} of  an infinite sequence $w = w(1)w(2)\ldots$ is a finite or infinite sequence $w(\i_1)w(\i_2)\ldots$, such that $1 \leq \i_j \leq \i_{j+1}$, for all $1 \leq j$. %A \emph{factor} of  $w = w(1)w(2)\ldots$ is a continuous, finite or infinite, subsequence $w(i)w(i+1)\ldots$, where $1 \leq i$. A \emph{prefix} of $w$ is a finite factor starting at $i=1$, and a \emph{suffix} of $w$ is an infinite factor.
Boolean operator XOR (exclusive or) is denoted by~$\oplus$, positive integers and non-negative real numbers are denoted by $\Nat$ and $\Real_0^+$, respectively.



%^\subsection{System Model, Specification, and Control Synthesis}
\label{sec:prelims:synthesis}

%\begin{definition}[Labeled transition system]
A \emph{labeled transition system (TS)} is a tuple $\TS$, where
%\begin{itemize}
%\item 
$S$ is a finite set of states;
%\item 
$s_{init} \in S$ is the initial state;
%\item 
$A$ is a finite set of actions;
%\item 
{$T \subseteq S \times A \rightarrow S$} is a partial deterministic transition function;
%\new{\item $W: A \rightarrow \Nat$ is a weight function;}
%\item 
%\item 
$\Pi$ is a set of atomic propositions; and
%\item 
%\item 
$L: S \rightarrow 2^\Pi$ is a labeling function.
%\end{itemize}
%{For simplicity, we denote a transition $T(s,\alpha) = s'$ by $s \xrightarrow{\alpha} s'$. 
A \emph{trace} of $\T$ is an infinite alternating sequence of states and actions $\tau = s_1\alpha_1s_2\alpha_2\ldots$, such that $s_1=s_\init$, and for all $i \geq 1$, 
$T(s_i,\alpha) = s_{i+1}$.
%$s_i \xrightarrow{\alpha_i} s_{i+1}$. 
%A \emph{trace fragment} $\hat \tau = s_i \alpha _i s_{i+1}\ldots s_{j-1}\alpha_{j-1}s_j$ is a finite factor of a trace $\tau$ that begins and ends with a state.

%\label{def:TS}
%\end{definition}

%\begin{definition}[LTL]
An \emph{LTL formula} $\varphi$ over {the set of atomic propositions $\Ser$} is defined
  inductively:
% $$\varphi ::= \top \mid \prop \mid \varphi \lor
%    \varphi \mid \lnot\,\varphi \mid \Next\,\varphi \mid \varphi\,\Until\,\varphi$$
 %  \begin{enumerate}
  %\setlength{\itemsep}{1pt}
  %\setlength{\parskip}{0pt}
  %\setlength{\parsep}{0pt}
  %\item [(i)] 
  (i) $\prop \in \Ser$ is a formula, and
  (ii) if $\varphi_1$ and $\varphi_2$ are formulas, then $\varphi_1 \lor
    \varphi_2$, $\lnot \varphi_1$, $\Next\, \varphi_1$, $\varphi_1\,\Until\,\varphi_2$, $\Event \, \varphi_1$, and $\Always \, \varphi_1$
    are each {a formula},
 % \end{enumerate}
 %where $\top$ is a predicate true in each state of a system, % $\prop \in
%   \Pi$ is an atomic proposition,
 where $\neg$ and $\vee$
 are standard Boolean connectives, and $\Next$ (next), $\Until$ (until), $\Event$ (eventually), and  $\Always$ (always) are temporal operators.
%  \end{definition}
The semantics of LTL are defined over infinite words over~$2^\AP$ (see, e.g.,~\cite{principles}).
%, such as those produced by traces of the transition system from Def.~\ref{def:TS}. 
%Intuitively, an atomic proposition $\pi \in \AP$ is satisfied on a word {$w = \varpi_1\varpi_2\ldots$} if it holds at its first position {$\varpi_1$}, {i.e. if $\pi \in \varpi_1$}. Formula $\Next \, \varphi$ holds true if $\varphi$ is satisfied on the word   that begins in the next position {$\varpi_2$}, whereas $\varphi_1 \, \Until\, \varphi_2$ states that $\varphi_1$ has to be true until $\varphi_2$ becomes true. $\Event \, \varphi$ and $\Always \, \varphi$ are true if $\varphi$ holds on $w$ eventually, and always, respectively. For the full formal definition of the LTL semantics see, e.g.~\cite{principles}. The set of all words that are accepted by an LTL formula $\varphi$ is denoted by $\mathit{Lang}(\varphi)$. 
%\LTLX is a fragment of LTL that does not allow for the use of $\Next$ operator.
%\begin{definition}[LTL satisfaction]
A trace $\tau = s_1\alpha_1s_2\alpha_2\ldots$ of $\T$ \emph{satisfies}  an LTL formula $\varphi$ over $\Pi$ ($\tau \models\varphi$) iff $L(s_1)L(s_2) \ldots$ satisfies $\varphi$ ($L(s_1)L(s_2)\ldots \models\varphi$).
%\label{def:LTLsat}
%\end{definition}

%A trace $\tau$ of a transition system $\T$ satisfies LTL formula $\varphi$, denoted by $\tau \models \psi$ if and only if the word $w(\tau)$ satisfies $\psi$, denoted $w(\tau) \models \psi$. 
%\begin{definition}[B\"uchi automaton (BA)]
A \emph{B\"uchi automaton (BA)} is a tuple $\A =  (Q,q_{init},\Sigma,\delta,F)$, where
%\begin{itemize}
%\item 
$Q$ is a finite set of states; 
%\item 
$q_{init}\in Q$ is the initial state; 
%\item 
$\Sigma$ is an input alphabet; 
%\item 
$\delta \subseteq Q \times \Sigma \times Q$ is a non-deterministic transition relation; 
%\item 
$F \subseteq Q$ is an accepting condition.
%\end{itemize}
%\end{definition}
%An automaton is \emph{non-blocking} if  for all $q \in Q, \sigma \in \Sigma$ it holds that $\delta(q,\sigma) \neq \emptyset$.
%Given an automaton $\A$, we define the set of states $\hat \delta^k(q)$ that are reachable from a state $q \in Q$ in exactly $k$ steps inductively as
%\begin{align*}
% \hat \delta^0(q)  & = \{q\}, \text{ and}  \\ 
%\hat \delta^{k}(q) & = \bigcup_{q' \in \hat \delta^{k-1}(q)} \{q'' \mid \exists \, \sigma \in \Sigma. \, (q',\sigma,q'') \in \delta\}, \forall k \geq 1.
% \end{align*}
%A \emph{B\"uchi automaton} is an automaton with the accepting condition given as a set of accepting states $F \subseteq Q$ .
%The semantics of BA are defined over infinite input words over the input alphabet $\Sigma$. %, such as those generated by a transition system from Def.~\ref{def:TS} if $\Sigma = 2^\Pi$. 
A \emph{run} of the BA $\B$ from a state $q_1 \in Q$ \emph{over} a word {$w=\sigma_1\sigma_2\ldots \in \Sigma^\omega$}  is a sequence
$\rho=q_1q_2\ldots$, such that 
{$(q_i,\sigma_i,q_{i+1}) \in \delta$}, for all $i\geq 1$ and it is \emph{accepting} if it intersects $F$ infinitely many times. A word $w$ is \emph{accepted} by $\B$ if there exists an accepting run over~$w$ from the state $q_\init$. %The set of all words accepted by $\B$ is denoted by $\mathit{Lang}(\B)$.
Any LTL formula $\varphi$ over $\Pi$ can be algorithmically translated into an equivalent BA $\B$ with $\Sigma=2^\Pi$. % and $\Lang(\B) = \Lang(\varphi)$.%, and many software tools for the translation exist, such as LTL2BA~\cite{ltl2ba}. 
Any BA can be also viewed as a graph and the terminology from graph theory applies.% with the set of vertexes $V$ equal to $Q$, and the set of edges $E$ defined via $\delta$ in the expected way. %A path in the graph is a sequence of vertices connected via edges. The set of successors of $v\in V$ is the set of states $\{v' \mid (v,v'\in E)\}$ and the set of predecessors is $\{v'\mid (v',v)\in E\}$.

%Given a transition system $\T$, and an LTL formula $\varphi$, a control strategy, i.e., a trace of $\T$ that satisfies $\varphi$ can be synthesized with the use of automata-based model checking approach~\cite{principles}: . Then, a product between the transition system $\T$ and the B\"uchi automaton $\B$ can be built, that, loosely speaking, contains only behaviors admissible by both $\T$ and $\varphi$. Third, an accepting run of the product  that projects onto a desired trace of $\T$ can be found using graph algorithms.


%\jana{TODO: predecessor, sucessor, \LTLX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM FORMULATION}
\label{sec:pf}
Two general viewpoints can be taken in multi-agent planning: either the system acts as a team with a common goal, or the  agents have their individual, local specifications. Here, we adopt the second viewpoint and we do not look at the global team behavior. In contrast,  we
propose local specification satisfaction to determine whether an agent's task is fulfilled from its own perspective.
Each agent's temporal specification comprises of a \emph{motion}  % that expresses the requirements on the states it goes through, 
and a \emph{task} formula. % that specifies the desired actions to be taken. 
 %We would like to emphasize that motion and task requirements are typical, however not the only requirements, that can be expressed through the motion and action specifications. 
Loosely speaking, the motion formula can be viewed as the agent's safety, reachability, surveillance or sequencing, while the task one represents its {effectiveness}, i.e, the motion formula limits the sequence of states the agent's goes through, while  the task formula corresponds to an accomplishment of a high-level task composed of simple services that the agent has the ability to provide. Unlike the motion one, the task formula may involve collaboration requirements.%, i.e., requirements on the actions performed by the other agents.
%combine the two approaches: \jana{REWRITE the agents are given both a single team goal defined in terms of simple, possibly collaborative, tasks and local specifications that limit their individual behaviors to meet complex temporal requirements.} Informally, our goal is to synthesize a control strategy for each agent that comprises of (i) ~the actions to be executed and (ii)~the requests for synchronization imposed on other agents. Together, the strategies have to ensure the satisfaction of both the team mission specification and each of the task specifications. % regardless of the time duration of the planned action executions.
%\jana{Ideally, we would like to decouple the two ...}

Our goal is to synthesize a control strategy for each agent that involves (i)~the actions to be executed and (ii)~the requests for synchronization imposed on other agents. Together, the strategies have to ensure the local satisfaction of each of the motion and task specifications regardless of the time duration of the planned action executions.


%\jana{TODO: write on how the specs look like, informally, how the decisions are made.., mention the motion and the action part}

\subsection{System Model}

{Let us consider $N$ agents (e.g., robots in a partitioned environment). Each agent $i \in \N$, where $\N = \{1,\ldots, N\}$ has two different types of capabilities: the ability to execute an action primitive, and to synchronize with the others. }

%\new{Loosely speaking, our aim is to automatically synthesize agents' traces that satisfy certain complex requirements. The requirements are given as LTL formulas. As opposed to the traditional point of view, when the LTL formulas are defined over atomic propositions that are inherent properties of system states, we define LTL formulas over \emph{atomic actions} that the agents can execute in certain states. Hence, LTL serves as a means to express missions in terms of executing actions, or in other words providing services.}\janamargin{}{careful with the word action}

\subsubsection{Action Execution Capabilities} The agent $i$'s action-execution capabilities are modeled as a  finite TS $\TSi$. The states of the TS correspond to states of the agents (\eg the location of the robots in the regions of the environment). The atomic propositions represent inherent properties of the system states (\eg the robot is in a safe region). The actions represent abstractions of the agent's low-level controllers, and the transitions between the states correspond to the agent's capabilities to execute the actions (\eg the ability of the robots to move between two regions of the environment). The traces are, roughly speaking, the abstractions of the agents' long-term behaviors (\eg the robots' trajectories). %For the simplicity of  the presentation, we assume that each state $s \in S_i$ is reachable from all states $s'\in S_i$ via a sequence of transitions, i.e., that any agent can return to a state, where it already was in the past. }
Each of the agents' action executions takes a certain amount of time. Given a trace $\tau = s_1\alpha_1s_2\alpha_2\ldots$ of $\T_i$, we denote by $\Delta_{\alpha_j} \in \Real_0^+$ the time \emph{duration} of the transition $s_j\xrightarrow{\alpha_j}s_{j+1}$. Note that a transition duration is arbitrary and unknown prior its execution, and that the execution of the same action $\alpha$ may induce different transition durations in its different instances on the trace. %In other words, the fact that $\alpha_j = \alpha_k = \alpha$, such that $j \neq k$ does not necessarily imply that $\Delta_{\alpha_j} = \Delta_{\alpha_k}$. 

\subsubsection{Synchronization Capabilities} Next to the action-execution capabilities, the agents have the ability to \emph{synchronize}, i.e., to wait for each other and to proceed with the further  execution simultaneously. The synchronization is modeled through the \emph{synchronization requests}. While being in a state $s$, an agent $i$ can send a request $sync_i(I)$ to a subset of agents $\{i\} \subseteq I \subseteq \N$ notifying that it is ready to synchronize. Then, before proceeding with the execution of any action $\alpha \in A_i$, it has to wait till $sync_{i'}(I)$ has been sent by each agent $i' \in I$, i.e., till the moment when each agent $i' \in I$ is ready to synchronize, too. For simplicity, we assume the perfect propagation of the synchronization requests. The synchronization is immediate once each of the agents $i' \in I$ has sent its request  $sync_{i'}(I)$ and all agents in $I$ start executing the next action collaboratively, at the same time. %Alternatively, an agent $i$ indicates that it does not need to synchronize through requesting $\nosync_i$.
The set of all synchronization requests of an agent $i$ is 
$\Sync_i = \{\sync_i(I) \mid \{i\} \subseteq I \subseteq \N\}$.
Note that the synchronization request $sync_i(\{i\})$ indicates that no synchronization with the others is needed, and the next action of agent $i$ is executed immediately, independently on the other agents.
We assume that each agent sends a synchronization request instantly once it completes an action execution and that it starts executing an action instantly once it synchronizes with the other agents. %In other words, no time is spent idling in our system model; at any moment, each agent is either executing an action or waiting for the synchronization. This does not prevent us to capture the agents' ability of staying in their respective states; 
Instead of allowing for idling, we include an existence of a special action $\stay_i \in A_i$ and a so-called \emph{self-loop} $s \xrightarrow{\stay_i} s$ for all $s \in S_i$, and all $\T_i$, where $i \in \N$.
Given a trace $\tau_i = s_{i,1}\alpha_{i,1}s_{i,2}\alpha_{i,2}\ldots$ of $\T_i$,  we denote by $\Delta_{s_{i,j}} \in \Real_0^+$ the time duration of the synchronization that has been requested in the state $s_{i,j}$. 
Note that $\Delta_{s_{i,j}} = 0$ for $\sync_i(\{i\})$ in $s_{i,j}$.



\subsubsection{Services} Each of the agents' specification is given via two components: the first one are temporal requirements on the atomic propositions that need to hold along its trace, and the second one is a task given in terms of events of interest associated with their actions, which we call \emph{services} (e.g., an object pick-up). The set of services that can be \emph{provided} by an agent $i\in \N$ is $\Ser_i$. Services are {provided} within the agents' transitions; each action $\alpha \in A_i$ is associated, or in other words \emph{labeled}, either with 
%\begin{enumerate}
%\item [(i)] 
(i) a service set $\sigma \in 2^{\Ser_i}$ provided by $i$  upon the execution of $\alpha$, or 
%\item [(ii)] 
(ii) a special \emph{silent} service set $\Epsilon_i = \{\epsilon_i\}$, where $\epsilon_i \not \in {\Ser_i}$ indicating that the action $\alpha$ does not provide any event of interest.
% \end{enumerate} 
{Hence, two additional components of the agent $i$'s model are
the set of all available services $\Ser_i$ and the action-labeling function $\Lab_i: A_i \to 2^{\Pi_i} \cup 2^{\Epsilon_i}$.} Note that we specifically distinguish between a silent service set $\Epsilon_i$ and an empty service set $\{\}$. 
The above mentioned self-loops of form $s \xrightarrow{\stay_i} s$ that we use to model the agents' ability of staying in their  respective current states are labeled with the silent service set $\Lab_i(\stay_i) = \Epsilon_i$.
%Intuitively, the silent service $\epsilon_i$ indicates that from the agent $i$'s point of view, there is no interesting event happening. In contrast, the empty service $\emptyset$ indicates that even though agent $i$ does not provide any service itself, the services provided by the other agent's are of interest.
Without loss of generality, we assume that $\Ser_i \cap \Ser_{i'} = \emptyset$, for all $i,i' \in \N$, such that $i\neq i'$, which is necessary for the final step of our solution. 
Finally, we model an agent $i \in \N$ as  the tuple 
$\model_i = (\TSi, \Sync_i, \Ser_i, \Lab_i)$.


\subsubsection{Behaviors} \emph{Behavior} of an agent $i$ is defined by its states,  actions,  synchronizations with the others, and the time instants of the action executions and the synchronizations.

\begin{definition}[Behavior and strategy] A behavior of an agent $i$ is a tuple $\beta = (\tau,\gamma, \mathbb T)$, where
\begin{itemize}
\item 
$\tau = s_1\alpha_1s_2\alpha_2\ldots$ is a trace of $\T_i$;
\item 
$\gamma = r_1r_2\ldots $ is a \emph{synchronization sequence}, where $r_j \in {\Sync_i}$ is the synchronization request sent at $s_j$; and
\item 
$\mathbb{T} = t_{s_1}t_{\alpha_1}t_{s_2}t_{\alpha_2}\ldots$ is a non-decreasing \emph{behavior time sequence}, where  
$t_{s_j}$ is the time instant when the synchronization request $r_j$ was sent, and $t_{\alpha_j}$ is the time instant when the action $\alpha_j$ started being executed. The following properties hold: $t_{s_1}=0$, and for all $j \geq 1$, $t_{s_{j+1}}  - t_{\alpha_j} = \Delta_{\alpha_j}$, and $t_{\alpha_j} - t_{s_j}=\Delta_{s_j}$.
\end{itemize}
{A \emph{strategy} $(\tau,\gamma)$ for an agent $i$ is a trace $\tau$ and a synchronization sequence $\gamma$.} 
\label{def:behavior}
\end{definition}

{
The notion of behavior does not reflect the above described inter-agent synchronization rules. To that end, we define 
\emph{behaviors induced by strategies} admissible by a team of agents.} % that all follow the synchronization scheme. }
We denote the behavior of an agent $i \in \N$ by $\beta_i = (\tau_i,\gamma_i,\mathbb T_i)$, and we use $\tau_i = s_{i,1}\alpha_{i,1}s_{i,2}\alpha_{i,2}\ldots$, $\gamma_i = r_{i,1}r_{i,2}\ldots $, and $\mathbb{T}_i = t_{s_{i,1}}t_{\alpha_{i,1}}t_{s_{i,2}}t_{\alpha_{i,2}}\ldots$ to denote its trace, synchronization and time sequence. 

\begin{definition}[Induced behaviors]
The set of behaviors induced by a collection of strategies $(\tau_1, \gamma_1), \ldots, (\tau_N, \gamma_N)$ of  agents in $\N$ are the subset of the collections of their behaviors $\mathbb B \subseteq \{\mathfrak B \in \{ \beta_1,\ldots,\beta_N \mid \beta_i \text{ is a behavior of agent } i\}\}$ satisfying the following condition for all $i \in \N$, and $j \geq 1$: Suppose that $r_{i,j} = sync_i(I)$. Then for all $i' \in I$ there exists a \emph{matching index} $j' \geq 1$, such that $r_{i',j'} = sync_{i'}(I)$, and $t_{\alpha_{i,j}} = t_{\alpha_{i',j'}}$. Furthermore, there exists at least one $i' \in I$, such that $t_{s_{i',j'}} = t_{\alpha_{i',j'}}$, i.e., such that $\Delta_{s_{i',j'}} = 0$, for the matching index $j'$.
\label{def:compatible}
\end{definition}

%Suppose that the trace $\tau_i$, the synchronization sequence $\gamma_i$, and the transition time durations $\Delta_{\alpha_{i,1}},\Delta_{\alpha_{i,2}},\ldots$ are all fixed for all $i \in \N$. Note that in such a case, there exists at most one collection of synchronization time durations $\Delta_{s_{i,1}}\Delta_{s_{i,2}}\ldots$, where $i \in \N$ that yields a set of compatible behaviors $\{\beta_i = (\tau_i, \gamma_i, \mathbb T_i) \mid i \in \N\}$. In other words, if the agents follow the synchronization scheme, then the existence and the values of their synchronization time durations and hence also their behavior time sequences are uniquely determined by $\tau_i$, $\gamma_i$, and $\Delta_{\alpha_{i,1}},\Delta_{\alpha_{i,2}},\ldots$ given for all $i \in \N$.




\subsection{Motion and Task Specifications}


{The individual agents' tasks are collaborative; on the one hand, they involve requirements on the agents' states, i.e., the atomic propositions associated with them and on the other hand, they concern the respective agent's services as well as the services of the other agents. Formally,} each of the agents is given 
%\begin{itemize}
%\item[(i)] 
(i) an \LTLX formula $\phi_i$ over $\AP_i$, which we call a \emph{motion} specification and (ii) a collaborative LTL formula
$\psi_i$ over
{$\Sers = \bigcup_{i' \in \N} \Ser_{i'}$}, which we call a \emph{task} specification. 
%\end{itemize}
%Loosely speaking, the satisfaction of an agent's specification depends on its own trajectory, on the services it provides, and also on the services provided by the other agents at the time instances when its own non-silent services are provided.
%{Let us now introduce several intermediate definitions before proceeding with the formal definition of the local specification satisfaction.}
{Consider for a moment a single agent $\model_i = (\T_i,\Sync_i, \Ser_i, \Lab_i)$, and its behavior $\beta = (\tau, \gamma, \mathbb T)$, where $\tau = s_{1}\alpha_{1}s_{2}\alpha_{2}\ldots$, and  $\mathbb{T} = t_{s_1}t_{\alpha_1}t_{s_2}t_{\alpha_2}\ldots$.

\begin{definition}[Words and time sequences] We denote by  $v_\tau = \varpi_1\varpi_2\ldots = \Lab_i(\alpha_{1})\Lab_i(\alpha_{2})\ldots  \in (2^{\Ser_i} \cup 2^{\Epsilon_i})^\omega$ the  \emph{service set sequence} associated with $\tau$. 
The \emph{word} $w_\tau$ produced by $\tau$ is the subsequence of the \emph{non-silent} elements of $v_\tau$; $w_\tau = \varpi_{\i_1}\varpi_{\i_2}\ldots \in (2^{\Sigma_i})^\omega$, such that $\varpi_1, \ldots, \varpi_{\i_1-1} = \Epsilon_i$, and for all $j \geq 1$, $\varpi_{\i_j} \neq \Epsilon_i$ and $\varpi_{\i_j+1}, \ldots, \varpi_{\i_{j+1}-1} = \Epsilon_i$.
%%Let us consider a trace $\tau$, a synchronization sequence $\gamma$, and a behavior time sequence $\mathbb T = t_{s_1}t_{\alpha_1}t_{s_2}t_{\alpha_2}\ldots$.
With a slight abuse of notation, we use $\mathbb{T}(v_\tau) = t_1t_2\ldots = t_{\alpha_1}t_{\alpha_2}\ldots$ to denote the \emph{service time sequence}, i.e. the subsequence of $\mathbb T$ when the services are provided.
Furthermore, $\mathbb{T} (w_\tau)= t_{\i_1}t_{\i_2}\ldots$ denotes the \emph{word time sequence}, i.e. the subsequence of $\mathbb{T}(v_\tau)$ that corresponds to the time instances when the non-silent services are provided. %, and $$t_{i_j} = \sum_{k=1}^{i_j-1} \Delta_{\alpha_k}\text{, for all } j \geq 1.$$
\end{definition}
}

As in this work we are interested in infinite behaviors, we  consider as \emph{valid} traces only those producing infinite words.

\begin{definition}[Service set at a  time]
Let  $\tau$ be a trace of $\T_i$ with $v_\tau = \varpi_1\varpi_2\ldots$, and 
%the word $w_\tau = \varpi_{\i_1}\varpi_{\i_2}\ldots$, and the respective trace and 
 %$\mathbb{T}(\tau) = t_1t_2\ldots$ and 
$\mathbb{T}(v_\tau) = t_{1}t_{2}\ldots$. Given $t \in \Real_0^+$, % the service set $\tau(t) \in 2^{\Pi} \cup \{\varepsilon\}$ and the 
the service set $v_\tau(t) \in 2^{\Pi_i} \cup 2^{\Epsilon_i}$ provided at time $t$ is
$ v_\tau(t) = 
  \varpi_j \text{ if $t=t_j$ for some $j \geq 1$; and }
    v_\tau(t) =  \Epsilon_i \text{ otherwise.}$
 
%\[ w_\tau(t) = \left\{ 
%  \begin{array}{l l}
%   \varpi_{\i_j} & \quad \text{ if $t=t_{\i_j}$ for some $j\geq 1$}\\
%    \bot & \quad \text{otherwise.}
%  \end{array} \right.\]
\end{definition}
%The satisfaction of each formula $\psi_i$ is defined over the traces $\tau_j = s_{j,1}\alpha_{j,1}s_{j,2}\alpha_{j,2}\ldots$ of transition systems $\T_j$, where $j \in d(i)$. 


%We are now finally ready to define the {satisfaction} of the collaborative LTL formulas over $\Sers$. % from the agent $i$'s point of view.
Note that the above definition is designed in a way accommodating the general asynchronicity of the agents.
Each formula $\psi_i$ is interpreted locally, from the agent $i$'s point of view, based on the word {$w_{\tau_i}$} it produces and on the services of the other agents $i' \in \N$ provided at the time instances $\mathbb T(w_{\tau_i})$. In other words, the agent $i$  takes into consideration the other agents' services only at times, when $i$ provides a non-silent service set (even an empty one) itself.

\begin{definition}[Local LTL satisfaction]
Let $\mathfrak B = \beta_1,\ldots,\beta_N$ be a collection of behaviors, where $\beta_{i} = (\tau_i,\gamma_i,\mathbb T_i)$ for all $i \in \N$ and let $\mathbb T(w_{\tau_i}) =  t_{i,\i_1}t_{i,\i_2}\ldots$ be the word time sequence of agent $i$. The \emph{local word} produced by $\mathfrak B$ is
%\begin{align}
%\label{eq:teamword}
$w_{\mathfrak{B_i}} = \omega_{i,\i_1}\omega_{i,\i_2}\ldots, \text{ where}$
$\omega_{i,\i_j} = \big(\bigcup_{i' \in \N} v_{\tau_{i'}}(t_{i,\i_j})\big) \cap  {\Sers}, \text{ for all } j\geq 1$.
%\end{align}
%Formally, let 
%$\mathfrak w_\epsilon = \varpi_1 \varpi_2 \ldots \in (2^{\APs_i} \cup \mathcal E)^\omega$, where $\varpi_k = \bigcup_{j \in d(i)} \varpi_{j,k}$ denote the sequence of (both silent and non-silent) services associated with the set of traces $\mathfrak{T}_i=\{\tau_j \mid j \in d(i)\}$, and let \new{$\mathbb T(\tau_i) = \mathbb T(w_\epsilon(\tau_i)) = t_1t_2\ldots$}. The \emph{word produced} by $\mathfrak{T_i}$  is then a sequence
%\jana{TO FIX} 
%\begin{align}
%\label{eq:teamword}
%& w(\mathfrak{T}_i) = w(\mathfrak w_\epsilon) = \omega_{k_1}\omega_{k_2}\ldots, \\ \nonumber & \text{such that }  \omega_{k_m} =  \varpi_{k_m} \cap 2^{\APs_i},\text{ for all } m\geq 1.
%\end{align}
%Analogously, given that $w_\varepsilon \in (2^\APs_i \cup \{\varepsilon\})^\omega$ is a word with ep
%Consider the sequence $\omega_{1}\omega_{2}\ldots \in 2^{\APs_i} \cup \{\varepsilon\}$, where $\omega_{k} = \bigcup_{j \in d(i)} \varpi_{j,k}$, for all $k \geq 1$. The word produced by the set of traces $\mathfrak{T}_i=\{\tau_j \mid j \in d(i)\}$ is then a subsequence of nonempty elements of $\omega_{1}\omega_{2}\ldots$, \ie 
%$$w(\mathfrak{T}_i) = \omega_{k_1}\omega_{k_2}\ldots,$$
%such that $\omega_{1}, \ldots, \omega_{k_1-1} = \emptyset$, $\omega_{k_j+1}, \ldots, \omega_{k_{j+1}-1} = \emptyset$,  and $\omega_{k_j} \neq \emptyset$, for all $j \geq 1$. 
%The set of behaviors $\mathfrak{B}_i$ is \emph{valid}  if $\tau$ is valid.% and $w_{\tau_k}(t_{\i_j}) \neq \bot$ for any $k \in \D_i$ and $j \geq 1$.
$\mathfrak{B}$ \emph{locally satisfies} the formula $\psi_i$ for the agent~$i$, $\mathfrak{B} \models_i \psi_i$, iff $w_{\mathfrak{B}_i} \models \psi_i$.\label{def:localsat}
\end{definition}

Note that even if $\psi_i = \psi_j$,
%even if $\mathfrak{B} = \mathfrak{B}_i = \mathfrak{B}_j$, it may be the case that $w_{\mathfrak B_i} \neq w_{\mathfrak B_j}$. Hence, 
it is possible that $\mathfrak{B} \models_i \psi_i$ for the agent $i$, while $\mathfrak{B} \not \models_j \psi_j$ for the agent $j$, since it might be the case that $w_{\mathfrak{B}_i} \neq w_{\mathfrak{B}_j}$.

%\jana{On top of behaviors, we need to define this...to be able to reconstruct it...}



\subsection{Problem Statement}
%Our problem is formulated as follows.
\begin{problem}
\label{prob:main}
\emph{Consider} a set of agents $\N = \{1,\ldots,N\}$, and suppose that each agent $i \in \N$ is modeled as a tuple $\model_i = (\TSi, \Sync_i, \Ser_i, \Lab_i)$, %with the set of available services $\Ser_i$ and the action-labeling function $L_i$, 
and assigned a task in the form of an \LTLX formula $\phi_i$ over $\Pi_i$ and $\psi_i$ over %$\Alpha_i = 2^{\Sers_i}$. %, where 
$\Sers =  \bigcup_{i' \in \N} \Ser_{i'}$.
\emph{For each $i \in \N$ find a strategy, i.e.,}
%\begin{itemize}
%\item 
(i)~a trace $\tau_i = s_{i,1}\alpha_{i,1}s_{i,2}\alpha_{i,2}\ldots$ of $\T_i$ and 
%\item 
(ii)~a synchronization sequence $\gamma_i$ over $\Sync_i$
%\end{itemize}
with the property that the set of induced behaviors $\mathbb B$ from Def.~\ref{def:compatible} is nonempty, and for all $\mathfrak B \in \mathbb B$  and all $i \in \N$, it holds that 
the trace $\tau_i$ satisfies $\phi_i$% in terms of Def.~\ref{def:LTLsat}, 
and the word $w_{\mathfrak B_i}$ produced by $\mathfrak B$ locally satisfies $\psi_i$ for the agent $i$ in terms of Def.~\ref{def:localsat}.
%\end{itemize}
%$\mathfrak{T}_i = \{\tau_j \mid j \in \D_i\}$ locally satisfies the formula $\psi_i$, for all $i \in \{1,\ldots, N\}$.
\end{problem}

As each LTL formula can be translated into a BA, from now on, we pose the problem  with the motion specification of each agent $i$  given as a  BA $\B_i^\phi = (Q_i^\phi, q_{\init, i}^\phi, \delta_i^\phi, 2^{\AP}, F_i^\phi)$, and the task one as a BA $\B_i^\psi = (Q_i^\psi, q_{\init, i}^\psi, \delta_i^\psi, 2^{\Sers}, F_i^\psi)$. Given that $\tau_i = s_{i,1}\alpha_{i,1}s_{i,2}\alpha_{i,2}\ldots$, the motion specification satisfaction is formulated as  $L(s_{i,1})L(s_{i,2})\ldots \in \mathit{Lang(\B_i^\phi)}$ and the local satisfaction of  the task specification as $w_{\mathfrak B_i} \in \mathit{Lang(\B_i^\psi)}$.

% and the local task satisfaction condition formulated as $ w_{\mathfrak B_i} \in Lang(\B_i)$. 

%\jana{we assume that they are all dependent, either directly or transitively; otherwise we can simply solve each subgroup separately}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{PROBLEM SOLUTION}
\label{sec:solution}

%In this section, we first summarize a straightforward solution to Problem~\ref{prob:main} that leverages ideas from centralized multi-agent automata-based approach to control strategy synthesis. Later on, we present our solution, where we aim to decouple the synthesis of the motion part of the specification from the task one as much as possible.

%\subsection{Centralized solution}

%If each agent was given only the motion specification and not the action one on top of that, the problem would have a straightforward decentralized solution. Each of the strategies could be synthesized separately, and no synchronization would be needed at all. In contrast, in our case, 
Even though the agents' motion specifications are mutually  independent, each of them is dependent on the agent's respective task specification, which is dependent on the task specifications of the other agents. As a result, the procedures of synthesizing the desired $N$ strategies cannot be decentralized in an obvious way. However, one can quite easily obtain a centralized solution when viewing the problem as a synthesis of a single team strategy.

First of all, we realize that if there exists a solution to Problem~\ref{prob:main}, then there exists a solution in which all the agents synchronize after every single step. Informally, the reason is that each agent $i$ is able to execute action $\stay_i$, i.e., that $L_i(\stay_i) = \Epsilon_i$, and that the motion specification $\phi_i$ is a formula of \LTLX, i.e., that the execution of $\stay_i$ does not influence its satisfaction.
%proof: take an arbitrary solution, pad it with synchronization and adequate amount of stay transitions.
The standard automata-based procedure for solving the LTL control strategy synthesis problem for deterministic systems 
%citation?
can  be then easily applied in multi-agent settings in a centralized way.
1) A synchronized TS $\T_\N$ with the set of states $S_\N = S_{1}\times \ldots \times S_{N}$ is built that represents all stepwise-synchronized traces of the agents in $\N$. 
2) A BA $\B_\N$ is built for the formula $\bigwedge_{i \in \N} (\phi_i \wedge \psi_i)$ over the alphabet ${2^{\bigcup_{i\in \N} \AP_i \cup \Sers}}$.
3) A product automaton $\P_\N$ of $\T_\N$ and $\B_\N$ is constructed that captures only the agents' traces that are admissible by $\T_\N$ and result into behaviors that satisfy $\phi_1,\ldots,\phi_N$, and locally satisfy $\psi_{1},\ldots,\psi_{N}$, for the agents $1,\ldots, N$, respectively. The product $\P_\N$ is analyzed using standard graph algorithms in order to find its accepting run that projects onto the desired traces of $\T_i$, for all $i \in \N$.
4) The synthesized strategy for an agent $i \in \N$ is a trace $\tau_i = s_{i,1}\alpha_{i,1}s_{i,2}\alpha_{i,2}\ldots$ of $\T_i$, and a synchronization sequence $\gamma_i = r_{i,1}r_{i,2}\ldots$ where $r_{i,j} = \sync_i\{\N\}$, for all $j \geq 1$. We notice that the amount of synchronization required by agent $i \in \N$ can be reduced by replacing $r_{i,j} = \sync_i(\N)$ with $\sync_i(\{i\})$, if for each agent $i' \in \N$ it holds that $\Lab_{i'}(\alpha_{i',j}) = \Epsilon_{i'}$, since in such a case, $w_{\mathfrak B_i}$ remains unchanged. Furthermore, the $\stay_i$ actions can be removed from $\tau_i$ without any harm, since they influence neither the satisfaction of $\phi_i$, nor the word $w_{\mathfrak B_i'}$ for any $i'\in \N$.
%\begin{itemize}
%\item First of all, we realize that if there is a solution to Problem 1, then there is a solution in which the agents synchronize after every single step. This will allow us to take a centralized point of view on the problem.
%\item We build a big conjunction formula, big product and find a collective trace. Project, done. 
%\item But we may realize that the full synchronization is indeed not needed, that the way the collective trace can be executed is imposing the synchronization only where the non-silent services happen. Projection on the alpahbets, on the traces of the individiuals -- interleaving not a problem...
%\end{itemize}

\subsection{Our solution}
A major drawback of the centralized solution is the state space explosion, which makes it practically unusable. We aim to decentralize the solution as much as possible. Namely, we aim to separate the synthesis of service plans yielding the local satisfaction of the task specifications from the syntheses of traces that guarantee the motion specifications. %However, we cannot simply first generate an arbitrary action plan, since we cannot ensure the existence of a trace complying with the motion specification. Instead, 
Our approach is to pre-compute possible traces and represent them efficiently, abstracting away the features that are not significant for the synthesis of action plans. This abstraction serves as a guidance for the action and synchronization planning, which, by construction, allows for finding a trace complying with both the synthesized action and synchronization plans and and the motion specification. %The action plan is subsqeunece of a desired trace. Finally, we generate the remainders of the traces, i.e. the motion between ... that satisfies the ...

%\subsubsection{Approach}
%\begin{itemize}
%\item Decouple the "motion" and the "action".
%\item As discussed above, synchronization is in fact needed only sometimes, between that the planning can be done completely independently.  \end{itemize}


\subsubsection{Preprocessing the motion specifications}
Consider for now an agent $i \in \N$ modeled as $\model_i = (\T_i, \Sync_i, \Ser_i, \Lab_i)$, where $\TSi$ and its motion specification BA $\B_i^\phi$. We slightly modify the classical construction of a product automaton of $\T_i$ and $\B_i^\phi$ to obtain a BA that represents the traces of $\T_i$ accepted by $\B_i^\phi$ and furthermore explicitly captures the services provided along the trace.

\begin{definition}[Motion product]
\label{def:PA}
The \emph{motion product} of a TS $\TSi$, and a BA $\B_i^\phi = (Q_i^\phi, q_{\init, i}^\phi, \delta_i^\phi, 2^{\AP_i}, F_i^\phi)$ is a BA $\P_i = (Q_{i}, q_{\init,i}, \delta_{i}, 2^{\Ser_i} \cup \{\Epsilon_i\}, F_{i})$, where
%\begin{itemize}
%\item 
$Q_{i} = S_i \times Q_i^\phi$;
%\item 
$q_{\init,i} = (s_{\init,i},q_{\init,i}^\phi)$;
%\item 
$((s,q),\Lab_i(\alpha),(s',q') \in \delta_{i}$
if and only if $(s,\alpha,s') \in T_i$, and $(q,L_i(s),q') \in \delta_i^\phi$; and
%\item 
$F_{i} = \{(s,q) \mid q \in F_i^\phi\}$.
%\end{itemize}
\label{def:motion}
\end{definition}

%Our aim is to reduce the size of the motion product by removing all states and transitions that are insignificant with respect to the local satisfaction of the task specification, and hence with respect to the collaboration with others. 
Intuitively, we propose to keep only the significant states that have an outgoing transition labeled with $\Lab_i(\alpha) \neq \Epsilon_i$ and replace exact sequences of transitions in $\P_i$ with single transitions representing reachability. While doing so, we have to take into account whether the removed state is accepting or not to correctly preserve the accepting condition of $\P_i$.

\begin{definition}[Insignificant states in $\P_i$]
A state $p$ of the motion product $\P_i$ is \emph{significant} if it is (i) the initial state $p = q_{\init,i}$, or (ii) if there exists a transition $(p,\sigma,p') \in \delta_i$, such that $\sigma \neq \Epsilon_i$; and \emph{insignificant} otherwise.
\end{definition}

A \emph{reduced motion product} $\ddot \P_i$ is built  from $\P_i$ according to Alg.~\ref{alg:removal}. First, we remove all  insignificant non-accepting states and their incoming and outgoing transitions (lines~\ref{line:5},~\ref{line:6}). We replace each state with a set of transitions leading directly from the state's predecessors to its successors, i.e., we concatenate the incoming and the outgoing transitions (line~\ref{line:7}). The labels of the new transitions differ: if both labels of the concatenated incoming and outgoing transition are $\Epsilon_i$, then the new label will be  $\irrelevant$ to indicate that the transition represents a sequence of actions that are not interesting with respect to the local satisfaction of task specifications. On the other hand, if the label $\sigma$ of the incoming transition belongs to $2^{\Ser_i}$, we use the action $\sigma$ as the label for the new transition. Each path between two significant states in $\P_i$ maps onto a path between the same states in $\ddot \P_i$ and the sequences of non-silent services read on the labels of the transitions of the two paths are equal;
 and vice versa. %If one is accepting, the other one is, too and vice versa. 
Second, we handle the insignificant accepting states (line~\ref{line:8}) similarly to the non-accepting ones, however, we do not remove the states whose predecessors include a significant state in order to preserve the accepting condition. There is a correspondence between the infinite runs of $\P_i$ and the infinite runs of $\ddot \P_i$: for each run of $\P_i$ there exists a a run of $\ddot \P_i$, such that the states of the latter one are a subsequence of the states of the former one, the sequences of non-silent services read on the labels of the transitions of the two runs are equal, and that the latter one is accepting if and only if the former one is accepting; and vice versa. This correspondence will allow us to reconstruct a desired run of $\P_i$ from a  run of $\ddot \P_i$, as we will show in Sec.~\ref{sec:synthesis}.
%From the construction, the upper bound on the number of states remaining in $\ddot \P_i$ is constant with respect to the number of significant states in~$\P_i$.
From $\ddot \P_i$, we further remove all states from which none of the  states in $\ddot F_i$ is  reachable, and we can keep only one copy of duplicate states that have analogous incomming and outgoing edges (omitted from Alg.~\ref{alg:removal}).

%...\jana{the above important property still holds. Furthermore, the size of the reduced motion product is at most twice the number of significant states}

\vspace{-0.3cm}
\begin{algorithm}
\caption{Reduction of the motion product}
\begin{algorithmic}[1]
\small{
\INPUT motion product $\P_i = (Q_{i}, q_{\init,i}, \delta_{i},  2^{\Ser_i} \cup 2^{\Epsilon_i}, F_{i})$
\OUTPUT reduced BA  $\ddot{\P}_i = (\ddot Q_{i}, \ddot q_{\init,i}, \ddot \delta_{i},2^{\Ser_i} \cup 2^{\Epsilon_i}, \ddot F_{i})$
\STATE initialize $\ddot \P_i  := \P_i$
\FORALL {insignificant states $p \in Q_i \setminus F_i$}
\STATE $\ddot Q_i  := \ddot Q_i \setminus \{p\}$ ~\label{line:5}
\STATE $\ddot \delta_i := \ddot \delta_i \setminus 
\{(p',\sigma,p),(p,\sigma,p') |  p' \in \ddot Q_i, \sigma \in 2^{\Sigma_i} \cup 2^{\Epsilon_i}\} $\label{line:6}
\STATE $\ddot \delta_i := \ddot \delta_i \cup 
\{ (p',\sigma, p'') \mid p',p'' \in \ddot Q_i, \sigma \in 2^{\Sigma_i} \cup 2^{\Epsilon_i}, $ $ (p',\sigma,p), (p,\Epsilon_i,p'') $ $ \in \ddot \delta_i\}$\label{line:7}
\ENDFOR
\FORALL {insignificant states $p \in F_i$, such that all predecessors of $p$ in $\ddot \P_i$ are insignificant}  \label{line:8}
\IF {$(p,\Epsilon_i,p) \in \ddot \delta_i$}
\STATE $\ddot \delta_i := \ddot \delta_i \cup \{(p',\irrelevant,p') \mid  (p',\Epsilon_i,p) \in \ddot \delta_i \}$
\ENDIF
\STATE $\ddot Q_i  := \ddot Q_i \setminus \{p\}$ ~\label{line:12}
\STATE  $\ddot \delta_i := \ddot \delta_i \setminus 
\{(p',\sigma,p),(p,\sigma,p') |  p' \in \ddot Q_i, \sigma \in 2^{\Sigma_i} \cup 2^{\Epsilon_i}\} $\label{line:13}
\STATE $\ddot \delta_i := \ddot \delta_i \cup  \{ (p',\Epsilon_i, p'') \mid p',p'' \in \ddot Q_i, (p',\Epsilon_i,p), $ $ (p,\Epsilon_i,p'') $ $ \in \ddot \delta_i\}$
 \label{line:14}
\ENDFOR
%\FORALL {$p, \bar p \in \ddot \P_i$, $p \neq p'$, such that  $(p',\sigma,p) \in \ddot \delta_i \iff (p',\sigma,\bar p) \in \ddot \delta_i $ and $ (p,\sigma,p') \in \ddot \delta_i \iff (\bar p,\sigma,p'') \in \ddot \delta_i$ holds for all $p',p'' \in \ddot \P_i$, $\sigma \in 2^{\Sigma_i} \cup 2^{\Epsilon_i}$}
%\STATE $\ddot Q_i  := \ddot Q_i \setminus \{\bar p\}$ ~\label{line:16}
%\STATE $\ddot \delta_i := \ddot \delta_i \setminus \{(p',\sigma,\bar p),(\bar p,\sigma,p')| p' \in Q_i, \sigma \in 2^{\Sigma_i} \cup \{\Epsilon_i\} \} $\label{line:17}
%\ENDFOR
}
\end{algorithmic}
\label{alg:removal}
\end{algorithm}
\vspace{-0.3cm}

%This has different semantics than the translation: I do not really care about capturing the precise language, only about capturing reachability.

%Namely lemma saying that (1) for each path in the original product, there exists a path in the reduced one and vice versa, while all the significant states stay there, in the same order. (removal of epsilons) (2) Furthermore acceptance.

%Now the reduced sort of captures "reachability". Epsilon transitin = there exists a path. Two epsilon transitions with an accepting state nin the middle: there exists a path with an accepting state...


\subsubsection{Preprocessing the task specifications}
Next, we build a local task and motion product automaton for each agent $i$ separately, to capture the admissible traces of $i$ that comply both with its motion and task specification. At this stage, the other agents' collaboration capabilities are not yet included.

\begin{definition}[Task and motion product]
\label{def:PA}
The \emph{task and motion product} of a reduced motion product automaton $\ddot \P_i = (\ddot Q_{i}, \ddot q_{\init,i}, \ddot \delta_{i}, 2^{\Sigma_i} \cup 2^{\Epsilon_i}, \ddot F_{i})$, and the task specification BA $\B_i^\psi = (Q_i^\psi, q_{\init, i}^\psi, \delta_i^\psi, 2^{\Sers}, F_i^\psi)$ is a BA $\bar \P_i = (\bar Q_{i}, \bar q_{\init,i}, \bar \delta_{i}, 2^{\Sers} \cup 2^{\Epsilon_i}, \bar F_{i})$, where
%\begin{itemize}
%\item 
$\bar Q_{i} = \ddot Q_i \times Q_i^\psi \times \{1,2,3\}$;
%\item 
$\bar q_{\init,i} = (q_{\init,i},q_{\init,i}^\psi,1)$; $\bar F_{i} = \{(q_1,q_2,2) \mid q_2 \in F_i^\psi\}$; and
%\item 
$((q_1, q_2, j),\sigma,(q_1', q_2', j') \in \bar \delta_{i}$
iff
\begin{itemize}
\item[$\circ$] $\sigma = \Epsilon_i$, $(q_1,\Epsilon_i,q_1') \in \ddot \delta_i$, and $q_2 = q_2'$; or
\item[$\circ$] $\sigma \in 2^\Sers$,  $(q_1,\sigma \cap 2^{\Ser_i},q_1') \in \ddot \delta_i$, and $(q_2,\sigma,q_2') \in \delta_i^\psi$,
\end{itemize}
and
%\begin{itemize}
%\item[$\circ$] 
$j'=2$, if $j=1$ and $q_1' \in \ddot F_i$, 
%\item[$\circ$] 
$j'=3$ if $j=2$ and $q_2' \in \ddot F_i^\psi$,
%\item[$\circ$] 
$j'=1$ if $j=3$, and 
%\item[$\circ$] 
$j = j'$ otherwise.
%\end{itemize}
%\item 
%\end{itemize}
\label{def:action}
\end{definition}

The above construction leverages ideas from building a BA that accepts a language intersection of multiple given BAs. The accepting runs of $\bar \P_i$ map onto accepting runs of $\ddot \P_i$, and hence to the traces of $\T_i$ satisfying the motion specification $\phi_i$, and onto accepting runs of $\B_i^\psi$; and vice versa. 
Clearly, some of the transitions of $\bar \P_i$ require a collaboration of some other agents, while some of them do not. In order to further reduce the size of $\bar \P_i$, we introduce a mapping $\Dep_i: \bar \delta_i  \rightarrow 2^\N$ to indicate for each transition $\trans= (p,\sigma,p') \in \bar \delta_i$ the set of agents $\Dep_i(\trans) \subseteq \N$ whose collaboration is required. We formalize $\Dep_i$ through the notion of assisting services. Moreover, for each agent $i$, we find a subset of its services that affect the local satisfaction of a task specification of another agent through the notion of globally {assisting} services.

\begin{definition}[Assisting services]
Suppose that $i \neq i'$. A service $\rho \in {\Ser_{i'}}$ is \emph{not assisting on a transition $(p,\sigma,p') \in  \bar \delta_{i}$} of $\bar \P_{i}$ if and only if it holds  that $(p,\sigma \cup \{\rho\} ,p') \in \bar \delta_{i} \iff (p,\sigma \setminus \{\rho\},p') \in \bar \delta_{i}$; it is \emph{assisting on $(p,\sigma,p')$} otherwise. 
%Moreover, a service set $\sigma_i \in 2^{\Sigma_i}$ is \emph{dependent in $q \in Q_i^\psi$} of $\B_{i}^\psi$ if and only if there exists $i' \neq i$ and $\sigma_{i'} \in 2^{\Sigma_{i'}}$, such that $\sigma_{i'}$ is dependent in $q$; and it is \emph{independent in $q$} otherwise.
%A service $\rho \in 2^{\Ser_{i'}}$ is \emph{globally dependent} if there exists an agent $i \in \N$, $i \neq i'$, and a state $q \in Q_{i}^\psi$, such that and $\rho_{i'}$ is dependent in $q$; and \emph{globally independent} otherwise.
$\Dep_i (\trans) =  \{i\} \, \cup \, \{i' \mid i'\neq i \text{ and } \exists \rho \in \Sigma_{i'} \text{ assisting on } \trans \}.$
\end{definition}
%Then, $\Dep_i(\trans)$  is defined as follows.
%\begin{align*}
%\end{align*}



%Let the action specification for each $i \in \N$ be given as a B\"uchi automaton $\B_i^\psi = (Q_i^\psi, q_{\init, i}^\psi, \delta_i^\psi, 2^{\Sers}, F_i^\psi)$.

\begin{definition}[Globally assisting services]
%A service $\rho \in {\Ser_{i'}}$ is \emph{independent in a state $q \in Q_{i}^\psi$} of $\B_{i}^\psi$, where $i \neq i'$ if and only if for all $\sigma \in 2^\Sers$ and all $q' \in Q_{i}^\psi$, it holds true that $(q,\sigma \cup \{\rho\} ,q') \in \delta_{i}^\psi \iff (q,\sigma \setminus \{\rho\},q') \in \delta_{i}^\psi$. It is \emph{dependent in $q$} otherwise. 
%Moreover, a service set $\sigma_i \in 2^{\Sigma_i}$ is \emph{dependent in $q \in Q_i^\psi$} of $\B_{i}^\psi$ if and only if there exists $i' \neq i$ and $\sigma_{i'} \in 2^{\Sigma_{i'}}$, such that $\sigma_{i'}$ is dependent in $q$; and it is \emph{independent in $q$} otherwise.
A service $\rho \in {\Ser_{i'}}$ of agent $i' \in \N$ is \emph{globally assisting} if there exists $i \in \N$, $i \neq i'$, and a transition $\trans \in \bar \delta_{i}$, such that $\rho$ is assisting on $\trans$. %; it is \emph{globally independent} otherwise.
\end{definition}

%For each agent $i$ it is thus possible to compute the set of all dependent services \jana{metion complexity .... Note that the notion of dependency is asymetric, it only says which services of an agent might be needed for the collaboration iwth the others, and not which services an agent needs}. 

Now, similar ideas as in Alg.~\ref{alg:removal} can be used to reduce the size of each action and motion product $\bar P_i$, with the following, altered definition of significant states:

\begin{definition}[Insignificant states in $\bar \P_i$]
A state $p$ of the task and motion product $\bar \P_i$ is \emph{significant} if it is either (i)~the initial state $p = \bar q_{\init,i}$, or (ii) if there exists a transition $(p,\sigma,p') \in \bar \delta_i$, such that there exists a globally assisting service $\rho \in \sigma \, \cap \, {\Sigma_{i}}$, or (iii) if there exists a transition $(p,\sigma,p') \in \bar \delta_i$,  such that $\Dep_i(p,\sigma,p') \neq \{i\}$;
%\sigma \in 2^\Sers$, and there exists an agent $i' \in \N$, $i \neq i'$, and its service $\rho' \in \Sigma_{i'}$, such that $(p,\sigma \cup \{\rho'\},p') \in \bar \delta_{i} \oplus (p,\sigma \setminus \{\rho'\},p') \in \bar \delta_{i}$; 
the state $p$ is \emph{insignificant} otherwise.
\end{definition}

{Informally, the condition (ii) states that at a significant state, the agent $i$ has the ability to assist other agents, whereas the condition (iii) states that at a significant state, the assistance of the other agents influences the agent $i$'s own task specification local satisfaction. %In contrast, any action taken from an insignificant state does not have any impact on other team members and its outcome is not affected by any other agent, either.}
{With a slight abuse of notation, we replace all labels of all outgoing transitions of insignificant states of $\bar P_i$ with $\Epsilon_i$. This time $\Epsilon_i$ represents a service set that is completely independent.
We can  now directly apply Alg.~\ref{alg:removal} to remove the insignificant states from $\bar P_i$, with the exception that $2^{\Sigma_i}$ is at all places replaced with $2^ \Sers$.
The resulting automaton is $\widehat \P_i = (\widehat Q_{i}, \widehat q_{\init,i}, \widehat \delta_{i}, 2^{\Sers} \cup 2^{\Epsilon_i}, \widehat F_{i})$.
Similarly as before, there is a correspondence beween the infinite runs of $\bar \P_i$ and the infinite runs of $\widehat \P_i$: for each run of $\bar \P_i$ there exists a a run of $\widehat \P_i$, such that the states of the latter one are a subsequence of the states of the former one, the sequences of services read on the labels of the transitions leading from the significant states of the two runs are equal, and that the latter one is accepting if and only if the former one is accepting; and vice versa. The number of states of $\widehat \P_i$ is at most twice the number of significant states in $\bar P_i$.
%After the removal, the accepting runs represent ...
%The size of the resulting automaton is ...
}




%What we will do here is that we will first compute which ones are important for collaboration and which not. Again, significant and insignificant.

%Making a small product with the previous. Two Buchi system -- two layers for switching. Now this new buchi can be again reduced. Perhaps?

%Building dependency graph not of Buchis, but of actual individual actions. Those classes that all belong to a single guy can be again removed from the BA...

%This is where local differs from global...


\subsubsection{Global product} 

From the reduced task and motion product automata $\widehat \P_1, \ldots, \widehat \P_N$, we build a single one, that finally represents the inter-agent collaborations. The construction is a twist to the well-known construction of BA intersection. We associate the transitions of the BA with the subsets of agents that are required to make this transition collaboratively, i.e., with the subsets of agents that need to synchronize prior this transition.

\begin{definition}[Global product]
\label{def:PA}
The \emph{global product} of the reduced task and motion product automata $\widehat \P_1, \ldots \widehat \P_N$, where $\widehat \P_i = (\widehat Q_{i}, \widehat q_{\init,i}, \widehat \delta_{i}, 2^{\Sers} \cup 2^{\Epsilon_i}, \widehat F_{i})$, for all $i \in \N$, is a BA $\P = (Q, q_{\init}, \delta, 2^{\Sers} \cup 2^{\Epsilon = \{\Epsilon_i \mid i \in \N\}}, F)$ with a mapping $\Dep: \delta \rightarrow 2^\N$, where $Q = \widehat Q_1 \times \ldots \times \widehat Q_N \times \{1,\ldots, N+1\}$; $ q_{\init} = (\widehat q_{\init,1}, \ldots, \widehat q_{\init,N},1)$; $\bar F_{i} = \{(q_1, \ldots ,q_N, N) \mid q_N \in \widehat F_N\}$; and
$\trans = ((q_1,\ldots,q_N,j),\sigma,(q_1', \ldots, q_N', j')) \in \delta$
iff either
\begin{itemize}
\item[$\circ$] $\exists i \in \N$, such that $\sigma = \Epsilon_i$, $(q_i, \Epsilon_i, q_i') \in \widehat \delta_i$, $q_{i'} = q_{i'}'$, for all $i' \neq i$, and 
$j' = j+1$ if $j=i$ and $q_i' \in\widehat F_i$, 
$j' = 1$ if $ j= N+1$, and
$j'  = j$ otherwise.
%\end{itemize}
Then we set $\Dep(\trans) = \{i\}$; or
\item[$\circ$] $\sigma \in 2^\Sers$, and $\exists \, \I \subseteq \N$, such that for all $i\in \I$ it holds that  $(q_i,\sigma,q_i') \in \widehat \delta_i$ while for all $i \not \in \I$ it holds that $q_i = q_i'$. Moreover, $\bigcup_{i \in \I} \Dep_i(q_i,\sigma,q_i') \subseteq \I$, and
%\begin{itemize}
%\item[$\star$] 
$j' = j+1$ if $j \in \I$ and $q_j' \in \widehat F_j$, 
%\item[$\star$] 
$j' = 1$ if $ j= N+1$, and
%\item[$\star$] 
$j' =j$ otherwise.
%\end{itemize}
 Then we set $\Dep(\trans) = \I$.
\end{itemize}

\label{def:global}
\end{definition}

Each accepting run of the global product $\P$ maps directly on the accepting runs of the reduced task and motion product automata and vice versa, for each collection of accepting runs of the reduced task and motion product automata, there exists an accepting run of the global product $\P$. Note that by this construction, deadlocks are avoided.

%Similarly as before, there is a correspondence beween the infinite runs of $\bar \P_i$ and the infinite runs of $\widehat \P_i$: for each run of $\bar \P_i$ there exists a a run of $\widehat \P_i$, such that the states of the latter one are a subsequence of the states of the former one, the sequences of services read on the labels of the transitions leading from the significant states of the two runs are equal, and that the latter one is accepting if and only if the former one is accepting; and vice versa. The number of states of $\widehat \P_i$ is at most twice the number of significant states in $\bar P_i$.


\subsubsection{Synthesis of the strategies}
\label{sec:synthesis}
The final step of our solution is the generation of the strategy in $\P$ and its mapping onto a trace $\tau_i$ of $\T_i$ and a synchronization sequence $\gamma_i$ over $\Sync_i$, for all $i \in \N$.  Using standard graph algorithms (see, \eg~\cite{principles}), we find an accepting run $q_1 q_2 \ldots$ over a word $\sigma_1\sigma_2\ldots$ in $\P$, where $q_j = (\widehat q_{1,j},\ldots,\widehat q_{N,j}, k)$, for all $j \geq 1$. For each agent $i\in \N$:
\begin{itemize}
\item[(i)] Consider the sequence $\widehat q_{i,1} \widehat q_{i,2} \ldots$, that is obtained by the projection of the accepting run $q_1q_2\ldots$ onto the states of $\widehat \P_i$. Let $\iota_1 \iota_2\ldots$ be the subsequence of all indexes, such that $i \in \Dep (q_{\i_j},\sigma_{\i_j},q_{\i_j+1})$. Then $\widehat q_{i,\iota_1}\widehat q_{i,\iota_2}\ldots$ is an accepting run of $\widehat \P_i$ over the word $\sigma_{\i_1}\sigma_{\i_2}\ldots$ and $\widehat \gamma_i =  \widehat r_{i,1} \widehat r_{i,2} \ldots = \Dep (q_{\i_1}\sigma_{\i_1}q_{\i_1+1}) \Dep (q_{\i_2}\sigma_{\i_2}q_{\i_2+1})\ldots$ is a synchronization sequence.
\item[(ii)] From the construction of $\widehat P_i$, we know that there exists an accepting run $\bar q_{i,1} \bar q_{i,2}\ldots$ in $\bar \P_i$ over  a word $\bar \sigma_{i,1}\bar \sigma_{i,2}\ldots$, such that  $\widehat q_{i,\iota_1}\widehat q_{i,\iota_2}\ldots$ is a subsequence  $\bar q_{i,\ell_1}\bar q_{i,\ell_2}\ldots$ of  $\bar q_{i,1} \bar q_{i,2}\ldots$ and $\sigma_{\i_1}\sigma_{\i_2}\ldots$ is the corresponding subsequence $\bar \sigma_{i,\ell_1}\bar \sigma_{i,\ell_2}\ldots$ of  $\bar \sigma_{i,1}\bar \sigma_{i,2}\ldots$. The synchronization sequence $\bar \gamma_i = \bar r_{i,1} \bar r_{i,2} \ldots$ is constructed by setting $\bar r_{i,\ell_j} = \widehat r_{i,\i_j}$, for all $j \geq 1$, and $\bar r_{i,j} = \sync(\{i\})$ otherwise.
\item[(iii)] The mapping from the task and motion product $\bar P_i$ onto $\ddot \P_i$ is processed as follows: Suppose that $\bar q_{i,j} = (\ddot q_{i,j}, q_{i,j}^\psi,k)$, for all $j \geq 1$. The accepting run $\bar q_{i,\ell_1}\bar q_{i,\ell_2}\ldots$ then maps onto the accepting run $\ddot q_{i,\ell_1}\ddot q_{i,\ell_2}\ldots$ over $\ddot \sigma_{i,1}\ddot \sigma_{i,2}\ldots$, where $\ddot \sigma_{i,j} = \Epsilon_i$ if $\bar \sigma_{i,j} = \Epsilon_i$, and $\ddot \sigma_{i,j} = \bar \sigma_{i,j} \cap 2^{\Sigma_i}$ otherwise.
Naturally, $\ddot \gamma_i = \bar \gamma_i$.
\item[(iv)] The accepting run $q_{i,1}q_{i,1}\ldots$ of the motion product $\P_i$ over a word $\sigma_{i,1}\sigma_{i,1}\ldots$ and a synchronization sequence $\gamma_i$ is obtained from the reduced motion product $\ddot P_i$ by an analogous construction as in the case of mapping from the reduced task and motion product $\widehat \P_i$ onto the task and motion product $\bar \P_i$.
\item[(v)] Finally, an accepting  run $q_{i,1}q_{i,2}\ldots$ of $\P_i$ maps onto a trace $\tau_i$ of $\T_i$. The desired synchronization sequence is $\gamma_i$.
\end{itemize}
%\begin{theorem}[Correctness]
%Altogether, the collection of traces and synchronization sequences $(\tau_1,\gamma_1) \ldots (\tau_N,\gamma_N)$ computed according to the algorithm above gives a solution to Problem~\ref{prob:main}. 
%\end{theorem}

\subsection{Discussion}
\emph {Strategy execution and event-based recomputation:} In the above described solution, the strategy for each agent is constructed in an offline manner, and executed independently. However, the solution can be modified to an event-triggered one, where synchronization is triggered  by need and strategies are periodically recomputed in order to adapt to different execution speed of different agents and to handle various optimization criteria. The details of this solution is one of our future topics of interest.
\emph{Mutually dependency:} We supposed that all of the considered agents are mutually dependent through their task specifications, either directly or transitively. If this is not the case, the team of agents can be partitioned into dependency classes as suggested in~\cite{meng-ijrr2015}.
\emph{Complexity:} In the worst case, our solution meets the complexity of the centralized solution. However, this is often not the case. Since the size of the global product is highly dependent on the number of globally assisting services available in the agents' workspace, our solution is particularly suitable for systems with complex motion capabilities, sparsely distributed services of interest, and occasional needs for collaboration. Its benefits are demonstrated in Sec.~\ref{sec:experiment}.


%\jana{In our problem solution, we first build product automata and preprocess them to achieve smaller size of the overall synchronized product. In comparison to the journal paper submission, we do not assume here the full synchronization after every step and we do not adapt it afterwords. Instead, we directly aim to synthesis of the synchronization moments. Furthermore, we prove that online recomputation and adaptation of the plans will still ensure the satisfaciton of the LTL formula. Hence, our algorithm is adaptive to unpredictable time durations of the agents' actions}

%\subsection{Compact Product Automata}

%First focus on one $i \in \N$ only.

%As the first step to our solution, we label each transition of each B\"uchi automaton as either \emph{dependent} or \emph{independent}, to indicate whether the collaboration of the other agents is needed or not. 

%\begin{definition}[Independent transition] We call a transition $(q,\sigma,q') \in \delta_i$ of $\B_i$  \emph{independent} if and only if for all $\sigma' \in \Sers$, such that $\sigma' \cap \Ser_i = \sigma \cap \Ser_i$, it holds that $(q, \sigma ', q') \in \delta_i$. 
%\label{def:participating}
%\end{definition}

%\jana{
%Intuitively, a transition is independent if its outcome does not depend on any other agents besides $i$...


%We build a product automaton for each agent separately, we propose a way to transform them into a compact version that possibly contains fewer states and transitions, and we prove that the original and the transformed product automata are language equivalent. Then, we combine the individual product automata into one, that represents the coordination and the synchronization of the individual agents. We show how certains paths in this product automaton project onto the plans, i.e., sequences of discrete states and actions, and synchronization sequences.

%The definition of the product automaton in our case relies on the traditional definition of the product automaton used in model checking~\cite{principles}, however, it reflects that the LTL task specifications are defined over services rather than atomic propositions and that the LTL satisfaction is local (see Def...).
%
%\begin{definition}[Product automaton]
%\label{def:PA}
%A product of an agent transition system $\T_{i}$, and the B\"uchi automaton $\B_i$ is a B\"uchi automaton $\P_i= (Q_{\P_i}, q_{\init,\P_i},  \Sigma_{\P_i} , \delta_{\P_i}, F_{\P_i})$, where
%\begin{itemize}
%\item $Q_{\P_i} = S_i \times Q_i$;
%\item $q_{\init,\P} = (s_{\init,i},q_{\init,i})$;
%\item $\Sigma_{\P_i} = A_i \times (2^\Sers \cup \mathcal E_i)$;
%\item $((s,q),(\alpha,\sigma),(s',q') \in \delta_{\P_i}$
%iff 
%\begin{enumerate}
%\item [(i)] $(s,\alpha,s') \in T_i$,
%\item [(ii)] $\sigma \cap 2^{\Ser_i} \subseteq L(\alpha)$, and
%\item [(iii)] either $\sigma =\mathcal E_i$ and $q = q'$, or $\sigma \in \Sers$ and $(q,\sigma,q') \in \delta_i$; and
%\end{enumerate}
%\item $F_{\P_i} = \{(s,q) \mid q \in F_i\}$.
%\end{itemize}
%\label{def:product}
%\end{definition}
%
%
%\begin{lemma}
%bla
%\end{lemma}
%
%\jana{Establish the projection: the runs of the product project on a trace of the agent $i$. In a special way also on the Buchi: take the accepting sequence, remove all epsilons and get a word accepted by $\B_i$. Similarly as in automatica paper...}
%
%Now, we focus on reducing the size of the product automaton. Instead of $\Sigma_\P$ we will have regular expressions over $\Sigma_\P$. The very same rules as in the translation from an automaton to a regular expressions apply... \jana{find a citation}
%
%Here we use dependent and independent transition. A state with all incomming being independent and all outgoing being independent will be removed. Concatenation. Pay attention to accepting/nonaccepting.
%
%\begin{lemma}
%language equivalence of $\P$ and the compact $\P$. 
%\end{lemma}
%
%Note that each transition in the compact $\P$ now projects onto a sequence of independent transitions or onto a single dependent transition.
%
%\subsection{Planning}
%
%From the compact product automata automata $\hat \P_i$ to a product system: asynchronosity!!! One can move the others don't have to. The only requirement: one moves. Is this going to help at all???
%
%\jana{PERHAPS BETTER:
%What if I synchronize first the Buchis? I get an intersection automaton ad automatica, in which dependent and independent can be also found easily.
%
%Proejction of the Buchi onto the alphabet.
%
%Because then I only sync dependent with dependent. Which is easier. I cannot sync independent with dependent...FULLY SYNC SOLUTION FIRST? A step in BA = a step in TS. So 
%
%Since I have self loops, I know that if there exists a plan, there exists one when they sync after every single step. I also know that it's enough to sync right before dependent actions.
%
%}
%
%\begin{itemize}
%\item $Q = \hat Q_{\P_1} \times \ldots \times \hat Q_{\P,N}$
%\item $\Sigma_\P = A_1 \times \ldots \times A_N \times (2^\Sers \cup \{\Epsilon_1, \ldots, \Epsilon_N\})$
%\item transition function: 
%\begin{itemize}
%\item 2 independent can be arbitrarily composed together. 
%\item independent and dependent: only if the independent can be broken into prefix, transition, suffix and that transition is compatible with the dependent
%\item 2 dependent: if they fit together, i.e. this time they have to match in temrs of =, not <
%
%\end{itemize}
%
%\end{itemize}
%
%How  do we generate the sequences? Projection from the big product; Regular expressions: ok without synchronization, between regular expressions sync needed.
%
%\subsection{Online Plan Adaptation}
%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ILLUSTRATIVE EXAMPLE}
\label{sec:experiment}

An illustrative example with 3 robots is given in Fig.~\ref{fig:workspace}. Their workspace is partitioned into 100 cells, and a robot's state is defined by the cell it is present at. Agent 1 (green) is a ground vehicle and has to avoid the obstacles (in gray), while agents 2 (orange) and 3 (purple) are UAVs and their workspace is obstacle-free except for walls (thick).
The cells are each labeled with an atomic proposition from $\{\mathsf{R1, R2, R3, R4}\}$ indicating the room to which the cell belongs. Services are available in cell marked with stripes. Agent 1 can \emph{load} (green horizontal stripe) and \emph{unload} (green vertical). Agent 2 can \emph{help} (orange horizontal) or \emph{inform} (orange vertical). Agent 3 can \emph{assist} (purple horizontal).
The motion formulas are: For agent 1 to  avoid room $\mathsf{R1}$, $\phi_1 = \Always \neg \mathsf{R1}$, for agent 2 to  avoid $\mathsf{R2}$, $\phi_2 = \Always \neg \mathsf{R2}$, and for agent 3 to survey $\mathsf{R1}$ and $\mathsf{R2}$, $\phi_3 = \Always \Event \, \mathsf{R1} \wedge \Always \Event \, \mathsf{R2}$.
The task formulas are: For agent 1 to periodically load collaboratively with agents 2 and  3 and then to unload, collaboratively with agent 2 or  3: $\psi_1 = \mathit{load} \, \wedge \, \mathit{help} \,  \wedge \mathit{assist} \wedge \Always \,(\mathit{load} \Rightarrow \Next \, (\mathit{unload} \, \wedge \,(\mathit{help} \,\vee\, \mathit{assist}))) \wedge \Always\, (\mathit{unload} \Rightarrow \Next \, (\mathit{load} \, \wedge \, \mathit{help} \, \wedge \, \mathit{assist}))$, for agent 2 to periodically service $\mathit{inform}$, $\psi_2 = \Always \Event \, \mathit{inform}$, for agent 3 $\psi_3 = \mathit{assist} \, \vee \neg \mathit{assist}$, i.e., agent 3 is not assigned a specific task.
An example of as collection of the desired trajectories and synchronizations is given in Fig.~\ref{fig:workspace}.  


\begin{figure}[!h]
\centering
\includegraphics[width=0.7\linewidth]{workspace}

\caption{\footnotesize{Examples of desired trajectories of 3 robots in a shared workspace. The synchronization events at the moments of providing nonsilent services are depicted with stars. First, all  agents synchronize in the bottom left corner and provide \emph{load, help, assist}; then agent 2 provides  \emph{inform} and then agents 1 and 3 provide  \emph{unload, assist}, or vice versa; finally, all  agents synchronize in the bottom left corner, and start periodically executing the above.}}

\label{fig:workspace}

\end{figure}



In classical centralized planning, only the synchronous product of the TSs of the three agents would have  $\approx$ 100 000 states. In our case, the BAs for the given formulas had 2,2,3,2,2,1 states, respectively, and hence their language intersection BAs reaches $2*2*3*2*2*1*7 \approx 330$ states. The overall product automaton has then up to $\sim 30$ millions states.
In contrast, in our solution, the individual task and motion products $\widehat \P_1, \widehat \P_2, \widehat \P_3$ after all reductions have 27,17, and 8 states, respectively. Hence the largest structure dealt with during the overall procedure, i.e., the product automaton $\P$ has only $27*17*8*4 \sim 15 000 $ states.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{CONCLUSIONS}
%\label{sec:summary}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{refer}


\end{document}
