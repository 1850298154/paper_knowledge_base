Let $\mathcal M_{\mathbf y}$ be the submanifold of $\mathbb R^n$ which contains the true state vector $\mathbf p$ on it. Denote by $(\mathcal M_{\mathbf y} - \hat{\mathbf p})$ the manifold constructed by translating each point of $\mathcal M_{\mathbf y}$ by $(-\hat{\mathbf p})$; equivalently, we may conceptualize it as the shifting of the origin of $\mathbb R^n$ to $\hat{\mathbf p}$. Observe that $(\mathcal M_{\mathbf y} - \hat{\mathbf p})$ is the manifold of all the error vectors which can explain the observed measurements, $\mathbf y$. In particular, we have $\mathbf x \in (\mathcal M_{\mathbf y} - \hat{\mathbf p})$.

Given a nonnegative integer $s< n$, consider the set of $s$-sparse vectors in $\mathbb R^n$, by which we mean the set of vectors that have at most $s$ non-zero elements. The set of $1$-sparse vectors are precisely the axes of $\mathbb R^n$, i.e., the union of each of the $1$-dimensional subspaces spanned by the standard basis vectors of $\mathbb R^n$. More generally, the set of $s$-sparse vectors is a union of $s$-dimensional subspaces \cite[p. 20]{wakin2007geometry_p20}. By a similar argument, the set of $s$ block-sparse vectors of $\mathbb R^n$ (whose block-sparsity is at most $s$, where $s<|\mathcal V|$) is a union of lower-dimensional subspaces. Therefore, if the errors are known to be sparse, we can intersect the set of $s$ block-sparse vectors with the manifold $(\mathcal M_{\mathbf y} - \hat{\mathbf p})$, significantly reducing our search space; this idea is illustrated in Fig. \ref{fig:sparsity}. However, since we do not assume that the set $\mathcal D$ or its cardinality is known, the block-sparsity of $\mathbf x$ is unknown as well.


The discussion thus far motivates the following optimization problem for simultaneously identifying the faulty agents as well as recovering their corresponding error vectors:
%
\begin{align*}
\begin{array}{rclc}
   \textsc{P1:}  &  &
\begin{array}{rl}
\underset{
% \bigstrut[t]
\scalebox{0.9}{$\hat{\mathbf x}\hsp\in\hsp\mathbb R^{n}$}}
{\textnormal{minimize\ }}\quad  
&\| \hat{\mathbf x}\|_{2,0}  
\\
\textnormal{\bigstrut[t] subject to\ } \quad
& \mathbf \Phi \left(\hat {\mathbf p} + \hat{\mathbf x}\right) \hsp = \hsp  \mathbf y 
\end{array} & \qquad \qquad
\end{array}
\end{align*}
%
Problem P1 identifies the minimum number of faults that are able to explain the observed measurement vector $\mathbf y$. This is a natural way to pose the FDIR problem when the occurrence of faults at each of the agents are independent and identically distributed (i.i.d.) processes, such that given a nonnegative integer $s<|\mathcal V|$, the likelihood of the occurrence of $s+1$ faults is strictly smaller than that of $s$ faults. Nevertheless, our present motivation for considering Problem P1 is that it has the potential\footnote{The condition for the intersection of two submanifolds of $\mathbb R^n$ to be a lower-dimensional submanifold is called \textit{transversality}; it can be found in \cite[p. 68]{bott1982differential}.} to reduce the dimension of the search space. In special cases (e.g., the distance-based localization problem considered in Section \ref{subsec:example}), it is possible to determine the exact conditions under which an $s$ block-sparse error can be uniquely recovered in this manner \cite{khan2023recovery}.

% Further comment regarding the uniqueness of the solution to P1 is beyond the scope of this paper, in part due to the generality of the problem formulation being considered herein.

\begin{figure}
         \centering
         \includegraphics[width=0.30\textwidth]{images/sparse_error_recovery.png}
        \caption{The intersection of a generic two-dimensional manifold (yellow surface) with the set of $2$-sparse vectors is a one-dimensional manifold (red curves). Its intersection with the set of $1$-sparse vectors is a zero-dimensional manifold (red points).}
        \label{fig:sparsity}
\end{figure}