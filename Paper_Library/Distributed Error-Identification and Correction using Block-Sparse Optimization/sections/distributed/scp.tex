The objective of SCP is to solve a nonconvex optimization problem by breaking it down into convex sub-problems, motivated by the ease and speed of solving convex optimization problems \cite{scp_zillober2004,scp_morgan2014}.  To arrive at the convex sub-problem, we first linearize the nonlinear constraint of P1 as follows.
Let $\mathbf x^*\in\mathbb R^n$ denote a partially reconstructed error vector which has been computed over a given number of SCP iterations. The subsequent iteration of SCP searches for a block vector $\hat{\mathbf x}\in \mathbb R^n$ satisfying $\mathbf \Phi( \hat{\mathbf p} + \mathbf x^* + \hat {\mathbf x})=\mathbf y$, where $(\hat{\mathbf p} + \mathbf x^*)$ is treated as an updated estimate of $\mathbf p$.
The first-order Taylor series approximation of $\mathbf \Phi$ near the point $(\hat{\mathbf p} + \mathbf x^*)$ is given by
\begin{align}
\mathbf \Phi( \hat{\mathbf p} + \mathbf x^* + \hat {\mathbf x}) \approx \mathbf \Phi(\hat{\mathbf p} + \mathbf x^*)  + \mathbf J_{\mathbf \Phi} (\hat{\mathbf p} + \mathbf x^*) (\hat {\mathbf x})
\label{eq:linearization}
\end{align}
Defining $\mathbf z \coloneqq \mathbf y - \mathbf \Phi(\hat{\mathbf p} + \mathbf x^*)$ and $\mathbf R \coloneqq \mathbf J_{\mathbf \Phi}(\hat{\mathbf p} + \mathbf x^*)$, we arrive at a linearized version of the equality constraint, $\mathbf R \hat{\mathbf x} = \mathbf z$.

The objective function of P1, $\|\hsp\cdot\hsp\|_{2,0}$, is still a non-convex function. Thus, consider replacing it with the convex function, $\|\hsp\cdot\hsp\|_{2,1}$. The justification for this is as follows; when the matrix $\mathbf R$ satisfies a certain numerical property, called the \textit{block null space property}, the objective functions $\| \hsp \cdot \hsp \|_{2,0}$ and $\|\hsp \cdot \hsp \|_{2,1}$ both yield the same minimum \cite[Thm. 1]{robust_NSP_2017}. 

\vspace{2pt}
\begin{remark}
The exact conditions on the multi-agent configuration under which the block null space property holds can be found in \cite{khan2023recovery}, where it was studied for the special case of multi-agent localization using distance or bearing measurements. 
% For the general case being considered in this paper, we proceed under the motivation that $\|\hsp\cdot\hsp\|_{2,1}$ is a sparsity-promoting objective function. 
As for the general FDIR problem being considered in this paper, our analysis in Section \ref{subsec:interpretation} reveals that $\|\hsp \cdot \hsp \|_{2,1}$ promotes the block sparsity of the solution irrespective of whether any conditions on $\mathbf R$ are met.
\end{remark}
\vspace{2pt}

Together, the two preceding steps lead us to the following optimization problem:
%
\begin{align*}
\begin{array}{rclc}
   \textsc{P2:}  &  &
\begin{array}{rl}
\underset{
% \bigstrut[t]
\scalebox{0.9}{$\hat{\mathbf x}\hsp\in\hsp\mathbb R^{n}$}}
{\textnormal{minimize\ }}\quad  
&\| \mathbf x^* + \hat{\mathbf x}\|_{2,1}  
\\
\textnormal{\bigstrut[t] subject to\ } \quad
& \mathbf R \hat{\mathbf x} = \mathbf z
\end{array} & \qquad \qquad
\end{array}
\end{align*}
which is indeed convex. 
% Note that $\mathbf R$ is the linearization of $\mathbf \Phi$ about an estimate of the multi-agent configuration, as the true configuration $\mathbf p$ is unknown.
In each iteration of SCP, one first solves the linearized sub-problem P2, while keeping $\mathbf x^*$, $\mathbf z$, and $\mathbf R$ fixed, and then updates $\mathbf x^*$ by adding to it the minimizer of P2. In the next SCP iteration, the constraint is re-linearized using the new value of $\mathbf x^*$.
By repeatedly performing these two steps (i.e., minimization followed by re-linearization), a locally optimal solution to the original nonconvex optimization problem can be obtained \cite[Prop. 2]{khan2023recovery}.

\vspace{2pt}
\begin{remark}
The sub-problem P2 may be infeasible due to the linearization error in the constraint. To resolve this, slackness can be introduced in the constraint \cite{khan2023recovery} or a trust-region method can be used \cite[Sec. 6]{bonalli2022sequential}. In our numerical examples in Sec. \ref{sec:numerical}, it is seen that approximate minimization of P2 also works quite well in practice. In fact, ADMM is particularly well-suited for fast approximate minimization of a convex optimization problem \cite[Sec. 3.2.2]{boyd2011distributed}, which motivates the use of ADMM to solve the sub-problem P2.
\end{remark}
\vspace{2pt}

However, the equality constraint of P2 still poses a challenge, as it
causes the optimization problem to be coupled between the agents. In the next subsection, we further separate Problem P2 into sub-problems that can be solved in parallel by the agents in the network. 