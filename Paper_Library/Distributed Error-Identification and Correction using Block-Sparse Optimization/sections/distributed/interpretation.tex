Consider the term $\|\mathbf x^* + \hat{\mathbf x}\|_{2,1}$ in the objective function of Problem P3. The reason why this term promotes the block sparsity of the error vector is that it is non-differentiable at the points where any of its blocks are equal $\bold 0$. 
Intuitively, if one attempts to `touch' the graph of a non-differentiable (but essentially differentiable) function from below with a set of arbitrarily chosen hyperplanes, the hyperplanes are more likely to touch the non-differentiable points of the graph than not. 
We can make this idea mathematically precise using the concept of subgradients of convex functions.

\vspace{2pt}
\begin{lemma}
Given $\mathbf A\in\mathbb R^{o\times n}$ and $\mathbf b\in\mathbb R^{o}$, where $o$ is a positive integer, let $f:\mathbb R^n \rightarrow \mathbb R$ denote the function
$f(\bold v) = \|\bold v\| + \frac{1}{2}\|\bold A \bold v - \bold b\|^2$.
A vector $\bold v^*\in\mathbb R^n$ is the unique global minimizer of $f$ if and only if either
\begin{itemize}
    \item
$\|\bold A^\top \bold b\| \leq 1 $ and $\bold v^* = \bold 0$, or
\item $\|\bold A^\top \bold b\| > 1 $, $\bold v^*\neq \bold 0$, and
$
\bold A^\top \bold A \bold v^* + \dfrac{\bold v^*}{\|\bold v^*\|}  = \bold A^\top \bold b.
$
\end{itemize}
\vspace{3pt}
\label{lem:proximal}
\end{lemma}
\begin{proof}
The proof is given in Appendix 1.
\end{proof}
%
% \vspace{4pt}
\begin{theorem}[Thresholding Property]
The minimizer $\bar {\mathbf x}[i]$ of the first primal minimization problem at agent $i$ (step 3 of Alg. \ref{alg:inner}) is given by $\bar{\mathbf x}[i]=-\mathbf x^*[i]$ if and only if
\begin{align}
\Big\|
&\sum_{l \in \mathcal E_i}\mathbf R[l,i]^\top 
\Big(
\mathbf c_i^{(l)}(-\mathbf x^*, \bar{\mathbf w}) + \tilde{\boldsymbol \lambda}_i^{(l)}
\Big) 
\nonumber\\&\qquad \qquad 
+ \sum_{j\in\mathcal N_i}\Big(
\mathbf d_i^{(j)}(-\mathbf x^*, \bar{\mathbf w})
+\tilde{\boldsymbol{\mu}}_i^{(j)}\Big)
\Big\| \leq \frac{1}{\rho},
\label{eq:threshold}
\end{align}
where $\tilde{\boldsymbol{\lambda}}_i^{(l)}\coloneqq \frac{{\boldsymbol{\lambda}}_i^{(l)}}{\rho}$ and $\tilde{\boldsymbol{\mu}}_i^{(j)}\coloneqq \frac{{\boldsymbol{\mu}}_i^{(j)}}{\rho}$.
\label{thm:threshold}
\end{theorem}
% \vspace{3pt}
\begin{proof}
 Define $\mathbf v_i=\mathbf x^*[i]+\hat{\mathbf x}[i]$, where $\hat{\mathbf x}[i]$ is the variable being minimized over in step 3 of Alg. \ref{alg:inner}. Then, the objective function in step 3 can be expressed as
$\|\mathbf v_i\| + \frac{1}{2}\|\mathbf A_i \mathbf v - \mathbf b_i\|^2 + \gamma_i$,
 where $\gamma_i \in \mathbb R$ is a constant that is independent of $\mathbf v_i$, and
%
\begin{align}
\mathbf A_i = \sqrt{\rho} \begin{bmatrix}\vspace{-10pt}\\
\mathbf R[l_1, i]\\
\mathbf R[l_2, i]\\
\vdots \vspace{3pt}\\
% \mathbf R[\mathcal E_i^{(|\mathcal E_i|)}, i]\\
\mathbf I\\
\mathbf I\\
\vdots\vspace{2pt}
\end{bmatrix},
&\quad 
\mathbf b_i = -\sqrt{\rho} \begin{bmatrix}
    \mathbf c_i^{(l_1)}(-\mathbf x^*, \bar{\mathbf w}) + \tilde{\boldsymbol{\lambda}}_i^{(l_1)}\\
    \mathbf c_i^{(l_2)}(-\mathbf x^*, \bar{\mathbf w}) + \tilde{\boldsymbol{\lambda}}_i^{(l_2)}\\
    \vdots \\
    \mathbf d_{i}^{(j_1)}(-\mathbf x^*, \bar{\mathbf w}) + \tilde{\boldsymbol{\mu}}_{i}^{(j_1)}\vspace{2pt}\\
    \mathbf d_{i}^{(j_2)}(-\mathbf x^*, \bar{\mathbf w}) + \tilde{\boldsymbol{\mu}}_{i}^{(j_2)}\\
    \vdots
\end{bmatrix},
\label{eq:A_i-b_i}
\end{align}
where $l_1,l_2, \dots, l_{|\mathcal E_i|}$ denote the elements of $\mathcal E_i$, and $j_1, j_2, \dots, j_{|\mathcal N_i|}$ denote the elements of $\mathcal N_i$.
% \input{sections/distributed/tikz_array}
Note that the minimization of $\|\mathbf v_i\| + \frac{1}{2}\|\mathbf A_i \mathbf v_i - \mathbf b_i\|^2$ over $\mathbf v_i$ is equivalent to the minimization problem in step 3 of Alg. \ref{alg:inner}, as neither the constant factor $\gamma_i$ nor the change of variables $\hat{\mathbf x}[i]\rightarrow \mathbf v_i$ changes the underlying optimization problem.
Thus, we can use Lemma \ref{lem:proximal} to complete the proof.
\end{proof}

Theorem \ref{thm:threshold} can be used to obtain a meaningful interpretation of the proposed multi-agent FDIR algorithm, as follows. Firstly, 
observe that agent $i$ sets its error vector to $\mathbf 0$ if and only if the value on the left-hand side of inequality (\ref{eq:threshold}), which may be interpreted as the \textit{residual} of agent $i$, lies below a certain \textit{threshold}. The residual is a function of the vectors in $\lbrace \bar{\mathbf w}_i^{(j)} \rbrace_{j\in\mathcal N_i}$, which are updated by the neighbors of agent $i$. This interdependency between the agents' residuals is what enables the proposed algorithm to identify the faults in a collaborative manner.
Furthermore, we see that the penalty parameter $\rho$ is inversely proportional to the threshold in inequality (\ref{eq:threshold}). Lastly, observe that step 7 of Algorithm \ref{alg:inner} can be rewritten as: $\tilde{\boldsymbol \lambda}_i^{(l)+} \leftarrow \tilde{\boldsymbol \lambda}_i^{(l)} + \hsp \mathbf c_i^{(l)}(\bar {\mathbf x}, \bar{\mathbf w})$, which means that $\tilde{\boldsymbol \lambda}_i^{(l)}$ (and similarly, $\tilde{\boldsymbol \mu}_i^{(j)}$) is a running sum of the amount of constraint violation in each iteration. Hence, a repeated violation of the constraints at agent $i$ compels the agent to set its error vector to a non-zero value, whereas the term $\mathbf c_i^{(l)}(-\mathbf x^*, \bar{\mathbf w})$ in the residual checks whether this constraint violation can be attributed to the neighbors of agent $i$ instead.

A secondary contribution of Theorem \ref{thm:threshold} is that it informs an efficient strategy for minimizing the non-differentiable function in step 3 of Algorithm \ref{alg:inner}.
In general, the minimization of a non-differentiable function using subgradient descent achieves a convergence speed of $O(1/\sqrt{t})$ \cite{gordon2012subgradient}. However, if the inequality in (\ref{eq:threshold}) holds at agent $i$, then $\bar{\mathbf x}[i]$ can be set to $-\mathbf x^*[i]$, bypassing the need to solve an optimization problem altogether. If the inequality does not hold, then Lemma \ref{lem:proximal} guarantees that the minimizer is bounded away from the non-differentiable point. Therefore, one can use Nesterov's accelerated gradient descent method
% (as the gradient is well-defined at almost all points in the domain) 
to achieve a convergence speed of $O(1/t^2)$ \cite{nesterov1983method}, as long as the gradient descent procedure is initialized within a neighborhood of the minimizer where the function is differentiable.
