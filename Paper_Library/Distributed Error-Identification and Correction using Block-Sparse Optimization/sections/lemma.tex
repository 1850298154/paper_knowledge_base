\begin{proof}
Using the property of subdifferentials \cite[Thm. 4.1.1]{hiriart2004fundamentals}, we have
\begin{equation}
    \partial f(\bold v) = \partial g(\bold v) + \lbrace \bold A^\top \bold A \bold v - \bold A^\top \bold b\rbrace
\end{equation}
where $\partial f(\bold v)$ is the subdifferential (i.e., the set of subgradients) of $f$ at $\bold v$, $g(\bold v)=\|\bold v\|$, and `$+$' denotes the Minkowski sum. $g(\bold v)$ is differentiable everywhere but at the origin.
The subdifferential of $g(\bold v)$, where $\bold v\in \mathbb R^n$, is
\begin{align}
    \partial g({\bold v}) = \begin{cases}
    \begin{array}{cc}
        \left\lbrace \dfrac{{\bold v}}{\|{\bold v}\|} \right\rbrace & {\bold v} \neq \bold 0 \vspace{5pt}\\
        \left\lbrace \bold u \hspace{1pt}\big|\hspace{1pt} \bold u\in \mathbb R^n, \|\bold u\|\leq 1 \right\rbrace & {\bold v} = \bold 0
    \end{array}
    \end{cases}
\end{align}
\textbf{Case $\|\bold A^\top \bold b\| \leq 1$:}
By choosing the subgradient $\bold A^\top \bold b$ at $\bold v = \bold 0$, we see that $\bold 0 \in \partial f(\bold 0)$.  Moreover, if $\bold b = \bold 0$ then $\bold 0$ is clearly a unique global minimum. Now let $\bold b\neq \bold 0$. To prove that $\bold 0$ is the unique point where a subgradient of $f$ vanishes, we use the fact that $\|{}\cdot{}\|$ is only `flat' in the radial directions, whereas the hyperplane corresponding to $\bold A \bold v = \bold b$ is an affine subspace which does not contain any of the radial lines. To formalize this, assume there is another point $\tilde {\bold v}$ such that $\bold 0\in \partial f(\tilde{\bold v})$. Since $f(\bold 0)  \geq f(\tilde{\bold v}) $ and $f(\tilde{\bold v})\geq f(\bold 0) $, $f(\bold 0) = f(\tilde{\bold v})$. Choose a number $\theta$ such that $0\leq \theta \leq 1$.
From convexity, $f(\theta \tilde{\bold v})\leq f(\bold 0)$, and because $\bold 0 \in \partial f(\bold 0)$, $f(\theta \tilde{\bold v})\geq f(\bold 0) $. Thus, for all $0\leq \theta \leq 1$, we have $f(\bold 0) = f(\theta \tilde{\bold v}) = f(\tilde {\bold v})$, which implies that $\tilde {\bold v} \in \ker(\nabla^2 f(\theta \tilde {\bold v}))$. Therefore, we have
\begin{equation}
\tilde{\bold v} \in \ker\left( \frac{1}{\theta\|\tilde {\bold v}\|}\left(I - \frac{\tilde {\bold v} \tilde {\bold v}^\top}{\|\tilde {\bold v}\|^2}\right) + A^\top A\right)
\end{equation}
or equivalently, $\tilde {\bold v} \in \ker (\bold A)$. Setting the gradient at $(\theta \tilde {\bold v})$ to $\bold 0$, we get
\begin{equation}
    \frac{\tilde{\bold v}}{\|\tilde{\bold v}\|} = \bold A^\top \bold b
\end{equation}
but a vector cannot be in both the kernel of $\bold A$ and the range space of $\bold A^\top$, giving us a contradiction.

\noindent\textbf{Case $\|\bold A^\top \bold b\| > 1$:}
If $\bold v^*\neq0$, then $\partial f(\bold v^*)$ is a singleton containing the gradient vector, and both directions of the claim follow from setting the gradient to $\bold 0$. The uniqueness of $\bold v^*$ follows from similar arguments to the ones we used above.

To see that $\bold v^* \neq \bold 0$, choose a unit vector $\bold u\in \mathbb R^n$ and consider that
\begin{align}
 \lim_{k\rightarrow 0^+}\nabla f(k \bold u) &= \lim_{k \rightarrow 0^+} k \bold A^\top \bold A \bold u + \bold u - \bold A^\top \bold b\\
&=  \bold u - \bold A^\top \bold b
\end{align}
where $\nabla f(\hsp \cdot \hsp)$ is the gradient of $f$, which is well-defined at all non-zero points. Since $\|\bold A^\top \bold b\|>1$, we can always choose a direction $\bold u$ such that $f(\bold v)$ is strictly decreasing along that direction near the origin, which completes the proof.
\end{proof}