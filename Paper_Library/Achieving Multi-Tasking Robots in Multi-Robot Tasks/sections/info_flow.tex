%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Problem Formulation}
\label{sec:coal-coord}

The setting of multi-tasking robots with multi-robot tasks (with instantaneous assignment) is given as follows:

\begin{definition}[MT-MR Setting]
A MT-MR setting is given by a set $\{S_i\}$,
where $S_i$ corresponds to the set of constraints to be satisfied by the coalition for task $t_i$, where the values of $S_i$ are determined by each coalition. 
\end{definition}

We further stipulate that the task requirements, manifested as physical constraints, are {\it independent} among themselves, which depend only on the environment, task and robot configurations. 
For example, in our motivating example (Fig. \ref{fig:demo}), the constraint introduced by the monitoring task is solely a requirement of the monitoring task, and independent of the centroid task. 
The problem of enabling MT-MR 
thus becomes that of determining whether there exists a physical configuration of the robots that satisfies all these constraints at the same time:

\begin{definition}[Compatibility]
A  set of constraints $S$ is compatible if 
there exists a physical configuration for all the referents in $S$ such that all the constraints are satisfied.
\end{definition}

To reason about compatibility, 
we first consider the inverse when a set of constraints is incompatible. 
Assuming that the physical constraints are independent and based on the definition above, the set of constraints becomes incompatible if two constraints associated with the same information instance are constrained by different values. 
We formally define this intuition in the following claim:

\begin{claim}
Given a MT-MR setting $\{S_i\}$, $\{S_i\}$ is incompatible if no two constraints are restricted by the same information with different values. 
\label{am:comp}
\end{claim}

While the above claim provides a sufficient condition for a set of constraints to be incompatible, 
it is not a necessary condition. 
%While this may seem to be a restrictive, it is in fact is a rather mild assumption. First, it is obviously a sufficient condition. 
For necessity to hold, however, a process must exist such 
that two constraints restricted by the same information with different values will {\it always} be found whenever a physical configuration does not exist for a given set of constraints. 
This requires us to reason about the {\it equivalences} between constraint systems, or in our case information systems, which are exactly what the information invariant theory~\cite{donald1995information} deals with!
%no other constraints ever derivable from the set of constraints may lead to the same situation. 
%we will eventually find out about the conflicting information given sufficient time. 
The underlying assumption for realizing this process is the ability to identify all information instances that are relevant  and can be derived (or inferred) from known information in the domain.
To achieve this, we must first assume that a complete set of inference rules is identified in a domain, which is an implicit assumption made throughout the paper.
%--we term it as {\it information completeness}, which is closely tied to the notion of information inference as we will discuss next. 
% The challenge, however, lies in the fact that information instances (and hence the constraints) are not mutually independent from each other. 
Next, we incrementally develop a mechanism to implement this process for our problem settings. 
First, we introduce a new concept:
\begin{definition}[Inference Closure]
   Denoting the inference closure of a set of information instances $S$ by $\mathcal{C}(S)$, any $F$ belongs to $\mathcal{C}(S)$ if:
    \begin{enumerate}
    	\item $F \in S$ or
        \item $\mathcal{C}(S) \Rightarrow F$
    \end{enumerate}
    \label{def:pow-iis}
\end{definition}

Note the recursive definition here. 
Given the inference rules in Tab. \ref{tab:rules}, for example,
we can conclude that $\mathcal{C}(\{F_G(r_1)$, $F_G(r_2)\}) 
= \{F_G(r_1)$, $F_G(r_2), F_R(r_1, r_2)$, $F_R$ $(r_2$, $r_1)\}$.
We also refer to any information instance that is in $\mathcal{C}(S)$ %but not in $S$ 
as {\it ``inferable''} from $S$, 
or that $S$ infers it. 
Based on this definition, $S$ trivially infers any instance already in $S$. 
We use $\rightarrow$ to distinguish it from that used in inference rules.
Note, however, that $\rightarrow$ subsumes $\Rightarrow$.
$\rightarrow$ is clearly transitive by definition.
Next, we more formally define the notion of information inference that links us to inference closure:

\begin{definition}[Information Inference]
    Given a set of information instances, $S$, and an information instance $F$, 
    an information inference defines a relationship such that any value set for $S$, i.e., $\{f_1: F_1 \in S\}$, uniquely determines the value of $F$ (i.e., $f$), or written as $S \rightarrow F$.
    \qed
    \label{def:infer-iis} 
\end{definition}

Note the similarity between inference rule and information inference. 
When $S_1 \leftrightarrow S_2$, we refer to them as being equivalent sets.
Intuitively, information inference enables us to reason about the constraints that are implicitly ``{\it required}'' as a result of the given set of constraints.
We show it more formally next:
%To connect it to our main conclusion, 
%we first step through a few results that will prove useful later. 

\begin{lemma}
Given an information inference in the form of $S \rightarrow F$,
if a set of constraints is defined over $S$, it also introduces a constraint on $F$.
\label{lm:constraints}
\end{lemma}

%\begin{proof}
This follows almost immediately from the definition. 
Given a set of values for $S$, the value of $F$ is determined from Def. \ref{def:infer-iis},
which implies that $F$ is also constrained according to Def. \ref{def:info-config}. 
A derivative of this result is that if $S_1 \rightarrow S_2$, 
a set of constraints on $S_1$ also introduces a set of constraints on $S_2$.
% First, for any information instance $F$ that is in both $S_1$ and $S_2$, we can simply assign its value in $S_2$ according to $f$ for $F$ in $S_1$. 
% Otherwise, denote an information instance from $S_2$ that is not in $S_1$ as $F_{2,\neg1}$.
% Given $S_1 \leftrightarrow S_2$ and the definition of information closure, 
% there must exist a set of rules that can be sequentially applied to derive $F_{2,\neg1}$ from $S_1$: 
% it starts with a subset of $S_1$ on the left hand side of the first rule for deriving some instance, 
% and ultimately ends with the last rule for deriving $F_{2,\neg1}$.
% Given the definition of information inference, the value of $F_{2,\neg1}$ is thus fully and uniquely determined by $S_1$.
% Since this holds for all $F_{2,\neg1}$, we know that  all values for information instances in $S_2$ are uniquely determined,
% hence also constrained. 
%\end{proof}

\begin{definition}[Minimally Sufficient Inference]
	$S \rightarrow F$ is a minimally sufficient inference if removing any instance from $S$ would no longer infer $F$.
    \label{def:min-suff}
\end{definition}
Any inference rule is always assumed to be a minimally sufficient inference in this work,
since otherwise the rule can be simplified by removing the instances that are not required. 
We use $\rightarrow^*$ to denote a minimally sufficient inference. 
In the following,
we further simplify our discussion by assuming linear information systems:

\begin{lemma}[Linear Information Systems]
Assuming all inference rules specify linear relationships among the information instances,
any information inference of the form $S \rightarrow F$ also specifies a linear relationship. 
\label{lm:linear}
\end{lemma}

\begin{proof}
Given that $S \rightarrow F$, 
there must exist a set of inference rules that are sequentially applied to derive $F$, 
in the forms of $S_1 \Rightarrow F_1, S_2 \Rightarrow F_2, \dots, S_k \Rightarrow F_k (F)$,
where $S_i \subseteq S \bigcup_{j < i} \{F_j\}$.
Since all the inference rules are assumed to be linear, 
we may replace $F_i$ appearing after the $i$th rule using the $i$th rule for expressing $F_i$, which removes $F_i$ from the equations.
After performing this operation sequentially from $i = 1$ to $k - 1$,
we end up with an expression of $F$ using only $S$. 
\end{proof}
The rules in Tab. \ref{tab:rules} define a linear information system. 

\begin{lemma}[Permutability]
Assuming a linear information system,
any minimally sufficient inference of the form $S \rightarrow F$ is permutable, or in other words it satisfies that $S \cup \{F\} \setminus F_x \rightarrow F_x$, which is also a minimally sufficient inference, for all $F_x \in S$. 
\label{lm:perm}
\end{lemma}

\begin{proof}
Given that $S \rightarrow^* F$ specifies a linear relationship (Lemma \ref{lm:linear}), the linear expression of $F$ using $S$ as constructed in Lemma \ref{lm:linear} must contain all the instances in $S$ without any coefficients being zero. 
Given a linear relationship, 
we can swap the positions of any $F_x$ and $F$ in the expression, and the result is still a valid linear equation for expressing $F_x$. 
Since $F_x$ expressed by this equation is uniquely determined by $S \cup \{F\} \setminus F_x$ collectively only, 
by Def. \ref{def:min-suff} we have $S \cup \{F\} \setminus F_x \rightarrow^* F_x$.
\end{proof}


\begin{lemma}
Assuming linear information systems and $S_1$ and $S_2$ are two sets of constraints in a MT-MR setting:  if
$S_1 \rightarrow F$ and $S_2 \rightarrow F$ are both minimally sufficient inferences, and $S_1$ and $S_2$ are compatible at the same time, then we must have
$S_1 = S_2$.
\label{lm:complete}
\end{lemma}

\begin{proof}
We prove it by contradiction. Suppose that $S_1$ and $S_2$ are compatible at the same time and $S_1 \not= S_2$. There must exist
a set of values for $S_1$, which  corresponds to a physical configuration of the referents that also satisfies $S_2$. 
Given that $S_1 \rightarrow F$, we know that $S_1$ introduces a constraint on $F$ given Lemma \ref{lm:constraints}.
Hence, to ensure that $S_2$ is compatible, $S_2$ must compute the same value $f$ for $F$. 

If $S_1$ and $S_2$ are the same, the conclusion trivially holds. 
Otherwise, 
when $S_1 \supset S_2$, it results in a contradiction given that both $S_1 \rightarrow F$ and $S_2 \rightarrow F$ are minimally sufficient.
Otherwise, $S_2$ must contain at least one instance $F_{2, \neg 1}$ that is not present in $S_1$. 
In such a case, our problem setting (MT-MR) has the flexibility to set the value in $S_2$ independently of $S_1$.
Since updating the value of $F_{2, \neg 1}$ will change the value of $F$ given Lemma \ref{lm:perm}, it leads to a contradiction that $S_1$ and $S_2$ must compute the same value for $F$.
% According to Lemma \ref{lm:perm}, we can update the value of $F$, 
% which leads to a uniquely determined value for $F_{2, \neg 1}$ while holding the other values in $S_2$ fixed. 
% Notice that updating $F_{2, \neg 1}$ does not require the values for $S_1$ to be updated given $S_1 \not\rightarrow F_{2, \neg 1}$. 
% When the constraint for $F_{2, \neg 1}$ requires this value in $S_2$, 
% the values of $F$ computed by $S_1$ and $S_2$ will not match, thus leading to a contradiction. 
\end{proof}


\begin{figure}
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/layer.png}
    \caption{Illustration of the multi-level graphical structure constructed (from the bottom up) to determine whether a MT-MR setting is compatible. The nodes are labeled by information instances. It shows two cases where a duplicate node is found: one for $F_5$ and one for $F_0$. The $F_0$ at level $3$ is not added and it does not lead to incompatibility. The $F_5$ at level $2$ however leads to incompatibility. In the actual implementation, our algorithm would already stop at level $2$ after the incompatibility is detected.}
    \vskip-15pt
    \label{fig:layer}
\end{figure}

Finally, we state the main theorem in the following:


\begin{theorem}
Assuming linear information systems:
given a MT-MR setting $\{S_i\}$ with non-overlapping $S_i$'s,
the following is a {\textbf{necessary and sufficient}} condition for $\{S_i\}$ to be incompatible:
\begin{equation}
 S_1 \cap S_2 \not\rightarrow F,  S_1 \rightarrow F, S_2 \rightarrow F \text{ where } S_1, S_2 \subseteq \bigcup_i S_i
\label{eqn:complete}
\end{equation}
\label{thm:complete}
\end{theorem}
\vskip-10pt

\begin{proof}
For sufficiency, we prove it by contradiction. 
In particular, we assume that there exist $S_1$ and $S_2$ that satisfy the above conditions and they are compatible. 
Given that $S_1 \rightarrow F, S_2 \rightarrow F$, 
we know that there exist subsets $S_1^*$ and $S_2^*$ of $S_1$ and $S_2$, respectively, such that $S_1^* \rightarrow^* F, S_2^* \rightarrow^* F$.
From  Lemma \ref{lm:complete}, we know that for them to be compatible (as a result of $S_1$ and $S_2$ being compatible), it must satisfy that $S_1^* = S_2^*$. 
This conflicts with the fact that $S_1 \cap S_2 \not\rightarrow F$.


For necessity, we must prove that the above conditions must hold for all 
situations where $\{S_i\}$ is not compatible. 
Assume a situation where the conditions do {\it not} hold and $\{S_i\}$ is incompatible. 
In such a case, there must exist two different sets $S_a \subseteq \bigcup_i S_i$ and $S_b \subseteq \bigcup_i S_i$ that infer $F$ (given Claim \ref{am:comp} and the assumption about a complete set of inference rules), 
and that  $S_a \cap S_b \rightarrow F$ (given the assumption above).
In which case, however, $S_a$ and $S_b$ must be compatible for $F$, 
resulting in a contradiction. 
% and $S_a \leftrightarrow S_b$ (due to the negation of the condition in Eq. \eqref{eqn:complete} above).
% In such a case, $S_a$ can infer any instance in $S_b$. In which case, 
% we can set $S_2$ to contain only an instance $F$ in $S_b$ that is inferable from $S_a$ but not in $S_a$,  and $S_1$ to $S_a$, to derive a contradiction with the assumption that the condition in Eq. \eqref{eqn:complete} does not hold. 
\end{proof}

Note that when $S_i$'s overlap, they are trivially incompatible by Claim \ref{am:comp}. 

\subsection{Solution Method}
Brute-forcing the solution is clearly intractable since it requires checking all subset-pairs of $\bigcup_i S_i$, 
which is exponential. Instead, we propose the following procedure based on a directed and multi-level graphical structure constructed from the bottom up: 


\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.6\columnwidth]{sections/stddevunnamed.png}
    \includegraphics[width=0.6\columnwidth]{sections/stddevunnamed1.png}
    \includegraphics[width=0.6\columnwidth]{sections/stddevunnamed3.png}
    \caption{%\YZ{just a note. first is 0.5 times on both, second is 0.5 times centroid and 3 times monitoring, and third is 3 times both}
    Plots of average tasks assigned as number of vehicles increases. Each plot specifies a different test configuration with fewer tasks of both types, more monitoring tasks, and more tasks of both types, with respect to the number of vehicles. The data for each plot was generated from 100 iterations, each given a random number of vehicles from $3$ to $7$.}
    \vskip-10pt
    \label{fig:1}
\end{figure*}


\begin{itemize}
    \item \textbf{\textit{Level 0}}: Make a node for each $F \in \bigcup_i S_i$ as leafs for the structure.
    \item \textbf{\textit{Level i + 1}} $(i \geq 0)$: For all inference rules that can be applied to the nodes at levels $0$ to $i$, make a parent node for each instance $F$ that can be inferred directly based on an inference rule, if this instance does not appear previously in the graph. Otherwise, we compute the intersection of its footprint (all descendant-leaf nodes, see Fig. \ref{fig:layer}) and that of the previous node, to see if it infers $F$. If so, continue with building the graph (without adding the duplicate node); otherwise, return incompatible.
    % This is often node created, if any newly generated instance already appears as a node in the structure, the new node does not include the set of leaf descendants of the lowest-level node appeared, return incompatibility. 
    \item \textbf{\textit{Stopping criteria}}: when no new nodes can be created, return compatible.
\end{itemize}

Fig. \ref{fig:layer} shows an example of the graphical structure constructed to illustrate the compatibility detection process. 

\subsection{Solution Analysis}
To analyze the complexity of the algorithm, we consider the following variables:

\begin{itemize}
    \item number of inference rules, $R$
    \item number of agents, $G$
    \item number of information types, $F$
    \item maximum number of referents in instances, $E$
    \item maximum number of information instances on the left hand side of an inference rule, $N$
\end{itemize}



The maximum number of information instances is bounded by $O(FG^E)$.
At any level $i$, the number of candidate rules to check is bounded by $O(RG^{EN})$. 
Hence, the total computation for constructing the graph is bounded by $O(FRG^{EN})$. 
Hence, the computational complexity is only exponential in two constants (determined by the domain), and otherwise polynomial with respect to the number of agents. 

\begin{theorem}
The solution method  specified above is both sound and complete for detecting incompatibility in a MT-MR setting with linear information systems. 
\end{theorem}

This is a direct result of Theorem \ref{thm:complete} since the solution method essentially implements the same checking process described there. 
Note, however, when the system returns compatible, it does not necessarily mean that there exists a physical configuration in the current situation, since the environment may also affect the compatibility. 
However, assuming that the influence of the environment is temporary, a system should be able to recover from an incompatible state. 
Further discussion on this is delayed to future work. 
% \begin{proof}
% For soundness, 
% %given a MT-MR setting $\{S_i\}$ that is not compatible, from Theorem \ref{thm:complete},
% when the procedure returns incompatibility, 
% there must be two nodes of the same instance $F$ that have leaf descendants as $S_1$ and $S_2$, respectively, 
% and $S_1 \setminus S_2 \neq \emptyset$ (assuming $S_1$ is the lowest-level node). 
% Given the procedure, we know that $S_1$ must correspond to a minimally sufficient inference for $F$ (assuming the minimally sufficient inference rules for all information instances are provided as domain knowledge).
% In such a case, we may update the values for $S_1 \setminus S_2$ to change the value of $F$ while holding the other values in $S_1$ and $S_2$ fixed to derive an incompatibility. 

% For completeness, we must show that any incompatibility will be detected by the above procedure. 
% Given Theorem \ref{thm:complete}, we only need to show that the procedure checks all possible ways incompatibility may be introduced. 
% First, we note that there two places where incompleteness may have been introduced: 1) we do not allow a node to be recreated when it would appear as an ancestor of the same instance; 2) we report incompatibility when any new node does not include the set of leaf descendants of the lowest node appeared with the same instance.  

% For 1), given that any $F$ (at a lower level) can be used in the creation of any nodes at the higher levels, we know that the absence of $F$ from a higher level when it already appears at a lower level would not affect the completeness.
% For 2), again, given the procedure, when know that the leaf descendants for $F$ appearing at the lowest level must correspond to a minimally sufficient inference for $F$. Hence, 
% if another node of the same instance shares the set of leaf descendants with it, they are compatible since they must determine the same value for $F$.
% Hence, if the procedure does not report incompatibility, 
% it is compatible. 
% \end{proof}


% \subsection{Algorithms}
% %\YZ{Please update the algorithm for computing compatibility, and add a brief explanation for the algorithm as well.}
% Alg. \ref{alg:algorithm-com} presents the procedure for checking compatibility. 
% It follows the solution method described above.
% It incrementally builds the graph and check at each level whether any node can be added as well as for incompatibility. 
% It stops when no node is added to the current level.
% Alg. \ref{alg:algorithm-com} presents the task allocation algorithm for our method. 
% It starts with sorting the tasks based on their utilities and then again sorting the coalitions based on how likely they seem to benefit from task synergies. 
% Note again that since the main focus on our work is not on task allocation, 
% a simple greedy heuristic is adopted in this algorithm to identify the most promising set of robots for a task. 
% The heuristic prefers coalitions with more overlapping robots over those with fewer overlapping robots.
% It will be our future work to study how our method can be integrated into existing task allocation methods for a better performance.


% \begin{algorithm}[tb]
% \caption{Algorithm for Determining Compatibility}
% \label{alg:algorithm-com}
% \textbf{Input}: A MT-MR setting $\{S_i\}$, a set of inference rules \mathcal{U}, $i = 1$, graph $G$\\
% \textbf{Output}: $\text{true}$ or $\text{false}$
% \begin{algorithmic}[1] %[1] enables line numbers
% \FOR{each physical constraint $F \in \bigcup_i S_i$}
%     \STATE Construct a leaf node for $F$ in $G$
% \ENDFOR
% \WHILE{true}
%     \FOR{nodes up to level $i - 1$ that satisfy a rule $u \in U$}
%         \STATE Construct a node $n$ based on $u: L \Rightarrow R$
%         \IF{no node $v$ is currently present in the graph for $R$}
%             \STATE Add $n$ as the parent of $L$ in $G$
%         \ELSIF{$\text{footprint}(n)$ $\cap$ $\text{footprint}(v) \rightarrow R$}
%             continue
%         \ELSE
%             \RETURN false
%         \ENDIF
%     \ENDFOR
%     \IF{no node is added at level $i$}
%         \RETURN true
%     \ENDIF
%     \STATE increment $i$
% \ENDWHILE
% \end{algorithmic}
% \end{algorithm}



%\YZ{Please update the algorithm for making task assignment, and add a brief explanation for the algorithm as well.}
% \begin{algorithm}[tb]
% \caption{Algorithm for Task Assignment}
% \label{alg:algorithm-ta}
% \textbf{Input}: a set of multi-robot tasks, $T$, a set of robots $R$, a set of inference rules, $U$\\
% \textbf{Output}: an assignment $M$
% \begin{algorithmic}[1] %[1] enables line numbers
% \STATE Sort the tasks
% \FOR{each task $t_i \in T$}
%     \STATE Sort candidate coalitions based on a greedy heuristic
%     \FOR{$c$ in the ordered list}
%         \STATE Compute $S_i$ based on the task specifications
%         \STATE Run compatibility check with $\{S_{1:i}\}$ and $U$
%         \IF{incompatibility is returned}
%             continue
%         \ELSE 
%             Assign $c$ to $r$ in $M$
%         \ENDIF
%     \ENDFOR
%     \IF{no coalition can be assigned}
%         \STATE Skip task $t_i$. 
%     \ENDIF
% \ENDFOR
% \RETURN $M$
% \end{algorithmic}
% \end{algorithm}