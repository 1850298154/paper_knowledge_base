\section{Background}
\label{sec:background}

In this section we discuss the concept of critical interference that our work is based on, 
and present a general framework to bound response-times of DAG tasks scheduled under G-FP. 
In the next section, we summarize the state-of-the-art analyses for G-FP and 
give an overview of our method. 

\subsection{Critical Chain and Critical Interference}
\label{subsec:critical_interference}
The notions of \emph{critical chain} and \emph{critical interference} were introduced by 
Chwa et al.~\cite{chwa2017global, chwa2013global} for analyzing parallel tasks scheduled with G-EDF. 
Unlike sequential tasks, analysis of 
DAG tasks with internal parallelism is inherently more complicated: 
(i) some subtasks of a task can be interfered with by other subtasks of the same task 
(i.e., \emph{intra-task interference}); (ii) subtasks of a task can be interfered with by subtasks of 
higher-priority tasks (i.e., \emph{inter-task interference}); and (iii) the parallelism of a DAG task 
may vary during execution, subject to the precedence constraints imposed by its graph. 
The critical chain and critical interference concepts alleviate the complexity of the analysis 
by focusing on a special chain of subtasks of a task which accounts for its response time, 
thus bringing the problem closer to a more familiar 
analysis technique for sequential tasks. Although they were originally proposed for analysis of 
G-EDF~\cite{chwa2017global, chwa2013global}, these concepts are also useful for analyzing G-FP. 
We therefore use them in our analysis and include a discussion of them in this section. 


Consider any job $J_k$ of a task $\tau_k$ and its corresponding schedule. 
A \emph{last-completing subtask} of $J_k$ is a subtask 
that completes last among all subtasks in the schedule of $J_k$. 
A \emph{last-completing predecessor} of a subtask $v_{k, a}$ is a predecessor 
that completes last among all predecessors of $v_{k, a}$ in the schedule of $J_k$. 
Note that a subtask can only be ready after a last-completing predecessor finishes, 
since only then are all the precedence constraints for the subtask satisfied. 
Starting from a last-completing subtask of $J_k$, we can recursively trace back through all 
last-completing predecessors until we reach a subtask with no predecessors. 
If during that process, a subtask has more than one last-completing predecessors, 
we arbitrarily pick one. The chain that is reconstructed by appending those 
last-completing predecessors and the last-completing subtask 
is called a \emph{critical chain} of job $J_k$. We call the subtasks that belong to a critical 
chain \emph{critical subtasks}. 

\begin{figure}[h]
\center
\includegraphics[width=\linewidth]{figures/critical_chain.pdf}
\caption{Critical chain and critical interference of $J_k$.}
\label{fig:critical_chain}
\end{figure}

\begin{example} 
Figure~\ref{fig:critical_chain} presents an example of a critical chain of a job $J_k$ of 
task $\tau_k$, which has the same DAG as shown in Figure~\ref{fig:example_task}. In Figure~\ref{fig:critical_chain}, 
boxes with bold, solid borders denote the execution of critical subtasks of $J_k$; boxes with bold, 
dashed borders denote the execution of the other subtasks of $J_k$. The other boxes are 
for jobs of other tasks. Subtask $v_{k, 6}$ is a last-completing subtask. 
A last-completing predecessor of $v_{k, 6}$ is $v_{k, 5}$. 
Similarly, a last-completing predecessor of $v_{k, 5}$ is $v_{k, 3}$, and a last-completing 
predecessor of $v_{k, 3}$ is $v_{k, 1}$. Hence a critical chain of $J_k$ is 
$(v_{k, 1}, v_{k, 3}, v_{k, 5}, v_{k, 6})$. 
\end{example}


The critical chain concept has a few properties 
that make it useful for schedulability analysis of parallel DAG tasks. 
First, the first subtask of any critical chain of a job is 
ready to execute as soon as the job is released, since it does not have any predecessor. 
Second, when the last subtask of a critical chain completes, the corresponding job finishes --- 
this is from the construction of the critical chain. Thus the scheduling window of a critical chain 
of $J_k$ --- i.e., from the release time of its first subtask to the completion time of 
its last subtask --- is also the scheduling window of job $J_k$ --- i.e., from the job's release 
time to its completion time. 
Third, consider a critical chain $\lambda_k$ of $J_k$: 
at any instant during the scheduling window of $J_k$, 
either a critical subtask of $\lambda_k$ is executed \textit{or} a critical subtask of $\lambda_k$ 
is ready but not executed because all $m$ processors 
are busy executing subtasks not belonging to $\lambda_k$, 
including non-critical subtasks of job $J_k$ and subtasks from other tasks 
(see Figure~\ref{fig:critical_chain}). 
Therefore, the response-time of a critical chain of $J_k$ is also the response-time of $J_k$. 
Hence if we can upper-bound the response-time of a critical chain for any job $J_k$ of 
$\tau_k$, that bound also serves as an upper-bound for the response-time of $\tau_k$. 


The third property of the critical chain suggests that we can partition the scheduling window of 
a job $J_k$ into two sets of intervals. One includes all intervals during which critical subtasks of 
$J_k$ are executed and the other includes all intervals during which a critical subtask of $J_k$ 
is ready but not executed. The total length of the intervals in the second set is called the 
\emph{critical interference} of $J_k$. We include definitions for critical interference and 
interference caused by an individual task on $\tau_k$ as follows. 
\begin{definition}
\label{defn:critical_interference}
\emph{Critical interference} $I_k(a, b)$ on a job $J_k$ of task $\tau_k$ is the aggregated \textbf{length} 
of all intervals in [a, b) during which a critical subtask of $J_k$ is ready but not executed. 
\end{definition}

\begin{definition}
\label{defn:critical_interfering_indi}
\emph{Critical interference} $I_{i, k}(a, b)$ on a job $J_k$ of task $\tau_k$ due to task $\tau_i$ is the aggregated 
\textbf{processor time} from all intervals in [a, b) during which one or more subtasks of $\tau_i$ are executed and 
a critical subtask of $J_k$ is ready but not executed. 
\end{definition}

In Figure~\ref{fig:critical_chain}, the critical interference $I_k(0, 14)$ of $J_k$ is the sum of the lengths of intervals 
$[0, 2)$, $[4, 5)$, $[7, 9)$, and $[11, 13)$ which is 7. The critical interference $I_{i, k}(0, 14)$ 
caused by a task $\tau_i$ is the total processor time of $\tau_i$ in those four intervals. Note 
that $\tau_i$ may execute simultaneously on multiple processors, and we must sum its processor time 
on all processors. From the definition of critical interference, we have: 
\begin{equation}
\label{eqn:critical_interference}
I_k(a, b) = \frac{1}{m} \sum\limits_{\tau_i\in\tau} I_{i, k}(a, b).
\end{equation}



\subsection{A General Method for Bounding Response-Time}
\label{subsec:general_method}

\begin{figure*}
\centering
\includegraphics[width=0.9\textwidth]{figures/workload.pdf}
\caption{Workload generated by an interfering task $\tau_i$ in an interval of length $\Delta$.}
\label{fig:workload}
\end{figure*}

We now discuss a general framework for bounding response-time in G-FP that is used in this work 
and was also employed by the state-of-the-art analyses~\cite{melani2015response, fonseca2017improved}. 
Based on the definitions of critical chain and critical interference, the response-time $R_k$ of $J_k$ is: 
$$R_k = len(\lambda_k) + I_k(r_k, r_k+R_k),$$
where $\lambda_k$ is a critical chain of $J_k$ and $len(\lambda_k)$ is its length 
(see Figure~\ref{fig:critical_chain} for example). 
Applying Equation~\ref{eqn:critical_interference} we have: 
\begin{multline}
\label{eqn:resptime}
R_k = \Big( len(\lambda_k) + \frac{1}{m} I_{k, k}(r_k, r_k+R_k) \Big) + 
\frac{1}{m} \sum\limits_{\tau_i\in hp(\tau_k)} I_{i, k}(r_k, r_k+R_k), 
\end{multline}
where $hp(\tau_k)$ is the set of tasks with higher priorities than $\tau_k$'s. 
Thus if we can bound the 
right-hand side of Equation~\ref{eqn:resptime}, we can bound the response-time of $\tau_k$. 
To do so, we bound the contributions to $J_k$'s response-time 
caused by subtasks of $J_k$ itself and by jobs of higher-priority tasks separately. 


\subsubsection{Intra-Task Interference}
The sum $\Big( len(\lambda_k) + \frac{1}{m} I_{k, k}(r_k, r_k+R_k) \Big)$, which includes 
the intra-task interference on the critical chain of $J_k$ caused by non-critical subtasks of $J_k$, 
is bounded by Lemma V.3 in~\cite{melani2015response}. 
We include the bound below. 
\begin{lemma}
\label{lem:intra_interference}
The following inequality holds for any task $\tau_k$ scheduled by any work-conserving algorithm: \\
$$len(\lambda_k) + \frac{1}{m} I_{k, k}(r_k, r_k+R_k)\leq L_k + \frac{1}{m} (C_k - L_k)$$
\end{lemma}

\subsubsection{Inter-Task Interference}
Now we need to bound the inter-task interference on the right-hand side of Equation~\ref{eqn:resptime}. 
Since the interference caused by a task in an interval is at most the workload generated 
by the task during that interval, we can bound $I_{i, k}(a, b),~\forall\tau_i\in hp(\tau_k)$ 
using the bound for the workload generated by $\tau_i$ in the interval $[a, b)$. 
Let $W_i(a, b)$ denote the maximum workload generated by $\tau_i$ in the interval $[a, b)$. 
Let $W_i(\Delta)$ denote the maximum workload generated by $\tau_i$ in any interval of 
length $\Delta$. The following inequality holds for any $\tau_i$: 
\begin{equation}
\label{eqn:workload_relation}
I_{i, k}(r_k, r_k+R_k)\leq W_i(r_k, r_k+R_k)\leq W_i(R_k).
\end{equation}
Let the \emph{problem window} be the interval of interest with length $\Delta$. 
The jobs of $\tau_i$ that may generate workload within the problem window are classified into three types: 
(i) A \emph{carry-in job} is released strictly before the problem window and has a deadline within it, 
(ii) A \emph{carry-out job} is released within the problem window and has its deadline strictly after it, 
and (iii) \emph{body jobs} have both release time and deadline within the problem window. 
Similar to analyses for sequential tasks (e.g., Bertogna et al.~\cite{bertogna2007response}), 
the maximum workload generated by $\tau_i$ in 
the problem window can be attained with a release pattern in which (i) jobs of $\tau_i$ are released 
as quickly as possible, meaning that the gap between any two consecutive releases is exactly 
the period $T_i$, (ii) the carry-in job finishes as late as its worst-case 
finishing time, and (iii) the body jobs and the carry-out job start executing as soon as 
they are released. 
Figure~\ref{fig:workload} shows an example of such a job-release pattern of an interfering 
task $\tau_i$ with the DAG structure shown in Figure~\ref{fig:example_task}. 

However, unlike sequential tasks, analysis for parallel DAG tasks is more challenging in 
two aspects. First, it is not obvious which schedule for the subtasks of the carry-in (carry-out) job 
would generate maximum carry-in (carry-out) workload. This is because the parallelism 
of a DAG task can vary depending on its internal graph structure. Second, for the same reason, aligning 
the problem window's start time with the start time of the carry-in job of $\tau_i$ may not correspond to the 
maximum workload generated by $\tau_i$. For instance, in Figure~\ref{fig:workload} if we shift 
the problem window to the right 2 time units, the carry-in 
job's workload loses 2 time units but the carry-out job's workload gains 5 time units. 
The total workload thus increases 3 time units. Therefore in order to compute the 
maximum workload generated by $\tau_i$ we must slide the problem window to find 
a position that corresponds to the maximum sum of the carry-in workload and carry-out workload. 
We discuss an existing method for computing carry-in workload in Section~\ref{sec:sota} and 
our technique for computing carry-out workload in Section~\ref{sec:carryout}. 
In Section~\ref{sec:rta_schedtest}, we combine those two bounds in a 
response-time analysis and explain how we slide problem windows to compute maximum workloads. 

We note that the maximum workload generated by each body job does not depend 
on the schedule of its subtasks and is simply its total work. 
Furthermore, regardless of the position of the problem window, the workload contributed by 
the body jobs, denoted by $W_i^{BO}(\Delta)$, is bounded as follows. 
\begin{lemma}
The workload generated by the body jobs of task $\tau_i$ in a problem window with length $\Delta$ 
is upper-bounded by 
$$W_i^{BO}(\Delta) = \max \Big\{ \big(\Bigl\lfloor \frac{\Delta-L_i+R_i}{T_i} \Bigr\rfloor - 1\big) C_i,  0\Big\}. $$
\end{lemma}
\begin{proof}
Consider the case where the start of the problem window is aligned with the starting time of 
the carry-in job, as shown in Figure~\ref{fig:workload}. The number of body jobs is at most 
$\max\big\{\Bigl\lfloor \frac{\Delta-L_i+R_i}{T_i} \Bigr\rfloor - 1, 0\big\}$. 
Thus for this case the workload 
of the body jobs is at most $\max \big\{ \big(\Bigl\lfloor \frac{\Delta-L_i+R_i}{T_i} \Bigr\rfloor - 1\big) C_i, 0\big\}$. 

Shifting the problem window to the left or right can change the workload contributed by the 
carry-in and carry-out jobs but does not increase the maximum number of body jobs or their 
workload. The bound thus follows. 
\end{proof}


Let the \emph{carry-in window} and \emph{carry-out window} be the intervals within the problem 
window during which the carry-in job and the carry-out job are executed, respectively. 
Intuitively, the carry-in window spans from the start of the problem window to the completion time
of the carry-in job; the carry-out window spans from the starting time of the carry-out job to the 
end of the problem window. We denote the lengths of the carry-in window and carry-out window 
for task $\tau_i$ by $\Delta_i^{CI}$ and $\Delta_i^{CO}$ respectively. 
The sum of $\Delta_i^{CI}$ and $\Delta_i^{CO}$ is: 
\begin{equation}
\label{eqn:ci_co_length} 
\Delta_i^{CI} + \Delta_i^{CO} = L_i + (\Delta-L_i+R_i)\mod T_i
\end{equation}
Let $W_i^{CI}(\Delta_i^{CI})$ be the maximum carry-in workload of $\tau_i$ for a carry-in window 
of length $\Delta_i^{CI}$. Similarly, let $W_i^{CO}(\Delta_i^{CO})$ be the maximum carry-out workload 
of $\tau_i$ for a carry-out window of length $\Delta_i^{CO}$. 
The maximum workload generated by $\tau_i$ in any problem window of length $\Delta$ can be 
computed by taking the maximum over all $\Delta_i^{CI}$ and $\Delta_i^{CO}$ that satisfy 
Equation~\ref{eqn:ci_co_length}: 
\begin{equation}
\label{eqn:max_workload}
W_i(\Delta) = W_i^{BO}(\Delta) + \max\limits_{\Delta_i^{CI}, \Delta_i^{CO} \text{satisfy Eq.~\ref{eqn:ci_co_length}}} 
\Big\{ W_i^{CI}(\Delta_i^{CI}) + W_i^{CO}(\Delta_i^{CO}) \Big\}.
\end{equation}
Therefore if we can bound $W_i^{CI}(\Delta_i^{CI})$ and $W_i^{CO}(\Delta_i^{CO})$, we can 
bound the inter-task interference of $\tau_i$ on $\tau_k$ and thus the response-time of $\tau_k$. 










