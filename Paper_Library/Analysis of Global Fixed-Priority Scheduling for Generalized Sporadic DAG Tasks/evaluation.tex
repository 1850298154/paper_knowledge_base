\section{Evaluation}
\label{sec:evaluation}

\begin{figure*}[t]
\centering
\begin{subfigure}{0.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/m=16_beta=02_vary_util.pdf}
  \caption{Result for $m=16$, minimum task utilization $\beta = 0.2$, and varying total utilization.}
  \label{fig:varyutil1}
\end{subfigure}
\hfill
\begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/m=16_beta=04_vary_util.pdf}
  \caption{Result for $m=16$, minimum task utilization $\beta = 0.4$, and varying total utilization.}
  \label{fig:varyutil2}
\end{subfigure}

\begin{subfigure}{0.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/util=05_vary_procs.pdf}
  \caption{Result for total utilization $U = 0.5m$, minimum utilization $\beta=0.1$, and varying $m$.}
  \label{fig:varyprocs1}
\end{subfigure}
\hfill
\begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/util=07_vary_procs.pdf}
  \caption{Result for total utilization $U = 0.7m$, minimum utilization $\beta=0.1$, and varying $m$.}
  \label{fig:varyprocs2}
\end{subfigure}

\caption{Ratio of schedulable task sets for varying total utilization and varying number of processors.}
\label{fig:eval}
\end{figure*}


As we discussed in Sections~\ref{sec:sota} and~\ref{sec:carryout}, we apply a similar, high-level framework for 
analyzing schedulability of G-FP scheduling to the one used by Fonseca et al.~\cite{fonseca2017improved} 
--- i.e., accounting for the interfering workloads caused by the body jobs, the carry-in and carry-out jobs 
separately, and maximizing the interference by sliding the problem window. 
However, unlike~\cite{fonseca2017improved} our technique for bounding carry-out workload works 
directly for general DAGs and does not introduce pessimism due to the removal of precedence constraints 
between subtasks, as presented in~\cite{fonseca2017improved}. Though for carry-in workload, we reuse the result 
from~\cite{fonseca2017improved}. Hence, we consider our work as a generalization/extension 
of~\cite{fonseca2017improved} that can be applied for general sporadic DAG tasks. 
The performance of our method in term of schedulability ratio is compatible with~\cite{fonseca2017improved}'s 
--- it theoretically is at least as good as~\cite{fonseca2017improved} for NFJ-DAGs and is better 
than~\cite{fonseca2017improved} for non NFJ-DAGs. We thus focus on measuring the performance of 
our method and use the work by Melani et al.~\cite{melani2015response} as a reference for evaluating 
the improvement of our method upon their simple one. 

We applied the Erd\H{o}s-R\'enyi $G(n, p)$ method, described in~\cite{cordeiro2010random}, to generate 
DAG tasks. In this method the number of subtasks, given by parameter $n$ in $G(n, p)$, is first fixed. 
Then, directed edges between pairs of vertices are added with probability $p$. Since the obtained DAG may not 
necessarily be connected, we added a minimum number of edges to make it weakly connected. 
In our experiments, the probability for a directed edge to be added is $p=0.2$. 
We chose the number of subtasks uniformly in the range $[10, 20]$. 
Other parameters for each DAG task $\tau_i$ were generated similarly to~\cite{melani2015response}. 
In particular, the WCETs of subtasks of $\tau_i$ were generated uniformly in the range $[1, 100]$. 
After that, the work $C_i$ and span $L_i$ were calculated. $\tau_i$'s utilization was generated uniformly 
in the range $[\beta, C_i/L_i]$, where $\beta\leq 1$ is a parameter to control the minimum task's utilization and 
$C_i/L_i$ represents the degree of parallelism of task $\tau_i$. $\tau_i$'s deadline $D_i$ was 
generated using a normal distribution with mean equal to $(\frac{T_i+L_i}{2})$ and 
standard deviation equal to $(\frac{T_i-L_i}{4})$. We kept generating the relative deadline until a value in 
the range $[L_i, T_i]$ was obtained. 

To generate a task set for a given total utilization, we repeatedly add DAG tasks to the task set until the 
desired utilization is reached. The utilization (and period) of the last task may need to be adjusted to 
match the total utilization. We used the SCIP solver~\cite{scip} with CPLEX~\cite{cplex} as 
its underlying LP-solver to compute the bound for carry-out workload. 
For our experiments, we set the default minimum utilization of individual tasks $\beta$ to $0.1$. 
For each configuration we generated 
500 task sets and recorded the ratios of task sets that were deemed schedulable. We compare our response-time 
analysis, denoted by DGA-RTA, with the response-time analysis introduced in~\cite{melani2015response}, 
denoted by MBB-RTA. 
For all generated task sets, priorities were assigned in Deadline Monotonic order 
--- studying an efficient priority assignment scheme for G-FP is beyond the scope of this paper. 

Figures~\ref{fig:varyutil1},~\ref{fig:varyutil2},~\ref{fig:varyprocs1}, and~\ref{fig:varyprocs2} show representative 
results for our experiments. In Figure~\ref{fig:varyutil1} and~\ref{fig:varyutil2}, we fixed the total number 
of processors $m=16$ and varied the total utilization from 1.0 to 14.0. The minimum task utilization $\beta$ was 
set to $0.2$ and $0.4$ in these two experiments, respectively. Unsurprisingly, DGA-RTA dominates MBB-RTA, 
as also observed in~\cite{fonseca2017improved}. Notably, its schedulability ratios for some configurations are 
two times or more greater than MBB-RTA, e.g., for total utilizations of 8.0, 9.0 in Figure~\ref{fig:varyutil1}, and 
7.0, 8.0 in Figure~\ref{fig:varyutil2}. 
In Figures~\ref{fig:varyprocs1} and~\ref{fig:varyprocs2}, we fixed the normalized total utilization and 
varied the number of processors $m$ from 2 to 36. 
For each value of $m$, we generated task sets with total utilization $U = 0.5m$ or $U = 0.7m$ for these two 
experiments, respectively. Similar to the previous experiments, the schedulability ratios of the generated 
task sets were improved significantly using DGA-RTA compared to MBB-RTA. 

To provide a trade-off between computational complexity and accuracy of schedulability test, 
one can employ our analysis in combination with the analysis 
presented in~\cite{fonseca2017improved} by first applying their response-time analysis and then using our 
analysis if the task set is deemed unschedulable by~\cite{fonseca2017improved}. In this way, one can get 
the best result from both analyses.




























