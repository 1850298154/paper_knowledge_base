% ;; -*- coding: iso-latin-1; TeX-PDF-mode: t; TeX-master: "main" -*-%

% We consider a distributed programming model with explicit
% locations. Each location represents a processor with a procedure stack
% and an unordered queue of pending tasks.  Initially all processors
% are idle. When an idle processor's task queue is non-empty, some task
% is selected for execution, this selection is non-deterministic.
%  Besides accessing its own processor's
% global storage, each task can post tasks to the queues of any
% processor, including its own, and synchronize with the termination of
% tasks. The language uses \emph{future variables}~\cite{deboer07esop}
% for synchronizing program execution with the completion of
% asynchronous tasks.
% A future variable acts as a proxy for a result
% that is initially unknown, usually because the computation of its
% value is yet incomplete. When the future variable is ready, the result
% can be retrieved.
% %
% An asynchronous call $\sf m({\bar{z}})$ spawned at location $\sf x$ is
% associated with a future variable $\sf f$ as follows $\sf
% f=x~!~m({\bar{z}})$.Instruction \await{f} allows non-blocking synchronization with the
% termination of \textsf{m} that is associated to
% $\sf f$ terminates. On the other hand, instruction $\sf r=\get{f}$ allows blocking the
% execution until the task executing \textsf{m} and it retrieves the result in $\sf r$.
% When a task completes or
% when it is awaiting with a non-blocking {\sf await} for a task that
% has not finished yet, its
% processor becomes idle again, chooses the next pending task, and so
% on.  The number of distributed locations need not be known a priori
% (e.g., locations may be virtual).
% Syntactically, a location will
% therefore be similar to a \emph{concurrent object} that can be
% dynamically created using the instruction \newb. 
%For instance, the
%instruction $b{=}\newb~Location();$ creates a distributed location of
%type $Location$ which is referenced by $b$. % All methods must
% return something, hence \lst{void} methods are by-default expressed as
% \lst{int} methods returning $0$. For the sake of generality, the
% syntax of expressions $e$ and types $T$ is left open.


% \newcommand{\rrrule}[2]{
% \begin{array}{c}
% #1 \\
% \hline
% #2 
% \end{array}
% %\vspace*{-0.25cm}
% }

% \begin{figure}[t]
% % \begin{center}{\textsf{\textbf{Macro-step semantics}}} \end{center} 
% {\small\begin{center}
% \textsc{(mstep)}~$\rrrule{
%   \selectTask(S)=\tkid,~S =
%   \buffer(\objid,\bot,\heap,\queue \cup \{\tkid\}) \sepo S' \\
%   \buffer(\objid,\tkid,\heap,\queue \cup \{\tkid\}) \sepo S'  \microstepstar{\objid\cdot \tkid} S''
%  }{S  \macrostep{\objid\cdot \tkid} S''} $
% \end{center}
% }

% {\small\begin{center}
% \textsc{(newloc)}~$\rrrule{~\tkid
%   =tsk(\tkid,\namemethod,\mapping,{pp{:} {\sf x=\textsf{new}~D({\bar{z}});s}}),~\text{fresh}(\objid_1),~\heap_1=\newheap(D),~\mapping_1=\mapping[x\rightarrow \objid_1]}
%  {\buffer(\objid,\tkid,\heap, \queue  \cup  \{\tkid \})
% \rrderiv 
% {\buffer(\objid,\tkid,\heap, \queue  \cup
%   \{tsk(\tkid,\namemethod,\mapping_1, {\sf s})\}) \sepo \buffer(\objid_1,\bot,\heap_1,\{\})}}$
% \end{center}
% }
% %\vspace{0.1cm}
% {\small\begin{center}
% \textsc{(async)}~$\rrrule{\tkid=tsk(\tkid,\namemethod,\mapping,pp{:}
%   {\sf y~{=}~x~!~m_1(\many{z});s}),
%    ~ \mapping(x){=}\objid_1,% ~ \objid_1\neq \nil,
%   ~ \text{fresh}(\tkid_1), ~\text{fresh}(\future_1), \\
%     \mapping_1{=}buildLocals(\bar{z},\namemethod_1,\mapping), ~ \mapping'=\mapping[y\rightarrow \future_1]}
%   { \buffer(\objid,\tkid,\heap,\queue \cup \{\tkid\})\sepo 
%     \buffer(\objid_1,\_,\_, \queue_1) 
% \rrderiv 
% \buffer(\objid,\tkid, \heap,  \queue \cup
% \{tsk(\tkid,\namemethod,\mapping',{\sf s})\})\sepo \\
%  \buffer(\objid_1,\_,\_,  \queue_1\cup
%  \{tsk(\tkid_1,\namemethod_1,\mapping_1,body(\namemethod_1))\}) \sepo \fut(\future_1,\objid_1,\tkid_1,ini(\namemethod_1),\bot)}  $
% \end{center}
% }
% %\vspace{0.1cm}
% {\small\begin{center}
% \textsc{(return)}~$\rrrule{\tkid
%   =tsk(\tkid,\namemethod,\mapping,pp{:}\textsf{return x; s}), ~\mapping(x)=v}
% {\buffer(\objid,\tkid,\heap,\queue \cup \{\tkid\}) \sepo \fut(\future,\_,\tkid,\_,\bot)
% \rrderiv 
% \buffer(\objid,\bot,\heap, \queue) \sepo \fut(\future,\_,\tkid,\_,v)}$
% \end{center}
% }

% {\small\begin{center}
% \textsc{(await1)}~$\rrrule{\tkid =tsk(\tkid,m,l,pp{:}\await{y};s),   
%  ~\mapping(y)=\future, ~\fut(\future,\_,\_,\_,v) \in \futset}
% {\buffer(\objid,\tkid, h, \queue \cup \{\tkid\})
% \rrderiv  \buffer(\objid,\tkid,h,\queue \cup \{tsk(\tkid,m,l,s)\})}  $
% \end{center}
% }

% {\small\begin{center}
% $\textsc{(await2)}~\rrrule{\tkid=tsk(\tkid,m,l,pp{:}\await{y};s),
%   ~\mapping(y)=\future, ~\fut(\future,\_,\_,\_,\bot) \in \futset}
% {\buffer(\objid,\tkid, h, \queue \cup \{\tkid\}) 
% \rrderiv  \buffer(\objid,\bot,h,\queue \cup \{\tkid\})} $
% \end{center}
% }

% {\small\begin{center}
% \textsc{(get1)}~$\rrrule{\tkid=
%   tsk(\tkid,\namemethod,\mapping,pp{:}{\sf x~=~\get{y};s}),
%   ~\mapping(y)=\future,~ \fut(\future,\_,\_,\_,v) \in \futset,
%   ~\mapping_1=\mapping[x\rightarrow v]}
% {\buffer(\objid,\tkid,\heap, \queue \cup \{\tkid\})
% \rrderiv  \buffer(\objid,\tkid,\heap,
% \queue \cup \{tsk(\tkid,\namemethod,\mapping_1,{\sf s})\})} $
% \end{center}
% }

% %\vspace{0.1cm}
% {\small\begin{center}
% \textsc{(get2)}~$\rrrule{~\tkid = tsk(\tkid,\namemethod,\mapping,pp{:}{\sf
%     x {=} \get{y};s}),
%   ~\mapping(y)=\future, ~\fut(\future,\_,\_,\_,\bot) \in \futset}
% {\buffer(\objid,\tkid,\heap, \queue \cup \{\tkid\}) 
% \rrderiv \buffer(\objid,\tkid,\heap, \queue \cup \{\tkid\})} $
% \end{center}
% }
% \caption{Macro-Step Semantics of Asynchronous Programs}\label{Summarized_semantics}
% \end{figure}
A program consists of a
set of classes that define the types of locations, each of them
defines a set of fields and methods of the form $M{:}{:}{=} T~
m(\bar{T}~ \bar{x}) \{s\}$, where statements $s$ take the form $\sf s
{:}{:}{=} s; s \mid x{=}e \mid
\ifte~\mathit{e}~\iftethen~s~\ifteelse~s \mid
\while~\mathit{e}~\whilebody~\mathit{s} \mid \return~x; \mid
b{=}\newb~T({\bar{z}})\mid f=x~{\bold !}~m({\bar{z}}) \mid \await{f} \mid
x=\get{f}$.
%As locations do not share their states, % the semantics can be presented
% as a macro-step semantics \cite{DBLP:conf/fase/SenA06} (defined
% by means of the transition ``$\macrostep{}$'') in which the evaluation
% of
%  In
% this case, we apply rule {\sc mstep} to select non-deterministically
% an available task from one \emph{active} location in the state (i.e.,
% a location with a non-empty task buffer).
%
%
% The transition $\rrderiv$ defines the evaluation within a given
% location. {\sc newloc} creates a new location without tasks, with a
%fresh identifier and heap.
 Syntactically, a location will
 therefore be similar to a \emph{concurrent object} that can be
 dynamically created using the instruction \newb $\sf T(\bar{z})$. 
The
declaration of a future variable is as follows $\sf Fut \langle T \rangle~f$, where
$\sf T$ is the type of the result $\sf r$, it adds a new future
variable to the state.  
Instruction $\sf f=x~{\bold !}~m({\bar{z}})$ spawns a new task (instance of
method {\sf m}) 
%(the initial state is created by \emph{b with a fresh task identifier $\tkid_1$, 
and it is set to the future {\sf f} in the state. %$ini(m)$ refers to
%the first program point of method $m$.%   We assume $\objid \neq
% % \objid_1$, but the case $\objid = \objid_1$ is analogous, the new task
% % $\tkid_1$ is added to $\queue$ of $\
% objid$.  The rules for sequential
% % execution are standard and are thus omitted.
%%
Instruction \await{f} allows non-blocking
synchronization.  If the future variable {\sf f} we are awaiting for
points to a finished task, then the \Await{} can be
completed. Otherwise the task yields the lock so that any other task
of the same location can take it.
%%
On the other hand, instruction $\get{f}$ allows blocking
synchronization. It waits for the future variable without yielding the
lock, i.e., it blocks the execution of the location until the task
that is awaiting is finished. Then, when the future is ready, it
retrieves the result and allows continuing the execution.  This
instruction introduces possible deadlocks in the program, as two tasks
can be awaiting for termination of tasks on each other's locations.
%
Finally, instruction $\return~x;$ releases the lock that will never be
taken again by that task. Consequently, that task is \emph{finished}
and removed from the task queue.
%
%
All statements of a task takes place serially (without interleaving
with any other task) until it gets to a \return or \await{f}
instruction. Then, the processor becomes idle again, chooses
non-deterministically the next pending task, and so on.

% Figure~\ref{Summarized_semantics} presents the semantics of the
% language.
A \emph{program state} or \emph{configuration} is a set of locations
$\{\mathit{loc}_0,...,\mathit{loc}_n\}$.
%%
 A \emph{location} is a term $\buffer(\objid,\tkid,\heap,\queue)$
 where $\objid$ is the location identifier,
%$\anc$ is a list with the program points that created
%itself and its more recent ancestors, % $C$ is the class name,
$\tkid$ is the identifier of the \emph{active task} that holds the
location's lock or $\bot$ if the location's lock is free, $h$ is its
local heap, and $\queue$ is the set of tasks in the location.
%%
A \emph{task} is a term $tsk(\tkid,\namemethod,\mapping,s)$ where
$\tkid$ is a unique task identifier, $\namemethod$ is the method name
executing in the task, $\mapping$ is a mapping from local variables to
their values, and $s$ is the sequence of instructions to be executed. 
% and $c$ is the line in which \tkid was invoked or $0$, if $m$ is the
% main method.  $\extend{S}$ has the form $(S,table,timeConst)$ where
% S is the set of objects $\objid_0 \sepo \objid_1 \sepo \cdots \sepo
% \objid_n$, where $\objid_i \equiv \buffer(\objid_i,\tkid_i,\heap_i,$
% $\queue_i)$,$table$ is a \emph{interleaving table} and $timeConst$
% is the time contraint store.
We assume that the execution starts from a $main$ method without
parameters. The initial state is
% with an initial location with identifier $0$ executing task $0$ of
% the form
$\extend{\initstate}{=}\{\buffer(0,0,\bot,\{tsk(0,main,\mapping,\body{main})\}$
with an initial location with identifier $0$ executing task $0$,
% $\many{\initstate}=(\{\buffer(0,0,$
% $\bot,\{tsk(0,m,l,\body{m},0)\},\itable_{\emptyset},\{true\}).$
% 
%($\nil$
% in case of reference variables) $\bot$ is the empty heap, $\mapping$
maps local variables to their initial values, and $\body{m}$ is the
sequence of instructions in method $m$ and $ini(main)$ is the initial
program point in method $m$. From now on, we represent the state as a
Prolog list, and we write $[x \mapsto v]$ to denote $h(x)=v$
(resp. $l(x)=v$), that is, field $x$ in the heap $h$ (resp. local
variable $x$ in the mapping $l$) takes the value $v$.
%, and we can know the program point $pp$ where an instruction $s$ is
% in the program as follows $pp{:}s$.


 In what follows, a \emph{derivation} or \emph{execution}
\cite{DBLP:conf/fase/SenA06} % $\ex \equiv \extend{S}_0 \!\macrostep{} \cdots \macrostep{}
% \extend{S}_n$
is a sequence of states %macro-steps (applications of rule {\sc mstep}).
 $S_0 \macrostep{o_1.t_1} ...
 \macrostep{o_{n}.t_{n}} S_n $, where $S_i
\macrostep{o_i.t_i} S_{i+1}$ denotes the execution of task $t_i$ in
location $o_i \in S_i$. The derivation is
\emph{complete} if $S_0$ is the initial state and $\nexists~loc(\objid,\_,\_,\{\tkid\} \cup\queue) \in
S_n$ such that
$S_{n} \macrostep{\objid.\tkid} S_{n+1}$ and $S_n \neq S_{n+1}$. 
Given a state $S$, $\exec(S)$ denotes the set
of all possible complete executions starting at $S$. % We
% sometimes label transitions with $\objid \cdot \tkid$, the name of the
% location $\objid$ and task $\tkid$ selected (in rule {\sc mstep}) or
% evaluated in the step (in the transition $\rrderiv$).
%The systematic exploration of $\exec(\extend{S_0})$ thus corresponds
%to the standard systematic testing setting in which all possible
%explorations are performed without eliminating any redundancy.

