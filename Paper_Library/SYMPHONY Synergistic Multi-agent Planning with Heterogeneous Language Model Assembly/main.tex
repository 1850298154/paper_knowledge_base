\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2025

 \PassOptionsToPackage{numbers, compress}{natbib}
% ready for submission
\usepackage[final]{neurips_2025}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2025}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2025}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2025}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}


\usepackage{algorithm}
\usepackage{algpseudocode}
% \usepackage[ruled,vlined]{algorithm2e}
% \usepackage{amsfonts}       % blackboard math symbols
% \usepackage{listings}
% % listings 配置：等宽字体、小字号、自动断行
% \lstset{
%   basicstyle=\ttfamily\small,
%   breaklines=true,           % 自动断行
%   breakatwhitespace=true,    % 在空格处断行
%   breakindent=0pt,           % 续行无额外缩进
%   breakautoindent=false,     % 关闭自动续行缩进
%   columns=fullflexible,
%   keepspaces=true,
%   xleftmargin=0pt,           % 整体左贴环境左边界
%   frame=none
% }
\usepackage{listings} % 加载 listings 包

% 配置 listings 样式（可根据需求调整）
\lstset{
    basicstyle=\ttfamily\small, % 代码字体和字号
    breaklines=true, % 关键：自动换行
    columns=flexible, % 灵活列宽（避免字符挤压）
    tabsize=4, % Tab 缩进为 4 个空格
    showstringspaces=false, % 不显示字符串中的空格
}

\usepackage{amsmath} 
\usepackage{amssymb}
\usepackage{graphicx}       % for including graphics
\usepackage{hyperref}
\usepackage{caption}
\usepackage{makecell}

% \usepackage[UTF8]{ctex}
\newcommand{\comment}[2][red]{\textcolor{#1}{\fbox{\textbf{#2}}}}

\title{
SYMPHONY: Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly
}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


% \author{%
%   David S.~Hippocampus\thanks{Use footnote for providing further information
%     about author (webpage, alternative address)---\emph{not} for acknowledging
%     funding agencies.} \\
%   Department of Computer Science\\
%   Cranberry-Lemon University\\
%   Pittsburgh, PA 15213 \\
%   \texttt{hippo@cs.cranberry-lemon.edu} \\
%   % examples of more authors
%   \And
%   Coauthor \\
%   Affiliation \\
%   Address \\
%   \texttt{email} \\
%   \AND
%   Coauthor \\
%   Affiliation \\
%   Address \\
%   \texttt{email} \\
%   % \And
%   % Coauthor \\
%   % Affiliation \\
%   % Address \\
%   % \texttt{email} \\
%   % \And
%   % Coauthor \\
%   % Affiliation \\
%   % Address \\
%   % \texttt{email} \\
% }



\author{%
  Wei Zhu 
  % \And
  \quad
  Zhiwen Tang\thanks{Corresponding author} 
  % \And
  \quad
  Kun Yue \\
  School of Information Science and Engineering, Yunnan University, Kunming, China \\
  Yunnan Key Laboratory of Intelligent Systems and Computing, Kunming, China \\
  \texttt{zhuwei@stu.ynu.edu.cn, \{zhiwen.tang, kyue\}@ynu.edu.cn} \\
}



\begin{document}


\maketitle


\begin{abstract}
Recent advancements have increasingly focused on leveraging large language models (LLMs) to construct autonomous agents for complex problem-solving tasks. However, existing approaches predominantly employ a single-agent framework to generate search branches and estimate rewards during Monte Carlo Tree Search (MCTS) planning. This single-agent paradigm inherently limits exploration capabilities, often resulting in insufficient diversity among generated branches and suboptimal planning performance.
To overcome these limitations, we propose  \textbf{SY}nergistic \textbf{M}ulti-agent \textbf{P}lanning with \textbf{H}eter\textbf{O}geneous la\textbf{N}gauge model assembl\textbf{Y} (\textbf{SYMPHONY} \footnote{Code is available at \url{https://github.com/ZHUWEI-hub/SYMPHONY}}),  a novel multi-agent planning framework that integrates a pool of heterogeneous language model-based agents. 
By leveraging diverse reasoning patterns across agents, SYMPHONY enhances rollout diversity and facilitates more effective exploration.
Empirical results across multiple benchmark tasks show that SYMPHONY achieves strong performance even when instantiated with open-source LLMs deployable on consumer-grade hardware. When enhanced with cloud-based LLMs accessible via API, SYMPHONY demonstrates further improvements, outperforming existing state-of-the-art baselines and underscoring the effectiveness of heterogeneous multi-agent coordination in planning tasks.

\end{abstract}


\input{intro}




\input{related_work}

% \input{preliminary}

% \input{method}

\input{method_new}

\input{exp}

% \section{Limitation} \label{sec:limit}
% One current limitation of our work lies in the reliance on manually tuned hyperparameters, which may vary across different tasks to achieve optimal performance and cost-efficiency.  It highlights the need for more robust and automated hyperparameter optimization strategies. We view this as a promising direction for future work and expect that integrating adaptive tuning methods will further enhance the generality and usability of our approach.

% Our framework has several limitations. First, it heavily relies on the LLM's ability to accurately assess the current reasoning state, which contributes to the performance gap observed between SYMPHONY-S and SYMPHONY-L. In addition, users are required to configure certain hyperparameters, such as the maximum number of expansions and trajectories. The optimal values of these parameters may vary across different tasks.

\section{Conclusion and Future Work}
We present SYMPHONY, a multi-agent planning framework that combines MCTS with a diverse pool of language models. By leveraging model heterogeneity and incorporating adaptive scheduling, entropy-modulated confidence scoring, and memory sharing, SYMPHONY improves both search diversity and planning effectiveness. Experiments across multiple benchmarks show consistent gains in accuracy and efficiency. Importantly, SYMPHONY performs well even with models that run on consumer-grade hardware, making it a practical and scalable solution.

Future research will focus on extending SYMPHONY to unstructured or noisy environments, reducing reliance on manually tuned hyperparameters, and integrating fairness and robustness considerations into the planning process. We also plan to explore more efficient memory architectures to support scalable, continual adaptation.

\section*{Acknowledgements}
This work is supported by the Joint Key Project of National Natural Science Foundation of China (U23A20298), Yunnan Fundamental Research Project (202501AT070231), Open Project Program of Yunnan Key Laboratory of Intelligent Systems and Computing (ISC24Y03), and Professional Degree Graduate Practice Innovation Project of Yunnan University (ZC-252514097).



% We introduced SYMPHONY, a synergistic multi-agent planning framework that integrates Monte Carlo Tree Search with a heterogeneous pool of language models. By moving beyond the conventional single-model paradigm, SYMPHONY enhances exploration through diversity-aware rollouts that reduce redundancy and mitigate model-specific biases. The framework further incorporates UCB-based model scheduling, entropy-modulated confidence scoring, and pool-wise memory sharing to enable more effective coordination, uncertainty-aware evaluation, and reflective learning across agents. Experimental results across multiple benchmark datasets demonstrate that SYMPHONY consistently improves both accuracy and planning efficiency. Notably, the framework achieves competitive or superior performance even when using models that can be deployed on consumer-grade GPUs, highlighting its practical value for scalable, accessible autonomous agent design. Future directions include exploring theoretical underpinnings of diversity-driven planning, extending to multimodal agents, and reducing reliance on manually set hyperparameters.



% \section*{References}
\bibliographystyle{plainnat}
\bibliography{reference}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\newpage
\appendix

\input{appendix}

\input{checklist}


\end{document}