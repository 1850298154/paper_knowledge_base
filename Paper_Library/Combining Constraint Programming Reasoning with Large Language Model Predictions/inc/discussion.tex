
\section{Discussion \& Perspectives}
\label{sec:discussion}

\subsection{GPU and CPU Interplay}

The article shares a proof-of-concept showing that interesting results can be obtained using CPU resources combined with a small quantized LLM in a CP solver.
However, LLMs, in general, work best with much larger computational resources and require GPU resources.
Even though smaller models (e.g., Mistral 8x7B) sometimes manage to take top places in specific scenarios. The top spots in the LLM Elo rankings feature gigantic models \cite{chiang2024chatbot}. Given their size, clusters of GPU are quickly mandatory. 
Hence, it would be interesting to study in more detail how the joint use of resources (for instance, CPU for solver and GPU for LLM) could improve the results of the paper and correspond to more real-world usage in industry.


\subsection{Token Management}

In this article, GenCP ignores tokens and works at the word level (pre-token). 
It is possible to handle tokens by adapting the problem modeling. Indeed, it is possible to consider a word as a meta-variable $X_1$ composed of several decision variables (e.g., $X_{1_1}$, $X_{1_2}$, $X_{1_3}$...). This is useful and straightforward, as it is not clear in advance how the tokenizer will cut the words.
For instance, let us consider the following sentence: \emph{The first step in the recruitment of a new hire is to make sure that the job requisition is clear}.
Let us look at the assignments of the variables (space separates meta-variables, and semicolon decision variables): \emph{The; first; step; in; the; rec;ruit;ment; of; a; new; h;ire; is; to; make; sure; that; the; job; requ;is;ition; is; clear;}. The word \emph{recruitment} needs three decision variables because it is composed of three tokens (i.e., \emph{rec, ruit} and \emph{ment}).
It is easy to manage in GenCP because it can generate as many variables as required. Nevertheless, the evolution of the CSP (generation of variables and domains) is rather technical and, therefore, depends on the tokenizer.


\subsection{CSP Modeling}

The idea that a CSP can evolve in response to external information is not new (e.g., Dynamic Constraint Network \cite{dechter-dechter:88dcn}). This dynamic vision of CSPs has been motivated by several real-world problems, particularly in product configuration \cite{junker2006handbook}. GenCP proposes ML integration in modeling by letting LLMs manage operations for CSP domains during the resolution process. The "outside the world" information \cite{bessiere:91acindynamiccsp} is given by the LLM. The article shows that LLMs can contribute to CSP modeling for generation tasks. However, how ML/LLMs can be used for CSP modeling in general for any problem remains an open problem \cite{Freuder_2024,lawless2024iwantwayenabling,tsouros2023holygrail20natural,serdarkadioglu:2023ner}.

