\section{Introduction}
\label{sec:intro}

Human pose estimation, which aims at identifying anatomical keypoints (\textit{e.g.}, elbow, knee, etc.)  of human bodies from images or videos, has been extensively studied in the computer vision community~\cite{TokenPose_CVPR2023,CID_cvpr2022,Vitpose_NIPS2022,HRFormer_NIPS2021}. It plays a crucial role in a variety of human-centric tasks, including motion capture, activity analysis, surveillance, and human-robot interaction~\cite{PoseFormer_ICCV2021}. Recently, significant progress has been made in the field of human pose estimation, particularly with the advent of deep convolutional neural networks (CNNs)~\cite{Resnet_cvpr2016,HRNet_CVPR2019,mobilenetv2_cvpr2018} and Transformer networks~\cite{Attention_NIPS2017,ViT_2021}. 
While the majority of recent methods focus on estimating human poses in \textit{static images}, it has been demonstrated in~\cite{PoseWarper_NIPS2019,DCPose_CVPR2021,TDMI_CVPR2023,} that the significance of \textit{dynamic cues} (\textit{i.e.}, temporal dependency and geometric consistency) across video frames cannot be overlooked. To address inherent challenges in human motion images, such as motion blur, video defocus, and pose occlusions, it is essential to sufficiently exploit the temporal cues in video sequences.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{demo.jpg}
    \caption{(a) Compared to our proposed video-based regression method, previous image-based regression methods of RLE~\cite{RLE_ICCV2021} and Poseur~\cite{Poseur_ECCV2022} have a substantial performance decline when processing video input,\textit{ e.g.}, the dataset of PoseTrack2017~\cite{PoseTrack2017_CVPR2017}. (b) Despite the intrinsic spatial correlations among human body joints, each joint exhibits independent motion trajectories temporally. }
    \label{fig:demo}
    \vspace{-5mm}
\end{figure}

Existing methods of human pose estimation can be divided into two categories: heatmap-based~\cite{Vitpose_NIPS2022,HRNet_CVPR2019,HRFormer_NIPS2021,CID_cvpr2022,FirstHeatmap_NIPS2014,SimplePose_ECCV2018,TokenPose_CVPR2023,DCPose_CVPR2021}, and regression-based~\cite{FirstRegression_CVPR2014,RLE_ICCV2021,Poseur_ECCV2022,Distilpose_CVPR2023,PRTR_CVPR2021}. Heatmap-based methods generate a likelihood
heatmap for each joint, whereas regression-based methods directly map the input to the output joint coordinates.
Owing to their superior performance, heatmap-based methods dominate in the field of human pose estimation, particularly among video-based approaches~\cite{PoseWarper_NIPS2019,DCPose_CVPR2021,OTPose_SMC2022,TDMI_CVPR2023}. The high computation and storage requirements of heatmap-based methods, however, make them expensive in 3D contexts (temporal), which restricts their versatility and real-time deployment in video applications, especially on edge devices. On the other hand, regression-based methods are more flexible and efficient. According to~\cite{RLE_ICCV2021}, while a standard heatmap head (3 deconv layers) costs $1.4\times$ FLOPs of the ResNet-50 backbone, the regression head only costs 1/20000 FLOPs of the same backbone. Moreover, recent regression-based approaches~\cite{RLE_ICCV2021,Poseur_ECCV2022} have demonstrated outstanding performance that is on par with heatmap-based methods.
Unfortunately, these regression-based approaches are all built for static images and neglect the temporal dependency between video frames, leading to a marked decline in performance when handling video input, as shown in Fig.~\ref{fig:demo}(a).

In this work, we explore the video-based human pose regression to facilitate multi-person pose estimation in video sequences. Regression-based approaches primarily focus on regressing the coordinates of pose joints, often overlooking the rich structural information inherent in the pose~\cite{CompositionalPose_ICCV2017}. As demonstrated in~~\cite{Poseur_ECCV2022}, the self-attention module employed in the Transformer architecture~\cite{Attention_NIPS2017} can be used across the pose joints to naturally capture their spatial dependency. A simple and direct extension is to use the self-attention module across all the joints from consecutive video frames to capture both the structural information of the pose and its temporal dependency in video sequences. 
However, as illustrated in Fig.~\ref{fig:demo}(b), while there's an inherent spatial correlation between adjacent joints of the human pose, the temporal trajectory of each joint tends to be rather independent. This implies that the spatial structure of the pose and its temporal dynamics across video frames cannot be conflated and must be captured separately.

To this end, we propose a novel and effective video-based human pose regression method, named Decoupled Space-Time Aggregation (DSTA), that
models the spatial structure between adjacent joints and the temporal dynamic of each individual joint separately, thereby avoiding the conflation of spatiotemporal information. Rather than using the output feature maps of a CNN backbone to regress the joints' coordinates as in existing regression models~\cite{RLE_ICCV2021,Poseur_ECCV2022}, DSTA converts the backbone's output into a sequence of tokens, with each token uniquely representing a joint.
Intuitively, each token embodies the feature embedding of its corresponding joint; therefore, it is natural to use them to model the spatiotemporal dependencies of pose joints. Specifically, DSTA first establishes the feature token for each joint via Joint-centric Feature Decoder (JFD)
module, which are hence used to capture the spatiotemporal relations of pose joints in the Space-Time Decoupling (STD) module. To efficiently and flexibly model the spatial dependency between adjacent joints and the temporal dependency of each joint itself, we introduce a joint-wise local-awareness attention mechanism to ensure each joint only attends to those joints that are structurally or temporally relevant. The aggregated spatial and temporal information is utilized to determine the coordinates of the joints. During training, the JFD and STD modules are optimized simultaneously, with the entire model undergoing end-to-end training.

To the best of our knowledge, this is an original effort on regression-based framework for multi-person pose estimation in video sequences.
We evaluate our method through the widely-utilized 
video-based benchmarks for human pose estimation: PoseTrack datasets~\cite{PoseTrack2017_CVPR2017,PoseTrack2018_CVPR2018,PoseTrack21_CVPR2022}.
%across three prominent video-based pose estimation datasets, including PoseTrack2017~\cite{PoseTrack2017_CVPR2017}, PoseTrack2018~\cite{PoseTrack2018_CVPR2018}, and PoseTrack21~\cite{PoseTrack21_CVPR2022}. %, and HiEve~$\diamond$. 
With a simple yet effective architecture,
DSTA achieves a notable improvement of \textbf{8.9}
mAP over previous regression-based methods tailored for static images and obtains superior performance to the heatmap-based methods for video sequences. Moreover, it offers greater efficiency of computation and storage than heatmap-based multi-frame human pose estimation methods, making it more suitable for real-time video applications and easier to deploy, particularly on edge devices.
For instance, utilizing the HRNet-W48 backbone, our regression-based DSTA achieves \textbf{83.4} mAP on the PoseTrack2017~\cite{PoseTrack2017_CVPR2017} dataset with a head computation of merely \textbf{0.02} GFLOPs, while heatmap-based DCPose~\cite{DCPose_CVPR2021} attains 82.8 mAP on the same dataset with a significantly higher head computation of 11.0 GFLOPs.

%outperforms the heatmap-based method DCPosePoseWarper~\cite{PoseWarper_NIPS2019} by $\diamond$ AP on the PoseTrack2017 dataset, while utilizing \textcolor{red}{$49\%$} fewer FLOPs.

%The FLOPs of 564
%our regression-based head are an almost negligible 1/7835 565
%or 1/550 of those heatmap-based heads.

%making it more suitable for real-time video applications and easier to deploy, particularly on edge devices.
%Specifically,
%on the PoseTrack2017 dataset, our regression-based model with ResNet-50 backbone achieves $\diamond$ mAP with
%4.0 GFLOPs per frame, whereas the heatmap-based PoseWarper~\cite{PoseWarper_NIPS2019} with SimplePose~\cite{SimplePose_ECCV2018} as its backbone achieves $\diamond$ mAP with $\diamond$ GFLOPs per frame. 

Our main contributions can be summarized as follows: 
\begin{itemize}
    \item We propose \textbf{DSTA}, a novel and effective video-based human pose regression framework. The proposed method efficiently and flexibly models the spatiotemporal dependencies of pose joints in the video sequences.
    \item  Our method is the first regression-based method for multi-frame human pose estimation. Compared to heatmap-based methods, our method is efficient and flexible, opening up new possibilities for real-time video applications.
    \item We demonstrate the effectiveness of our approach with extensive experiments. Our method not only delivers a marked improvement over prior regression-based methods designed for static images, but also achieves performance superior to the heatmap-based methods.
\end{itemize}

%-------------------------------------------------------------------------










