\section{Networking Middleware for Information Freshness}\label{sec.Middleware}

%% Óutline in comments

%\igor{In this section, we discuss the design principles of the middleware. In particular, AoI, LIFO queueing, Max-Weight, and Dynamic Weights. Then, we describe the basic functions and information flow in Fig.~\ref{fig.overview}. In the next section, we will discuss the design and implementation of WiSwarm which is an instantiation of the networking middleware for an object tracking application.}
\begin{figure}
	%\captionsetup{justification=centering}
	\centering
	\includegraphics[width=\linewidth]{Images/overview_drones_v2.png}
	%\vspace{-0.4cm}
	\caption{AoI-based application layer Networking Middleware.}% that provides information freshness for applications with a team of followers and a single leader.}%\igor{Add sections, store data at queue, and time-stamp.}}
	\label{fig.overview}
	%\vspace{-0.4cm}
\end{figure}

%In this section, we formally define the Age-of-Information metric and discuss the design principles of the networking middleware. Figure~\ref{fig.overview} provides an overview of its architecture, which is motivated by the need for information freshness in large-scale time-sensitive applications. %The networking middleware is designed to enable standard WiFi networks to support large-scale applications that rely on a team of agents, called followers, collecting and transmitting time-sensitive information to a central compute controller which is responsible for centralized computation and coordination among the team. In this important class of applications, it is imperative to keep the leader as updated as possible, since outdated information loses its value and can lead to poor control and coordination. To achieve this design goal, the key idea is to dynamically control the flow of information in the WiFi network in order to: (i) avoid network congestion and packet collisions; (ii) prioritize transmissions from the most relevant followers/sources; and (iii) at each source, prioritize the transmission of the most relevant pieces of information. 

%In this section, we describe the networking middleware 
In this section, we describe a networking middleware (illustrated in Fig.~\ref{fig.overview}) that customizes WiFi to the needs of the important and broad class of time-sensitive applications that rely on multi-agent systems. In these applications, agents (also called followers) collect and transmit time-sensitive information to a central compute node (also called the leader). 
%composed of multiple agents, called \emph{followers}, and a central compute node, called \emph{leader}. Each follower collects and transmits time-sensitive information to the leader. 
The leader consolidates the received information and coordinates the followers' behavior in a timely manner. Naturally, it is critical to keep information in the network as fresh as possible. 
%
%Figure~\ref{fig.overview} provides an overview of the middleware architecture, which is motivated by the need for information freshness. 
We formally define the Age-of-Information metric in Sec.~\ref{sec.AoI}. In Sec.~\ref{sec.MiddlewareDesign}, we describe the middleware design based on the considerations in Secs.~\ref{sec.AoI}, \ref{sec.Queueing}, and~\ref{sec.Scheduler}.

%To customize WiFi to the needs of the application, we propose a middleware that can control the storage and flow of information in the WiFi network in order to: (i) avoid network congestion and packet collisions; (ii) prioritize transmissions from the most relevant followers, taking into account both information freshness and application-defined priorities; and (iii) within each follower, eliminate packets that are no longer useful to the application and prioritize transmissions of the most relevant packets. Figure~\ref{fig.overview} provides an overview of the middleware's architecture.

% %In this section, we discuss the design principles of the middleware. Figure~\ref{fig.overview} provides an overview of its architecture. %, which is motivated by the need for information freshness in large-scale time-sensitive applications. 
% The networking middleware is designed to enable standard WiFi networks to support large-scale time-sensitive applications that rely on multi-agent systems composed of \emph{several followers} and a central compute node, called \emph{leader}. Each follower collects and transmits time-sensitive information to the leader. The leader consolidates the received information and coordinates the followers' behavior in a timely manner. 
% Naturally, in this important class of time-sensitive applications, it is critical to keep the information as fresh as possible. %leader as updated as possible, since outdated information loses its value and can lead to poor control and coordination. 
% To achieve this goal, we propose a programmable middleware that can control the storage and flow of information in the WiFi network in order to: (i) avoid network congestion and packet collisions; (ii) prioritize transmissions from the most relevant followers, taking into account both information freshness and application-defined priorities; and (iii) within each follower, eliminate packets that are no longer useful to the application and prioritize transmissions of the most relevant packets. Figure~\ref{fig.overview} provides an overview of the middleware's architecture.

%Specifically, to avoid network congestion that can lead to excessive packet collisions in the WiFi network, the middleware drives the CSMA-based network to behave like a \emph{polling-based network}. To dynamically prioritize the most relevant followers, the middleware employs an \emph{application-centric transmission scheduler}. This scheduler uses Age-of-Information (a metric that measures information freshness) and application specific scheduling weights that describe the relative importance of each follower to design an efficient scheduling policy. We formally define the Age-of-Information metric in Section~\ref{sec.AoI} and discuss the scheduler in detail in Section~\ref{sec.Scheduler}. Finally, to prioritize what information to transmit from each follower, we eliminate stale pieces of information before they are ever transmitted. Our middleware achieves this by employing a tail drop information queue with an \emph{application-centric queueing discipline} (typically Last-In-First-Out). An important feature of our networking middleware is that it controls the information flow in the network from the application layer, without requiring modifications to lower layers of the networking protocol stack.

%Prior to delving into the details of the design of the networking middleware for information freshness,
%We present in Section~\ref{sec.AoI} the definition and intuition behind the Age-of-Information metric. Then, in Sec.~\ref{sec.Queueing} we discuss the queueing discipline employed at the followers/sources. Next, in Sec.~\ref{sec.Scheduler}, we discuss the application-centric transmission scheduler that runs at the leader/controller. Finally, in Sec.~\ref{sec.MiddlewareDesign}, we provide an overview of the middleware design, describing its basic functions and the flow of information over the WiFi network.

\subsection{Age-of-Information Metric}
\label{sec.AoI}
\begin{figure}
	%\captionsetup{justification=centering}
	\centering
	\includegraphics[width=0.95\linewidth]{Images/AoI_continuous.png}
	%\vspace{-0.4cm}
	\caption{AoI evolution.} %The first update is generated at the source at time $t_1$ and is delivered to the destination at time $t'_1$. The destination now has information about the source that is $t'_1 - t_1$ old, so AoI drops to $A(t'_1) = t'_1 - t_1$.} %The second update is generated at time $t_2$ and delivered at $t'_2$. So, $A(t)$ increases linearly until time $t'_2$ and then drops to $A(t'_2) = t'_2 - t_2$.}
	\label{fig.AoI}
	%\vspace{-0.5cm}
\end{figure}
%\igor{outline in comments}
%\igor{Introduce the concept of Age-of-Information (continuous time) and the “Network Age-of-Information”. Connect Network Age-of-Information to monitoring objects on the ground. High Network Age-of-Information translates to stale information at the leader which results in outdated trajectory updates at the followers. Minimizing Network Age-of-Information yields good automated object tracking. Discuss AoI literature. Few system papers. No real-world applications. Here we are using AoI-based design to improve feedback control. Define time stamp. Define Age of Information. Discuss the intuition. Define Time-Average Age-of-Information. Relate Time-Average Age-of-Information and position uncertainty by giving one concrete example that can build intuition. Discuss that each AoI is associated with one type of information.}

AoI is an end-to-end metric that characterizes \emph{how old the information is from the perspective of the destination} \cite{kaul2012real}. Consider a multi-agent system in which updates from followers are time-stamped upon generation. Let $\tau_i(t)$ be the \emph{largest time-stamp} of an update from follower~$i$ received by the leader by time~$t$. The AoI associated with follower~$i$ is defined as $A_i(t):=t-\tau_i(t)$. The AoI increases linearly with time when no updates are delivered, representing the information getting older. At the moment a \emph{fresher} update from follower~$i$ is received by the leader, the value of $\tau_i(t)$ increases and the AoI reduces to the delay of the received update. This evolution of the AoI metric with time is illustrated in Fig.~\ref{fig.AoI}. 

%\textbf{Illustrative example:} Consider the mobility tracking application described in Sec.~\ref{sec.Intro}. If the AoI associated with the last known position of a moving object is $A(t)=1.5$\thinspace{seconds}, this means that the object has been moving around for $1.5$\thinspace{seconds} without the leader knowing about it. Clearly, a larger AoI corresponds to the leader having a higher uncertainty about the current position of the object. Similarly, a larger average object velocity also corresponds to the leader having a higher position uncertainty. Therefore, to support mobility tracking applications, the underlying communication network should strive to keep the AoI associated with the position of every moving object as low as possible, further prioritizing objects with higher velocities. The networking middleware proposed in this work allows for the design of resource allocation mechanisms based on AoI and estimated velocities, as described in Secs.~\ref{sec.Scheduler} and \ref{sec.LeaderNode}.

%AoI has been receiving increasing attention in the literature for its application in communication systems that carry time-sensitive data such as position, command and control, or sensor information. In recent years, several theory-oriented papers have analyzed AoI in queuing systems \cite{kaul2012real, kam2013age, huang2015optimizing, inoue2018general, yin17_tit_update_or_wait, bedewy2019minimizing, AoI_management} and proposed novel network control mechanisms \cite{kadota2018scheduling2, tripathi2017age, talak2018optimizing, jhun2018age, farazi2018age, tripathi2019whittle, tripathi2021online} that could potentially be leveraged in real-world applications. A related line of work has looked at AoI as a metric for monitoring and control over networks \cite{sun2017remote,ornee2019sampling, champati2019performance, klugel2019aoi}. However, as we discuss in Sec.~\ref{sec.RelatedWork}, only a few \cite{AoI_measure_1,AoI_measure_3,kadota2021age,kadota2021wifresh,shreedhar2018acp,AoI_Wierman,AoI_SDR,ayan2021experimental} have considered system implementations. 

Over the past decade there has been a rapidly growing body of works analyzing AoI in different contexts (see surveys in \cite{yates2021age,kosta2017age,sun2019age_book}). Several theory-oriented papers have analyzed AoI in queuing systems \cite{kaul2012real, kam2013age, huang2015optimizing, inoue2018general, yin17_tit_update_or_wait, bedewy2019minimizing} and proposed novel network control mechanisms \cite{kadota2018scheduling2, talak2018optimizing, maatouk2020optimality, tripathi2019whittle, tripathi2021online,jhun2018age,farazi2018age} that could potentially be leveraged in real-world applications. %A related line of work has looked at AoI as a metric for monitoring and control over networks \cite{sun2017remote,ornee2019sampling, champati2019performance, klugel2019aoi}. 

More recently, a few works \cite{AoI_measure_1,AoI_measure_3,shreedhar2018acp,AoI_Wierman,AoI_SDR,ayan2021experimental,kadota2021age,kadota2021wifresh} have considered system implementations. These system-oriented works can be separated into two categories: (i) measurement of AoI in real networks %using devices connected via Ethernet, WiFi, or LTE
\cite{AoI_measure_1,AoI_measure_3}; and (ii) evaluation of communication networks that attempt to minimize AoI by looking at congestion control \cite{shreedhar2018acp}, traffic engineering \cite{AoI_Wierman}, and medium access using Software Defined Radios (SDRs) \cite{ayan2021experimental,kadota2021age,kadota2021wifresh,AoI_SDR}. However, there has been no prior work on the experimental evaluation of the impact of an AoI-based networking solution in a real-world time-sensitive application, which is the focus of this work.
%there has been no prior work on minimizing AoI at the application layer or making readily deployable systems for real applications. 
%\textbf{To the best of our knowledge, this is the first work to (i) develop an AoI-based solution that can be easily deployed on standard WiFi networks and (ii) to evaluate its performance using a real-world time-sensitive application.}

%\igor{Add example from mobility tracking?}
%An important feature of the AoI metric is that it captures the freshness of information from the perspective of the application, in contrast to the long-established packet delay metric, that represents the freshness of the information with respect to individual packets. AoI effectively tries to represents a measure of distortion between the state of the source that is expected at the destination based on past updates and the actual current state of the source. Thus, a larger AoI corresponds to the monitor having a higher uncertainty about the current state of the source being observed. This, in turn, means that ensuring a low average AoI can lead to higher monitoring accuracy and better control performance.
%\autoref{fig.AoI} shows how AoI evolves for an example update generation and delivery process. Consider the first update that is generated at the source at time $t_1$. At the instant that this update is generated, it is ``fresh". This update is eventually delivered to the destination at time $t'_1$. At the time of delivery, the destination now has information about the source that is $t'_1 - t_1$ old, so AoI drops to $A(t'_1) = t'_1 - t_1$. The second update is generated at time $t_2$ and delivered at $t'_2$. So, AoI $A(t)$ increases linearly up till time $t'_2$ and then drops to $A(t'_2) = t'_2 - t_2$. This evolution leads to the saw-tooth style plot depicted in \autoref{fig.AoI}.  

%An interesting feature of the AoI metric is that it captures the freshness of information from the perspective of the application, in contrast to the long-established packet delay metric, that represents the freshness of the information with respect to individual packets. AoI effectively tries to represents a measure of distortion between the state of the source that is expected at the destination based on past updates and the actual current state of the source. Thus, a larger AoI corresponds to the monitor having a higher uncertainty about the current state of the source being observed. This, in turn, means that ensuring a low average AoI can lead to higher monitoring accuracy and better control performance.

%In particular, AoI measures the time elapsed since the generation of the packet that was most recently delivered to the destination, while packet delay measures the time elapsed from the generation of a packet to its delivery.

%For the setting of our interest, there are $N$ followers sending status updates to the central leader, which in turn, performs control and coordination. The process $A_i(t)$ denotes the AoI of the $i^{th}$ follower at the central node. The followers send updates over a shared wireless channel, thus requiring scheduling to prevent collisions and deliver fresh information. \color{blue} Mention AoI scheduling literatures

%\color{blue} \textit{Vishrant: move WiFresh discussion to sec 6.}\color{black} %For example, the authors of \cite{} proposed a MAC layer architecture based on Polling Multiple Access mechanism and Last-Come First-Served queues, implemented this architecture in a Software Defined Radio testbed, and showed that it achieves near optimal information freshness.\color{black}

\subsection{Customizable Queueing at the Followers}\label{sec.Queueing}
%\igor{Discuss the effect of queueing discipline on the AoI. FIFO versus LIFO. Effect of dropping packets. Discuss issues with fragmentation: (i) AoI reduction when a subset of fragments is received and (ii) fragmentation and LIFO that replaces packets while transmitting their fragments. An implementation of fragmentation will be discussed in Sec.~\ref{sec.MiddlewareDesign}]. Recall that the queue is implemented at the Application layer. Hence, it is easy to implement queueing disciplines tailored to the specific application.}
Data generation and queueing have significant impact on information freshness. The \emph{follower middleware} architecture illustrated on the left in Fig.~\ref{fig.overview} receives updates at rates that are determined by sensors/applications, then it time-stamps and enqueues these updates. Upon receiving a polling request from the leader, the follower middleware releases a \emph{single} update via UDP/IP to lower layers of the network protocol stack. Our middleware incorporates two key ideas from the AoI literature to enable information freshness - a mechanism to control the update generation rate, and an implementation of Last-In First-Out (LIFO) queues.  %allows the system designer to employ different queueing disciplines and rate control to store/drop/prioritize updates depending on the application. %Next, we discuss potential queueing disciplines and their impact on information freshness. 

%Two important factors that control the AoI and consequently information freshness are the rate at which a source generates updates and the queuing discipline employed in sending these updates. 
First-In First-Out (FIFO) queues are the default queuing implementation in most communication networks. %Consider a middleware implementation utilizing FIFO queues to store information updates at the followers before transmitting them to the leader.
However, to manage AoI, they require careful control of the arrival rate. If updates are generated at a low rate, then the information updates are too infrequent. On the other hand, if updates are generated at a very high rate, then the FIFO queue will often be backlogged and fresh updates will have to face large queueing delays. To address this problem, we implement a rate control mechanism at the followers that can be used when applications use FIFO queues.
%This queueing delay leads to outdated information and, thus, high AoI. When FIFO queues are employed, it is imperative that the generation rate is carefully controlled to minimize AoI. 

\textbf{Rate Control}: To adjust the update generation rate, the rate control mechanism %that selectively discards updates. 
only updates its queue at fixed intervals of time, dropping any updates generated in between. This mechanism ensures that the middleware only accepts new updates at the desired rate. 
Note that finding the optimal generation rate for a given network setup is a nontrivial task, as the optimal rate depends on the network's topology, traffic load, link reliability, and Medium Access Control (MAC) mechanism. To illustrate the impact of the generation rate on information freshness, we plot in Fig.~\ref{fig.plot_wifi_1}(a)  the AoI of a standard WiFi system (that uses FIFO queues at the MAC layer) with different update generation rates, including the optimal rate which is obtained by grid search.  

%Thus, for FIFO queues, the followers need to carefully select their update generation rate to keep information fresh at the destination. For example, in a FIFO M/M/1 queue: to minimize queuing delay, the rate must be as small as possible (close to zero) while to optimize throughput the rate must be as close to the service rate of the queue $\mu$. On the other hand, to minimize AoI, the optimal generation rate turns out to be approximately $0.53\mu$ where $\mu$ is the service rate of the queue \cite{kaul2012real}. 

%Consider a source utilizing a FIFO queue to store generated updates before transmitting them. Very low generation rates would mean too few update deliveries to the destination leading to high inter-update times and high AoI, while very high generation rates would mean excessive queuing leading to large delays and high AoI. Thus, for FIFO queues, the sources need to carefully select their update generation rate to keep information fresh at the destination. For example, in a FIFO M/M/1 queue: to minimize queuing delay, the rate must be as small as possible (close to zero) while to optimize throughput the rate must be as close to the service rate of the queue $\mu$. On the other hand, to minimize AoI, the optimal generation rate turns out to be approximately $0.53\mu$ where $\mu$ is the service rate of the queue \cite{kaul2012real}. 

%Note that high generation rates in networks with many sources will also lead to frequent packet collisions and congestion making performance even worse, which further highlights the need for rate control. Our framework allows the application designer to specify rates of generation and queueing discipline for each source to control information freshness and reduce congestion in the network.

%Last-In First-Out (LIFO) queues transmit the most recently generated packet first, making them ideal for applications that rely on the knowledge of the \emph{current state} of the system, such as mobility tracking. LIFO queues were shown to be \emph{optimal} for minimizing AoI in a wide variety of network settings \cite{bedewy2019minimizing}. However, LIFO queues are rarely implemented at the transport, MAC, or physical layers in practice. Consider a follower middleware utilizing a LIFO queue. If updates are generated at a high rate, the LIFO queue would frequently replace its head-of-line packet with fresh packets. It follows that, the higher the update generation rate at the followers, the fresher the information received by the leader and, thus, the lower the AoI. For this reason, LIFO queues eliminate the need for adjusting the update generation rate.

\textbf{LIFO Queues:} Last-In First-Out (LIFO) queues transmit the most recently generated update first, making them ideal for applications that rely on the knowledge of the \emph{current state} of the system, such as mobility tracking. When an update is generated, the LIFO queue simply replaces the old head-of-line update with the fresh update. %whenever they arrive. 
A higher update generation rate at the followers can only lead to fresher updates at  the leader and, hence, a lower AoI. %For this reason, LIFO queues eliminate the need for adjusting the update generation rate. 
LIFO queues have been shown to be \emph{optimal} for minimizing AoI in a wide variety of network settings \cite{bedewy2019minimizing,AoI_management}. However, LIFO queues are rarely implemented at the transport, MAC, or physical layers in practice. Our middleware supports both FIFO and LIFO queues at the application layer, while also supporting rate control, providing the system designer with two important tools to manage AoI. %For example, encoded video that needs packets to be delivered sequentially can be stored in FIFO queues with appropriate rate control, while raw video frames that don't need sequential updates can be stored in a LIFO queues with the highest update rates.

%In general, delivering \emph{older} information updates to the leader after a \emph{fresher} update was successfully received does not improve information freshness. Hence, discarding older updates when a fresh update arrives at the follower middleware %i.e. before the older update is ever transmitted, 
%could save network resources, alleviating congestion. On the other hand, older information may still be useful to the application. For example, in a mobility tracking application, older position information can be useful in predicting future movement. This trade-off should be considered by the system designer when deciding whether or not to discard older updates at the follower middleware.

%The follower middleware receives updates from different sensors/applications and enqueues them according to the rules set forth by the system designer. Specifically, the system designer can choose between different queueing disciplines, e.g., LIFO, FIFO, Priority Queueing, and Fair Queueing, and set the rate at which this queue accepts new updates from the application. %Moreover, the designer can choose to implement different strategies for updates from different sensors/applications. 
%For example, encoded video that needs frames to be delivered sequentially can be stored in a FIFO queue, while raw video frames can be stored in a LIFO queue that keeps only the freshest update. 

%For applications where consecutive updates cannot be dropped easily such as encoded video data, FIFO queues can be used with appropriately chosen generation rates. In applications involving transmission of event-triggered data or safety information, a priority queue with appropriately chosen priorities for events can be implemented.

%It is also well known in the AoI community that the pre-emptive Last-Come-First-Serve queuing discipline is \textit{optimal} for minimizing AoI in general networks \cite{bedewy2019minimizing}. However, LIFO queues are rarely implemented at the transport or MAC layers in practice. So, our framework allows the application designer to choose between three different queueing discplines at the application layer - FIFO, LIFO and priority queues. We also allow control of the buffer size of the queues. We avoid implementing pre-emption since that would involve stopping a transmission that has already started at the lower layers, which is not feasible due to signaling overheads. \igor{Perhaps, most importantly, it would envolve changing lower layers of the networkiung protocol stack.} Thus, for applications in which older updates can be dropped for newer updates, \textit{the choice of LIFO queues with a single update buffer ensures the best performance}. This is because whenever a newer update arrives, it replaces an older buffered update if there was one waiting, without interrupting the current update being transmitted. For applications where consecutive updates cannot be dropped easily such as encoded video data, FIFO queues can be used with appropriately chosen generation rates. In applications involving transmission of event-triggered data or safety information, a priority queue with appropriately chosen priorities for events can be implemented.



%\color{red} Vishrant: \textit{maybe avoid discussion on fragments here} and keep it to 3.4. cite paper - pre-emptive LCFS minimizes AoI. Possibly also discuss application layer control of the rate at which sources send updates to the queue. In case of applications which must have FIFO + WiFi, rate optimization becomes crucial to control congestion.\color{black}

%\igor{Great point, Vishrant!}
%\vspace{-0.1cm}
\subsection{Customizable Transmission Scheduling at the Leader}\label{sec.Scheduler}

%Consider a time-sensitive multi-agent system with several followers and a leader. % while the leader coordinates the followers' behavior by transmitting control updates in a timely manner.
The multiple access mechanism controls the method by which followers and leader share information using the limited communication resources. WiFi employs a distributed random access mechanism that works well for small-scale underloaded networks. However, for large-scale congested networks, it leads to excess packet collisions that in turn lead to lower throughput and higher latency, and ultimately poor performance for real-time applications.%which can result in degraded information freshness.

%One approach to reducing congestion and packet drops is to implement congestion control at the application \cite{kadota2021age} or transport layers \cite{shreedhar2018acp}. However, these approaches do not address the issue of medium access. Distributed congestion control cannot eliminate packet collisions at the MAC layer, which are a major cause of high latency and poor scalability of 802.11 WiFi. Further, it is not trivial to find the optimum rate to generate information updates or to develop a scheme that adaptively finds the optimum operation point.  

We design the \emph{leader middleware}, illustrated on the right in Fig.~\ref{fig.overview}, to: (i) prevent packet collisions; (ii) enable dynamic prioritization of the transmissions that are most valuable to the application; and (iii) facilitate integration with existing multi-agent systems that use WiFi. %To achieve these goals, we propose the \emph{leader middleware} illustrated on the right in Fig.~\ref{fig.overview}.
The middleware drives the underlying distributed WiFi network to behave like a centralized network with support for polling. Specifically, the leader middleware coordinates the flow of information in the network by sending polling packets to the followers selected for transmission. At every decision time $t$, the leader selects the next follower to poll based on an application-centric \emph{transmission scheduling policy} $\pi$, which can be a function of the current AoI of the followers $A_i(t)$, the reliability of the WiFi links $p_i(t)$, where $p_i(t)\in(0,1]$ represents the probability of a successful transmission from follower $i$ to the leader, and the application-defined priority weights $w_i(t)\geq 0$, which represent the relative importance of each follower's information to the overall application goal. For example, in a mobility tracking application, the estimated velocities of the moving objects can be assigned as application weights $w_i(t)$, since faster objects may require more updates than slower objects in order to achieve the same tracking performance. 

%The approach that we take in this paper to address the issue of medium access is to implement a centralized scheduling scheme over WiFi. Specifically, our application-centric scheduler allows for the specification of priority weights $w_i$ for each follower $i$ in the network. These weights denote the relative importance of each follower's information to the overall application goal. For example, in a mobility tracking application, the priority weights can be the velocities of the objects being tracked: since faster objects need more updates than slower objects to get the same tracking performance. 

To capture application priorities and information freshness, we define the expected time-average of the weighted sum of AoIs across the entire network as
\begin{equation}\label{eq:AoI_opt}
\frac{1}{T} \mathbb{E} \left[ \sum_{i=1}^{N} \left(\int_{t=0}^{T} w_i(t)A_i(t) dt \right) \right] \; ,
\end{equation}
where $N$ is the number of followers, $T$ is the time-horizon, and the expectation is with respect to the randomness in the link's reliability $p_i(t)$ and the policy $\pi$. %To minimize \eqref{eq:AoI_opt}, the scheduling policy $\pi$ should attempt to improve information freshness, i.e. reduce $A_i(t)$, where the application needs it the most, i.e. where $w_i(t)$ is higher.
%
%Given the values of $\{A_i(t),p_i(t),w_i(t), \forall i \in [N]\}$, the goal of the transmission scheduling policy $\pi$ is to select followers $i$ that minimizes the expected time average of the weighted sum of AoIs across the entire network:
% \begin{equation}\label{eq:AoI_opt}
% \min_{\pi}~~~\frac{1}{T} \mathbb{E} \Bigg[ \sum_{i=1}^{N} \bigg(w_i \int_{t=0}^{T} A_i(t) dt \bigg) \Bigg].
% \end{equation}
%
% Plenty of theoretical work \cite{kadota2018scheduling, kadota2018scheduling2, tripathi2017age, talak2018optimizing, farazi2018age} has gone into studying the structure of scheduling policies that solve the optimization problem of the form described by \eqref{eq:AoI_opt} under interference constraints. The key result from these works is that given the scheduling weight $w_i$ and link reliability $p_i$ for each source $i$, a Whittle index style policy (described below) is near optimal for achieving information freshness. At every transmission opportunity, the Whittle index policy chooses the source that satisfies:
% \begin{equation}
%     \label{eq:AoI_whittle}
% 	i^{*} = \underset{i}{\operatorname{argmax}} \biggl\{ w_i p_i A^2_i(t) \biggr\}.
% \end{equation}

Many theoretical works \cite{kadota2018scheduling2, talak2018optimizing, maatouk2020optimality,tripathi2019whittle} have studied the structure of scheduling policies that attempt to minimize objective functions of the form \eqref{eq:AoI_opt}. A key take away from these works is that, given the knowledge of the application weights $w_i(t)$, link reliabilities $p_i(t)$, and information freshness $A_i(t)$ of every follower $i$, \emph{the Whittle's Index Policy is a near-optimal solution to the problem of minimizing} \eqref{eq:AoI_opt}. The \textbf{Whittle's Index Policy} selects, at every decision time $t$, the follower $i^*$ that satisfies
\begin{equation}
    \label{eq:AoI_whittle}
	%i^{*} \in \textstyle\operatorname{argmax}_{i\in\{1,\cdots,N\}} \left\{ w_i(t) p_i(t) A^2_i(t) \right\} \; ,
	i^{*} \in \textstyle\operatorname{argmax}_i \left\{ w_i(t) p_i(t) A^2_i(t) \right\} \; ,
\end{equation}
with ties being broken arbitrarily. 
%
Intuitively, the Whittle's Index Policy is polling the followers associated with high application weights, reliable WiFi links, and outdated information at the leader. %It is important to emphasize that the Whittle's Index Policy has low computational complexity. It only requires the computation in \eqref{eq:AoI_whittle} and estimates of $w_i(t)$, $p_i(t)$, and $A_i(t)$. Algorithms that estimate these parameters are described in Sec.~\ref{sec.MiddlewareDesign}. 

Recent works have developed similar Whittle's Index Policies to address generalizations of \eqref{eq:AoI_opt}. Specifically, \cite{tripathi2019whittle} addressed the problem of minimizing general non-decreasing cost functions of AoI, $f_i(A_i(t))$, as opposed to simply minimizing $A_i(t)$, and \cite{tripathi2021online} considered network settings with time-varying, unknown and even adversarial application weights $w_i(t)$. This suggests that Whittle's Index Policies are remarkably robust and can be applied to a wide variety of applications. Moreover, the Whittle's Index Policy has low computational complexity: it only requires solving the maximization in \eqref{eq:AoI_whittle} and computing estimates of $w_i(t)$, $p_i(t)$, and $A_i(t)$. %Algorithms that estimate these parameters are described in Sec.~\ref{sec.MiddlewareDesign}. 

%Recent works have further extended the performance guarantees for Whittle's Index Policies to (i) more general information freshness costs where the cost of AoI increases non-linearly \cite{tripathi2019whittle} and (ii) to settings with time-varying, unknown and even adversarial weights \cite{tripathi2021online}. This suggests that such index based policies are remarkably robust and can be applied to a wide variety of networked monitoring and control applications. 

%\autoref{eq:AoI_whittle} is pivotal to our application-centric transmission scheduler. It uses the relative importance of each follower (weights), the quality of connection to the leader (link reliabilities), and the information freshness at the leader (AoIs) to decide which follower currently has the most pressing or ``valuable'' update to be sent. Importantly, the centralized polling mechanism ensures that no two followers ever transmit at the same time, thus avoiding collisions between sources and removing a major cause of congestion and delay.
%Once the leader decides which follower to poll, it sends a polling packet to the corresponding follower and receives a new update (or a failed transmission). Once the application processes the new update and generates monitoring or control information, the scheduler decides which follower to poll next and the cycle repeats.

%Since the AoIs and weights are updated and maintained at the application layer, it makes it much easier to implement the transmission scheduler at the application layer as well, without worrying about cross-layer signaling and overheads. It also allows the scheduler to be easily tailored for different applications.

%Our middleware design allows for non-linear functions mapping AoI to a monitoring or control cost that can also be used to specify application specific latency requirements and design a scheduling policy. 


%Polling is performed using a Transmission Scheduling policy with dynamic weights and controls when each follower gets to transmit fresh updates to the leader. 

% \color{red} Vishrant: Discuss application specific weights and cost functions that describe the latency requirements of each source/follower. The specific parameters can be modified based on the application at hand. Convert the problem to an AoI scheduling problem and use the Whittle index solution. When weights and/or cost functions change with time, use an online adaptive scheme to update weights. Also keep track of channel reliabilities using polling acks and use for making scheduling decisions. Weights, probabilities, etc. are updated after reception of every complete information update.\color{black}

% \color{blue}
% %Igor: Describe multi-polling (V: better to discuss in 3.4). %We can also discuss functions of AoI (V: will confuse reader).%Recall that the Transmission Scheduler is implemented at the Application layer. Hence, it is easy to implement Transmission Schedulers with dynamic weights tailored to the specific application.
% \color{black}

\subsection{Middleware Design}\label{sec.MiddlewareDesign}


We describe the networking middleware illustrated in Fig.~\ref{fig.overview}, which incorporates both the application-centric queueing at the followers and transmission scheduling at the leader.
%
% %\igor{Describe the basic functions and information flow in Fig.~\ref{fig.overview}.}
% Now, we discuss the design of our middleware, which incorporates the two ideas introduced above: 1) application-centric queuing at the followers and 2) centralized application-centric transmission scheduling at the leader. %\color{blue}V: removed repeated line\color{black}
% % This design approach enables standard WiFi networks to support large-scale applications in which a team of followers collects and transmit time-sensitive information to a leader which coordinates the team. 

%First, we describe the role of the middleware at the followers: how information updates are fragmented, queued and transmitted in response to polling packets. Then we describe the role of the middleware at the leader: keeping track of AoI and scheduling weights, running the scheduler, sending polling packets and control information.

%\subsubsection{Followers} 

\textbf{Followers} collect information updates about their immediate environment (e.g., video, pictures, laser scans, and temperature) and about their own platforms (e.g., position, attitude, velocity, and battery level). These updates are sent to the \emph{follower middleware} to be prepared for transmission.

The rate control mechanism decides whether each update is discarded or enqueued. The follower middleware time-stamps each update that is not discarded at the time of collection and enqueues them. These time-stamps are used to compute $A_i(t)=t-\tau_i(t)$ at the leader upon delivery. %After time-stamping, updates are enqueued.
%We also provide a rate control mechanism that decides how often to send a newly collected update to the application-layer queue. 
The queuing discipline, update rates, and queue buffer sizes can be controlled by the middleware to satisfy the requirements of the application. %For example, in applications in which older updates can be dropped for newer updates, we set up the sources to have LIFO queues with  buffers that can accommodate only one update at a time.
%Our design allows the user to specify the queuing discipline at the application layer queue: FIFO, LIFO, or any other priority queue. The best choice of queueing discipline and queue size depend on the specific application and on the type of information. For example, ... 

%\textbf{Data fragmentation and transmission.} 
%Note that our communication architecture is polling based. 

When the follower receives a polling packet, %if its queue is empty, then it transmits an \emph{empty update} to the leader. The empty update is used by the leader to distinguish between not receiving an update due to WiFi transmission errors and not receiving an update due to an empty queue, which impacts the estimation of the reliability of the links $p_i(t)$. If the follower's queue is not empty, then 
it releases a single information update from its queue. Assuming that the update does not exceed the maximum length of the UDP payload (or any threshold set by the system designer), the released update can be simply forwarded via UDP/IP to lower layers of the networking protocol stack. However, if the update is too large, then the middleware divides the update into \emph{fragments}. %, which are used to implement acknowledgements and error control at the application layer, as well as to calculate estimates of channel reliabilities $p_i(t)$. 
%
Fragments are stored in a separate FIFO queue and then transmitted one-by-one to the leader. Each fragment is transmitted via UDP/IP over standard WiFi. Since the maximum WiFi frame length can be smaller than the UDP payload size, it is possible that WiFi will require multiple successful over-the-air transmissions to deliver a single fragment to the leader. If WiFi fails to deliver a fragment, the middleware attempts to re-transmit the fragment using an error-control mechanism based on acknowledgements at the fragment level.% until either successful delivery or when a timeout (of 300 milliseconds) is hit, stopping new polls from the leader. 

%When the polling packet acknowledging the final fragment is received, the follower's queue releases the next information update. 

%When a follower receives a polling packet from the leader, the follower's queue releases a single information update to be sent to the leader. Assuming that this information update fits into a single UDP packet, upon being released from the queue, the update can be simply forwarded to lower layers of the networking protocol stack. However, if the size of the information update exceeds the maximum length of the UDP payload (chosen based on the application), then upon being released from the application layer queue, our middleware \textit{fragments} the information update into separate UDP packets. These fragments are stored in a separate FIFO queue and then transmitted one-by-one to the leader until the entire update is sent. Our middleware also implements an acknowledgement mechanism at the fragment level. This allows the leader to keep track of link reliabilities for each follower. %Fragments are stored in a FIFO queue which is separate from the follower's queue containing information updates. 
%Upon receiving a packet acknowledging the previous fragment, the follower forwards the next fragment, until all fragments are successfully delivered to the leader. 
%When the polling packet acknowledging the final fragment is received, the follower's queue releases the next information update, which is then fragmented, stored in the FIFO queue and then transmitted following the same procedure. 

%If the follower's queue is empty when a polling packet arrives, the follower transmits a small \emph{empty packet} to the leader. The \emph{empty packet} is used by the leader to differentiate between not receiving data due to a transmission error or due to an empty queue, which impacts its estimate of the condition of the network. 

%Each fragment is transmitted to the leader via UDP/IP over standard WiFi. Since the maximum WiFi packet length can be smaller than the chosen UDP payload size, it is possible that WiFi will require multiple successful over-the-air transmissions to deliver a single fragment to the leader. 

%\subsubsection{Leader} 
%At the leader, our middleware implements the centralized application-centric transmission scheduler discussed in \autoref{sec.Scheduler}. 
%\textbf{Leader.} The leader is responsible for coordinating the followers' behavior and for controlling the information flow in the WiFi network. To do so, the leader controls the generation of polling packets. Since a new update is only transmitted upon reception of a polling packet from the leader, the leader has almost full control of the flow of information in the WiFi network.

\textbf{The Leader's} responsibilities include coordinating both the flow of information in the WiFi network and the followers' behavior. To do so, the leader manages the generation and transmission of \emph{polling packets} and \emph{control information}. Since follower's updates are transmitted only upon reception of a polling packet, the leader has almost full control of the flow of information in the WiFi network, irrespective of the number of followers and the amount of data they generate. %This control allows the leader to alleviate congestion and prevent excessive packet collisions in the WiFi network. 

%By transmitting control information to the followers, the leader can coordinate their 

%\igor{New scheduling decisions are made after each fragment or after each complete image?} 
The leader uses the Whittle's Index Policy \eqref{eq:AoI_whittle} to decide the next follower to poll. After transmitting a polling packet, the leader waits for the reception of a fragment. If this waiting period exceeds a timeout interval (e.g., $300$\thinspace{milliseconds}), the attempt is assumed to have failed. Upon receiving a fragment or after a timeout, the leader prepares for the transmission of the next polling packet.

Prior to transmitting the next polling packet, the leader takes a series of steps that depend on whether the received fragment was the final fragment of an information update or not. If the received fragment from follower $i$ was not the final one, then the leader middleware simply updates $p_i(t)$. On the other hand, if the received fragment was the final, then the leader: 
%Specifically, the reception of a fragment of an information update triggers the update of the AoI, link reliability, application weight, and control information. Upon receiving the final fragment, the leader should: 
(i) updates $p_i(t)$; (ii) combines fragments to obtain the original information update; (iii) extracts the associated time-stamp and updates $A_i(t)$; (iv) sends the information update to the application for processing; and (v) updates both $w_i(t)$ and the \emph{control information} based on the results of this processing.

%If the last fragment of an update was delivered in the previous polling cycle, the leader updates its application weights $w_i(t)$, its estimates of $p_i(t)$ and $A_i(t)$ accordingly. %The algorithms used to estimate $p_i(t)$ and $A_i(t)$ are described next. 
To estimate $p_i(t)$, the leader computes $\hat{p}_i(t)=D_i(t)/W,$ where $D_i(t)$ is the number of polling packets which received a successful response from follower $i$ out of the last $W$ polling packets sent to it. To accurately compute $A_i(t)=t-\tau_i(t)$, where $t$ is the current time measured by the leader and $\tau_i(t)$ is the largest time-stamp received from follower $i$, the clock at follower $i$ should be synchronized with the leader's clock. The middleware performs periodic clock synchronization across all followers and the leader, at every $120$ seconds using NTP \cite{NTP}. %Note that $A_i(t)$ is typically on the order of tens or hundreds of milliseconds. Thus the synchronization accuracy of NTP, which is around 1 millisecond for local area networks, is sufficient for our experiments. %a built-in algorithm based on the \emph{on-wire protocol} that is part of

% The reception of the final fragment of an information update triggers the update of the AoI, application weight, and control information. Upon receiving the final fragment, the leader should: (i) combine fragments to obtain the original information update; (ii) extract the associated time-stamp and update $A_i(t)$ accordingly; (iii) send the information update to the application for processing; and (iv) update both $w_i(t)$ and the control information based on the results of this processing. 
After performing the necessary updates, the leader middleware transmits a new polling packet to the selected follower. The latest control information is broadcast to all followers along with every polling packet. %This repeated broadcast ensures redundancy in the delivery of control information.% which is critical to multi-agent systems. 

%When the leader receives the final fragment, the middleware takes a series of steps. First, it combines all the received fragments to recreate the original information update. Then, it extracts the corresponding time-stamp and updates the AoI associated with the transmitting follower if all fragments are delivered without error. Finally, it sends the update to the application for processing. Based on the results of this processing, the application might set new scheduling weights and link reliabilities for the scheduler. Using this updated configuration, the middleware then runs the scheduler described in Sec.~\ref{sec.Scheduler} to generate a polling packet which contains the address of the follower that should respond with a new update next. It also appends the control information generated from processing to this polling packet, which is then broadcast to all followers.

%\igor{Importantly, the centralized polling mechanism ensures that no two followers ever transmit at the same time, thus avoiding collisions between sources and removing a major cause of congestion and delay.}
%\igor{empty packet}
%\igor{discuss multi-polling (depends on space)}
%\igor{clock sync}
%\igor{esitmation of p}
%\igor{transmit control packets}

%\textbf{Polling-based channel access.} To control the flow of information in the WiFi network, the leader controls the generation of polling packets. The Application-centric Transmission Scheduler determines the generation time and the destination of each polling packet. Since fragments are only transmitted upon reception of a polling packet from the leader, the leader has almost full control of the flow of information in the WiFi network.



%To demonstrate the performance improvement of our middleware in a real-world application, we 


% \igor{Draft of the leader part:}

% The reception of a fragment of an information update triggers the update of the AoI, link reliability, application weight, and control information. Upon receiving the final fragment, the leader middleware: (i) combines fragments to obtain the original information update; (ii) extracts the associated time-stamp and updates $A_i(t)$ accordingly; (iii) sends the information update to the application for processing; and (iv) update both $w_i(t)$ and the control information based on the results of this processing. %The latest control information is stored by the leader middleware. and broadcast to all followers right before every polling packet. The repeated broadcast ensures timely delivery of the latest control information which is critical to multi-agent systems. 

% To estimate $p_i(t)$, the leader computes $\hat{p}_i(t)=D_i(t)/W,$ where $D_i(t)$ is the number of polling packets which received a successful response from follower $i$ out of the last $W$ polling packets sent to it. To accurately compute $A_i(t)=t-\tau_i(t)$, where $t$ is the current time measured by the leader and $\tau_i(t)$ is the largest time-stamp received from follower $i$, the clock at follower $i$ should be synchronized with the leader's clock. The middleware performs periodic clock synchronization across all followers and the leader, at every $120$ seconds using NTP \cite{NTP}. Note that AoIs $A_i(t)$ are typically of the order of tens or hundreds of milliseconds. Thus the synchronization accuracy of NTP, which is around 1 millisecond for local area networks, is sufficient for our experiments.



