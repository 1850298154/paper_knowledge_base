% Consistency models play a crucial role for distributed systems in providing fault tolerance and consistent data for the system components. Strong consistency model guarantees to keep exactly same state of data at any time  by ensuring linearisability, atomic reads and writes and sequential ordering. However, it sacrifice the availability according to CAP theorem. In contrast, eventually consistent model offers the state of data will be same in some time in the future. In spite of high availability it provides, there is no guarantee for linear reads or writes which results in losing the ordering of requests, thus causes stale reads and unordered writes. This simply makes clients read different data at a certain time. Casual consistency model resides between them by ordering guarantees for dependent requests although it does not keep global order of all requests. Strong consistency model prevents any client side inconsistencies. Similarly, casual consistency model provides read your writes, monotonic reads, write follow reads and monotonic writes guarantees by keeping the common casual ordering \cite{Casual}. However, eventually consistent model guaranties none. 
% Benchmarking consistency of a distributed system is not a trivial task due to the differences in consistency models and the complexity of the algorithms. In order to evaluate the consistency model, staleness, ordering guarantees, transactions and partitions should be tested or the related algorithms of the model should be proven mathematically. 
\hfill\\ 
Evaluating the consistency properties of a protocol or an algorithm is no trivial task. Part of the reason is understanding the consistency itself, since many different consistency models exist. The ambiguity of consistency definitions also makes it difficult to compare the consistency guarantees provided by various systems without careful examination of the algorithms and protocols. For instance, many different systems claim strong consistency for their protocols; however, the actual guarantees provided may differ drastically, based on the transaction modes, assumptions about command ordering (total order, partial total order, etc), and assumptions about the client interaction with the system. %On the other hand, the level of serializability and linearizability guarantees provide a better understanding of the actual consistency model. 

% Achieving linearizability over the entire data space is complicated especially for globally distributed or multi leader systems. Out of the systems we have studied, only Spanner claims such guarantee by using synchronous replication and a global clock called TrueTime \cite{TrueTime}. Other systems provides linearizability at different levels as per data object, per bucket (partition of the data space) or per cluster. Similarly, serializability guarantees of the systems diverges from serializing all write requests globally to serializing them only when they produce conflicts. 

Although benchmarking serializability or linearizability is not simple, testing for these guarantees is feasible. Bizur and Multi-Paxos perform such tests to detect any inconsistencies in their strictly serialized write operations. Bizur uses Serialla, a testing tool for strict serializability in the Elastifile file system \cite{Elastifile}, which produces concurrent updates while checking the responses at all replicas. It detects the requests causing inconsistent execution orders at any replica and provides a descriptive log of operations. Similarly, Multi-Paxos uses runtime checking for any inconsistencies at any replica by periodically sending checksum requests to all replicas. Replicas calculate the checksum value of their fault-tolerant log and compare that with the master's value. Jepsen \cite{jepsen} carries out a test on ZooKeeper to confirm the linearizability variant maintained under network partition and leader failure by partitioning the site that has the leader and another replica and keeps sending the write requests during partition. Then, it recovers the region and checks the logs at each replica. Elle \cite{Elle}, built over Jepsen, efficiently checks for violations of ScalarDB's strict serializability guarantees by constructing transaction dependency graphs and identifying critical dependency cycles.

In our study, we found very few systematic evaluations for consistency. However, some systems evaluate their consistency in terms of data {\bf staleness} at different nodes or geographical regions. Such staleness-based evaluations aim to show that clients cannot read stale or old values of data, no matter which node is being used for reading the data. In this manner, ZooNet measures the performance degradation while disabling stale reads by synchronizing read requests first with the owner of the requested data object to make sure it serves the most up-to-date data. 

