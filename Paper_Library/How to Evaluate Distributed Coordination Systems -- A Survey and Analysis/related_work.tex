Distributed systems have been maintaining their importance for the last several decades due to the increase in the need for scalable and reliable distributed applications while preserving high performance. 
To analyze distributed systems comprehensively and compare them in terms of features and services, various surveys and evaluations have been published in the past. Surveys on cloud providers, data warehouses, distributed file systems, or metadata services can be counted among them. 

Cloud providers are analyzed and evaluated in terms of elasticity \cite{CMART}, computing power \cite{comperative-benchmarking}, and cost to performance efficiency \cite{fair-benchmarking} in previous efforts. Widely used distributed services are also analyzed in many works, such as a survey on stream processing \cite{stream-benchmarking} or performance and dependability evaluation of MapReduce systems \cite{MapReduce-benchmarking}. Similarly, different aspects of distributed systems are studied in several surveys, like reliability analysis on distributed systems \cite{reliability-survey} and load balancing characteristics of known systems \cite{load-balancing-survey}.

As a big part of distributed systems, data warehouses and file systems are studied for many specifications. Evaluation of distributed data warehouses for the cost-effectiveness of different hardware configurations \cite{ALOJA} and query performance of distinct design choices\cite{benchmarking-data-warehouse} are among the known efforts in these works. Distributed file systems are examined in many past works for general concepts \cite{file-systems-concepts,file-systems-gen1} or specific applications such as distributed access control \cite{access-control-file-systems}. Due to the differences in optimization, design techniques, and the complex interactions between the file systems and other system components like the kernel or operating system, benchmarking distributed file systems is not trivial. To identify the important metrics for the evaluation of distributed file systems, researchers also studied benchmarking file systems \cite{File-system-benchmarking,benchmarking-file-rocket}. 

Analysis of distributed coordination services in terms of general characteristics and importance of coordination \cite{importance-of-coordination} and the comparison of existing algorithms \cite{paxos-made-simple} are among the published works. However, to the best of our knowledge, there is no published work on the evaluation of distributed coordination systems. As mentioned in the Introduction, due to the lack of standard benchmarking tools for distributed coordination services, developers widely use their ad-hoc benchmarks, which are prone to unfair comparisons or limited results for the evaluation of the systems. This study is unique in identifying the metrics and parameters for the evaluation of distributed coordination systems, discussing how each system uses these metrics and parameters for its evaluation, pinpointing the deficiencies of well-known benchmarking suites in evaluating distributed computing systems, and finally discussing the features of an ideal distributed coordination benchmark. 