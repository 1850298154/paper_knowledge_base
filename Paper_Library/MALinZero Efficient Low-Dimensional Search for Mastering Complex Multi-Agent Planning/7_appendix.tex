\newpage

\appendix
\section{Proof of Theorems}
\subsection{Proof of Theorem \ref{thm:f-linucb}}
We will show the proof for the regret bound of our proposed LinUCT.

\paragraph{Setup.}
Let $\theta^*\in\mathbb R^{nd}$, $\|\theta^*\|_2\le S$.  At each round $t$ we observe $A_t\in\mathbb R^{nd}$, $\|A_t\|_2\le \sqrt{n} = L$, and receive\(X_t=\langle\theta^*,A_t\rangle+\eta_t\), where $\eta_t$ is conditionally $1$‑sub‑Gaussian.  Suppose \(f:\mathbb{R}\to\mathbb{R}\) is strongly-convex and \(\mu\)-smooth, we have \(f''(z)\in[\varepsilon, \mu], \forall z\in\mathbb{R}\) for some positive \(\varepsilon\).
The solution to (\ref{f-linucb}) is obtained by differentiation and yields \(\hat{\theta}_t = V_t^{-1}\sum_{s=1}^t w_s A_s X_s\) where we use \(w_t = f''(\xi_t)\) with \(\xi_t\in(0, X_t - \langle\theta_{t-1}, A_t\rangle)\) and thus have \(\varepsilon\le w_t\le\mu\) for any \(t\) and \(\xi_t\).

We consider an ellipsoid confidence set centered around the optimal estimator \(\hat{\theta}_{t-1}\), i.e., \(\mathcal{C}_t = \left\{\theta\in\mathbb{R}^{nd}: \|\theta - \hat{\theta}_{t-1}\|_{V_{t-1}}\right\}\le\beta_t\), for any increasing sequence of \(\beta_t\) with \(\beta_1 \ge1\). Note that as $t$ grows, this ellipse $\mathcal{C}_t$ is shrinking as $V_t$ has increasing eigenvalues and if $\beta_t$ does not grow too fast. We show that the problem of selecting optimal action $A_t\in \mathcal{A}$ by solving $\max_{A_t\in \mathcal{A}, \theta\in \mathcal{C}_t} \langle \theta, a \rangle $ in this contextual linear bandit problem is equivalent to \(
A_t \;=\;\arg\max_{a}\;\Bigl\langle \hat{\theta}_{t-1},\,a\Bigr\rangle
\;+\;\beta_{t-1}\,\|a\|_{V_{t-1}^{-1}},
\)
which is referred to as our LinUCT rule for action selection. We consider the realized regret defined by 
$
 \widehat R_T
 =\sum_{t=1}^T\!(X_t^* - X_t)
 =\sum_{t=1}^T\!\bigl(\langle\theta^*,A_t^*\rangle - \langle\theta^*,A_t\rangle\bigr)
 \;+\;\sum_{t=1}^T(\eta_t^*-\eta_t)
$. 

\begin{lemma}[Confidence Ellipsoid]\label{lem:confidence}
With probability at least $1-\delta$, for all $t\le T$,
\begin{equation}
    \|\theta_t-\theta^*\|_{V_t}\le\beta_t.
\end{equation}
\end{lemma}

\begin{proof}
Observe
\begin{equation}
\theta_t-\theta^*
=V_t^{-1}\Bigl(\sum_{s=1}^t w_sA_sX_s-V_t\theta^*\Bigr)
=V_t^{-1}\Bigl(\sum_{s=1}^t w_sA_s\eta_s-\lambda\theta^*\Bigr).    
\end{equation}

Set $Y_t=\sum_{s=1}^t w_sA_s\eta_s$ and $b=\lambda\theta^*$.  Then we have 
\begin{equation}
\|\theta_t-\theta^*\|_{V_t}^2
=(b-Y_t)^\top V_t^{-1}(b-Y_t)
=Y_t^\top V_t^{-1}Y_t-2b^\top V_t^{-1}Y_t+b^\top V_t^{-1}b.
\end{equation}
Since $V_t\succeq\lambda I$, $V_t^{-1}\preceq\frac1\lambda I$ and $\|\theta^*\|\le S$, we can get
\begin{equation}
b^\top V_t^{-1}b
=\lambda^2{\theta^*}^\top V_t^{-1}\theta^*
\le\lambda^2\frac{S^2}{\lambda}
=\lambda S^2.
\end{equation}

According to Cauchy–Schwarz inequality and $V_t^{-1}\preceq\frac1\lambda I$,
\begin{equation}
    |b^\top V_t^{-1}Y_t|
\le\|b\|_2\,\|V_t^{-1}Y_t\|_2
\le\lambda S\sqrt{\tfrac1\lambda Y_t^\top V_t^{-1}Y_t}
=\sqrt\lambda S\sqrt{Y_t^\top V_t^{-1}Y_t}.
\end{equation}
Hence 
\begin{equation}
-2b^\top V_t^{-1}Y_t
\le2\sqrt\lambda S\sqrt{Y_t^\top V_t^{-1}Y_t}.
\end{equation}

To bound $Y_t^\top V_t^{-1}Y_t$, note $Y_t=\sum_{s=1}^t w_sA_s\eta_s$ is a martingale sum. According to Lemma \ref{lem:selfnorm}, the self‑normalized tail bound yields

\begin{equation}
Y_t^\top V_t^{-1}Y_t
\le2\mu\ln\frac{\det(V_t)^{1/2}}{\det(\lambda I)^{1/2}\delta}.
\end{equation}

Combining these three yields
\begin{equation}
\|\theta_t-\theta^*\|_{V_t}
\le\sqrt{Y_t^\top V_t^{-1}Y_t}+\sqrt\lambda S
\le\beta_t,
\end{equation}
and a union bound over $t=1,\dots,n$ gives the result.
\end{proof}



\begin{lemma}[Self‑Normalized Martingale Tail]\label{lem:selfnorm}
Let \(\{\eta_t\}_{t=1}^T\) be a sequence of conditionally \(1\)‑sub‑Gaussian noises, and let \(A_t\in\mathbb R^nd\) and \(w_t\in[\varepsilon,\mu]\) be \(\mathcal F_{t-1}\)-measurable.  Define
\begin{equation}
Y_t \;=\;\sum_{s=1}^t w_s\,A_s\,\eta_s,\;
V_t \;=\;\sum_{s=1}^t w_s\,A_sA_s^\top + \lambda I.
\end{equation}

Then for any \(\delta\in(0,1)\), with probability at least \(1-\delta\) simultaneously for all \(t\le T\),
\begin{equation}
Y_t^\top V_t^{-1} Y_t
\;\le\;
2\mu\,
\ln\!\Bigl(
\frac{\det(V_t)^{1/2}}{\det(\lambda I)^{1/2}\,\delta}
\Bigr).
\end{equation}
\end{lemma}

\begin{proof}
First, we define 
\begin{equation}
M_t(x)
\;=\;
\exp\Bigl(
x^\top Y_t
\;-\;\tfrac \mu2\,x^\top V_t\,x
\Bigr)
\end{equation}
for each fixed \(x\in\mathbb R^nd\).
Since \(\eta_t\) is conditionally \(1\)-sub‑Gaussian and \(w_t\le \mu\), we have for any \(\mathcal F_{t-1}\)-measurable \(u\)
\begin{equation}
\begin{split}
\mathbb E\bigl[e^{u\,\eta_t}\mid\mathcal F_{t-1}\bigr]
\;\le\;
\exp\bigl(\tfrac12 u^2\bigr)
&\implies
\mathbb E\bigl[e^{w_t\,A_t^\top x\,\eta_t}\mid\mathcal F_{t-1}\bigr] \\
\;
&\le\;\exp\bigl(\tfrac12 w_t^2 (A_t^\top x)^2\bigr)
\;\le\;
\exp\bigl(\tfrac \mu2\,x^\top (w_t A_tA_t^\top)\,x\bigr).
\end{split}
\end{equation}
Therefore
\begin{equation}
\mathbb E\bigl[M_t(x)\mid\mathcal F_{t-1}\bigr]
=
M_{t-1}(x)
\;\mathbb E\!\Bigl[e^{\,x^\top(w_tA_t\eta_t)\;-\;\tfrac \mu2\,x^\top(w_tA_tA_t^\top)\,x}\Bigm|\mathcal F_{t-1}\Bigr]
\;\le\;
M_{t-1}(x).
\end{equation}
Hence each \(M_t(x)\) is a nonnegative supermartingale with \(M_0(x)=1\).

Then we lift the pointwise supermartingale bound to a uniform one by integrating $M_t(x)$ against the Gaussian prior over $x$. Let \(h\) be the density of \(\mathcal N(0,\lambda^{-1}I)\).  Define the mixture
\begin{equation}
\overline M_t
\;=\;
\int_{\mathbb R^nd} M_t(x)\,h(x)\,dx.
\end{equation}
By Fubini and the supermartingale property,
\begin{equation}
\mathbb E[\overline M_t\mid\mathcal F_{t-1}]
=\int\mathbb E[M_t(x)\mid\mathcal F_{t-1}]\,h(x)\,dx
\;\le\;
\int M_{t-1}(x)\,h(x)\,dx
=\overline M_{t-1},
\end{equation}
so \(\overline M_t\) is also a nonnegative supermartingale with \(\overline M_0=1\).
A Gaussian integral gives
\begin{equation}
\begin{split}
\overline M_t
&=\frac{1}{(2\pi)^{nd/2}\det(\lambda^{-1}I)^{1/2}}
\int
\exp\Bigl(x^\top Y_t - \tfrac12 x^\top(\lambda I + \mu V_t)x\Bigr)
\,dx\\
&=\Bigl(\tfrac{\det(\lambda I)}{\det(\lambda I + \mu V_t)}\Bigr)^{1/2}
\exp\!\Bigl(\tfrac12 Y_t^\top(\lambda I + \mu V_t)^{-1}Y_t\Bigr).
\end{split}
\end{equation}

Since \(V_t\succeq\lambda I\), one checks
\((\lambda I + \mu V_t)^{-1}\succeq \tfrac1\mu V_t^{-1}\), and
\(\det(\lambda I + \mu V_t)\le \mu^{nd}\det(V_t)\).  Thus
\begin{equation}
\overline M_t
\;\ge\;
\mu^{-nd/2}\,\Bigl(\tfrac{\det(\lambda I)}{\det(V_t)}\Bigr)^{1/2}
\exp\!\Bigl(\tfrac1{2\mu}Y_t^\top V_t^{-1}Y_t\Bigr).    
\end{equation}
By Ville’s maximal inequality for nonnegative supermartingales,
\begin{equation}
\Pr\Bigl(\exists\,t\le T:\overline M_t\ge\tfrac1\delta\Bigr)
\;\le\;
\delta\,\overline M_0
=\delta.    
\end{equation}
On the complementary event, for all \(t\le T\),
\begin{equation}
\overline M_t<\tfrac1\delta
\;\implies\;
\tfrac1{2\mu}Y_t^\top V_t^{-1}Y_t
\;\le\;
\tfrac {nd}2\ln \mu
\;+\;\tfrac12\ln\!\frac{\det(V_t)}{\det(\lambda I)}
\;+\;\ln\!\frac1\delta.
\end{equation}
Absorbing the constant \(\tfrac {nd}2\ln \mu\) into \(\ln(1/\delta)\) yields
\begin{equation}
Y_t^\top V_t^{-1}Y_t
\;\le\;
2\mu\,
\ln\!\Bigl(\tfrac{\det(V_t)^{1/2}}{\det(\lambda I)^{1/2}\,\delta}\Bigr),
\end{equation}
as claimed.
\end{proof}


\begin{lemma}[Elliptical Potential]\label{lem:weighted_elliptical}
Let \(V_0=\lambda I\) and for \(t=1,2,\dots,T\) define
\begin{equation}
V_t \;=\; V_{t-1} \;+\; w_t\,A_tA_t^\top,
\end{equation}
where \(A_t\in\mathbb R^{nd}\) satisfies \(\|A_t\|_2\le \sqrt{n}=L\) and 
\(\,w_t\in[\varepsilon,\mu]\) with \(\varepsilon\ge0\).  Then
\begin{equation}
\sum_{t=1}^T \min\!\Bigl\{1,\;w_t\,\|A_t\|_{V_{t-1}^{-1}}^2\Bigr\}
\;\le\;
2\,
\ln\!\frac{\det(V_T)}{\det(V_0)}
\;\le\;
2\,nd\,\ln\!\Bigl(1+\tfrac{\mu T}{d\lambda}\Bigr).
\end{equation}

\end{lemma}

\begin{proof}
First, for any \(z\ge0\) we have \(z\wedge1\le2\ln(1+z)\).  Hence
\begin{equation}
\sum_{t=1}^T \min\{1,w_t\|A_t\|_{V_{t-1}^{-1}}^2\}
\;\le\;
2\sum_{t=1}^T \ln\!\bigl(1 + w_t\,\|A_t\|_{V_{t-1}^{-1}}^2\bigr).
\end{equation}
Next, by the matrix determinant lemma,
\begin{equation}
\det(V_t)
=\det(V_{t-1})
\det\!\bigl(I + w_t\,V_{t-1}^{-1/2}A_tA_t^\top V_{t-1}^{-1/2}\bigr)
=\det(V_{t-1})\bigl(1 + w_t\,\|A_t\|_{V_{t-1}^{-1}}^2\bigr).
\end{equation}
Telescoping the product for \(t=1,\dots,T\) gives
\begin{equation}
\prod_{t=1}^T\bigl(1 + w_t\,\|A_t\|_{V_{t-1}^{-1}}^2\bigr)
=\frac{\det(V_T)}{\det(V_0)},    
\end{equation}
and taking logarithms,
\begin{equation}
\sum_{t=1}^T \ln\!\bigl(1 + w_t\,\|A_t\|_{V_{t-1}^{-1}}^2\bigr)
=\ln\!\frac{\det(V_T)}{\det(V_0)}.
\end{equation}
Combining with the earlier bound yields the first inequality.
Finally, since \(w_t\le \mu\) and \(\|A_t\|\le L\), we have
\begin{equation}
V_T
=\lambda I + \sum_{t=1}^T w_t\,A_tA_t^\top
\;\preceq\;
\lambda I + \mu\,L^2\,T\;I,    
\end{equation}
so
\begin{equation}
\ln\!\frac{\det(V_T)}{\det(\lambda I)}
\;\le\;
nd\,\ln\!\Bigl(\frac{nd\lambda + \mu\,L^2\,T}{nd\lambda}\Bigr)
=nd\,\ln\!\Bigl(1+\tfrac{\mu T}{d\lambda}\Bigr),
\end{equation}
giving the second inequality.
\end{proof}


Here we reclaim Theorem \ref{thm:f-linucb}
\begin{reptheorem}\ref{thm:f-linucb}
    [Regret Bound of LinUCT] With probability \(1-\delta\), the regret of LinUCT satisfies
\begin{equation}
    \hat{R}_t \le \sqrt{8\mu t \beta_t \operatorname{ln}\left(\frac{\operatorname{det}(V_t)}{\operatorname{det}(\lambda I)}\right)} \le \sqrt{8\mu ndt\beta_t\operatorname{ln}\left(\frac{nd \lambda + \mu nt}{nd\lambda}\right)}.
\end{equation}
\end{reptheorem}

\begin{proof}
Let 
\begin{equation}
S_t =\sum_{s=1}^t w_s A_s\eta_s,
\qquad
V_t=\lambda I +\sum_{s=1}^t w_s A_sA_s^\top,
\end{equation}
and define
\begin{equation}
    \beta_t
=\sqrt{2\mu\,
  \ln\!\frac{\det\bigl(V_t\bigr)^{1/2}}
           {\lambda^{nd/2}\,\delta}}
\;+\;\sqrt{\lambda}\,\|\theta^*\|_2.
\end{equation}

By Lemma \ref{lem:selfnorm}, with probability at least $1-\delta$ simultaneously for all $t$,
\begin{equation}
\|S_t\|_{V_t^{-1}}
\;\le\;
\sqrt{\,2\mu\,
  \ln\!\frac{\det\bigl(V_t\bigr)^{1/2}}
           {\lambda^{nd/2}\,\delta}
}\;=\;\beta_t - \sqrt{\lambda}\,\|\theta^*\|_2.
\end{equation}

On this event, Lemma \ref{lem:confidence} shows
\begin{equation}\label{eq:ci}
\|\hat\theta_t-\theta^*\|_{V_t(\lambda)}
\;\le\;
\|S_t\|_{V_t(\lambda)^{-1}}
\;+\;\sqrt{\lambda}\,\|\theta^*\|_2
\;\le\;\beta_t.
\end{equation}

Next let $\Delta_t=\eta_t^*-\eta_t$.  Since each $\eta_t,\eta_t^*$ is $1$-sub-Gaussian and independent, we can get 
\begin{equation}
\mathbb E\!\left[e^{\lambda\Delta_t}\mid\mathcal F_{t-1}\right]
      \;=\;
      \mathbb E\!\left[e^{\lambda\eta_t^{*}}\right]\;
      \mathbb E\!\left[e^{-\lambda\eta_t}\right]
      \;\le\;
      \exp\!\Bigl(\tfrac{\lambda^{\,2}}{2}\Bigr)\;
      \exp\!\Bigl(\tfrac{\lambda^{\,2}}{2}\Bigr)
      \;=\;
      \exp\!\Bigl(\lambda^{\,2}\Bigr).
\end{equation}
Thus $\Delta_t$ is conditionally \emph{$\sqrt2$‑sub‑Gaussian}:
\begin{equation}
\mathbb E\!\left[e^{\lambda\Delta_t}\mid\mathcal F_{t-1}\right]
      \;\le\;
      \exp\!\Bigl(\tfrac{(\sqrt2\,\lambda)^{2}}{2}\Bigr).
\end{equation}

By Hoeffding’s inequality,
\begin{equation}
    \Pr\!\Bigl(\sum_{s=1}^t \Delta_t > u\Bigr)
      \;\le\;
      \exp\!\Bigl(-\tfrac{u^{2}}{4T}\Bigr).
\end{equation}

Choose  
\(u = 2\sqrt{T\ln\tfrac1\delta}\).  
Then  
\begin{equation}
    \Pr\!\Bigl(\sum_{s=1}^t \Delta_t > 2\sqrt{T\ln\tfrac1\delta}\Bigr)
      \;\le\;
      \exp\!\Bigl(-\tfrac{4T\ln(1/\delta)}{4T}\Bigr)
      \;=\;\delta .
\end{equation}


Because $A_t$ is chosen by  
\(
A_t=\arg\max_{a}\langle\hat\theta_{t-1},a\rangle + \beta_{t-1}\|a\|_{V_{t-1}^{-1}},
\)
while
\(A_t^{*}=\arg\max_{a}\langle\theta^{*},a\rangle\),
we first compare the optimistic upper–confidence values:

\begin{equation}
\langle\hat\theta_{t-1},A_t\rangle+\beta_{t-1}\|A_t\|_{V_{t-1}^{-1}}
      \;\ge\;
      \langle\hat\theta_{t-1},A_t^{*}\rangle
      +\beta_{t-1}\|A_t^{*}\|_{V_{t-1}^{-1}} .
\end{equation}


Whenever the confidence event \eqref{eq:ci} holds for any \(a\),
\begin{equation}
|\langle(\theta^{*}-\hat\theta_{t-1}),\,a\rangle|
      \;\le\;
      \|\theta^{*}-\hat\theta_{t-1}\|_{V_{t-1}}
      \,\|a\|_{V_{t-1}^{-1}}
      \;\le\;
      \beta_{t-1}\|a\|_{V_{t-1}^{-1}},
\end{equation}

Applying this with $a=A_t^{*}$ and then with $a=A_t$ gives
\begin{equation}
    \langle\theta^{*},A_t^{*}\rangle
      \;\le\;
      \langle\hat\theta_{t-1},A_t^{*}\rangle
      +\beta_{t-1}\|A_t^{*}\|_{V_{t-1}^{-1}},
\qquad
\langle\theta^{*},A_t\rangle
      \;\ge\;
      \langle\hat\theta_{t-1},A_t\rangle
      -\beta_{t-1}\|A_t\|_{V_{t-1}^{-1}} .
\end{equation}

Subtracting the second inequality from the first and using the choice of $A_t$,
\begin{equation}
    \langle\theta^{*},A_t^{*}\rangle-\langle\theta^{*},A_t\rangle
      \;\le\;
      \beta_{t-1}\,\|A_t\|_{V_{t-1}^{-1}} .
\end{equation}

Then we can get
\begin{equation}
\label{X*-X}
    X_t^{*}-X_t
      \;=\;
      \bigl[\langle\theta^{*},A_t^{*}\rangle-\langle\theta^{*},A_t\rangle\bigr]
      +\Delta_t
      \;\le\;
      \beta_{t-1}\|A_t\|_{V_{t-1}^{-1}}
      +\Delta_t .
\end{equation}

The single‑step regret is  
\begin{equation}\label{single_step_regret}
    r_{t}:=X_{t}^{*}-X_{t}
      =\langle\theta^{*},A_{t}^{*}\rangle
       -\langle\theta^{*},A_{t}\rangle
       +\Delta_{t}
      \;{\le}\;
      \beta_{t-1}\|A_{t}\|_{V_{t-1}^{-1}}
      +\Delta_{t}.
\end{equation}

Sum the single-step regret from $t=1$ to $T$:
\begin{equation}\label{eq:regret1}
    \hat R_{T}
      :=\sum_{t=1}^{T}r_{t}
      \;\le\;
      \sum_{t=1}^{T}\beta_{t-1}\,\|A_{t}\|_{V_{t-1}^{-1}}
      \;+\;
      2\sqrt{T\ln\!\tfrac1\delta}.
\end{equation}

Inequality (\ref{single_step_regret}) is the starting point for the final
bounding of the main term
\begin{equation}
\sum_{t=1}^T\beta_{t-1}\|A_{t}\|_{V_{t-1}^{-1}}
\end{equation}

via Cauchy–Schwarz together with the weighted elliptical potential lemma.

By Cauchy–Schwarz and Lemma \ref{lem:weighted_elliptical},
\begin{equation}
\sum_{t=1}^T\beta_{t-1}\|A_t\|_{V_{t-1}^{-1}}
\;\le\;
\sqrt{\sum_{t=1}^T\beta_{t-1}^2}
\;\sqrt{\sum_{t=1}^T\|A_t\|_{V_{t-1}^{-1}}^2}
\;\le\;
\sqrt{T}\,\beta_T
\;\sqrt{\,2
  \ln\!\frac{\det\bigl(V_T\bigr)}
           {\lambda^{nd}}\,}\,.
\end{equation}

Combined with \eqref{eq:regret1},
\begin{equation}\label{eq:regret2}
\hat R_T
\;\le\;
\sqrt{2T}\,\beta_T
\;\sqrt{\ln\!\frac{\det (V_T)}{\lambda^{nd}}}
\;+\;
2\sqrt{T\ln\tfrac1\delta}.
\end{equation}

According to the definition of \(\beta_T\), we have
\begin{equation}
\beta_T
\;\le\;
\sqrt{2\mu\,
  \ln\!\frac{\det (V_T)}{\lambda^{nd}}}
\;\Longrightarrow\;
\ln\!\frac{\det (V_T)}{\lambda^{nd}}
\;\le\;
\frac{\beta_T^2}{2\mu}.
\end{equation}
Therefore the first term in \eqref{eq:regret2} satisfies
\begin{equation}
\sqrt{2T}\,\beta_T
\;\sqrt{\ln\!\frac{\det (V_T)}{\lambda^{nd}}}
\;\le\;
\sqrt{2T}\,\beta_T
\;\sqrt{\frac{\beta_T^2}{2\mu}}
\;=\;
\sqrt{\frac{T}{\mu}}\;\beta_T^2.
\end{equation}

Moreover,
\begin{equation}
2\sqrt{T\ln\tfrac1\delta}
\;\le\;
2\sqrt{T\;\frac{\beta_T^2}{2\mu}}
\;=\;
\sqrt{\frac{2T}{\mu}}\;\beta_T
\;\le\;
\sqrt{\frac{T}{\mu}}\;\beta_T^2.
\end{equation}

Hence
\begin{equation}
\hat R_T
\;\le\;
2\,\sqrt{\tfrac{T}{\mu}}\;\beta_T^2
\;=\;
2\,\sqrt{\tfrac{T}{\mu}}
\Bigl(
  \sqrt{2\mu\,
    \ln\!\frac{\det (V_T)^{1/2}}{\lambda^{nd/2}\delta}}
  \;+\;\sqrt{\lambda}\,\|\theta^*\|_2
\Bigr)^{\!2},
\end{equation}


With \(w_t\le\mu\) and \(\|A_t\|_2\le\sqrt n = L\), according to Lemma \ref{lem:weighted_elliptical} we have
\begin{equation}
V_T
      \;=\;\lambda I
      +\sum_{s=1}^T w_s A_sA_s^{\top}
      \;\preceq\;
      nd\lambda I+\mu L^2T\,I,
\end{equation}
and 
\begin{equation}
\det (V_T)
      \;\le\;
      \left(\frac{nd\lambda+\mu L^2 T}{nd}\right)^{nd},
\qquad
\frac{\det (V_T)}{\lambda^{nd}}
      \;\le\;
      \left(\frac{nd\lambda+\mu L^2 T}{nd \lambda}\right)^{nd}.
\end{equation}

Thus, with probability at least \(1-\delta\),
\begin{equation}
  \hat R_t
      \;\le\;
      \sqrt{\,8\mu\,t\,
             \beta_t\,
             \left(\frac{nd\lambda+\mu L^2 t}{nd \lambda}\right)^{nd}}\;
      =\;
      \sqrt{\,8\mu nd\,t\,\beta_t\,
             \ln\!
                   \left(\frac{nd\lambda+\mu n t}{nd \lambda}\right)
               }\; .
\end{equation}



\end{proof}




\subsection{Proof of Theorem \ref{thm:submodular}}


\begin{reptheorem}{\ref{thm:submodular}}
\label{thm:submodular_revised_full}
[Submodularity of \(\Psi\)] \(\Psi\) is a non-negative monotonic submodular function over the ground set \(\mathcal{A}\).
\end{reptheorem}

\begin{proof}
Throughout, $\Vert x\Vert_{M}:=\sqrt{x^{\!\top}Mx}$ for $M\succ0$.

\paragraph{(i) Non‑negativity.}
Both summands in $\Psi(S)$ are non‑negative, hence $\Psi(S)\ge0$ for all
$S\subseteq\mathcal A$.

\paragraph{(ii) Monotonicity.}
Fix $S\subseteq\mathcal A$ and $a\notin S$.
Write
\begin{equation}
\label{Delta_define}
\Delta(a\mid S)\;=\;\Psi(S\cup\{a\})-\Psi(S)
                 \;=\;
                 a^{\!\top}\theta
                 +\underbrace{\Vert a\Vert_{V(S\cup\{a\})^{-\!1}}}_{\text{new radius}}
                 -\!\!\!\sum_{v\in S}\!
                       \Bigl(\Vert v\Vert_{V(S)^{-\!1}}
                             -\Vert v\Vert_{V(S\cup\{a\})^{-\!1}}\Bigr).
\end{equation}

Apply Lemma \ref{lem:aggregate-loss} with $V:=V(S)$ and $u:=a$:
\begin{equation}
\label{sum_v_V}
\sum_{v\in S}
\Bigl(\Vert v\Vert_{V(S)^{-\!1}}
      -\Vert v\Vert_{V(S\cup\{a\})^{-\!1}}\Bigr)
      \;\le\;
      \Vert a\Vert_{V(S)^{-\!1}}
      \;\le\;
      \Vert a\Vert_{V(S\cup\{a\})^{-\!1}}.
\end{equation}

Substituting inequality (\ref{sum_v_V}) in (\ref{Delta_define}) gives
\(\Delta(a\mid S)\ge a^{\!\top}\theta\ge0\);
therefore $\Psi$ is monotone.

\paragraph{(iii) Submodularity (diminishing returns).}
Let $S\subseteq T\subseteq\mathcal A$ and let $a\notin T$.
Set $U:=T\setminus S$.
For any finite $R\subseteq\mathcal A$ define
\begin{equation}
L(R)\;:=\;\sum_{v\in R}
            \Bigl(\Vert v\Vert_{V(R)^{-\!1}}
                 -\Vert v\Vert_{V(R\cup\{a\})^{-\!1}}\Bigr).
\end{equation}

With this notation
\begin{equation}
\label{Delta_S_T}
\Delta(a\mid S)
      =a^{\!\top}\theta
       +\Vert a\Vert_{V(S\cup\{a\})^{-\!1}}
       -L(S),\qquad
\Delta(a\mid T)
      =a^{\!\top}\theta
       +\Vert a\Vert_{V(T\cup\{a\})^{-\!1}}
       -L(T).
\end{equation}

\emph{Step 1 – Compare the new‑radius terms.}
Because $V(S\cup\{a\})\succeq V(T\cup\{a\})$, we have
\begin{equation}
\label{a_S_T}
\Vert a\Vert_{V(S\cup\{a\})^{-\!1}}
\;\ge\;
\Vert a\Vert_{V(T\cup\{a\})^{-\!1}}.
\end{equation}

\emph{Step 2 – Compare the loss sums.}
For every $v\in S$ Lemma \ref{lem:gap-monotone} applied with
$x:=v,\;u:=a,\;A:=V(T),\;B:=V(S)$ yields
\begin{equation}
\label{v_V_inequality}
\Vert v\Vert_{V(S)^{-\!1}}
-\Vert v\Vert_{V(S\cup\{a\})^{-\!1}}
\;\le\;
\Vert v\Vert_{V(T)^{-\!1}}
-\Vert v\Vert_{V(T\cup\{a\})^{-\!1}}.
\end{equation}
Summing (\ref{v_V_inequality}) over all $v\in S$ gives
\begin{equation}
\label{LS}
L(S)\;\le\;\sum_{v\in S}
            \Bigl(\Vert v\Vert_{V(T)^{-\!1}}
                 -\Vert v\Vert_{V(T\cup\{a\})^{-\!1}}\Bigr).
\end{equation}
Adding the non‑negative terms
$\Vert v\Vert_{V(T)^{-\!1}}-\Vert v\Vert_{V(T\cup\{a\})^{-\!1}}$
for $v\in U$ to both sides of (\ref{LS}) we obtain
\begin{equation}
\label{L_S_T}
L(S)\;\le\;L(T).
\end{equation}

\emph{Step 3 – Combine.}
Subtracting (\ref{L_S_T}) from (\ref{a_S_T}) and using representation (\ref{Delta_S_T}) yields
\begin{equation}
\Delta(a\mid S)
      -\Delta(a\mid T)
      =\bigl[\Vert a\Vert_{V(S\cup\{a\})^{-\!1}}
            -\Vert a\Vert_{V(T\cup\{a\})^{-\!1}}\bigr]
       -\bigl[L(S)-L(T)\bigr]
      \;\ge\;0,
\end{equation}
that is, \(\Delta(a\mid S)\ge\Delta(a\mid T)\).
Hence $\Psi$ satisfies the diminishing‑returns property and is submodular.
\end{proof}


\begin{lemma}[Aggregate–loss bound]
\label{lem:aggregate-loss}
Let $V\in\mathbb R^{nd\times nd}$ be positive definite,
let $u\in\mathbb R^{nd}$, and let
$S\subseteq\mathbb R^{nd}$ be a finite set.
Then
\begin{equation}
\sum_{v\in S}
\Bigl(\Vert v\Vert_{V^{-\!1}}
      -\Vert v\Vert_{(V+uu^{\!\top})^{-\!1}}\Bigr)
      \;\le\;\Vert u\Vert_{V^{-\!1}}.
\end{equation}
\end{lemma}

\begin{proof}
Write $\Delta_v:=\Vert v\Vert_{V^{-\!1}}-\Vert v\Vert_{(V+uu^{\!\top})^{-\!1}}$.
Using Woodbury’s identity
\(
(V+uu^{\!\top})^{-\!1}=V^{-\!1}
      -\frac{V^{-\!1}uu^{\!\top}V^{-\!1}}{1+u^{\!\top}V^{-\!1}u},
\)
compute
\begin{equation}
\label{after_woodbury}
v^{\!\top}V^{-\!1}v-v^{\!\top}(V+uu^{\!\top})^{-\!1}v
      =\frac{(v^{\!\top}V^{-\!1}u)^{2}}
             {1+u^{\!\top}V^{-\!1}u}.
\end{equation}
For any $\alpha>\beta>0$ one has
$\sqrt{\alpha}-\sqrt{\alpha-\beta}
      \le\beta/(2\sqrt{\alpha-\beta})
      \le\beta/\sqrt{2\alpha}$.

Applying the Triangle and Cauchy–Schwarz Inequalities, we have:
\begin{equation}
\label{Delta_v_V_u_V}
\Delta_v
   \;\le\;
   \frac{|v^{\!\top}V^{-\!1}u|}
        {\sqrt{1+u^{\!\top}V^{-\!1}u}}
   \;\le\;
   \Vert v\Vert_{V^{-\!1}}\;\Vert u\Vert_{V^{-\!1}}.
\end{equation}
Summing (\ref{Delta_v_V_u_V}) over $v\in S$ and applying Cauchy–Schwarz,
\[
\sum_{v\in S}\Delta_v
      \;\le\;
      \Vert u\Vert_{V^{-\!1}}
      \sqrt{\sum_{v\in S}\Vert v\Vert_{V^{-\!1}}^{2}}
      \sqrt{|S|}
      \;\le\;
      \Vert u\Vert_{V^{-\!1}},
\]
since $\Vert v\Vert_{V^{-\!1}}\le \frac{1}{|S|}$, completing the proof.
\end{proof}


\begin{lemma}[Monotone‑gap lemma]
\label{lem:gap-monotone}
Fix $x,u\in\mathbb R^{nd}$ and define, for every positive definite matrix
$A$,
\begin{equation}
d_x(A)
   :=\sqrt{x^{\!\top}A^{-\!1}\!x}
     -\sqrt{x^{\!\top}(A+uu^{\!\top})^{-\!1}\!x}.
\end{equation}
If $A\succeq B\succ0$ then $d_x(A)\ge d_x(B)$.
\end{lemma}

\begin{proof}
Let $H:=A-B\succeq0$ and define $A_t:=B+tH$ for $t\in[0,1]$.
Set $g(t):=d_x(A_t)$.
Using
$\frac{d}{dt}A_t^{-\!1}=-A_t^{-\!1}H A_t^{-\!1}$ and
$\frac{d}{dt}(A_t+uu^{\!\top})^{-\!1}
      =-(A_t+uu^{\!\top})^{-\!1}H(A_t+uu^{\!\top})^{-\!1}$,
we compute
\begin{equation}
\label{g'(t)}
g'(t)
 =-\frac{x^{\!\top}A_t^{-\!1}H A_t^{-\!1}x}
        {2\sqrt{x^{\!\top}A_t^{-\!1}x}}
  +\frac{x^{\!\top}(A_t+uu^{\!\top})^{-\!1}H(A_t+uu^{\!\top})^{-\!1}x}
        {2\sqrt{x^{\!\top}(A_t+uu^{\!\top})^{-\!1}x}}.
\end{equation}
Because $A_t+uu^{\!\top}\succeq A_t$, we have
$(A_t+uu^{\!\top})^{-\!1}\preceq A_t^{-\!1}$.
Consequently each numerator in (\ref{g'(t)}) is bounded by the same non‑negative
quantity and each denominator satisfies
$\sqrt{x^{\!\top}(A_t+uu^{\!\top})^{-\!1}x}
      \le\sqrt{x^{\!\top}A_t^{-\!1}x}$.
Hence $g'(t)\ge0$ for all $t\in[0,1]$.
Integrating $g'(t)$ from $0$ to $1$ gives
$g(1)-g(0)\ge0$, i.e.\ $d_x(A)\ge d_x(B)$.
\end{proof}

\subsection{Proof of Theorem \ref{thm:approximation}}
Here we reclaim Theorem \ref{thm:approximation}:
\begin{reptheorem}\ref{thm:approximation}
[{\((1-\tfrac1e)\)-Approximation under Cardinality and \(n\)-Hot Constraints}] There exists an [\((1-\tfrac1e)\)-approximation algorithm for the optimization of action selection.

\medskip
\noindent
\textbf{(a) Uniform‑matroid (cardinality) case \(\lvert S\rvert\le T\).}\;
The standard greedy algorithm
\begin{equation}
A_t \;=\;\arg\max_{a\in\mathcal A\setminus S_{t-1}}
           \bigl[\Psi(S_{t-1}\cup\{a\}) - \Psi(S_{t-1})\bigr],
\quad
S_t = S_{t-1}\cup\{A_t\},
\end{equation}
for \(t=1,\dots,T\), returns \(S_T\) satisfying
\(
\Psi(S_T)\;\ge\;\bigl(1-\tfrac1e\bigr)\,\Psi(S^\star),
\)
where \(S^\star\) is an optimal subset of size at most \(T\) \cite{nemhauser1978analysis}.

\medskip
\noindent
\textbf{(b) \(n\)-Hot (partition‑matroid) case.}\;
One may apply the continuous‑greedy algorithm to the multilinear relaxation
\(\max_{x\in P(\mathcal M),\;\mathbf1^\top x\le T}\mathbb E[\Psi(R(x))]\),
where \(P(\mathcal M)\) is the matroid polytope of the partition matroid and \(R(x)\) denotes the standard randomised rounding. It produces a feasible set \(\hat S\) with
\(
\Psi(\hat S)\;\ge\;\bigl(1-\tfrac1e\bigr)\,\Psi(S^\star)
\)

\cite{calinescu2011maximizing}.
\end{reptheorem}

\begin{proof}
    We recall that \(\Psi\) is a nonnegative, monotone, submodular set function on the ground set \(\mathcal A\).  The classic results of \cite{nemhauser1978analysis} and \cite{calinescu2011maximizing} then yield the claimed \((1-\tfrac1e)\)-approximation guarantees under the two matroid constraints.

\medskip\noindent
\textbf{(a) Uniform‐matroid (cardinality) constraint \(\lvert S\rvert\le T\).}

Let \(S_0=\emptyset\), and for \(t=1,\dots,T\) let
\begin{equation}
A_t \;=\;\arg\max_{a\in\mathcal A\setminus S_{t-1}}\;\bigl[\Psi(S_{t-1}\cup\{a\})-\Psi(S_{t-1})\bigr], 
\quad
S_t = S_{t-1}\cup\{A_t\}.
\end{equation}
By monotonicity and submodularity one shows inductively (cf.\ \cite{nemhauser1978analysis}) that
\begin{equation}
\Psi(S_t)\;\ge\;\Bigl(1-\bigl(1-\tfrac1T\bigr)^t\Bigr)\,\Psi(S^\star)
\quad\text{for all }t\,,
\end{equation}
where \(S^\star\) is any optimal solution with \(\lvert S^\star\rvert\le T\).  In particular at \(t=T\),
\begin{equation}
\Psi(S_T)\;\ge\;\Bigl(1-\bigl(1-\tfrac1T\bigr)^T\Bigr)\,\Psi(S^\star)
\;\ge\;\bigl(1-\tfrac1e\bigr)\,\Psi(S^\star).
\end{equation}

\medskip\noindent
\textbf{(b) Partition‐matroid (“\(n\)-hot”) constraint.}

Let \(\mathcal M\) be the partition matroid on \(\mathcal A\) that enforces the \(n\)-hot constraint (i.e.\ each block can contribute at most one element), together with the additional global cardinality bound \(\mathbf1^\top x\le T\).  Consider the multilinear extension
\begin{equation}
F(x)\;=\;E_{R\sim x}\bigl[\Psi(R)\bigr],
\end{equation}
where \(R\subseteq\mathcal A\) includes each element \(a\) independently with probability \(x_a\).  The continuous‐greedy algorithm (running for time \(T\)) constructs a fractional solution \(x^\star\in P(\mathcal M)\cap\{x:\mathbf1^\top x=T\}\) satisfying
\begin{equation}
F(x^\star)\;\ge\;\bigl(1-\tfrac1e\bigr)\,\max_{x\in P(\mathcal M),\,\mathbf1^\top x\le T}F(x)
\;\ge\;\bigl(1-\tfrac1e\bigr)\,\Psi(S^\star),
\end{equation}
where \(S^\star\) is the optimal integral solution (cf.\ \cite{calinescu2011maximizing}).  Finally, pipage (or swap) rounding converts \(x^\star\) into a random integral set \(\hat S\in\mathcal M\) of size at most \(T\) without decreasing the expectation:
\begin{equation}
E[\Psi(\hat S)]\;=\;F(x^\star)
\;\ge\;\bigl(1-\tfrac1e\bigr)\,\Psi(S^\star).
\end{equation}
By Markov’s inequality there exists a deterministic \(\hat S\) with
\(\Psi(\hat S)\ge(1-\tfrac1e)\,\Psi(S^\star)\), completing the proof.

\end{proof}

\section{Implementation Details}
\subsection{Model Structure}
Our proposed MALinZero consists of 6 neural network modules, including the representation function \(h\), communication function \(e\), dynamic function \(g\), reward function \(r\), value function \(v\) and policy function \(p\). For each agent \(i\), let \(s_{t,k}^i\) be the latent state, \(a^i_{t+k}\) be the action, \(e^i_{t,k}\) be the cooperative feature and \(p^i_{t,k}\) be the policy prediction where \(k\) denotes the \(k\)-th rollout and \(t\) denotes the \(t\)-th real-world interaction step. Set \(r_{t,k}\), \(v_{t,k}\) as the predicted reward and value under the corresponding global hidden state. Specifically, the representation function \(s^i_{t,0}=h(o^i_{\le t})\) maps the current individual observation history \(o^i_{\le t}\) into the latent space, which enables the model could conduct planning without knowing the real-world rule. The communication function \(\{e^i_{t,k}\}_{i:1,\dots,n}=e\left(\{e^i_{t,k}\}_{i:1,\dots,n}, \{a^i_{t+k}\}_{i:1,\dots,n}\right)\) generates additional cooperative information for each agent in the multi-agent system via the attention mechanism, with the individual states and actions of agents as the input and the cooperative features as the output. The dynamic function \(s^i_{t,k+1}=g(s^i_{t,k},a^i_{t+k},e^i_{t,k})\) plays the role of obtaining state transition prediction. The reward function \(r_{t,k}=r\left(\{e^i_{t,k}\}_{i:1,\dots,n}, \{a^i_{t+k}\}_{i:1,\dots,n}\right)\) and value function \(v_{t,k}=v\left(\{e^i_{t,k}\}_{i:1,\dots,n}\right)\) predicts the reward and value for the global state-action tuple and global state, respectively. The policy distribution of each agent will be the output of the policy function \(p^i_{t,k}=p(s^i_{t,k})\) with the input of the current individual state. For the general strongly-convex and \(\mu\)-smooth function \(f\), we set \(f''(X_s - \langle \theta, A_s\rangle)=0.75\) if \(X_s - \langle \theta, A_s\rangle < 0\) and \(f''(X_s - \langle \theta, A_s\rangle)=1\) if \(X_s - \langle \theta, A_s\rangle \ge 0\).

For all these modules except the communication function \(e\), the neural networks are implemented by Multi-Layer Perception (MLP) networks, and a Rectified Linear Unit (ReLU) activation and Layer Normalization (LN) follows each linear layer in MLP networks. The input observations of all three mentioned benchmarks in the experiment section are 1-dimensional vectors with a hidden state size of 128. For the representation network \(h\), the last four local observations are treated as the input for each agent to deal with partial observability. And before representation, an LN is applied to normalize the observation features. The dynamic function applies a residual connection between the next hidden state and the current one to tackle the problem that gradients tend to zero in the continuous unrolling of the model. Additionally, we use the categorical representation in MuZero and make the use of an invertible transform \(f(x)=\operatorname{sign}(x)\sqrt{1+x}-1+0.001*x\) to scale targets for value and reward prediction.

Specifically, the number of hidden layers for all MLP modules is set as follows:
\begin{itemize}
\item \([128, 128]\) for Representation function \(h\).
\item \([128, 128]\) for Dynamic function \(g\). 
\item \([32]\) for Reward function \(r\), Value function \(v\) and Policy function \(p\).
\end{itemize}


\subsection{Training Details}
We build our training pipeline similar to EfficientZero \cite{efficientzero} which synchronizes parallel stages of data collection, reanalysis, and training. In programming, we assign different workers to deal with these tasks in the complete training pipeline. Additionally, we choose the same advantage score computation and loss function as MAZero \cite{MAZero}. All experiments are conducted using NVIDIA RTX A6000 GPUs or NVIDIA A100 GPUs.

For MatGame environments, we select the number of MCTS sampled actions as 3 and the number of MCTS simulations as 50. For both SMAC and SMACv2 benchmarks, we set it as 7 and the number of MCTS simulations as 100. We list other important hyper-parameters in Table \ref{LinZeroSetting}. 

\begin{table*}[h]
\centering
\setlength{\tabcolsep}{0.6mm}{
\scalebox{0.8}{
\begin{tabular}{@{}cc@{}}
\toprule\toprule
Hyper-Parameter & Value  \\ \hline
Optimizer      & Adam      \\
Learning rate      & \(10^{-4}\)      \\
RMSprop epsilon    & \(10^{-5}\) \\
Weight decay        & 0 \\
Max gradient norm   & 5\\
Evaluation episodes & 32 \\
Target network updating interval & 200\\
Unroll steps & 5\\
TD steps & 5\\
Min replay size for sampling & 300\\
Number of stacked observation & 4\\
Discount factor & 0.99 \\
Minibatch size & 256\\
Priority exponent & 0.6\\
Priority correction & 0.4 \(\to\) 1\\
Dynamic generation ratio & 0.6 \\
\(\lambda\) for initialization & \(10^{-4}\) \\
Quantile in MCTS value estimation & 0.75 \\
Decay lambda in MCTS value estimation & 0.8 \\
Exponential factor in Weighted-Advatage & 3 \\
\bottomrule\bottomrule
\end{tabular}}}
\caption{Hyper-parameters for MALinZero in MatGame, SMAC and SMACv2 environments}
\label{LinZeroSetting}
\end{table*}


\section{Details of Baseline Algorithms}
MAZero \cite{MAZero} and MAZero-NP are implemented based on the code: \url{https://github.com/liuqh16/MAZero} with hyper-parameters in Table \ref{MAZeroSetting}. MAZero-NP refers to MAZero without the prior information in the UCT bound while keeping other implementations the same. For MatGame environments, we select the number of MCTS sampled actions as 3 and the number of MCTS simulations as 50. For both SMAC and SMACv2 benchmarks, we set it as 7 and the number of MCTS simulations as 100. Hyper-parameters of MAZero and MAZero-NP is set as Table \ref{MAZeroSetting}.

MA-AlphaZero is implemented on the codebase of MAZero but replaces the UCT score with that of AlphaZero \cite{alphazero}. That is, MA-AlphaZero use the Q-value instead of the advantage score in UCT. The AlphaZero code can be found in \url{https://github.com/suragnair/alpha-zero-general}. Since the implementation is based on MAZero model structure, we use the same hyper-parameters in Table \ref{MAZeroSetting}.

\begin{table*}[h]
\centering
\setlength{\tabcolsep}{0.6mm}{
\scalebox{0.8}{
\begin{tabular}{@{}cc@{}}
\toprule\toprule
Hyper-Parameter & Value  \\ \hline
Optimizer      & Adam      \\
Learning rate      & \(10^{-4}\)      \\
RMSprop epsilon    & \(10^{-5}\) \\
Weight decay        & 0 \\
Max gradient norm   & 5\\
Evaluation episodes & 32 \\
Target network updating interval & 200\\
Unroll steps & 5\\
TD steps & 5\\
Min replay size for sampling & 300\\
Number of stacked observation & 4\\
Discount factor & 0.99 \\
Minibatch size & 256\\
Priority exponent & 0.6\\
Priority correction & 0.4 \(\to\) 1\\
Quantile in MCTS value estimation & 0.75 \\
Decay lambda in MCTS value estimation & 0.8 \\
Exponential factor in Weighted-Advatage & 3 \\
\bottomrule\bottomrule
\end{tabular}}}
\caption{Hyper-parameters for MAZero, MAZero-NP and MA-AlphaZero in MatGame, SMAC and SMACv2 environments}
\label{MAZeroSetting}
\end{table*}


QMIX \cite{QMIXmixmab} is implemented based on the code: \url{https://github.com/oxwhirl/pymarl} with hyper-parameters in Table \ref{qmix_parameters} 

\begin{table*}[h]
\centering
\setlength{\tabcolsep}{0.6mm}{
\scalebox{0.8}{
\begin{tabular}{@{}cc@{}}
\toprule\toprule
Hyper-Parameter & Value  \\ \hline
Optimizer & RMSProp \\
Learning rate for actors & \(5 \times10^{-4}\) \\
Learning rate for critics & \(5 \times 10 ^{-4}\) \\
Initial \(\epsilon\) & 1.0 \\
Final \(\epsilon\) & 0.05 \\
Batch size &  32\\
Buffer size & 5000\\
Discount factor & 0.99 \\
Exploration noise & 0.1 \\

\bottomrule\bottomrule
\end{tabular}}}
\caption{Hyper-parameters for QMIX in MatGame, SMAC and SMACv2 environments}
\label{qmix_parameters}
\end{table*}


MAPPO \cite{mappo} is implemented based on the code: \url{https:// github.com/marlbenchmark/on-policy}. The specific hyper-parameters can be found in Table \ref{mappo_parameters}. 

\begin{table*}[!htb]
\centering
\setlength{\tabcolsep}{0.6mm}{
\scalebox{0.8}{
\begin{tabular}{@{}cc@{}}
\toprule\toprule
Hyper-Parameter & Value  \\ \hline
Optimizer & Adam \\
RMSprop epsilon & \(10^{-5}\) \\
Learning rate & \(5\times 10 ^{-4}\) \\
Recurrent data chunk length & 10 \\
Gradient clipping & 10 \\
GAE parameter & 0.95 \\
Discount factor & 0.99 \\
Value loss & huber loss, with delta 10 \\
Batch size & buffer length \(\times\) number of agents\\
\bottomrule\bottomrule
\end{tabular}}}
\caption{Hyper-parameters for MAPPO in MatGame, SMAC and SMACv2 environments}
\label{mappo_parameters}
\end{table*}


\section{Settings of Benchmarks}
\paragraph{MatGame} We test our proposed MALinZero and other baseline algorithms on MatGame with two different modes: (1) Linear mode, where the joint reward is the sum of agents' indexes in the system; (2) Non-linear mode, where a noise is added to the joint reward in the corresponding linear mode. For each joint reward, the noise is the sum of a Gaussian term \(u\sim\mathcal{N}(0,2^2)\) and a uniform term \(v \sim \mathcal{U}(-3, 3)\).  

\paragraph{SMAC}
The implementation and settings of SMAC environments are based on \url{https://github.com/oxwhirl/smac}. We chose three different maps containing a small, medium, and large number of agents, respectively. Experiments on each map is conducted under 3 different random seeds for the reproducibility of results. 

\paragraph{SMACv2}
The implementation and settings of SMACv2 environments are based on \url{https://github.com/oxwhirl/smacv2}. For each SMACv2 map in the experiment part, we randomize heterogeneous unit types and start positions for each games even in the same map to make the environment more challenging. Additionally, the unit sight and attack ranges are changed from SMAC to increase the diversity of agents.


































