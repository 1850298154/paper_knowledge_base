

Focusing on continuous allocations, we ask what properties of aggregators guarantee $\Delta R > 0$. We draw  on the concept of Schur-convexity. Schur-convex functions can be understood as generalizing symmetric, convex aggregators: every convex and symmetric function is Schur-convex, but a Schur-convex function is not necessarily convex \citep{roberts1974convex, peajcariaac1992convex}. Proofs for all results are available in \autoref{appendix:formal_analysis}.

Since both the outer aggregator $U$ and the task-level aggregators $T_j$ are non-decreasing, an optimal effort allocation will always have each agents' efforts summing to $1$. Hence, from here on, we \textbf{assume} without loss of generality that $\sum_{j=1}^{M} r_{ij} = 1$. We call such allocations \textbf{admissible}. 


\begin{definition}[Majorization]
\label{def:majorization}
Let \(x=(x_1,\dots,x_N)\) and \(y=(y_1,\dots,y_N)\) be two vectors in \(\mathbb{R}^N\) such that $\sum_{i=1}^N x_{(i)} = \sum_{i=1}^N y_{(i)}$. Let \(x_{(1)} \ge x_{(2)} \ge \cdots \ge x_{(N)}\) and \(y_{(1)} \ge y_{(2)} \ge \cdots \ge y_{(N)}\) be the components of \(x\) and \(y\) sorted in descending order. We say that \(x\) \emph{majorizes} \(y\) (written \(x \succ y\)) if
\(
\sum_{i=1}^k x_{(i)} \ge \sum_{i=1}^k y_{(i)}\) for \( k = 1,2,\dots, N-1,N.
\)
\end{definition}

% Occasionally, the relation in Definition \ref{def:majorization} is called ``weak majorization'', with majorization further requiring $\sum_{i=1}^N x_{(i)} = \sum_{i=1}^N y_{(i)}$. In this work, we do not assume equality of sums.

\begin{definition}[Schur-Convex Function]
A symmetric function \(f:\mathbb{R}^N \to \mathbb{R}\) is \emph{Schur-convex} if for any two vectors \(x,y \in \mathbb{R}^N\) with \(x \succ y\), we have
\(
f(x) \ge f(y).
\)
If the inequality is strict whenever \(x\) and \(y\) are not permutations of each other, then \(f\) is said to be \emph{strictly Schur-convex}. Similarly, \(f\) is \emph{Schur-concave} if \(f(x) \le f(y)\) whenever \(x \succ y\). 
\end{definition}

Intuitively, $x \succ y$ means one can obtain $y$ from $x$ by repeatedly moving mass from larger to smaller coordinates, thereby making the vector more uniform. Schur-convexity is then a statement on a function's  \textit{curvature}: $f$ is \emph{Schur-convex} if it increases with inequality, or is \emph{Schur-concave} if it increases with uniformity. We show here a connection between Schur-convexity (concavity) and $\Delta R$.

Call an allocation matrix $\mathbf A$ \emph{trivial} if there exists a task $j^\star$ such that every agent allocates its entire budget to that task, i.e.\ $r_{ij^\star}=B_{\max}$ and $r_{ij}=0\ \forall i,\; \forall j\neq j^\star$; otherwise $A$ is \emph{non-trivial}. Then:

\begin{theorem}[Positive \HeterogeneityGap via Schur-convex Inner Aggregators]
\label{thm:heterogeneity-gap-schurconvex}
% Let $N,M \ge 2$, and consider a reward function
% \[
%   R(\mathbf{A})
%   \;=\;
%   U\bigl( T_1(\mathbf{a}_1),\dots,T_M(\mathbf{a}_M) \bigr),
%   \quad
%   \text{where each } \mathbf{a}_j = \bigl(r_{1j},\dots,r_{Nj}\bigr)^\top.
% \]
Let $N,M \ge 2$, and assume that (i) each \emph{task‐level aggregator} $T_j$ is strictly Schur-convex and (ii) the \emph{outer aggregator} $U$ is coordinate-wise strictly increasing.  Then either all admissible optimal homogeneous allocations are trivial, or $\Delta R > 0$. 
% \begin{enumerate}[label=(\roman*)]
% \item 
% Each \emph{task‐level aggregator} $T_j$ is strictly Schur-convex. 
% \item 
% The \emph{outer aggregator} $U$ is strictly increasing in each coordinate.
% \end{enumerate}

% Furthermore, assume that in the best homogeneous solution, at least two tasks receive nonzero allocations. Then  
% \(
%   \Delta R
%   \;=\;
%   R_{\mathrm{het}} - R_{\mathrm{hom}}
%   \;>\;
%   0.
% \)
\end{theorem}

If the task-level aggregator is instead Schur-concave, we can show there is no \heterogeneitygap:

\begin{theorem}[No \HeterogeneityGap via Schur-concave Inner Aggregators]
\label{thm:heterogeneity-gap-schurconcave}
Let $N,M \ge 2$. If each task‐level aggregator $T_j$ is \emph{Schur-concave} then 
\(
\Delta R 
   \;=\;
   0.
\)
\end{theorem}


% We see then that Schur-convexity is a property of the inner aggregator that induces a positive \heterogeneitygap ($\Delta R > 0$), and Schur-concavity implies no gain. What about the outer aggregator $U$? Here, the notion of Schur-convexity or Schur-concavity is tricky to apply directly, since $U$ receives as its argument vectors of the form  $\bigl(T_1(\mathbf{a}_1) , \ldots T_M(\mathbf{a}_m) )$ for different effort allocations $\textbf{a}$, and $\sum_1^M T_i(\mathbf{a}_i)$ can vary, which means task scores are incomparable in terms of majorization. However, if we select our inner aggregators such that $\sum_1^M T_i(\mathbf{a}_i)$ always equals some constant $C$ (e.g., by normalizing the task-level rewards), we can investigate the relationship between the outer aggregator and heterogeneity from the lens of Schur-convexity. In particular, the relationship is the reverse of what it was for inner aggregators: when the outer aggregator is Schur-convex, the \heterogeneitygap is $0$. Let us prove this. 

We see that Schur-convexity of the inner aggregator produces \( \Delta R > 0 \), whereas Schur-concavity implies \( \Delta R = 0 \). Analyzing the outer aggregator \( U \) is trickier, because it acts on task-score vectors \(\bigl(T_{1}(\mathbf a_{1}), \dots, T_{M}(\mathbf a_{M})\bigr)\) whose sum \( \sum_{i=1}^{M} T_{i}(\mathbf a_{i}) \) may vary, so majorization is not directly applicable. However, we can extend our analysis to $U$ if our inner aggregators are \textit{normalized} to keep the sum constant: \(\sum_{i=1}^{M} T_{i}(\mathbf a_{i}) = C\) for any admissible allocation. Assuming this, we can  invoke majorization again, and the relationship between convexity and $\Delta R$ reverses: if the outer aggregator \( U \) is Schur-convex, the \heterogeneitygap vanishes. Let us prove this.

\begin{theorem}[No \HeterogeneityGap for Schur-Convex $U$ with Constant-Sum Task Scores]
\label{thm:no-gap-schurconvex-outer-detailed}
Let $N,M \ge 2$.  Suppose that for any admissible  allocation $\mathbf{A}$, (i) every task score is non-negative, and obeys $T_i(0, \ldots, 0) = 0$, and (ii)  the sum of task score is always
\(
  \sum_{j=1}^M T_j\bigl(\mathbf{a}_j\bigr) \;=\; C
\). If  $U$ is \emph{strictly Schur-convex} function, then 
\(
  \Delta R = 0.
\)
\end{theorem}

\textbf{Sum-Form Aggregators.} In \autoref{appendix:sumform_aggregators}, we show that the above results reduce to a simple convexity test for \textit{sum-form aggregators}: a broad class of aggregators that describes most reward structures we consider in this work. This makes testing whether $\Delta R > 0$ a simple computation in many cases.

\input{sections/parametrizedaggregators}



% \section{Discounted Rewards Over a Time Horizon}
% \label{sec:rl_transition}

% The framework introduced in the Problem Formulation section describes a static optimization problem where agents simultaneously choose their effort allocation \( \mathbf{r}_i = (r_{i1}, \ldots, r_{iM}) \) across tasks, forming the matrix \( \mathbf{A} \). The overall reward \( R(\mathbf{A}) \) is then calculated based on this joint allocation. However, many real-world multi-agent systems operate dynamically over time. To connect our above analysis to such settings, we can consider an action space such at time \( t \), agent $i$ puts $r_{ij,t}$ effort into task $j$. We can then consider, at every time step $t$, the corresponding instantaneous allocation matrix \( \mathbf{A}_t \). The reward given to the agents at time $t$ is then $R_t = R(\mathbf{A}_t) = \outeragg_{j=1}^M \inneragg_{i=1}^N r_{ij,t}$.

% In this temporal setting, agents' effort allocations are dependent on their policy \( \pi_i \), and their goal is to maximize the expected discounted sum of future rewards:
% \[
% J(\{\pi_i\}_{i=1}^N) = \mathbb{E}_{\{\pi_i\}, P} \left[ \sum_{t=0}^\infty \gamma^t R_t \right],
% \]
% where \( \gamma \in [0, 1) \) is the discount factor and \( P \) denotes the state transition dynamics (if any). This reward structure is directly applicable to reinforcement learning tasks, and in our experiments, we shall show that it allows one to predict the \heterogeneitygap in such settings.
