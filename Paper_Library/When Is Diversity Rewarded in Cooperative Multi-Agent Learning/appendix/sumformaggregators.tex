\section{Sum-Form Aggregators}
\label{appendix:sumform_aggregators}

Many useful reward functions are  \textit{sum-form aggregators}:

% If our aggregators can be expressed simply as \textit{sums of functions}, we can extend our analysis to conventional convexity and concavity by carefully examining how individual task-level reward functions and the outer aggregator influence the \heterogeneitygap. Concretely, let us define:

\begin{definition}[Sum-Form Aggregator]
\label{def:sum_task_agg}
A task-level aggregator $f:  \mathbb{R}^N \to \mathbb{R}$ for task $j$ is a \textbf{sum-form aggregator} if it can be written as:
\(
f(\mathbf{x}_j) 
\;=\;
\sum_{i=1}^{N} g(x_{j}),
\)
where $g_{j}:\mathbb{R}\to\mathbb{R}$ is differentiable. We say $f$ is (strictly) \emph{convex or concave} if $g$  is (strictly) convex or concave, respectively.
\end{definition}


\autoref{tab:param-agg-extended} contains examples. When our aggregators have this form, Schur-convexity (concavity) is determined by whether $g$ is convex (concave)--a simple computational test.   This is because of the following \textit{known} connection between sum-form aggregators and Schur-convexity/concavity: 



\begin{lemma}[Schur Properties of Sum-Form Aggregators \citep{peajcariaac1992convex}]
\label{lemma:schur_sum_form}
Given sum-form task-level aggregator $f(\mathbf{x}) = \sum_{i=1}^{N} g(x_i)$, the following holds: \textbf{\emph{(i)}} if $g$ is (strictly) convex, then $f$ is (strictly) Schur-convex; and \textbf{\emph{(ii)}}  if $g$ is (strictly) concave, then $f$ is (strictly) Schur-concave.
\end{lemma}

This lemma simplifies checking the conditions of our \heterogeneitygap results. For example, the following corollary can be used to establish $\Delta R > 0$ for many of the aggregators in \autoref{tab:param-agg-extended}:

\begin{corollary}[Convex-Concave Positive \HeterogeneityGap]
\label{prop:concavity_forces_multi_task}
Let $N,M \ge 2$. Let $g:[0,1]\to\mathbb{R}_{\ge 0}$ be a non-negative strictly convex function satisfying $g(0)=0$, and let $h:\mathbb{R}_{\ge 0}\to\mathbb{R}$ be a strictly concave, increasing function satisfying $h(0)=0$. If each task-level aggregator is a strictly convex sum-form aggregator  
\(
  T_j(\mathbf{a}_j)
  \;=\;
  \sum_{i=1}^N g\bigl(r_{ij}\bigr)
\), and the outer aggregator is a strictly concave sum-form aggregator $U(\mathbf{y}) = \sum_{j=1}^M h(y_j)$, then 
\(
  \Delta R > 0
\).

%, and in the optimal allocation, each agent puts effort $1$ on a different task.
\end{corollary}

\begin{proof}[Proof of \autoref{prop:concavity_forces_multi_task}]
We will apply Theorem~\ref{thm:heterogeneity-gap-schurconvex} by verifying its conditions:

First, by Lemma~\ref{lemma:schur_sum_form}, since $g$ is strictly convex, the (identical) task-level aggregators $T_j(\mathbf{x}) = \sum_{i=1}^{N} g(x_i)$ are strictly Schur-convex, satisfying condition (i) of Theorem~\ref{thm:heterogeneity-gap-schurconvex}.

Second, the outer aggregator $U(y_1,\ldots,y_M)$ is strictly increasing at every coordinate by definition, satisfying condition (ii).

Hence, the conditions of \autoref{thm:heterogeneity-gap-schurconvex} apply. To establish $\Delta R > 0$, it remains to verify that the optimal allocation is non-trivial: it distributes effort across at least two tasks. In any  admissible \emph{homogeneous} solution, each of the $N$ agents chooses the same effort‐distribution $(c_1,\dots,c_M)$ on tasks, with $\sum_j c_j=1$.  
Then task $j$’s reward is $T_j=N\,g(c_j)$, so
\(
  R(\mathbf{A})
  \;=\;
  \sum_{j=1}^M h\!\bigl(N\,g(c_j)\bigr).
\)
The trivial, \emph{all-agent single‐task allocation} uses $(c_j=1,c_{k\neq j}=0)$.  Its reward is therefore 
\(
  R_{\text{corner}}
  =
  h\!\bigl(N\,g(1)\bigr)
  + 
  \sum_{k\neq j} h\bigl(N\,g(0)\bigr)
  =
  h\!\bigl(N\,g(1)\bigr)
\)
since $g(0)=0$ and $h(0)=0$.

Strict concavity of $h$ implies that $h\!\bigl(N\,g(1)\bigr) < N \cdot h(g(1))$. Hence, agents can attain a better reward by allocating effort $1$ to $N$ different tasks rather than a single task. This shows that  the best solution \emph{must} use at least two nonzero $c_j$, completing the proof. 
\end{proof}
