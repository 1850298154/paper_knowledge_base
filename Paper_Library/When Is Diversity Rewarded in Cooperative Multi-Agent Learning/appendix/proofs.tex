\section{Formal Analysis}
\label{appendix:formal_analysis}
\subsection{Proof of \autoref{thm:heterogeneity-gap-schurconvex}}
\begin{proof}[Proof of \autoref{thm:heterogeneity-gap-schurconvex}] Let $\mathbf{A}_{\mathrm{hom}}$ be an optimal homogeneous allocation (i.e., $R(A_{hom}) = R_{hom}$), whose $i$th row is the vector 
\[
  \mathbf{c} \;=\; (c_1,\dots,c_M) \quad \text{with} \quad \sum_{j=1}^M c_j = 1.
\]
Then each column $j$ of $\mathbf{A}_{\mathrm{hom}}$ is the uniform vector 
\(
  \mathbf{u}_j \;=\; (c_j,c_j,\dots,c_j)^\top \;\in \mathbb{R}^N.
\)
Hence the task‐level reward is $T_j(\mathbf{u}_j)$, and the overall reward is
\[
R\bigl(\mathbf{A}_{\mathrm{hom}}\bigr) = U\!\bigl(T_1(\mathbf{u}_1),\dots,T_M(\mathbf{u}_M)\bigr).
\]

Because $\sum_j c_j=1$, there is at least one task $j$ with $c_j > 0$. We construct a heterogeneous allocation $A_{het}$ such that each column $x_j$ in $A_{het}$ has the same sum as the corresponding column in $A_{hom}$. 

The total effort allocated to a task $j$ can be expressed as $\lfloor N c_j \rfloor + f_k$, where  $0 \leq f_j < 1$. First, we assign $\lfloor N c_j \rfloor$ agents to allocate effort $1$ to task $j$, for every task $j$. These agents are all distinct. This leaves us with $\sum_j f_j~=~N~-~\sum_j \lfloor N c_j \rfloor$ agents that have not allocated any effort yet. Let $i$ be the first of those agents. We have agent $i$ allocate $f_1$ effort to task $1$, $f_2$ effort to task $2$, and so on, until we arrive at a task $k$ such that $f_1 + \ldots + f_k = 1 + s$, for some $s > 0$. We have $i$ allocate $f_k - s$ to this task $k$. Then, we move to agent $i+1$, and allocate the remaining fractional efforts in the same manner (and in particular, allocating $s$ effort to task $k$), until agent $i+1$ overflows. Then we move to agent $i+2$, and so on. This ensures that we have allocated $N$ effort in total across the agents, and that every agent's effort allocation sums exactly to $1$, so is feasible.

Let $x_j$ be the $j$th column of $A_{het}$. We note the following fact: any non-uniform vector whose sum is $Nc_j$ majorizes the uniform vector $u_j$. Hence, $T_j(x_j) \geq T_j(u_j)$, with equality only if $x_j = u_j$.  This means that if $A_{het} \neq A_{hom}$, then 

\[
  R\bigl(\mathbf{A}_{\mathrm{het}}\bigr)
  \;=\;
  U\!\bigl(T_1(\mathbf{x}_1),\dots,T_M(\mathbf{x}_M)\bigr)
  \;>\;
  U\!\bigl(T_1(\mathbf{u}_1),\dots,T_M(\mathbf{u}_M)\bigr)
  \;=\;
  R\bigl(\mathbf{A}_{\mathrm{hom}}\bigr).
\]

We note that $A_{hom} = A_{het}$ only if $A_{hom}$ is a trivial allocation, as $A_{het}$ contains at least one agent allocating effort $1$ to some task, and $A_{hom}$'s agents only allocate fractional efforts, if it is non-trivial. Otherwise, since $R(A_{hom}) = R_{hom}$, the above inequality implies \(\Delta R = R_{\mathrm{het}} - R_{\mathrm{hom}} > 0 \). This completes the proof.  
\end{proof}

\subsection{Proof of \autoref{thm:heterogeneity-gap-schurconcave}}

\begin{proof}[Proof of \autoref{thm:heterogeneity-gap-schurconcave}]
Let $\mathbf{A}$ be an arbitrary feasible allocation, and let $\mathbf{A}_{\mathrm{hom}}$ be a \emph{homogeneous} allocation with the same column sums.  Concretely, for each column $j$, define
\[
  s_j
  \;=\;
  \sum_{i=1}^N r_{ij}
  \quad\text{and}\quad
  \mathbf{u}_j
  \;=\;
  \bigl(\tfrac{s_j}{N},\tfrac{s_j}{N},\dots,\tfrac{s_j}{N}\bigr)^\top,
\]
so $\mathbf{u}_j$ is the \emph{uniform} distribution of total mass $s_j$ across $N$ agents.  
Then construct
\[
  \mathbf{A}_{\mathrm{hom}}
  \;=\;
  \begin{pmatrix}
  \tfrac{s_1}{N} & \cdots & \tfrac{s_M}{N} \\
  \vdots & \ddots & \vdots\\
  \tfrac{s_1}{N} & \cdots & \tfrac{s_M}{N}
  \end{pmatrix},
\]
which is clearly \emph{homogeneous} (each row is the same), and respects each column sum $s_j$. Since $\sum_j s_j = N$, each row sums to $1$, hence the allocation is feasible.  By Schur‐concavity of $T_j$, for each column $j$ we have
\[
  \mathbf{a}_j \;\succ\; \mathbf{u}_j
  \quad\Longrightarrow\quad
  T_j(\mathbf{a}_j) 
  \;\leq\;
  T_j(\mathbf{u}_j),
\]
unless $\mathbf{a}_j$ is $\mathbf{u}_j$.  
In other words, \emph{any} deviation from the uniform vector with the same sum \(\sum_{i=1}^N a_{ji} = s_j\) will not increase $T_j(\mathbf{a}_j)$ under Schur‐concavity. Hence for each column $j$ of $\mathbf{A}$, 
\(
  T_j(\mathbf{a}_j) 
  \;\le\;
  T_j(\mathbf{u}_j),
\).
Since $U$ is non-decreasing in each coordinate, 
\[
  R\bigl(\mathbf{A}\bigr)
  \;=\;
  U\!\bigl(T_1(\mathbf{a}_1),\dots,T_M(\mathbf{a}_M)\bigr)
  \;\le\;
  U\!\bigl(T_1(\mathbf{u}_1),\dots,T_M(\mathbf{u}_M)\bigr)
  \;=\;
  R\bigl(\mathbf{A}_{\mathrm{hom}}\bigr).
\]
 This implies 
\(
  \Delta R 
  \;=\;
  0.
\)
\end{proof}

\subsection{Proof of \autoref{thm:no-gap-schurconvex-outer-detailed}}


\begin{proof}[Proof of \autoref{thm:no-gap-schurconvex-outer-detailed}]

By hypothesis, the components of the task score vector 
\[
  \textbf{T}(\textbf{A}) = \Bigl(T_1(\mathbf{a}_1),\,T_2(\mathbf{a}_2),\,\dots,\,T_M(\mathbf{a}_M)\Bigr)
\]
always  sum to $C$. By strict Schur-convexity, the maximum value of $U$ over such vectors is attained precisely at an extreme point of the $C$-simplex, i.e.\ at some permutation of $(C,0,\ldots,0)$. Hence, we seek to find an allocation of efforts, $\mathbf{A}_{\mathrm{corner}}$, that causes $\textbf{T}(\textbf{A})$ to equal this vector.

Let each agent $i$ invest \emph{all} of its effort into task~1. This is the trivial allocation.  Then the first column of $\mathbf{A}_{\mathrm{corner}}$ is
\((1,1,\dots,1)^\top\),
and all other columns $\mathbf{a}_j$ are zero.  Since task scores sum to $C$, we get 
\(
  T_1\bigl(\mathbf{a}_1\bigr)
  =
  C,
  \quad
  T_j\bigl(\mathbf{a}_j\bigr)
  =
  0
  \;\;\text{for }j\neq 1.
\)
By assumption (2), we infer that the vector of task-level scores is indeed $(C,0,\dots,0)$.  

Notice that \emph{each row of $A_{corner}$ is the same} $(1,0,\dots,0)$, making $\mathbf{A}_{\mathrm{corner}}$ a \emph{homogeneous} allocation. Hence, we attained the maximum possible reward $R(\textbf{A})$ through a homogeneous allocation, implying $\Delta R = 0$. 
\end{proof}

\subsection{Proof of \autoref{thm:gap_NeqM_softmax_hetgap}}

Before proving the statement, let's write the expressions for homogeneous and heterogeneous optima. For each task \( j \), we defined
\[
T_j(\mathbf{A})
=
\sum_{i=1}^N 
\frac{\exp\bigl(t \cdot r_{i j}\bigr)}{\sum_{\ell=1}^N \exp\bigl(t \cdot r_{\ell j}\bigr)}
\; r_{i j},
\]

while defining the outer aggregator to be 
\[
U\bigl(T_1(\mathbf{a}_1) , \ldots T_M(\mathbf{a}_m) )
=
\sum_{j=1}^M 
\frac{\exp\bigl(\tau \cdot T_j(\mathbf{A})\bigr)}
     {\sum_{\ell=1}^M \exp\bigl(\tau \cdot T_\ell(\mathbf{A})\bigr)}
\; T_j(\mathbf{A}),
\]

where \(t, \tau \in \mathbb{R}\) are temperature parameters. In the \textbf{homogeneous setting}, where all agents share the same allocation \(\mathbf{c} = (c_1,\dots,c_M)\), we therefore have
  \(
  T_j(\mathbf{A})
  =
  \sum_{i=1}^N 
    \frac{\exp\bigl(t\,c_j\bigr)}{\sum_{\ell=1}^N \exp\bigl(t\,c_j\bigr)}
  \; c_j
  =
  c_j.
  \)
  Thus,
  \[
  R_{\mathrm{hom}}
  =
  \max_{\mathbf{c} \,\in\, \Delta^{M-1}}
  \quad
  \sum_{j=1}^M 
  \frac{\exp\bigl(\tau\,c_j\bigr)}{\sum_{\ell=1}^M \exp\bigl(\tau\,c_\ell\bigr)}
  \; c_j
  \]

where $\Delta^{M-1}$ is the simplex of all admissible allocations. 

  In the general \textbf{heterogeneous setting}, each row \((r_{i1},\dots,r_{iM})\) can be
  different. Then
  \[
  T_j(\mathbf{A})
  \;=\;
  \sum_{i=1}^N 
  \frac{\exp\bigl(t\,r_{i j}\bigr)}{\sum_{\ell=1}^N \exp\bigl(t\,r_{\ell j}\bigr)} \;
  r_{ij},
  \]
  and we choose \(\mathbf{A}\in(\Delta^{M-1})^N\) to maximize
  \[
  R_{\mathrm{het}} 
  \;=\;
  \max_{\mathbf{A}} 
  \sum_{j=1}^M 
  \frac{\exp\bigl(\tau \,T_j(\mathbf{A})\bigr)}{\sum_{k=1}^M \exp\bigl(\tau\,T_k(\mathbf{A})\bigr)}
  \; T_j(\mathbf{A}).
  \]

Keeping these expressions in mind, we proceed with the proof of \autoref{thm:gap_NeqM_softmax_hetgap}.

\underline{Reminder:} assuming $N = M \geq 2$, we want to prove $\Delta R(t,\tau;N)=0$ when $t \leq 0$, and 
\[
\boxed{%
\Delta R(t,\tau;N)\geq
\begin{cases}
\sigma(t,N)-\dfrac1N, & t>0,\;\;\tau\le 0,\\[10pt]
\max\!\bigl\{\sigma(t,N)-\sigma(\tau,N),\,0\bigr\}, & t>0,\;\;\tau\ge 0.
\end{cases}}
\] otherwise, where 
\(\sigma(t,N)\;:=\;\frac{e^{t}}{e^{t}+N-1}.
\)

%--------------------------------------------------------
%  Proof of Theorem 4.4  (heterogeneity gap, soft-max / soft-max, N=M)
%--------------------------------------------------------

\begin{proof}[Proof of \autoref{thm:gap_NeqM_softmax_hetgap}]

When $t\le0$, $T_j$ is Schur–concave, so $\Delta R = 0$ by \autoref{thm:heterogeneity-gap-schurconcave}. We assume $t > 0$ for the rest of the proof.

\textit{Homogeneous optimum.}
If every row of $\mathbf A$ equals the same allocation
$\mathbf c\in\Delta^{N-1}$, then $T_j(\mathbf A)=c_j$. 
$U$ is Schur–concave for $\tau\le0$, and Schur–convex for $\tau\ge0$, hence it is maximized by the uniform distribution in the former case, and by a $1$-hot vector in the latter case, yielding:

\[
  R_{\mathrm{hom}}
  \;=\;
  \max_{\mathbf c\in\Delta^{N-1}}U(\mathbf c)
  \;=\;
  \begin{cases}
     \dfrac1N,          & \tau\le0,\\[6pt]
     \sigma(\tau,N),    & \tau>0.
  \tag{H}
  \end{cases}
\]

\textit{Lower bound on $R_{het}$.}
The \emph{trivial} allocation, where every agent works on the same task, produces 
$R_{\mathrm{trivial}}=\sigma(\tau,N)$.
The \emph{spread} allocation, where agent $i$ works exclusively on task $i$,
makes each column ``one-hot''; this gives
$T_j=\sigma(t,N)$ for all $j$, and plugging this into $U$, we get 
$R_{\mathrm{spread}}=\sigma(t,N)$.
Consequently

\[
  R_{\mathrm{het}}\;\ge\;\max\{\sigma(t,N),\,\sigma(\tau,N)\}.
\tag{L}
\]

Combining (H) and (L) gives the desired lower bound.
\end{proof}

\section{Deriving the $\{\min, \textnormal{mean}, \max\}$ heterogeneity gains in the \autoref{fig:deltaR-vs-softmax} table}

We derive these heterogeneity gain case-by-case. \autoref{tab:continuous-minmeanmax} summarizes the derivation for continuous allocations ($r_{ij} \in [0,1]$), and  \autoref{tab:discrete-minmeanmax} does the same for discrete effort allocations ($r_{ij} \in \{0,1\}$).

\input{appendix/minmaxmean_tables}