\appendix

\setcounter{theorem}{0}

\section*{Appendix}
We complement omitted proofs~(Sec.~\ref{sec:proof:solution}, \ref{sec:proof:complexity}, and \ref{sec:proof:dbs}), the detailed procedure of detecting potential cyclic deadlocks (Sec.~\ref{sec:detection-details}), additional results of stress test on random graphs (Sec.~\ref{sec:stress-test-random}), and the details of experimental setups (Sec.~\ref{sec:exp-detail}).

\section{Proof of Solution Analysis}
\label{sec:proof:solution}

\begin{theorem*}[\ref{thrm:necessary-sufficient}; necessary and sufficient condition]
  Given an OTIMAPP instance, a set of path $\{ \path{1}, \ldots, \path{N} \}$ is a feasible solution if and only if there are:
  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \item No reachable terminal deadlocks.
    \item No reachable cyclic deadlocks.
  \end{itemize}
\end{theorem*}
\begin{proof}
  Without ``no reachable terminal deadlocks,'' there is an execution that one agent arrives at its goal and remains there; disturbing the progression of another agent.
  Without  ``no reachable cyclic deadlocks,'' a cyclic deadlock might occur and those agents stop the progression.
  Hence those two are necessary.

  We now prove that the two conditions are sufficient. Given a solution candidate $\{ \path{1}, \ldots, \path{N} \}$ with no reachable deadlocks, consider the potential function $\phi \defeq \sum_{i \in A} (|\path{i}| - \clock_i)$ defined over a configuration $\{ \clock_1, \ldots, \clock_N \}$.
  Observe that $\phi$ is non-increasing and $\phi=0$ means that all agents have reached their goals.
  Furthermore, when $\phi > 0$, $\phi$ is guaranteed to decrease if each agent is activated at least once.
  We explain this as follows.

  Suppose contrary that $\phi (\neq 0)$ does not differ for the period.
  Since $\phi \neq 0$, there are agents whose progress indexes are less than the maximum values.
  Let them $B \subseteq A$.
  For an agent $i \in B$, \loc{i}{\clock_i+1} is occupied by another agent $j \in B$, according to ``no reachable terminal deadlocks,'' otherwise, $i$ moves there.
  This is the same for $j$, i.e., there is an agent $k \in B$ such that $\loc{j}{\clock_j+1} = \loc{k}{\clock_k}$.
  By induction, this sequence of agents must form a cycle somewhere, i.e., occurring a cyclic deadlock; however, this contradicts ``no reachable cyclic deadlocks.''

  Each agent is activated at least once in a sufficiently long period due to the fair assumption, deriving the statement.
\end{proof}

\section{Proofs of Computational Complexity}
\label{sec:proof:complexity}

\begin{theorem*}[\ref{thrm:np-hard-undirected}; complexity on undirected graphs]
  For OTIMAPP on \emph{undirected} graphs, it is NP-hard to find a feasible solution with \emph{simple} paths.
\end{theorem*}
\begin{proof}
  We add a new gadget, which makes an undirected edge to a virtually directed one, to the proof of the NP-hardness on digraphs (Thm.~\ref{thrm:np-hard-directed}).
  We derive the claim by replacing all directed edges, except for bidirectional edges, with this gadget.

  Figure~\ref{fig:3-sat-finding} (right) is it, including two new agents: $z_1$ and $z_2$.
  In this gadget, any agents outside of the gadget are allowed to move only the direction from $u$ to $v$.
  Assume contrary that, one agent ($\neq z_1, z_2$) takes a path through $v$ to $u$ within this gadget, and there is another path from $v$ to $u$.
  To avoid cyclic deadlocks, $z_1$ and $z_2$ must move toward the left side, exit the gadget from $u$, use another path to enter $v$, and eventually reach their goals.
  In these paths, $z_1$ can arrive at its goal earlier than that of $z_2$, contradicting ``no reachable terminal deadlocks'' in the necessary and sufficient condition (Thm.~\ref{thrm:necessary-sufficient}).
  Therefore, these paths are invalid.

  The size of the OTIMAPP instance is still polynomial on the 3-SAT formula.
  Thus, we conclude the statement.

  Note that, if we allow non-simple paths, it might be possible for other agents to move through the way from $v$ to $u$.
  This is because, even though $z_1$ and $z_2$ temporarily leave from the gadget via $u$, we can construct paths that $z_1$ always arrive at its goal after $z_2$'s arrival, as illustrated in Fig.~\ref{fig:undirected-counterexample}.
\end{proof}

\input{fig/undirected-counterexample}
\input{fig/3-sat-deadlocks}
\input{fig/3-sat-deadlocks-detail}

\begin{lemma*}[\ref{lemma:deadlock-np-comp}; complexity of detecting cyclic deadlocks]
  Determining whether a set of paths contains either reachable or potential cyclic deadlocks is NP-complete.
\end{lemma*}
\begin{proof}
  The proof is a reduction from the 3-SAT problem, i.e., constructing a combination of an OTIMAPP instance and a set of paths such that potential cyclic deadlocks exist if and only if the corresponding formula is satisfiable.
  We show the case of directed graphs.
  The proof procedure applies to the undirected case without modifications.
  In addition, all potential cyclic deadlocks are reachable in the translated problem.
  The reduction is done in polynomial time, deriving the NP-hardness of detecting both reachable and potential cyclic deadlocks.
  Since a potential cyclic deadlock can be verified in polynomial time, and since a reachable cyclic deadlock can be verified in polynomial time with an execution schedule, they are NP-complete.

  We now explain how to translate the 3-SAT formula to the OTIMAPP instance and the corresponding set of paths.
  Without loss of generality, we assume that all variables appear positively and negatively in the formula.
  Throughout the proof, we use the following example.
  \begin{align*}
    (x_1 \lor x_2 \lor \lnot x_3) \land (\lnot x_1 \lor x_2 \lor x_3) \land (x_1 \lor \lnot x_2 \land \lnot x_3)
  \end{align*}
  Its outcome is partially depicted in Fig.~\ref{fig:3-sat-deadlocks}.
  The complete version is presented in Fig.~\ref{fig:3-sat-deadlocks-detail}.

\medskip
\noindent
\emph{A. Construction of an OTIMAPP instance and a set of paths}
For each literal in each clause, one \emph{literal agent} is introduced.
We denote by $c^j_k$ a literal agent for the $k$-th literal in $j$-th clause $C^j$ in the formula.
We also use one special agent $z$.

Next, consider two gadgets: \emph{variable decider} and \emph{clause constrainer}.
Note that they are different from those used in the proof of Thm.~\ref{thrm:np-hard-directed};
however, their intuitions are similar and we use the same names.

The variable decider determines whether a variable $x_i$ occurs positively or negatively.
For each variable one gadget is introduced.
All literal agents for $x_i$ (i.e., either $x_i$ or $\lnot x_i$) start from vertices in this gadget.
The gadget contains two paths: an \emph{upper} path, corresponding to assign true to $x_i$, and a \emph{lower} path, corresponding to assign false to $x_i$.
Positive literals are connected to the upper path.
Negative literals are connected to the lower path.
For instance, $x_2$ has three literal agents: $c^1_2$ ($x_2$), $c^2_2$ ($x_2$), and $c^3_2$ ($\lnot~x_2$).
In Fig.~\ref{fig:3-sat-deadlocks}, we highlight the upper and the lower paths by bold lines.
$c^1_2$ and $c^2_2$ are connected to the upper path while $c^3_2$ is connected to the lower path.
Each literal agent uses one edge in the upper/lower path and moves to a clause constrainer via one \emph{vacation} vertex.

The clause constrainer contains all goals of the literal agents in the clause.
Three edges are used to reach the goals.
Each edge is for each literal agent.
For instance, the clause constrainer of $C^2$ contains the goals of $c^2_1$, $c^2_2$, and $c^2_3$.
In Fig.~\ref{fig:3-sat-deadlocks}, three edges are annotated with the agent's name.
$c_2^2$ is supposed to use the colored middle one.
Note that we use multiple edges for simplicity.
It is not hard to convert the gadget to a simple graph version, as shown immediately later of this proof.

As a result, all literal agents take six edges to reach their goals.
This is visualized by colored edges in Fig.~\ref{fig:3-sat-deadlocks} and Fig.~\ref{fig:3-sat-deadlocks-detail}.
The special agent~$z$ uses two edges to reach its goal, through $\clubsuit$ marks in the figure.
We finish the description of how to construct the OTIMAPP instance and the corresponding set of paths.
The remaining part is to show these paths contain potential/reachable cyclic deadlocks if and only if the formula is satisfiable.
This translation from the formula is clearly done in polynomial time.

\newcommand{\true}{\m{\mathit{true}}}
\newcommand{\false}{\m{\mathit{false}}}

\medskip
\noindent
\emph{B. A potential cyclic deadlock exists if the formula is satisfiable.}
To see this, observe that if a potential cyclic deadlock exists, agents must try to use;
(a)~either an upper or a lower path for each variable decider,
(b)~one edge for each clause constrainer, and
(c)~the edge for $z$ ($\clubsuit$).

\input{fig/3-sat-deadlocks-steps}

When the formula is satisfiable for one assignment, consider the following execution.
\begin{enumerate}
\setlength{\itemsep}{0pt}
\item For each assigned value, move the corresponding clause agents to vacation vertices in each variable decider, i.e., one step before clause constrainers.
\item Among the above agents, for each clause constrainer, there is at least one agent that can enter the clause constrainer due to satisfiability.
  Move them one step further.
  As a result, all clause constrainers have one agent at the first vertices.
  Vertices in upper/lower paths in the variable deciders must be vacant now.
\item Move all unassigned clause agents one step.
  As a result, all vertices in the unassigned paths are filled by the unassigned clause agents.
\end{enumerate}
\noindent
We now have a cyclic deadlock, i.e., this deadlock is reachable thus potential.

As an example, consider a satisfiable assignment $x_1=\true$, $x_2=\true$, $x_3=\true$.
In the beginning, move assigned agents, $c^1_1$, $c^1_2$, $c^2_2$, $c^2_3$, and $c^3_1$ to vacation vertices in each variable decider (Fig.~\ref{fig:3-sat-deadlocks-steps}; Step 1).
Next, move $c^1_2$, $c^2_2$, and $c^3_1$ to the first vertices of each clause constrainer of $C^1$, $C^2$, and $C^3$, respectively (Fig.~\ref{fig:3-sat-deadlocks-steps}; Step 2).
Then, move all unassigned agents, $c^2_1$, $c^3_2$, $c^1_3$, and $c^3_3$, one step (Fig.~\ref{fig:3-sat-deadlocks-steps}; Step 3).
There is a cyclic deadlock with $c^2_1, c^3_2, c^1_3, c^3_3, c^1_2, c^2_2, c^3_1$, and $z$, annotated with bold lines in Fig.~\ref{fig:3-sat-deadlocks-steps}.

\medskip
\noindent
\emph{C. The formula is satisfiable if a potential cyclic deadlock exists.}
To form a potential cyclic deadlock, for each variable decider, one or several agents try to move along either an upper or a lower path.
Consider assigning an opposite value against the used path to the variable.
For instance, if $c^1_2$ and $c^2_2$ involve in the deadlock at the variable decider (see Fig.~\ref{fig:3-sat-deadlocks}), then assign \false to $x_2$.
This assignment must satisfy the formula because at least one literal in each clause becomes true; otherwise, at least one clause constrainer exists such that the first vertex is empty, i.e., no deadlock.

\medskip
\noindent
\emph{D. All potential cyclic deadlocks are reachable.}
So far, we established the claim that a potential cyclic deadlock exists if and only if the formula is satisfiable.
Next, we claim that all potential cyclic deadlocks are reachable.
According to the above discussion, given a potential cyclic deadlock, the corresponding satisfiable assignment exists.
Consider the execution of Part~B using this assignment, slightly changing Step~2.
In this step, we can choose arbitrary agents for each clause constrainer.
Therefore, it is possible to choose agents involved in the potential cyclic deadlock.
As a result, this deadlock is reachable.
%
\end{proof}

\input{fig/3-sat-multiple-edge}

In the proof of Lemma~\ref{lemma:deadlock-np-comp}, we used multiple edges in a gadget \textit{clause constrainer} for the reduction from 3-SAT.
Since OTIMAPP assumes a simple graph (i.e., no multiple edges), we complement how to convert it to a \emph{correct} OTIMAPP instance.
Figure~\ref{fig:3-sat-multiple-edges} shows an example of the clause constrainer for $C^2$.
Recall that a clause constrainer contains all goals for the corresponding clause agents.
In this new gadget, we add intermediate vertices for each edge that potentially leads to cyclic deadlocks.
For each agent $c^j_k$, a new agent $\hat{c}^j_k$ is introduced.
Its start is the intermediate vertex.
Its goal is the original goal of $c^j_k$.
We furthermore change a goal for $c^j_k$ to starts of $\hat{c}^j_k$.
Consider now replacing all old clause constrainers with this new gadgets.
The translation is done in polynomial time.
The rest of the proof is straightforward from Lemma~\ref{lemma:deadlock-np-comp}.

\section{Detecting Potential Cyclic Deadlocks}
\label{sec:detection-details}

\input{algo/deadlock-detection}

Using fragments, Alg.~\ref{algo:detecting-deadlock} detects a potential cyclic deadlock in a set of paths if exists.
The intuition is the following:
(1)~the algorithm checks each path one by one,
(2)~it stores all fragments created so far,
(3)~for each edge in each path, it creates new fragments using existing fragments, and
(4)~if a fragment ends at its start, this is a potential cyclic deadlock.
We describe the details in the proof of the completeness.

\begin{theorem}[completeness]
  Alg.~\ref{algo:detecting-deadlock} finds one potential cyclic deadlock if exists, otherwise returns \textbf{NONE}.
\end{theorem}
\begin{proof}
  The algorithm uses two tables that store fragments: \tablefrom and \tableto.
  Both tables take one vertex as a key.
  One entry in \tablefrom stores all fragments starting from the vertex.
  One entry in \tableto stores all fragments ending at the vertex.
  A fragment is registered in both tables.
  We now derive the statement by induction on \path{i}.

  \medskip
  \noindent
  \emph{Base case}:
  At the first iteration of the loop [Line~\ref{algo:deadlock:for-agents}--\ref{algo:deadlock:for-agents-end}], all fragments for $\{ \path{1} \}$ are registered on \tablefrom and \tableto due to Line~\ref{algo:deadlock:add-own}--\ref{algo:deadlock:add-own:register}.
  There are no potential cyclic deadlocks for $\{ \path{1} \}$.

  \medskip
  \noindent
  \emph{Induction Hypothesis}:
  Assume that there are no potential cyclic deadlocks for $\{ \path{1}, \ldots, \path{i-1} \}$ and all fragments for them are registered on \tablefrom and \tableto.

  \medskip
  \noindent
  \emph{Induction Step}:
  We now show the property for $i$; otherwise, a potential cyclic deadlock exists for $\{ \path{1}, \ldots, \path{i} \}$ and the algorithm returns it.
  All new fragments about \path{i} are categorized into two:
  (1)~a fragment only with \path{i} or
  (2)~a fragment that extends other fragments on \tablefrom and \tableto, using $(u, v) \in \path{i}$.
  The former is preserved due to Line~\ref{algo:deadlock:add-own}--\ref{algo:deadlock:add-own:register}.
  The latter is further categorized into three cases:
  (a)~a fragment ends at $v$,
  (b)~a fragment starts from $u$, and
  (c)~a fragment connecting two existing fragments that one ends at $u$ and another starts from $v$.
  Each case corresponds to Line~\ref{algo:deadlock:tableto}--\ref{algo:deadlock:tableto:end}, Line~\ref{algo:deadlock:tablefrom}--\ref{algo:deadlock:tablefrom:end}, and Line~\ref{algo:deadlock:connect-two}--\ref{algo:deadlock:connect-two:end}, respectively.
  As a result, all fragments are to register on \tablefrom and \tableto;
  otherwise, a potential cyclic deadlock exists and the algorithm returns it [Line~\ref{algo:deadlock:tableto:detecting}, \ref{algo:deadlock:tablefrom:detecting}, and \ref{algo:deadlock:connect-two:detecting}].
\end{proof}

The time complexity does not contradict the NP-completeness of detecting potential deadlocks (Lemma~\ref{lemma:deadlock-np-comp}).
\begin{proposition}[space and time complexity]
  Algorithm~\ref{algo:detecting-deadlock} requires $\Omega(2^{|n|})$ both for space and time complexity in the worst case.
\end{proposition}
\begin{proof}
  Consider an example in Fig.~\ref{fig:intractable-example}.
  In any solutions, the number of fragments starting from $u$ becomes $\Omega\left(2^{|n|}\right)$; this implies the statement.
\end{proof}

Although Alg.~\ref{algo:detecting-deadlock} does not run in polynomial time, it works sufficiently fast in a sparse environment such that not many paths use the same vertices.

\input{fig/intractable-example}

\section{Proof of DBS}
\label{sec:proof:dbs}
\begin{theorem*}[\ref{thrm:dbs}; DBS]
  DBS returns a solution when solutions satisfying Thm.~\ref{thrm:sufficient} exist; otherwise returns \FAILURE.
\end{theorem*}
\begin{proof}
  Assume that there is a solution $\paths = \{ \path{1}, \ldots, \path{N} \}$ satisfying the relaxed sufficient condition (Thm.~\ref{thrm:sufficient}).
  At each cycle [Line~\ref{algo:cp:while}--\ref{algo:cp:while:end}], at least one node in \open is \emph{consistent} with \paths, i.e., its constraints allow searching \paths.
  This is derived by induction:
  (1) the initial node $R$ is consistent with \paths, and
  (2) generated nodes from a consistent node with \paths must include at least one consistent node.
  The search space, i.e., which agents are prohibited using which edges in which directions, is finite.
  Therefore, DBS eventually returns \paths (or another solution); otherwise, such solutions do not exist.
\end{proof}

\section{Stress Test on Random Graphs}
\label{sec:stress-test-random}

\input{fig/stress-test-random}

Figure~\ref{fig:stress-test-random} summarizes the results.
The experimental setting is the same as Sec.~\ref{sec:stress-test}.
We can see that the difficulty of finding solutions is dominated by average degrees of graphs.

\section{Details of Experimental Setup}
\label{sec:exp-detail}
\subsection{Implementation of DBS}
An initial solution candidate is important for DBS.
It is ideal to find solutions (i.e., a set of paths without deadlocks) from the beginning.
Even if not, it is desired to obtain infeasible solutions with a small number of potential cyclic deadlocks, expected to expand a smaller number of nodes in the high-level search to reach feasible solutions.
We thus made the low-level search for the initial solution take a path having fewer potential cyclic deadlocks with already planned paths, partially using Alg.~\ref{algo:detecting-deadlock}.
This is akin to tie-breaks in low-level search of CBS~\cite{sharon2015conflict}.

\subsection{Setup of MAPF-DP}
We carefully designed experiments to be fair as follows.

\paragraph{Preliminaries}
MAPF-DP~\cite{ma2017multi} emulates the imperfect execution of MAPF plans by introducing the possibility of unsuccessful moves, but still agents have to avoid collisions.
Time is discrete.
At each timestep, an agent $i$ can either stay in place or move to an adjacent vertex with a probability $p_i$ of being unsuccessful.
Solution quality is assessed by the total traveling time, where the time is the earliest time step that one agent reaches its goal and remains there.

\paragraph{From OTIMAPP to MAPF-DP}
To adapt the execution of OTIMAPP to MAPF-DP, we introduce two changes for executions:
(1)~using \emph{mode}s to represent a state on edges, and,
(2)~an activation rule to represent the failure of movements.

\medskip
\noindent
\emph{Mode}:
In reality, an agent $i$ occupies two vertices simultaneously during a move from one vertex to another vertex.
We introduce two \emph{modes} in the execution of OTIMAPP to represent this state;
\begin{itemize}
  \setlength{\itemsep}{0pt}
  \item A mode \contracted corresponds to when the agent $i$ occupies one vertex.
  \item A mode \extended corresponds to when the agent $i$ occupies two vertices.
\end{itemize}
\noindent
Agents move towards their goals by changing two modes alternately.
Initially, they are in \contracted.
The names are from~\cite{okumura2021time}.

\medskip
\noindent
\emph{Activation Rule}:
We repeated the following two phases:
\begin{itemize}
  \setlength{\itemsep}{0pt}
\item Each agent $i$ in \extended is activated with probability $1-p_i$.
  As a result, the agent $i$ successfully moves to the adjacent vertex with probability $1-p_i$ and becomes \contracted.
\item Choose one agent in \contracted randomly then makes it activated.
  Repeat this until the configuration becomes stable, i.e, all agents in \contracted do not change their states unless any agent in \extended is activated.
\end{itemize}
\noindent
A pair of the two phases is regarded as one timestep.

\paragraph{Other Experimental Setup}
The delay probabilities $p_i$ were chosen uniformly at random from $[0, \bar{p}]$, where $\bar{p}$ is the upper bound of $p_i$.
The higher $\bar{p}$ means that agents delay often.
$\bar{p}=0$ corresponds to perfect executions without delays.
Implementations of the online time-independent planning, called Causal-PIBT, were obtained from the authors~\cite{okumura2021time}.
The offline MAPF plans for MCPs~\cite{ma2017multi} was obtained by ECBS~\cite{barer2014suboptimal}, a bounded sub-optimal solver for MAPF.
The sub-optimally was set to $1.1$, which was adjusted to solve all instances in the experiment.
The implementation of ECBS was obtained from~\citeAppendix{okumura2021iterative} (in the additional references).


\subsection{Setup of Robot Demonstrations}
\subsubsection{Centralized Execution}
\paragraph{Platform}
We used the \emph{toio} robots (\url{https://toio.io/}).
The toio robots, connected to a computer via BLE~(Bluetooth Low Energy), evolve on a specific playmat and are controllable by instructions of absolute coordinates.
We informally confirmed that there is a non-negligible action delay between robots when sending instructions to several robots simultaneously (e.g., 10 robots, see the movie).
Therefore, one-shot execution --- robots move alone without communication after the receipt of plans --- will result in collisions hence failure of the execution in a high possibility.
The robots need some kinds of execution policies.

\paragraph{Usage}
We created a virtual grid on the playmat and the robots followed the grid.
A central server (a laptop) managed the locations of all robots and issued the instructions (i.e., where to go) to each robot step by step.
The instructions were issued \emph{asynchrony} between robots while avoiding collisions.
The code was written in Node.js.

\subsubsection{Decentralized Execution}
\paragraph{Platform}
We used the \emph{AFADA} platform~\cite{kameyama2021active};
an architecture that consists of mobile robots that evolve over an active environment made of flat \emph{cells} each equipped with a computing unit (Fig.~\ref{fig:afada-description}).
Adjacent cells can communicate with each other via a serial interface.
Cells form the environment in two ways:
as a two-dimensional physical grid, and, as a communication network.
In addition, a cell can communicate with robots on it via NFC (Near Field Communication).

\input{fig/afada-description}

\paragraph{Usage}
Robots first receive the OTIMAPP solution from a laptop via Wi-Fi, then move following the plan.
Cells achieve mutual exclusion of locations for robots, i.e., collision avoidance, using local communication as follows.
Before moving to the next vertex (i.e., cell; denoted as \vnext), a robot first asks the underlying cell \vcurrent the availability of \vnext.
Then, \vcurrent asks \vnext its status.
If \vnext is \emph{reserved} by another robot, \vcurrent waits a while and asks the status of \vnext again; otherwise, \vcurrent makes \vnext reserved and notifies the robot to move to \vnext.
When the robot reaches \vnext, then the robot \emph{releases} \vcurrent via \vnext.
Importantly, there is \emph{no central control} at runtime.
Any actor (robots, cells, and the laptop that sends the plan) has no methods to know the entire configuration.
This also means that the system is fully asynchronous as for timing.
Furthermore, there is no global communication; robots and cells decide their actions based on information from nearby actors.

\bibliographystyleAppendix{named}
\bibliographyAppendix{ref}
