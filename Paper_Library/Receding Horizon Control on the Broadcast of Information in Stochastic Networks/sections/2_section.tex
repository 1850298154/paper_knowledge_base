

%In this section, we formally define 
%the problem tackled in this paper.
%Section \ref{sec:graph_theory} introduces the methodology
%applied to describe the network topology.
%In Section \ref{sec:SI_model} the agent's states and the state of the
%network are precisely defined.
%Finally,
%Section \ref{sec:control_statement} provides
%details on the
%control problem studied.

\subsection{Graph Theory}
\label{sec:graph_theory}
%We are interested in understanding the
%effects of stochastic
%communication topologies on the broadcast of information
%on networked systems.
We represent the communication network as a graph $\GG(\VV,\EE)$,
in which $\VV=\{1,...,n\}$ is the node set and
$\EE\subset \VV \times \VV$ the edge set.
Each element of the edge set represents a
\textit{directed} link from $i$ to $j$ 
if $(i,j)\in\EE$.
The set constituted by the nodes that have the
$i$th node as a child node is denoted by
$\NN_i=\{j\in\VV : (j,i)\in\EE\}$ and it is called
neighborhood of the $i$th node.
In accordance to this nomenclature, we call
a neighbor of a node $i$ a node $j$
in $\NN_i$.
The adjacency matrix $\A=[a_{ij}]$ associated with
the graph $\GG$ is an object that
maps the edge set into a matrix as,
\begin{align}
\label{eq:adjacency}
a_{ij}=\left\{
\begin{array}{ll}
0, & \text{if } i=j \text{ or } (j,i)\nexists \EE,  \\
\omega_{ij}(t), ~& \text{if } (j,i)\in \EE,
\end{array}
\right.
\end{align}
where $\omega_{ij}(t)>0$ is a positive number
that maps the transmission rate of information from node
$j$ to node $i$, which we will examine in more detail 
below.

\subsection{Information Propagation Model}
\label{sec:SI_model}

We study the stochastic broadcast of
information in a networked system represented
by a graph $\GG(\VV,\EE)$, in which the edges represent
communication channels and the nodes represent the robots.
We assume that each robot has limited communication 
capabilities,
in these scenarios the systems
may have to operate with
intermittent network connectivity due to
wireless signal attenuation, resulting from
obstacle occlusions and other
environmental factors \cite{Saddler2019}.
%We model
%such intermittent network connectivity 
%through the communication graph as 
%stochastic transmissions among nodes. 
We borrow an epidemiological model
from 
Van Mieghem and Cator \cite{Mieghem2012}, 
who defined an {\it exact} $2^n$-${\text{state}}$
joint Markov chain
to study the stochastic process of propagation of diseases 
using a Susceptible-Infected (SI) representation.
We investigate a similar
model to represent the broadcast of information.
Naturally, using $2^n$ states
to represent the broadcast of information can quickly
lead to computational infeasibility. 
To circumvent this problem
we apply a moment-closure 
to the model \cite{Cator2012,Schnoerr2015,Watikins2018},
which approximates the representation of the joint
Markov chain using a lower-dimensional representation.
Afterward, we 
compare the performance of both representations.

In a SI model, each individual can be either
``susceptible'' or ``infected'' by a disease, and
a susceptible agent can only become infected if
there is at least one infected agent in its neighborhood.
We adopt this idea to model the transmission of
information in a robot networked system,
such that each agent
can be either \textit{informed} or 
\textit{non-informed} about a 
message to be transmitted over the network.
We assume that the transmission process between
any given pair of agents $(j,i)$ 
follows a stochastic jump process with
Poisson distribution and transmission rate
$\omega_{ij}(t)$ \cite{Oksendal2007}.
%A scheme for the SI model is illustrated in Figure
%\thales{[ADD FIGURE]}.  
This type of modeling can represent 
scenarios where the information is carried
by mobile robots with low-range 
and limited communication capabilities,
which usually leads to intermittent interaction between
agents,
such as in \cite{Saddler2019,Yu2021}. 
%\thales{[the next part should be on the introduction]}
%As an example, consider
%applications such
%as surveillance, drifters in the ocean, and in GPS denied
%areas.

To be able to affect the transmission statistics over
the whole network while
satisfying a team's performance
criterion, 
we assume that the robots have 
access to the states of its neighborhood
on predefined sampling times, nevertheless, each
node can carry the computation with that information.
Even though this assumption can be conservative in 
general, there are scenarios in which it is possible to
have a higher range, but low transmission rate, to
perform general and simple coordination,
while agents need to
perform local higher demanding data transactions,
for example on data fusion tasks.
Also, estimates techniques might
help to alleviate such an assumption.

%\begin{rem}[Parameter and State Uncertainty]
%\thales{In the case we don't know those 
%parameters exactly,
%the way to go is to sample from the distribution and
%then infer other values.}
%\end{rem}

We model the current state of a robot 
as an indicator 
random variable $X_i(t)\in \{0,1\}$, such that
$X_i(t)=1$ if the $i$th robot 
is informed at time $t$,
and $X_i(t)=0$ otherwise.
Note that $X_i(t)$ is a Bernoulli 
random variable, therefore
the evolution of the network expectation of
broadcast of information 
can be determined by
the evolution of the probability 
$\mathrm{Pr}\{X_i(t) = 1 : X_j(0) = 1\}$
for any pair $(i,j)$,
over time $t>0$.
The joint state of the network maps the set of agents
that hold the
information in a given instant.
Since $X_i(t)\in\{0,1\}$ for each $i\in\VV$,
it is clear that the joint states of the network
evolve in a $2^n$ state-space. 
Inspired by \cite{Mieghem2012,Sahneh2013} in epidemiological studies,
we define a
time-dependent state-space vector for the
whole network as
\begin{align*}
Y(t) ={}&[Y_0(t) ~ Y_1(t) ~ \cdots~Y_{2^{n-1}}]',
\text{ with}
\\
Y_i(t) ={}&\left\{
\begin{array}{ll}
1, & i = \sum_{k=1}^n X_k2^{k-1}, \\
0, & \text{otherwise,}
\end{array}
\right.
\end{align*}
for all $X_k\in\{0,1\}$. 
Observe that $Y(t)\in\real^{2^n}$ corresponds to
a binary-valued vector that maps
the current state of each node into a 
specific element $Y_i(t)$ ({\it i.e.,}
we have a bijective map between each possible state
of the network and the vector $Y(t)$). Fig.
\ref{fig:1} illustrates the relation of 
all possible states of the network and $Y(t)$
for a network with three nodes.
In addition, note that the elements of $Y(t)$
also are Bernoulli random variables, hence 
$\mathrm{E}[Y_i(t)]=\mathrm{Pr}\{Y_i(t)=1\}$.
\begin{figure}[h]
\centering
\includegraphics[scale=.25]{figures/example_state_space.pdf}
%
\caption{{ Representation of all possible states
of a network with three agents. The arrows represent possible
switching between states. }
}
\label{fig:1}      
\end{figure}


One could try to model the states of the
whole network directly as $X(t)=[X_1(t)~X_2(t)~\cdots~X_n(t)]$,
since that would reduce the dimension of the 
representation from $\real^{2^n}$ to $\real^{n}$.
However, as shown in \cite{Sahneh2013},
the evolution of 
$\mathrm{E}[X(t)]$ represents only a {\it marginal 
probability distribution} of the states of the
network, and
this information is not enough to describe
the evolution of 
$\mathrm{Pr}\{X_i(t) = 1 : X_j(0) = 1\}$ for
any $t>0$.
Therefore, if we are interested in computing the expectation
of future states given a current distribution, using $X(t)$
alone
is not enough.
Alternative methods to reduce the dimension of the 
state-space include
mean-field type approximations and 
moment-closure methods (please, see \cite{Sahneh2013}
and references therein).
Typically those methods are valid under the
assumption of large numbers and 
have reduced precision about the underlying stochastic
process.
Indeed, as pointed out in \cite{Watikins2018},
in general, mean-field approximations do not
consistently provide
either an upper- nor a lower-bound for general
spreading processes.

Since $Y(t)$ is an exact characterization
of the states of the network,
an expression for
$\mathrm{Pr}\{Y_i(t)=1:Y(0)\}$
can be obtained using a
continuous-time Markov chain with
$2^n$ states, determined by the following
infinitesimal generator $Q(t)=[q_{ij}(t)] \in
\real^{2^n \times 2^n}$ 
\cite{Mieghem2012},
\begin{align}
\label{eq:transition_matrix}
q_{ij}(t) = \left\{
\begin{array}{ll}
\sum_{k=1}^n \omega_{mk}{X_k},
~& \text{for } m = 1,...,n, 
\text{  } X_m=1 \text{ if } 
i = j - 2^{m-1}, \\
-\sum_{k=1}^n q_{kj}, & \text{if } i=j,\\
0, & \text{otherwise,}
\end{array}
\right.
\end{align}
for all $X_k\in\{0,1\}$,
in which the corresponding Markov chain evolves according
the following Kolmogorov foward equation
\begin{align}
\label{eq:markov_2n}
\frac{dv(t)'}{dt}=v(t)'Q(t),
\end{align}
where the state vector is
defined as $v(t)=[v_0(t) ~\cdots~ v_{2^{n-1}}]'$ with elements
$v_i(t) = \mathrm{Pr}\{Y_i(t)=1\}$ and 
satisfies $\sum_{i}v_i=1$ for all $t>0$.

In this paper, we are interested in enforcing
a desired evolution for the propagation of
information on the network ({\it i.e.},
$\mathrm{Pr}\{X_i(t) \rightarrow 1 : X_j(0) = 1\}$)
exponentially fast,
by closing the loop of the network with
a feedback control strategy,
which chooses the control action
from a finite set of possible actions and minimizes a cost
of available resources. Specifically,
the problem investigated can be stated as:

\bigskip
\noindent \textbf{Problem 1.} 
Given a network with stochastic propagation of information
represented by the topology in \eqref{eq:adjacency},
define a feedback control that
actuates on the transmission rates $\omega_{ij}(t)$
such that
the evolution of the probability of
all nodes
in the network becoming informed nodes
follows
the desired convergence criteria.

\label{sec:control_statement}

