%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion and Limitations}
\label{sec:conclusion}

This paper is our first step toward learning a reactive collision avoidance policy for efficient and safe multi-agent navigation. By carefully designing the data collection process and leveraging an end-to-end learning framework, our method can learn a deep neural network based collision avoidance policy which demonstrates an advantage over the state-of-the-art ORCA policy in terms of ease of use (no parameter tuning), success rate, and navigation performance. 
In addition, even though being trained over dataset with only identical moving agents, our learned policy generalizes well to various unseen situations, including agents with different sizes and scenarios with static obstacles. 

The proposed method has some limitations. First, at the current stage, we are training a vanilla multilayer perceptron as the collision avoidance policy. As can be observed from the classification accuracy, the model does not completely fit the training data (the accuracy on training set is around $64\%$), thus there is still great potential for getting the model improved. Second, we did not add any static obstacles during training data generation, and therefore our model may not perform well in some challenging scenarios with obstacles (e.g., agents pass through a narrow hallway, multiple agents exit a room through a narrow doorway). These challenging tasks can be solved by combining our method with the cutting-edge deep reinforcement learning techniques, which will further improve agentsâ€™ navigation performance.

Besides the combination with reinforcement learning, there are many other exciting avenues for the future work, such as the extension to vehicles with complex dynamics (e.g., the quadrotors), how to directly leverage 2D/3D camera sensors, and most importantly, to make the entire framework work reliably in real systems (e.g., the automated warehouse) with a large number of agents.