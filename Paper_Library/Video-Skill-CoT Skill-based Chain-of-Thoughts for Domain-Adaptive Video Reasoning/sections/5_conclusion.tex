\section{Conclusion}
\label{sec:conclusion}
We propose \ours{}, a novel video understanding framework for effective domain adaptation of MLLMs.
We propose to automatically collect skill-specific CoT annotations from video QA datasets and construct a skill-based reasoning pipeline that combines a lightweight skill assigner with a collection of LoRA-based expert adapters.
Empirical results on three diverse benchmarks demonstrate consistent gains of \ours{} over strong baselines, highlighting the enhanced quality of our reasoning traces.
