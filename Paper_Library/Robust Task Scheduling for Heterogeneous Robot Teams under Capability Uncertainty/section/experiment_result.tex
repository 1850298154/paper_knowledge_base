\section{Experiments and Results}\label{sec:experiments}

In this section, we first initialize randomized flow networks to test the decomposition of the agent flows, and then use two practical applications to evaluate the robustness, generalizability, and scalability of the proposed risk minimization model. The models and algorithms are implemented using the GUROBI solver. All computations were done on a laptop with Intel i7-7660U CPU (2.50GHz).

\subsection{Decompose Agent Flows into Paths}
In this section, we use randomized test cases of different sizes to evaluate the computational cost of the flow decomposition process. The evaluation metric is the time to solve both the rounding and splitting problems to zero optimality gaps.

\subsubsection{Setup and Test Cases}
An agent flow network with random connections is initialized, and the flow and unit cost of each edge is sampled from uniform random distributions. The hyper-parameters are the maximum flow on an edge and the node number of the network. The optimization models in Sec. \ref{sec:flow_decompose} are then applied to the initialized random flow network to solve the minimum energy cost rounding and minimum max-energy flow split problems.

\subsubsection{Result and Discussion}

Different sizes of flow decomposition problems are solved, and the computational costs of the two steps are listed in TABLE \ref{tab:flow_decompose_result}. The size of the rounding and split problems are proportional to edge number and edge number \(\times\) sum integer flow, respectively. For the cases shown in TABLE \ref{tab:flow_decompose_result}, the rounding steps can be completed within several milliseconds. The rounding process scales well because the linear program can be solved in polynomial time. The split step involves solving an integer linear program, which does not scale well generally with the problem size. The largest test cases shown in the table involve 70 tasks and 241 agents on average, much larger than the typical teaming problem sizes that the risk minimization model will be applied to. Therefore, the flow decomposition part will not be the bottleneck of the overall teaming planner.

Though there is no explicit integer constraint in the rounding model in Sec. \ref{sec:flow_round_up}, we provided a proof in Appendix \ref{sec:appendix_integer} that showed that the solutions would be integers, and the results support it. As an example, the rounding solution for a case from the first row of the table is shown in Fig. \ref{fig:flow_round_result}, where we can see that the agent flow on each edge is rounded up to an integer, while the overall network flow constraint is maintained. For instance, the 13.41 on edge (S, 1) is rounded to 15 instead of 14 in order to maintain the flow constraint.

\newcommand{\stdsize}[1]{\scriptsize \(\pm\)#1}

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[t]
%   \centering
  \caption{The computational cost of the flow decomposition. }
  \label{tab:flow_decompose_result}%
    \begin{tabular}{cccccc}
    \toprule
    Task\(^*\)  & Edge  & Flow  & Int flow & Round time & Split time \\
    \midrule
    5     & 11\stdsize{1}    & 110.6\stdsize{33.7} & 114\stdsize{34}   & 0.001\stdsize{0.0005} & 0.09\stdsize{0.04}   \\
    10    & 28\stdsize{3}    & 21.3\stdsize{2.8}   & 30\stdsize{2}     & 0.001\stdsize{0.0004} & 0.13\stdsize{0.09}   \\
    10    & 26\stdsize{3}    & 213.7\stdsize{30.5} & 221\stdsize{31}   & 0.001\stdsize{0.0002} & 1.23\stdsize{0.89}   \\
    35    & 107\stdsize{8}   & 135.7\stdsize{13.2} & 172\stdsize{13}   & 0.001\stdsize{0.0001} & 19.33\stdsize{9.50}  \\
    70    & 210\stdsize{7}   & 163.6\stdsize{7.5}  & 241\stdsize{8}    & 0.001\stdsize{0.0009} & 197.0\stdsize{32.9}  \\
    \bottomrule
    \end{tabular}%
    \\
    \\
    * `Task' is the number of tasks, which equals the number of nodes in the flow network. `Flow' is the sum of agent flows from the start to the terminal node and `int flow' is the value after rounding (i.e., the number of agents used). `Round time' and `split time' are the times used to solve the rounding and splitting problems, with units in seconds. For each row, we randomly initialize 10 similar sized test cases to evaluate the algorithm and show the mean and standard deviation.
\end{table}%

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.8\linewidth]{figure/result/flow_round_result.png}
	\caption{Flow rounding results (5 task nodes, 15 edges). There are two numbers on each edge, indicating the agent flows before and after the rounding process. This example corresponds to one instance in the first row of TABLE \ref{tab:flow_decompose_result}.}
	\label{fig:flow_round_result}
\end{figure}

\subsection{Capture the Flag}\label{sec:capture_flag}
In this section, we apply the risk minimization model in Sec. \ref{sec:problem_model} to a team of agents in a capture the flag game setting and compare the team performance against the baseline (STRATA \cite{ravichandar2020strata}) in a simulation environment shown in Fig. \ref{fig:capture_flag_setup}.
The goal of this simulation is to evaluate and demonstrate the performance of the task assignment component of our framework. The number of wins is used as the metric for task performance.

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=1\linewidth]{figure/result/capture_flag_setup2.png}
	\caption{Capture the flag setup. Each small square tile is \(1 \times 1\) unit length. A line points to the current target of the corresponding agent.}
	\label{fig:capture_flag_setup}
\end{figure}

\subsubsection{Game Setup, Baseline, and Metrics}

The blue and green teams contain 12 heterogeneous agents initialized at random locations within their own sides. The overall goal is to win the game by capturing the flag from the other team. The 12 agents are from 4 species (3 individuals for each species). These species have different speed, viewing distance, health, and ammunition capabilities (TABLE \ref{tab:specie_capabililty}).
The specific values in the table are set according to the baseline paper \cite{ravichandar2020strata}. Among these capabilities, the first two are modeled as noncumulative, while the last two are cumulative.

Each agent is designed to play one role out of the 3 tasks listed in TABLE \ref{tab:task_description} and will disappear when its health reaches zero. The adversarial elements of the game are not explicitly modeled, and the focus is to assign tasks such that the requirements are fulfilled while overall time and energy costs are considered in the trade-off. Therefore, the agents follow predefined behaviors once their tasks are determined.

STRATA \cite{ravichandar2020strata} is chosen as the baseline for this work because its model makes use of similar concepts like agents, species, capability vectors, and task requirements specified by capabilities.
Since there is no scheduling involved in this game (the tasks are all `life-long' tasks), \modelrisk{} reduces to an instantaneous task assignment, tackling the same type of problem as STRATA.
Therefore, this game will provide a comparison between STRATA and the task assignment component of \modelrisk{}. 
% based on the performance metric of the number of wins.
In addition to STRATA, we also compare our model to a random task assignment mechanism where an agent is randomly assigned a task.

All games are played with two teams using different assignment models. The metric used in this simulation is the number of wins in 500 games, which reveals the relative task assignment performance. A win is either a team taking back the other side's flag or defeating all enemies through a fight mode. A draw happens when all of the agents from both sides decide to defend and no longer attack, or if no team wins the game within 120 seconds.

Both STRATA and our model need task requirements specified as capability distributions. For the three tasks, the agents are programmed to switch to a healing mode automatically when their health is lower than a threshold and return to attack/defend after they heal. 
Namely, the healing role is a temporary state that happens when we think an agent is too `unhealthy' to continue. In the game, \modelrisk{} and the baseline assign either the attack or defend role to the agents.
The threshold of entering the healing state is set to 33\% of an agent's full health. We have done a parametric study, and results show that the threshold does not affect the number of wins and the task assignment patterns that will be discussed.
The required capabilities of the attack and defend tasks are listed in TABLE \ref{tab:task_requirement}. The task requirements in this game are deterministic. However, since the agent capabilities in Table \ref{tab:specie_capabililty} are stochastic, the planning problem is still stochastic.

The specific numbers are manually decided to reflect the following requirements: the attack task needs agents with higher speed and health to capture the flag, while the defend task needs agents with higher viewing distance and ammunition to detect and defeat the opposing team. In TABLE \ref{tab:task_requirement}, 1131 is 65\% of the expected total initial health of the 12 agents, and 231 is 55\% of the expected total ammunition.

% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table}[htb!]
  \begin{center}
  \caption{Capability distributions of the four agent species.}
  \label{tab:specie_capabililty}%
    \begin{tabular}{c|cccc|cccc}
    \toprule
    species & \({\mu_1} ^*\)     & \(\mu_2\)     & \(\mu_3\)     & \(\mu_4\)     & \(\sigma_1^2\)     & \(\sigma_2^2\)     & \(\sigma_3^2\)     & \(\sigma_4^2\) \\
    \midrule
    1     & 1.5   & 2     & 90    & 40    & 0.35  & 0.1   & 10    & 3 \\
    2     & 1.5   & 4     & 60    & 40    & 0.35  & 0.1   & 10    & 3 \\
    3     & 3     & 2     & 80    & 30    & 0.35  & 0.1   & 10    & 3 \\
    4     & 3     & 4     & 350   & 30    & 0.35  & 0.1   & 10    & 3 \\
    \bottomrule
    \end{tabular}%
  \end{center}
    * \(\mu_i\) and \(\sigma_i^2\) (\(i =\) 1: speed, 2: view, 3: health, 4: ammunition) are the means and variances of the capability distributions (Gaussian in the experiment).
\end{table}%

\begin{table}[htb!]
  \centering
  \caption{General task descriptions.}
  \label{tab:task_description}%
    \begin{tabular}{c|l}
    \toprule
    Task & Description \\
    \midrule
    Attack   & Try to capture the flag of the other side. \\
    Defend   & Apply a defense mode to defeat opposing team members. \\
    Heal     & Use hearts to apply healing powers. \\
    \bottomrule
    \end{tabular}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table}[htb!]
  \caption{Task requirements are specified as capability distributions. }
  \label{tab:task_requirement}%
  \centering
    \begin{tabular}{c|cccc}
    \toprule
          & Speed & View  & Health & Ammunition \\
    \midrule
    Attack & \(\geq 2\)     &       & \(\geq 1131 \ (65\%)\) &  \\
    Defend &       & \(\geq 1\)     &       & \(\geq 231 \ (55\%)\) \\
    \bottomrule
    \end{tabular}%
\end{table}%

\subsubsection{Results}

Based on all the settings described in the above section, we developed a simulation environment in C++. A screenshot is shown in Fig. \ref{fig:capture_flag_setup}. The three task assignment models, random, baseline, and \modelrisk{}, are linked with the simulation environment. During the simulation, the mean time for the baseline and \modelrisk{} to optimize and output an assignment are 0.43 and 0.04 seconds, respectively.

The relative performances of the models are shown in Fig. \ref{fig:capture_flag_win}. 
As can be seen from Fig. \ref{fig:capture_flag_win}, \modelrisk{} results in a higher win rate as compared to the baseline or random selection methods. 
The average number of agents assigned to attack, grouped by species, is shown in Fig. \ref{fig:capture_flag_attack}.
Both the baseline and \modelrisk{} prefer using species 4 for the attacking task with the difference being that the baseline still uses species 1 and 2 for attack occasionally.

Though the baseline claims to be able to consider noncumulative capabilities through thresholding, it lacks an explicit mechanism to prevent incompetent agents from joining a task. For instance, though species 1 and 2 are not competent for the attack task due to their low speed, they are still allowed to conduct the task and contribute to other required capabilities such as health. However, this is not a good choice as there exist other agents that satisfy both the speed and health requirements of the attack task.

Another possible factor contributing to \modelrisk{}'s improved performance is that the \modelrisk{} algorithm directly minimizes the CVaR metric, which ensures enough task-required capabilities, whereas the baseline focuses on matching the expected requirements and penalizing variance of the assigned capability distributions.

In conclusion, through the comparison, our framework demonstrates superior task assignment performance against the baseline algorithm, and the task assignment patterns in Fig. \ref{fig:capture_flag_attack} support this performance result.

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=1\linewidth, trim=120 340 70 310, clip]{figure/result/capture_flag_win.pdf}
	\caption{Relative performances of random task assignment, baseline, and \modelrisk{}. Each row shows the mean and standard deviation from ten 500 capture the flag games. The length of the bars are proportional to the mean. }
	\label{fig:capture_flag_win}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth, trim=80 245 70 260, clip]{figure/result/capture_flag_attack.pdf}
	\caption{The average number of agents assigned to attack. \modelrisk{} is more likely to use species 4 and does not use species 1 and 2. The baseline shows a similar trend of preferring species 4 over the other species. This preference is logical since species 4 contains attributes of high speed and health, which are more suitable for the attack task than other species' attribute distributions (particularly species 1 and 2).}
	\label{fig:capture_flag_attack}
\end{figure}

