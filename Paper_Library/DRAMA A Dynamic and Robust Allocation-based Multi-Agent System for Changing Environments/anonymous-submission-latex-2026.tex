%File: anonymous-submission-latex-2026.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai2026}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{subcaption}
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
% \usepackage[table]{xcolor}
\usepackage{amssymb}
\definecolor{myblue}{cmyk}{0,0.22,0.33,0}
\definecolor{mygreen}{cmyk}{0.76,0,0.76,0.30} % 绿色（可调）
\definecolor{myred}{cmyk}{0,1,1,0} % 红色
\usepackage{pifont}
\newcommand{\cmark}{\textcolor{mygreen}{\ding{51}}} % 绿色打勾
\newcommand{\xmark}{\textcolor{myred}{\ding{55}}} % 红色打叉
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2026.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai2026.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{DRAMA: A Dynamic and Robust Allocation-based Multi-Agent System for Changing Environments}
\author{
    Naibo Wang\textsuperscript{\rm 1},
    Yifan Zhang\textsuperscript{\rm 1},
    Sai Liu\textsuperscript{\rm 1},
    Xinkui Zhao\textsuperscript{\rm 1}\textsuperscript{*},
    Guanjie Cheng\textsuperscript{\rm 1},
    Yueshen Xu\textsuperscript{\rm 2}
}
\affiliations{
    \textsuperscript{\rm 1}School of Software Technology, Zhejiang University\\
    \textsuperscript{\rm 2}School of Computer Science and Technology, Xidian University\\
    \textsuperscript{*}Corresponding author. Email: zhaoxinkui@zju.edu.cn
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}

\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle


\begin{abstract}
Multi-agent systems (MAS) have demonstrated significant effectiveness in addressing complex problems through coordinated collaboration among heterogeneous agents. However, real-world environments and task specifications are inherently dynamic, characterized by frequent changes, uncertainty, and variability. Despite this, most existing MAS frameworks rely on static architectures with fixed agent capabilities and rigid task allocation strategies, which greatly limits their adaptability to evolving conditions. This inflexibility poses substantial challenges for sustaining robust and efficient multi-agent cooperation in dynamic and unpredictable scenarios.
To address these limitations, we propose DRAMA: a \textbf{D}ynamic and \textbf{R}obust \textbf{A}llocation-based \textbf{M}ulti-\textbf{A}gent \textbf{S}ystem designed to facilitate resilient collaboration in rapidly changing environments. DRAMA features a modular architecture with a clear separation between the control plane and the worker plane. Both agents and tasks are abstracted as resource objects with well-defined lifecycles, while task allocation is achieved via an affinity-based, loosely coupled mechanism. The control plane enables real-time monitoring and centralized planning, allowing flexible and efficient task reassignment as agents join, depart, or become unavailable, thereby ensuring continuous and robust task execution. The worker plane comprises a cluster of autonomous agents, each with local reasoning, task execution, the ability to collaborate, and the capability to take over unfinished tasks from other agents when needed.
Extensive experiments reveal that DRAMA achieves a 17\% improvement in runtime efficiency and a 13\% reduction in resource consumption compared to existing frameworks, while maintaining superior robustness and adaptability under frequent agent turnover and dynamic task demands. To our knowledge, DRAMA is the first MAS framework capable of supporting agent dropout scenarios.
\end{abstract}


\section{Introduction}
The rapid advancement of Large Language Models (LLMs) has transformed capabilities across diverse domains, ranging from natural language processing~\cite{achiam2023gpt, touvron2023llama, liu2024deepseek} to code generation~\cite{guo2024deepseek, li2023starcoder, zhu2024deepseek, chowdhery2023palm, fried2022incoder}. These breakthroughs have also accelerated the evolution of multi-agent systems (MAS), empowering agents with advanced planning, reasoning, and autonomous collaboration abilities across a wide range of applications~\cite{rashid2020monotonic, hu2019simplified, guo2024large}. LLM-based multi-agent systems (LLM-MAS) have demonstrated impressive performance in complex problem-solving~\cite{qian2023chatdev, hong2023metagpt, chen2024scalable} and world simulation~\cite{park2023generative, kaiya2023lyfe}, leveraging collective intelligence and flexible communication mechanisms.

% Despite these advances, the majority of existing LLM-MAS frameworks are designed around static architectures, where agent abilities and task assignments remain fixed, which inherently limits their adaptability and robustness in dynamic, real-world environments. In real-world scenarios, both the makeup of the agent ensemble and the surrounding task environment are inherently dynamic—agents frequently join or depart, and task requirements can shift unpredictably~\cite{dias2004robust, zhou2023robust}. Such volatility highlights the necessity for MAS frameworks that support adaptive and robust task allocation, thereby enabling sustained cooperation and stable performance amid continual changes in team composition and task demands. Effectively addressing these challenges is essential for the successful application of MAS to complex, real-world problems.

Despite recent advances, most existing LLM-MAS frameworks are built on static architectures, where agent capabilities and task assignments remain fixed. This design inherently limits their adaptability and robustness in dynamic, real-world environments. In practice, both the composition of agent teams and the surrounding task conditions are highly dynamic—agents may frequently join or leave, and task requirements can change unpredictably~\cite{dias2004robust, zhou2023robust}. Such volatility underscores the need for MAS frameworks that enable adaptive and resilient task allocation, thereby supporting sustained collaboration and stable performance amid continuous changes in team structure and task demands. Addressing these challenges is critical for the effective deployment of MAS in complex, real-world applications.

% To address these challenges, we present \textbf{DRAMA}: a \textbf{D}ynamic and \textbf{R}obust \textbf{A}llocation-based \textbf{M}ulti-\textbf{A}gent \textbf{S}ystem designed for changing environments. We separate the system into two distinct planes: the \textbf{control plane} and the \textbf{worker plane}. The control plane serves as the global brain of the system. It is responsible for continuously monitoring the status of all agents and tasks, collecting system-wide state information, and making high-level decisions regarding task planning, resource scheduling, anomaly detection, and dynamic reallocation. Through real-time analysis and reasoning, the control plane ensures that task assignments remain optimal and the system can quickly adapt to events such as agent failures or arrivals. The worker plane is implemented as a heterogeneous agent cluster, where each agent interacts with the environment, executes tasks assigned by the control plane, and reports status and progress back to the controller. Each agent perceives its surroundings, plans and performs actions, and frequently reports its status and progress back to the control plane. This clear separation of concerns allows the control plane to focus on global adaptation and coarse-grained orchestration, while empowering worker agents with local autonomy and collaboration.

To address these challenges, we present \textbf{DRAMA}: a \textbf{D}ynamic and \textbf{R}obust \textbf{A}llocation-based \textbf{M}ulti-\textbf{A}gent \textbf{S}ystem designed for dynamic environments. 
 DRAMA is structured into two distinct layers: the \textbf{control plane} and the \textbf{worker plane}. The control plane functions as the system’s global brain, continuously monitoring agent and task statuses, aggregating system-wide state information, and making high-level decisions on task planning, resource scheduling, anomaly detection, and dynamic reallocation. Through real-time analysis and reasoning, it maintains optimal task assignments and enables rapid adaptation to events such as agent failures or arrivals. The worker plane consists of a heterogeneous cluster of agents, each interacting with the environment, executing tasks assigned by the control plane, and reporting their status and progress. Each agent is responsible for local perception, planning, and action execution, while maintaining frequent communication with the control plane. This separation of responsibilities allows the control plane to focus on global coordination and adaptation, while empowering worker agents with local autonomy and collaboration.



% A key innovation of DRAMA is the abstraction and management of both agents and tasks as resource objects. We model agents as heterogeneous workload carriers and tasks as workload entities with distinct lifecycles. The association between agents and tasks is decoupled and managed through an affinity mechanism: instead of statically binding tasks to specific agents, the planner dynamically matches tasks to appropriate agents based on real-time affinity decisions, which take into account factors such as agent capabilities, location, and current workload. Tasks can be seamlessly evicted and reassigned in response to system changes, ensuring continuous operation and high resource utilization.

A key innovation of DRAMA lies in the abstraction and unified management of both agents and tasks as resource objects. Agents are modeled as heterogeneous workload carriers, while tasks are treated as workload entities with distinct lifecycles. Rather than statically binding tasks to specific agents, DRAMA employs an affinity-based mechanism to decouple their association. The planner dynamically assigns tasks to suitable agents based on real-time affinity evaluations, which consider factors such as agent capabilities, location, and current workload. This design enables seamless task eviction and reassignment to system dynamics, promoting continuous operation and high resource utilization.


% To validate the effectiveness of our framework, we conducted extensive experiments in the embodied environment Communicative Watch-And-Help (C-WAH)~\cite{zhang2023building}, benchmarking DRAMA against existing task allocation strategies. Extensive experiments demonstrate that DRAMA stands out as the only MAS framework capable of handling agent dropout scenarios. In addition, DRAMA delivers a 17\% increase in runtime efficiency and reduces resource consumption by 13\% compared to other frameworks, all while providing enhanced robustness and adaptability in environments with frequent agent turnover and dynamic task requirements.
% The primary contributions of this work are as follows:

To validate the effectiveness of our framework, we conducted extensive experiments in the embodied environment Communicative Watch-And-Help (C-WAH)~\cite{zhang2023building}, benchmarking DRAMA against existing task allocation strategies. Results show that DRAMA is the only MAS framework capable of reliably handling agent dropout scenarios. Moreover, it achieves a 17\% improvement in runtime efficiency and a 13\% reduction in resource consumption compared to baseline methods, while offering superior robustness and adaptability in environments characterized by frequent agent turnover and dynamic task demands.

The main contributions of this paper are as follows:

\begin{itemize}
\item We propose DRAMA, a dynamic and robust multi-agent framework that enables seamless adaptation to agent arrivals, departures, and failures through dynamic task allocation and flexible resource management.
% \item We introduce a unified abstraction that models both agents and tasks as resource objects, supporting flexible, affinity-driven scheduling and decoupled management in heterogeneous multi-agent systems.
\item We propose a unified abstraction that models both agents and tasks as resource objects, enabling affinity-driven scheduling and decoupled management in heterogeneous multi-agent systems.
\item We design a hierarchical scheduling architecture with a global control plane for high-level coordination and autonomous agents for local, environment-aware adaptation, enhancing both robustness and responsiveness.
\item Extensive experiments in the embodied C-WAH environment demonstrate that DRAMA significantly outperforms state-of-the-art baselines in efficiency, resource utilization, and robustness.
\end{itemize}



% \begin{figure}[H]
%     \centering
%     \includegraphics[width=1\linewidth]{cycle.png}
%     \caption{The prompt explicitly requires the use of a while loop, but does not explicitly emphasize Python syntax rules (a colon must follow the loop condition), causing the LLM to omit critical symbols when generating code. }
%     \label{fig:enter-label}
% \end{figure}
\section{Background}
% This section reviews the core concepts of current Multi-Agent Systems (MAS). We then discuss current challenges and present our research motivation.
This section reviews the fundamental concepts of current Multi-Agent Systems (MAS), highlights current challenges, and outlines the motivation behind our research.

\subsection{Multi-Agent Systems}

A multi-agent system consists of a set of autonomous agents $\mathcal{A} = \{a_1, a_2, ..., a_N\}$ and a set of tasks $\mathcal{Q} = \{\mathtt{q}_1, \mathtt{q}_2, ..., \mathtt{q}_M\}$, all operating within a shared environment $\mathcal{E}$. Each agent $a_i$ can be described as a tuple:
\begin{equation}
    a_i = \langle S_i, O_i, A_i, \pi_i \rangle
\end{equation}
where $S_i$ is the local state space, $O_i$ is the observation space, $A_i$ is the action set, and $\pi_i$ is the policy.

The assignment of agents to tasks at time $t$ is described by a function $f_t: \mathcal{T} \rightarrow \mathcal{A}$, where $f_t(\mathtt{q}_j)$ denotes the agent responsible for task $q_j$ at time $t$. The overall objective of the MAS can thus be formulated as maximizing a system utility function over a time horizon $T$:
\begin{equation}
    \max_{\{f_t\}_{t=1}^T,\,\{\pi_i\}_{i=1}^N} \;\; U(\{f_t\}_{t=1}^T,\, \mathcal{A},\, \mathcal{Q},\, \mathcal{E},\, T)
\end{equation}
where $U$ evaluates the system-level performance based on assignments and agent behaviors across time.

% Such static assignment schemes constrain the adaptability of MAS in dynamic, real-world scenarios, where agents may join, leave, or fail, and task requirements may evolve over time. This highlights the need for MAS architectures that support dynamic agent populations, flexible task definitions, and adaptive scheduling mechanisms.

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{images/ma-overview.pdf}
    \caption{Overall architecture of DRAMA, featuring a separation between the control plane and the work plane. The control plane is responsible for high-level decision-making, such as global coordination, task allocation, monitoring, and reasoning. The work plane consists of heterogeneous agents that interact with the environment, execute assigned tasks, and report status.}
    \label{fig:overview2}
\end{figure*}
\subsection{Motivation}

% While the general MAS formulation allows for dynamic agent-task assignments across time, most existing frameworks in practice adopt a static assignment paradigm. Specifically, the assignment function is determined at initialization ($t=0$) and remains fixed throughout the system's operation, i.e.,

Although the general formulation of MAS supports dynamic agent-task assignments over time, most existing frameworks adopt a static assignment paradigm in practice. Specifically, the assignment function is determined at initialization ($t = 0$) and remains fixed throughout the system's operation, i.e.,

\begin{equation}
    f_t = f_0, \quad \forall t \in [1, T].
\end{equation}
The system objective thus reduces to:
\begin{equation}
    \max_{f_0,\,\{\pi_i\}_{i=1}^N} \;\; U(f_0,\, \mathcal{A},\, \mathcal{Q},\, \mathcal{E},\, T)
\end{equation}

% This static assignment approach, while simplifying design and deployment, introduces several critical limitations in dynamic, real-world settings:

While the static assignment approach simplifies system design and deployment, it introduces several critical limitations in dynamic, real-world environments:

\begin{itemize}
    % \item \textbf{Agent and Task Dynamism:} Agents may join, leave, or change capabilities over time; tasks may arrive, evolve, or be reprioritized, but the system cannot adjust assignments accordingly.
    
    \item \textbf{Agent and Task Dynamism:} Agents may join, leave, or change capabilities over time; tasks may arrive, evolve, or be reprioritized. Static assignments prevent the system from adapting to these changes.
    
    % \item \textbf{Suboptimal Resource Utilization:} Fixed assignments can lead to idle agents, overloaded tasks, or inefficient execution, especially as the environment changes.

    \item \textbf{Suboptimal Resource Utilization:} Fixed assignments can result in idle agents, overloaded tasks, or inefficient execution, particularly as environmental conditions shift.
    
    % \item \textbf{Lack of Real-Time Responsiveness:} Without mechanisms for monitoring and adapting $f_t$, the system is unable to react to failures, delays, or unexpected events.

    \item \textbf{Lack of Real-Time Responsiveness:} Without mechanisms to monitor and adapt $f_t$, the system cannot respond effectively to failures, delays, or unforeseen events.
    
    % \item \textbf{Limited Scalability and Robustness:} The inability to flexibly reallocate resources or adapt to changing conditions restricts performance and resilience in large-scale, open, or uncertain environments.

    \item \textbf{Limited Scalability and Robustness:} The inability to reallocate resources dynamically constrains system performance and resilience in large-scale, open, or uncertain settings.
\end{itemize}

% These challenges highlight the necessity for MAS architectures and algorithms that support adaptive, real-time assignment of agents to tasks, leveraging feedback and monitoring to optimize system utility in dynamic environments.

These challenges underscore the necessity for MAS architectures that enable adaptive, real-time agent-task assignment, leveraging continuous monitoring and feedback to optimize system utility in dynamic environments.

% \begin{figure*}
%     \centering
%     \includegraphics[width=\linewidth]{images/overview.pdf}
%     \caption{Overall architecture of DRAMA, featuring a separation between the control plane and the work plane. The control plane is responsible for high-level decision-making, such as global coordination, task allocation, monitoring, and reasoning. The work plane consists of heterogeneous agents that interact with the environment, execute assigned tasks, and report observations and status.}
%     \label{fig:overview}
% \end{figure*}





\section{Methodology}
% DRAMA models both agents and tasks as unified resource objects with explicit lifecycles. Agents are heterogeneous worker nodes with distinct capabilities and operational states, while tasks are workload entities awaiting dynamic scheduling. This abstraction enables consistent, extensible management and lays the foundation for adaptive resource allocation.

% The architecture is divided into two planes as illustrated in Fig.~\ref{fig:overview2}:  
% \begin{itemize}
%     \item \textbf{Worker plane:} A scalable cluster of autonomous agents. Each agent perceives its environment, executes assigned tasks, maintains local memory for contextual reasoning, and communicates status updates.
%     \item \textbf{Control plane:} The global coordinator, continuously monitoring agent and task states, planning and validating assignments, and dynamically reallocating tasks based on real-time affinity evaluations. By decoupling agents from tasks, the control plane ensures robust, efficient operation even as agents or tasks change during execution.
% \end{itemize}
% In this section, we introduce DRAMA, which is a modular architecture that abstracts both agents and tasks as resource objects, enabling unified and flexible management. The system is divided into a control plane, responsible for real-time monitoring and dynamic, affinity-based task allocation, and a worker plane, composed of autonomous agents that execute and adapt to assigned tasks as illustrated in Fig.~\ref{fig:overview2}.

In this section, we introduce DRAMA, a modular architecture that abstracts both agents and tasks as resource objects to enable unified and flexible management. The system is organized into two planes: a control plane, which handles real-time monitoring and dynamic, affinity-based task allocation; and a worker plane, consisting of autonomous agents that execute and adapt to assigned tasks. An overview of the architecture is illustrated in Fig.~\ref{fig:overview2}.



% \subsection{Agent and Task Abstraction}


% To improve scalability and enable unified scheduling in multi-agent systems, we abstract both agents and tasks as first-class resource objects. Agents are modeled as heterogeneous worker nodes—each encapsulating distinct capabilities, resource limits, and operational attributes—while tasks are represented as workload objects requiring scheduling and execution. This unified resource abstraction facilitates a consistent and extensible decision-making process, allowing the system to efficiently accommodate diverse agent and task types under a common framework as depicted in Fig.~\ref{fig:abs}.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{images/scheduler.pdf}
%     \caption{An illustration of the scheduler and task allocation process within the control plane. The scheduler selects an available agent based on workload and affinity to the task.}
%     \label{fig:abs}
% \end{figure}
% A key aspect of our design is that the relationship between agents and tasks is loosely coupled through an affinity-based mechanism. Instead of statically assigning tasks to specific agents, the scheduler dynamically matches tasks to the most suitable agents according to real-time system conditions and affinity evaluations. These evaluations consider factors such as agent capabilities, current workload, physical location, and specific task requirements. Consequently, tasks are not rigidly bound to individual agents; they can be evicted or reassigned in response to changes in system state—such as agent failures or the arrival of more suitable agents—thereby enhancing the overall robustness and adaptability of the system.


% Both agents and tasks are managed with explicit lifecycle states. Agents transition through states such as active, offline, joining, or leaving, while tasks progress through states including pending, running, completed, or evicted. The control plane continuously monitors these lifecycles: if an agent becomes unavailable or overloaded, its unfinished tasks can be promptly evicted and rescheduled to other suitable agents. This mechanism ensures that the system remains resilient to dynamic changes in agent availability and maintains uninterrupted task execution, preventing any single agent from becoming a point of failure.

\subsection{Agent and Task Abstraction}

% To enable unified and adaptive scheduling, we abstract both agents and tasks as resource objects described in a common attribute space. Let $\mathcal{R} = \{r_1, r_2, ..., r_{N+M}\}$ denote the set of all agent and task objects, where each $r_k = \langle \mathcal{X}_{r_k} \rangle$ is characterized by its attribute set $\mathcal{X}_{r_k}$, such as capabilities, requirements, current status, workload, and other operational properties. Both agents and tasks are managed with explicit lifecycle states, and any transition—such as an agent becoming unavailable, a new task arriving, or a workload change—can trigger a reassignment.

To support unified and adaptive scheduling, we abstract both agents and tasks as resource objects represented within a common attribute space. Let $\mathcal{R} = \{r_1, r_2, \ldots, r_{N+M}\}$ denote the set of all agent and task entities, where each resource object $r_k = \langle \mathcal{X}{r_k} \rangle$ is defined by an attribute set $\mathcal{X}{r_k}$, encompassing properties such as capabilities, requirements, current status, workload, and other operational characteristics. Both agents and tasks are managed through explicit lifecycle states, and any state transition—such as agent unavailability, task arrival, or workload change—can trigger dynamic reassignment to maintain system responsiveness.

% Within this unified resource framework, the scheduler operates directly over the attribute sets $\{\mathcal{X}_{r_k}\}$. The assignment function $f_t$ at time $t$ is dynamically generated based on the current system state:

Within this unified resource framework, the scheduler operates directly on the attribute sets ${\mathcal{X}_{r_k}}$. At each time step $t$, the assignment function $f_t$ is dynamically generated based on the current system state:

\begin{equation}
    f_{t} = \mathrm{Scheduler}\left(\{\mathcal{X}_{r_k, t}\}_{k=1}^{N+M},\, \mathcal{E}_t\right)
\end{equation}
Whenever a significant attribute change occurs in any resource object, the scheduler reevaluates affinity to maintain system robustness and adaptivity. This design allows for flexible, event-driven rescheduling and seamless integration of heterogeneous agents and diverse tasks.

By leveraging this unified abstraction, the overall goal of the system can be formally formulated as:
\begin{equation}
    \max_{\{f_t\}_{t=1}^T} U\left(\{f_t\}_{t=1}^T,\, \{\mathcal{X}_{r_k}\},\, \mathcal{E},\, T\right)
\end{equation}



\subsection{Control Plane}

The control plane in DRAMA serves as the global coordinator and decision maker, ensuring robust, adaptive, and efficient collaboration among agents. Its core functionalities are organized into the following modules:

\subsubsection{State Monitoring and Aggregation}

% In DRAMA, state monitoring and aggregation are performed by a dedicated \textbf{Monitor} agent, which serves as the interface for receiving system information from the worker plane. The monitor agent collects two main categories of data. \textit{First}, it receives periodic heartbeat signals from each agent, which indicate their liveness and fundamental availability. \textit{Second}, it gathers environment information, which includes each agent’s announced status, task progress, current location, and other relevant attributes, as well as all task completion status.

In DRAMA, state monitoring and aggregation are handled by a dedicated \textbf{Monitor} agent, which serves as the interface for collecting system information from the worker plane. The monitor agent gathers two primary categories of data. First, it receives periodic heartbeat signals from each agent, indicating their liveness and basic operational availability. Second, it collects environment-related information, including each agent’s reported status, task progress, current location, and other relevant attributes, along with the completion status of all tasks. Formally, at each time step $t$, the monitor aggregates the attribute sets of all resource objects as follows:

% Formally, at each time step $t$, the monitor aggregates the attribute set of all resource objects as:
\begin{equation}
    \mathcal{X}_t = \left\{ \mathcal{X}_{r_k, t} \mid r_k \in \mathcal{R} \right\}
\end{equation}


% When necessary, the monitor agent promptly signals the planning component to initiate task reallocation, thereby ensuring that the system remains adaptive and responsive to dynamic changes in the environment.

When necessary, the monitor agent promptly signals the planning module to initiate task reallocation, ensuring that the system remains adaptive and responsive to dynamic environmental changes.

\subsubsection{Task Scheduling and Allocation}

At each scheduling event, the global assignment $f_t$ is determined through a two-stage Planner-Critic process:

\begin{equation}
    f_t = \mathrm{Planner\mbox{-}Critic}(\mathcal{X}_t,\, \mathcal{E}_t)
\end{equation}
% where the Planner proposes candidate allocations and the Critic evaluates and refines them until the system objectives are satisfied. This explicit separation of planning and critique~\cite{zhang2024proagent,hong2023metagpt} allows each stage to be independently optimized or augmented, enabling the system to flexibly incorporate new objectives or domain-specific constraints.

where the Planner proposes candidate allocations, and the Critic evaluates and refines them until the system objectives are met. This explicit separation of planning and evaluation~\cite{zhang2024proagent,hong2023metagpt} enables independent optimization of each stage and allows flexible incorporation of new objectives or domain-specific constraints.

% The scheduling strategy incorporates agent heterogeneity—including current workload, location, capabilities, and task affinities—to achieve balanced and efficient task allocation. Whenever the system detects an event (e.g., agent failure, new agent arrival, or abnormal task progress) that changes the resource state $\mathcal{X}_t$, the above two-stage scheduling process is immediately triggered as shown in Fig.~\ref{fig:abs}:

As illustrated in Fig.~\ref{fig:abs}, the scheduling strategy incorporates agent heterogeneity—including current workload, location, capabilities, and task affinities—to achieve balanced and efficient task allocation. Whenever the system detects an event (e.g., agent failure, new agent arrival, or abnormal task progress) that changes the resource state $\mathcal{X}_t$, the two-stage scheduling process described above is immediately triggered:

\begin{equation}
    \text{If an event } \mathcal{E}_{\mathrm{trig}} \text{ occurs at time } t,\ \text{then re-compute } f_t.
\end{equation}

% This event-driven mechanism ensures that DRAMA remains robust and adaptive by only updating task assignments in response to significant changes in the system state. Compared to traditional multi-agent systems that rely on static initial assignments or frequent polling, our event-driven strategy significantly reduces unnecessary resource consumption—including bandwidth, computation, and energy overhead—by eliminating redundant updates. 

This event-driven mechanism ensures that DRAMA remains robust and adaptive by updating task assignments only in response to significant changes in the system state. Compared to traditional multi-agent systems that rely on static initial assignments or frequent polling, our approach significantly reduces unnecessary resource consumption—such as bandwidth, computation, and energy—by avoiding redundant updates.


\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{images/scheduler.pdf}
    \caption{An illustration of the scheduler and task allocation process within the control plane. The scheduler selects an available agent based on workload and affinity to the task.}
    \label{fig:abs}
\end{figure}

It is important to note that the control plane scheduling described above operates at a coarse-grained, system-wide level. As the global coordinator, the control plane is responsible for periodically or event-drivenly assigning tasks to appropriate agents based on the overall system state and objectives. This global planning ensures balanced load, robustness, and optimal resource utilization in DRAMA.

% It is important to note that the control plane scheduling described above operates at a coarse-grained, system-wide level. As the global coordinator, the control plane is responsible for assigning tasks to appropriate agents either periodically or in response to significant events, based on the overall system state and objectives. This global planning mechanism ensures balanced workload distribution, system robustness, and optimal resource utilization within DRAMA.

\subsection{Worker Plane}

% The worker plane in DRAMA consists of a set of autonomous agents that operate within the VirtualHome environment. Each agent is explicitly modeled with attributes such as location, capability, and current status, reflecting both its spatial position and operational state. The worker plane supports heterogeneous agents, allowing for diverse capabilities, memory architectures, and reasoning modules, thereby enhancing system flexibility and resilience. Agents receive task assignments and orchestration directives from the control plane, and dynamically adapt their behavior in response to changes such as task reallocation or updates in team composition. 

In DRAMA, the worker plane comprises a set of autonomous agents operating within the environment. Each agent is explicitly characterized by attributes such as location, capabilities, and current status, capturing both its spatial position and operational condition. The worker plane supports heterogeneous agents with varying capabilities, memory architectures, and reasoning modules, enhancing system flexibility and resilience. Agents receive task assignments and orchestration directives from the control plane and dynamically adapt their behavior in response to changes such as task reallocation or team composition updates.

% \subsubsection{Perception}

% Each agent continuously perceives its environment through various sensors or input channels and maintains an evolving internal state. The perception process allows agents to gather information about their own status, the surrounding context, and the presence or actions of other agents. This sensory data forms the foundation for state estimation, enabling each agent to construct an accurate and up-to-date understanding of its operational context, which is essential for informed reasoning and decision making.

\subsubsection{Hierarchical Memory Management}

Each agent in the worker plane maintains a temporal context by systematically recording its past actions, observations, and communications, together with the evolving state of its environment. This persistent memory enables the agent to adapt its behavior according to accumulated experience.

% Each agent in the worker plane maintains a temporal context by systematically recording past actions, observations, and communications, along with the evolving state of its environment. This persistent memory enables agents to adapt their behavior based on accumulated experience, enhancing situational awareness and decision-making over time.

% To manage increasing task complexity and the growing volume of historical data, agents implement a hierarchical memory management strategy. Information related to ongoing main tasks and critical subtasks is assigned the highest priority and is retained in detail to support immediate and informed decision making. For more recent but less critical events, agents store summarized representations, such as key outcomes or significant observations, ensuring that essential context remains accessible without incurring substantial memory overhead. Historical data that are both outdated and irrelevant are selectively discarded to conserve resources.

To manage increasing task complexity and the growing volume of historical data, agents employ a hierarchical memory management strategy. Information related to ongoing primary tasks and critical subtasks is assigned the highest priority and retained in detail to support timely and informed decision-making. More recent but less critical events are stored as summarized representations—such as key outcomes or notable observations—ensuring essential context remains accessible without imposing significant memory overhead. Outdated and irrelevant historical data are selectively discarded to conserve resources.



\subsubsection{Action Planning and Execution}

% When an agent receives a coarse-grained task from the control plane, it initiates planning how to do the work and carry it out. First, the agent breaks down the big task into smaller, clear steps that fit the current environment. It uses what it can see around it—like the layout, where objects are, and any changes—as well as what it remembers from past actions and outcomes.

When an agent receives a coarse-grained task from the control plane, it starts to determine how to execute the task. The agent begins by decomposing the high-level task into a sequence of smaller, actionable steps tailored to the current environment, which leverages real-time perceptual inputs—such as spatial layout, object locations, and environmental changes—alongside the internal memory of past actions and outcomes.

% The agent does not rely only on its own experience; it also accounts for the potential actions and intentions of other agents. It tries to guess if there could be conflicts, if two agents might want the same resource, or if they can work together. It considers the current situation and thinks ahead about what might happen next, both in the environment and with other agents.

The planning of an agent considers not only its own experience but also the potential behaviors of other agents. It anticipates conflicts over shared resources and explores opportunities for collaboration. By reasoning about the current situation and projecting possible future developments, the agent can make more informed and coordinated decisions.

% An agent’s planning process extends beyond its own experience; it also accounts for the potential actions and intentions of other agents. It anticipates possible conflicts—such as contention over shared resources—or opportunities for collaboration. By reasoning about the current situation and projecting possible future developments in both the environment and the behavior of other agents, the agent can make more informed and coordinated decisions.

% A main feature of our approach is that agents can \textbf{take over unfinished tasks} from others if needed. If one agent leaves or cannot finish its job, another agent can notice this and decide if it should step in. This helps the team keep working well, even if something goes wrong.

A key feature of our approach is that agents can \textbf{take over unfinished tasks}. If one agent leaves or cannot finish its job, another agent can notice this and decide if it should step in. This enables seamless recovery and maintains overall system performance under disruptions.

% The agent makes a plan by choosing and ordering simple built-in commands and actions. It looks at its current situation, what it knows, and what it expects might happen. After making the plan, the agent’s controller takes care of the details and checks if each step goes as planned.

The agent plans by selecting and ordering primitive actions based on its current situation, prior knowledge, and anticipated future developments. The controller then executes the plan and monitors each step to ensure correct execution.

% The agent constructs a plan by selecting and sequencing a set of built-in primitive actions based on its current state, prior knowledge, and anticipated future developments. Once the plan is formulated, the agent’s controller is responsible for executing each step, handling low-level control, and monitoring execution to ensure that actions proceed as intended.


\section{Experiment Setup}

\begin{figure*}
    \centering
    \includegraphics[width=.9\linewidth]{images/grouped_bar_as_ts.pdf}
    % \caption{Performance comparison of DRAMA and other baseline methods under different scenarios, where the shaded column represents the Total Steps (TS) of a method, while the solid-line framed column represents the Average Steps (AS) of it.}
    \caption{Performance comparison of DRAMA and baseline methods across different scenarios. Shaded columns indicate Total Steps (TS), while solid-bordered columns represent Average Steps (AS).}
    \label{fig:total}
\end{figure*}
\subsection{Dataset}
To better evaluate the effectiveness and robustness of different multi-agent coordination methods in embodied situations, we build upon the Communicative Watch-And-Help (C-WAH) benchmark~\cite{zhang2023building}, which extends the original Watch-And-Help Challenge~\cite{puig2020watch} in the VirtualHome-Social environment~\cite{puig2018virtualhome}. While C-WAH focuses on agent cooperation and supports inter-agent communication, we observed that the default task settings are relatively simple and may not sufficiently differentiate the capabilities of advanced methods. To address this, we construct a more challenging experimental setting by increasing the number of objects involved in each task, thereby introducing greater complexity and requiring more sophisticated cooperation strategies. 






\subsection{Baselines}

To comprehensively evaluate our framework, we compare it against several representative baselines, each reflecting a distinct coordination or planning paradigm. Since these baselines were not originally designed for the C-WAH dataset, we adapted and re-implemented them for this setting. For robustness evaluation, we adhere to each baseline’s original design, including their lack of support for task handover where applicable. For efficiency evaluation, however, we equip all methods with additional capabilities to ensure comparably high success rates: specifically, each method is provided with both the final target and current progress information as input. These enhancements enable a fair and direct comparison of the efficiency of different task assignment strategies across baselines.

The compared methods are:


\begin{itemize}
    \item \textbf{CoELA}~\cite{zhang2023building}: Enables agents to plan, communicate, and cooperate via explicit inter-agent messaging and modular teamwork.
    \item \textbf{MCTS}~\cite{gan2025master}: Employs Monte Carlo Tree Search for planning-based task allocation, selecting high-reward solutions within a fixed search budget.
    \item \textbf{AgentVerse-Static (AV-Static)}~\cite{chen2023agentverse}: Assigns agent roles and tasks only at initialization; assignments remain fixed throughout execution.
    \item \textbf{AgentVerse-Dynamic (AV-Dynamic)}: Triggers reallocation among agents only upon task completion, periodically redistributing remaining tasks.
    \item \textbf{ProAgent}~\cite{zhang2024proagent}: Adopts a fully decentralized approach—agents coordinate via communication, prediction, and negotiation, without a central scheduler.
\end{itemize}



\subsection{Metrics}

To rigorously assess multi-agent cooperation in dynamic environments, we employ a comprehensive set of metrics that evaluate both outcome and process-level performance. These metrics capture not only task completion but also system efficiency, adaptability, and resource utilization.


\textbf{Success Rate (SR):} 
Measures \emph{robustness} as the proportion of episodes in which all task requirements are fully met within the specified time horizon, reflecting the system’s reliability under uncertainty.

\textbf{Average Steps (AS):}
Quantifies temporal efficiency by calculating the mean number of steps taken by the agent completing the final task in each episode, indicating overall latency and the system’s \emph{effectiveness} in minimizing completion time for complex tasks.

\textbf{Total Steps (TS):}
Sums the steps taken by all agents per episode, representing total collaborative effort and resource consumption. In embodied environments, TS serves as a direct proxy for overall \emph{resource expenditure}, encompassing time, energy, and throughput, thereby reflecting the capability for efficient collaboration and resource management.



% \subsection{Implementation Details:} This environment is is running on Unity version linux\_exec.v2.2.4, GPU 4090,CPU 16 vCPU Intel(R) Xeon(R) Platinum 8358P CPU \@ 2.60GHz, CUDA 12.1.105,PYTHON 3.8.0.


\subsection{Scenario Design}

To thoroughly evaluate the robustness and adaptability of our framework, we design experimental scenarios encompassing both static and dynamic agent populations:


\begin{itemize}
    \item \textbf{Static Scenarios:} The number of worker agents remains constant throughout the experiment. We consider three static configurations with 2, 3, or 4 agents.
    \item \textbf{Dynamic Scenarios:} To evaluate adaptability to environmental changes, we introduce two dynamic scenarios, both initialized with 3 agents:
    \begin{itemize}
        \item \emph{Agent Dropout:} At a randomly selected step between 5 and 10, one agent is randomly removed from the environment (simulating a crash or disconnection), leaving the remaining agents to complete the task.
        \item \emph{Agent Addition:} At a randomly selected step between 5 and 10, a new agent is introduced into the environment, increasing the number of active agents for the remainder of the experiment.
    \end{itemize}
\end{itemize}

These scenarios are designed to reflect realistic settings, where agent availability may fluctuate due to unexpected failures or resource scaling. By evaluating the framework in both stable and dynamic scenarios, we aim to demonstrate its effectiveness and resilience in real-world deployments.

\section{Experimental Results}


\subsection{Effectiveness of DRAMA}

\subsubsection{Efficiency}
To evaluate the efficiency of DRAMA, we compare the AS and TS of all methods. As shown in Fig.~\ref{fig:total}, in static scenarios with fewer agents, the differences among methods are relatively small. However, as the environment becomes more complex—such as with an increased number of agents or the introduction of dynamic events—DRAMA exhibits more substantial advantages. In challenging scenarios, including more-agent (4 agents), agent addition, and agent disconnection, DRAMA consistently outperforms the strongest baseline methods. Specifically, it achieves a 4.8\% to 13.5\% reduction in AS and a 4.6\% to 17.3\% reduction in TS, demonstrating superior efficiency and adaptability.

% To evaluate efficiency, we compare the Action Steps (AS) and Time Steps (TS) required by each method, as shown in Fig.~\ref{fig:total}. In static scenarios with fewer agents, the performance differences among methods are relatively small. However, as the environment becomes more complex—such as with an increased number of agents or the introduction of dynamic events—DRAMA exhibits more substantial advantages. In challenging scenarios, including more-agent (4 agents), agent addition, and agent disconnection, DRAMA consistently outperforms the strongest baseline methods. Specifically, DRAMA achieves a 4.8% to 13.5% reduction in AS and a 4.6% to 17.3% reduction in TS, demonstrating superior efficiency and adaptability.

\subsubsection{Robustness}
% To more comprehensively illustrate framework-level robustness, Tab.~\ref{tab:dynamic_sr} summarizes the ability of each method to successfully handle various environmental scenarios, including static settings and different types of agent dynamics. Specifically, our dropout scenarios correspond to agent number reductions from 4 to 3 and from 3 to 2, while the addition scenario represents an increase from 3 to 4 agents. Notably, DRAMA is the only framework that passes all these cases, including both agent dropout and agent addition, as well as the static case. In contrast, all baselines fail in agent dropout scenarios, as they are unable to reassign unfinished tasks when agents leave the system.

To comprehensively illustrate framework-level robustness, Tab.~\ref{tab:dynamic_sr} summarizes whether each method successfully completes the task across a variety of environmental scenarios, including static settings and different types of agent dynamics. Specifically, the dropout scenarios simulate reductions in the number of agents (from 4 to 3), while the addition scenario involves an increase from 3 to 4 agents. Notably, DRAMA is the only framework that successfully addresses all scenarios. In contrast, all baseline methods fail under agent dropout conditions, as they lack the capacity to reassign incomplete tasks when agents leave.

\begin{table}[t]
\centering
\resizebox{\linewidth}{!}{
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{cccccc}
\toprule
\textbf{CoELA} & \textbf{MCTS} & \textbf{ProAgent} & \textbf{AV-static} & \textbf{AV-dynamic} & \textbf{DRAMA} \\
\midrule
% \rowcolor{gray!15}
\multicolumn{6}{c}{\textbf{Static}} \\

\cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\


% \rowcolor{gray!15}
\multicolumn{6}{c}{\textbf{Dynamic: Agents Dropout}} \\

\xmark & \xmark  & \xmark & \xmark  & \xmark  & \cmark \\


% \rowcolor{gray!15}
\multicolumn{6}{c}{\textbf{Dynamic: Agents Addition}} \\

\cmark & \cmark & \cmark & \cmark & \cmark & \cmark \\

\bottomrule
\end{tabular}
}
% \caption{Scenario pass/fail comparison across different environmental conditions. \cmark: passed, \xmark: failed. Only DRAMA supports agent dropout scenarios.}
\caption{Scenario success comparison across varying environmental conditions. \cmark~indicates success; \xmark~indicates failure. Only \textbf{DRAMA} successfully supports all scenarios.}

\label{tab:dynamic_sr}
\end{table}





\subsection{Stableness of DRAMA}

% Two tasks from C-WAH are each evaluated over 100 runs to rigorously assess framework stability. Fig.~\ref{fig:stable} shows the distributions of AS and Total Steps TS across dynamic scenarios with agent dropout (3$\rightarrow$2) and agent addition (3$\rightarrow$4). DRAMA consistently achieves lower median AS and TS, with notably tighter distributions compared to all baselines. In both scenarios, DRAMA demonstrates strong robustness and stability, maintaining efficient task completion despite fluctuations in agent population. In contrast, other methods exhibit greater variability and higher resource consumption, indicating higher sensitivity to environmental changes. These results highlight DRAMA’s superior resilience and efficiency in dynamic multi-agent settings. 

To rigorously assess framework stability, two tasks from C-WAH are each evaluated over 100 independent runs. Fig.~\ref{fig:stable} presents the distributions of Average Steps (AS) and Total Steps (TS) under dynamic scenarios involving agent dropout (3$\rightarrow$2) and agent addition (3$\rightarrow$4). As shown in the figure, DRAMA consistently achieves lower median AS and TS, with significantly tighter distributions compared to all baselines. These results demonstrate strong robustness and stability of DRAMA in maintaining efficient task execution despite fluctuations in agent population. In contrast, baseline methods exhibit greater variability and increased resource consumption, indicating higher sensitivity to environmental dynamics. Overall, the results highlight the superior resilience and operational efficiency of DRAMA in dynamic multi-agent environments.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{images/combined_violin_scalability_disconnect_task_0_scalability_new_task_0.pdf}
    % \caption{Distribution of Action Steps (AS) and Total Steps (TS) for different frameworks, each evaluated over 100 runs on the same task. Yellow denotes DRAMA.}
    \caption{Distributions of Average Steps (AS) and Total Steps (TS) across 100 runs for each framework on the same task.}

    \label{fig:stable}
\end{figure}
\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{images/casestudy.pdf}
    % \caption{A case study example of DRAMA occurring when Bob disconnects.}
    \caption{An example scenario demonstrating the dynamic adaptation of DRAMA after Bob disconnects.}
    \label{fig:case}
\end{figure*}
\subsection{Generalization of DRAMA}
% To rigorously evaluate the model-agnostic generalization capability of the DRAMA framework, we conducted additional experiments using multiple state-of-the-art foundation models as agent backbones. Specifically, we selected two strong large language models—Qwen-Max and GPT-4.1—as well as a high-performance reasoning model, Qwen-QWQ-Max. To further assess performance under resource-constrained settings, we also included GPT-4o-mini.

To comprehensively evaluate the model-agnostic generalization capability of our DRAMA framework, we conducted experiments with a diverse set of state-of-the-art foundation models serving as agent backbones, which include two powerful large language models (Qwen-Max and GPT-4.1), a high-performing reasoning model (Qwen-QWQ-Max), and also a lightweight model (GPT-4o-mini) to test DRAMA’s performance under resource-limited conditions.

% For each agent configuration, we instantiated the DRAMA framework with the respective model and executed the standard task suite under both static and dynamic scenarios. Results shown in Tab.~\ref{tab:models} demonstrate that DRAMA consistently achieves high task success rates and efficient collaboration across all models, with only marginal differences observed between large and small models. Notably, even when using the lightweight GPT-4o-mini, DRAMA maintains robust operation and efficient task allocation.

Under each agent configuration, we deployed DRAMA with the corresponding foundation model and evaluated it across the full task suite under both static and dynamic conditions. The results in Tab.~\ref{tab:models} confirm that DRAMA delivers consistently high task success rates and efficient multi-agent coordination, regardless of model size. Remarkably, DRAMA remains robust and effective even when backed by the lightweight GPT-4o-mini model. These results demonstrate that DRAMA operates independently of the underlying agent model, exhibiting strong generalization across diverse LLM backbones.

\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{2pt}
\begin{tabular}{c|cccc}
\toprule
\textbf{Metric} & \textbf{GPT-4.1} & \textbf{Qwen-max} & \textbf{Deepseek-v3} & \textbf{4o-mini} \\
\midrule


\multicolumn{5}{c}{\textbf{Dynamic: 3 Agents to 2 Agents}} \\

SR (\%)      & 100 & 100 & 100 & 100 \\
AS (Steps)   & 56.13 & 58.74 & 59.48 & 62.26 \\
TS (Steps)   & 93.88 & 99.96 & 93.90 & 102.94 \\
\midrule


\multicolumn{5}{c}{\textbf{Dynamic: 3 Agents to 4 Agents}} \\

SR (\%)      & 100 & 100 & 100 & 100 \\
AS (Steps)   & 49.64 & 51.26 & 52.62 &  53.81 \\
TS (Steps)   & 119.63 & 116.00 & 120.55 & 124.67 \\
\bottomrule
\end{tabular}
\caption{Performance of DRAMA with different models in the agent dropout scenario (3$\rightarrow$2 agents) and addition scenario (3$\rightarrow$4 agents). SR indicates \textit{Success Rate}.}
\label{tab:models}
\end{table}

% These findings indicate that the DRAMA framework is fundamentally independent of the choice of agent model, capable of supporting a wide variety of LLM backbones. 


\subsection{Case Study}

% As illustrated in Fig.~\ref{fig:case}, the system demonstrates robust adaptation to agent failure. When the monitor detects that Bob has become unresponsive in the living room, it flags the issue and triggers the control plane to reassign Bob’s tasks. The planner, observing that only Alice and Carter remain available—neither ideally positioned for Bob’s subtasks—randomly assigns these tasks to Carter. This reassignment is validated by the critic and enacted by the scheduler, ensuring no interruption in task execution.

As illustrated in Fig.~\ref{fig:case}, the system demonstrates robust adaptability to agent failure. Upon detecting that Bob has become unresponsive in the living room, the monitor flags the issue and triggers the control plane to reassign his tasks. The planner, recognizing that only Alice and Carter remain—neither optimally located for Bob’s subtasks—randomly assigns them to Carter. This reassignment is validated by the critic and executed by the scheduler, ensuring uninterrupted task completion.

% Following the update, worker agents promptly adapt their strategies. Alice continues with her plan to collect pudding and juice from the kitchen and deliver them to the coffeetable. Carter, now responsible for Bob’s remaining subtask, prioritizes delivering the cupcake he is holding and prepares to search for any additional required items. Through such dynamic coordination between control and worker planes, the team maintains steady progress toward the shared goal, effectively handling unexpected disruptions.

Following the update, the worker agents promptly adapt their strategies. Alice proceeds with her plan to collect pudding and juice from the kitchen and deliver them to the coffee table. Carter, now reassigned Bob’s remaining subtask, prioritizes delivering the cupcake he is holding and prepares to search for any additional required items. This dynamic coordination between the control and worker planes enables the team to maintain steady progress toward the shared goal, effectively handling unexpected disruptions.

\section{Related Work}

% MAS refers to computational frameworks in which multiple autonomous agents interact, cooperate, or compete to achieve individual or collective goals~\cite{torreno2017cooperative}. Traditionally, MAS research has focused on designing agents that can perceive their environment, make decisions, and coordinate actions, enabling the system to tackle complex tasks that surpass the capabilities of a single agent.

% With rapid progress in artificial intelligence, especially the emergence of LLMs, there has been a shift toward leveraging LLMs as the backbone for more powerful and versatile agent systems~\cite{li2024survey,guo2024large}. LLM-powered agents exhibit remarkable capabilities in reasoning, planning, and communication, making them well-suited as autonomous decision-makers or collaborators across domains. Recent LLM-based MAS have achieved impressive progress in solving complex and real-world problems~\cite{li2024agent}, including collaborative problem-solving~\cite{qian2023chatdev,hong2023metagpt,chen2024scalable}, world simulations~\cite{park2023generative,kaiya2023lyfe}, and embodied tasks~\cite{guo2024embodied,zhang2023building}. These systems harness collective intelligence, flexible communication, and agent-oriented planning to decompose queries into effective sub-tasks, as well as leveraging meta-agents for dynamic scheduling and feedback-driven adjustment~\cite{li2024agent}.

% A key research frontier involves the \emph{automation of agent workflow and architecture design}. Early works such as CAMEL~\cite{li2023camel} and AgentVerse~\cite{chen2023agentverse} focused on scalable, role-based multi-agent cooperation and dynamic team assembly. MASTER~\cite{gan2025master} integrated LLM-driven MCTS for dynamic agent recruitment and reward estimation, while ProAgent~\cite{zhang2024proagent} enabled real-time belief updating and adaptation among agents. To reduce manual effort and enhance adaptability, recent methods automate the generation and optimization of agentic workflows. For example, AFlow~\cite{zhang2024aflow} frames workflow construction as a code search problem, using MCTS to iteratively refine executable workflows with feedback. Similarly, MaAS~\cite{zhang2025multi} proposes the concept of an agentic supernet—a probabilistic distribution over agentic architectures—which allows query-dependent sampling of multi-agent systems.

MAS refers to computational frameworks where multiple autonomous agents interact, cooperate, or compete to achieve individual or collective goals~\cite{torreno2017cooperative}. Traditionally, MAS research has focused on building agents capable of perceiving their environment, making decisions, and coordinating actions to solve complex problems beyond the capacity of any single agent.

With the rapid advancement of LLMs, MAS has undergone a paradigm shift. LLMs now serve as powerful and versatile backbones for agent systems~\cite{li2024survey,guo2024large}, offering strong capabilities in reasoning, planning, and communication. Recent LLM-based MAS frameworks have demonstrated promising results in collaborative problem-solving~\cite{qian2023chatdev,hong2023metagpt,chen2024scalable}, world modeling and simulation~\cite{park2023generative,kaiya2023lyfe}, and embodied decision-making tasks~\cite{guo2024embodied,zhang2023building}. These systems leverage collective intelligence, structured communication, and agent-oriented planning to effectively decompose complex tasks, often employing meta-agents for dynamic scheduling and adaptive feedback~\cite{li2024agent}.

A major emerging research frontier involves the \emph{automation of agent workflow and architectural design}. Early systems like CAMEL~\cite{li2023camel} and AgentVerse~\cite{chen2023agentverse} explored scalable, role-based cooperation and dynamic team formation. MASTER~\cite{gan2025master} incorporated LLM-driven Monte Carlo Tree Search (MCTS) for adaptive agent recruitment and reward estimation, while ProAgent~\cite{zhang2024proagent} focused on real-time belief updating and agent adaptation. AFlow~\cite{zhang2024aflow} frames workflow generation as a code search problem, using MCTS for iterative refinement guided by feedback. MaAS~\cite{zhang2025multi} introduces the concept of an agentic supernet—a probabilistic distribution over MAS architectures—to enable query-conditioned sampling and optimization.


\section{Conclusion}
In this work, we propose \textbf{DRAMA}, a dynamic and robust allocation-based multi-agent system designed for rapidly changing environments. By unifying agent and task abstraction as resource objects and employing an affinity-driven, event-triggered scheduling mechanism, DRAMA achieves superior adaptability, efficiency, and robustness in dynamic scenarios. Experimental results demonstrate consistent improvements in runtime efficiency and resource utilization. Also, DRAMA remains resilient under agent turnover and dynamic task demands. These encouraging results highlight its practical applicability for real-world multi-agent systems.

\section{Limitations}
% While DRAMA’s centralized control enables effective global coordination, it introduces risks of single-point failure and scalability bottlenecks. Future work could explore decentralized or hierarchical control to improve resilience and scalability. Also, DRAMA currently relies on LLM reasoning to evaluate agent-task affinity. This introduces inevitable inference latency, which may become a bottleneck in real-time scheduling. Additionally, LLMs are susceptible to hallucination, potentially resulting in sub-optimal or erroneous task assignments. Future work should explore incorporating lightweight reasoning models, hybrid affinity estimation to enhance both efficiency and reliability.

While DRAMA’s centralized control facilitates effective global coordination, it also poses potential risks such as single points of failure and scalability limitations. Furthermore, DRAMA currently depends on LLM-based reasoning for agent-task affinity evaluation, which introduces inference latency and may hinder real-time scheduling.
\newpage



\newpage
\bibliography{aaai2026}

% \input{ReproducibilityChecklist}

\end{document}
