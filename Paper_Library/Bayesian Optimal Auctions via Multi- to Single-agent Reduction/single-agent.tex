\section{The Single-agent Problem}
\label{sec:single-agent}

Given an allocation rule $\talloc(\cdot)$ as a constraint the
single-agent problem is to find the (possibly randomized) outcome rule
$\toutcome(\cdot)$ that allocates no more frequently that
$\talloc(\cdot)$, i.e., $\forall \type \in \typespace$,
$\expect[\toutcome(\type)]{\ALLOC(\toutcome(\type))} \leq
\talloc(\type)$, with the maximum expected performance.  Recall that the optimal
such outcome rule is denoted $\RULE(\talloc)$ and its performance
(e.g., revenue) is denoted $\REV(\talloc)$.  We first observe that $\REV(\cdot)$ is concave.

\begin{proposition}
\label{claim:concave}
$\REV(\cdot)$ is a concave function in $\Inter \alloc$.
\end{proposition}
\begin{proof}
Consider any two allocation rules $\intalloc$ and $\intalloc'$,
and any $\alpha \in [0,1]$.  Define $\intalloc''$ to be $\alpha
\intalloc + (1-\alpha) \intalloc'$.  We will show that $\alpha
\REV(\intalloc) + (1 - \alpha) \REV(\intalloc') \leq
\REV(\intalloc'')$, which proves the claim.  To see this, let
$\toutcome$ and $\toutcome'$ be $\RULE(\intalloc)$ and
$\RULE(\intalloc')$, respectively.
%the optimizers of $\REV(\Inter \alloc)$ and $\REV(\Inter y)$. 
Define $\toutcome''$ to be the outcome rule that runs $\toutcome$ with
probability~$\alpha$, and $\toutcome'$ with probability $1-\alpha$.
The incentive compatibility of outcome rules $\toutcome$ and
$\toutcome'$ imply the incentive compatibility of $\toutcome''$, since
for any $\type, \type' \in \typespace$,
\begin{align*}
\expect{\util(\type, \toutcome''(\type))} 
  &= \alpha \expect{\util(\type, \toutcome(\type))} + (1 - \alpha)
\expect{\util(\type, \toutcome'(\type))} \\
&\geq  \alpha \expect{\util(\type, \toutcome(\type'))} + (1 - \alpha)
\expect{\util(\type, \toutcome'(\type'))}\\
& = \expect {\util(\type,\toutcome''(\type'))}.
\end{align*}
Also, $\toutcome''$ is feasible as $\expect{\ALLOC(\toutcome''(\type))} = \alpha
\expect{\ALLOC(\toutcome(\type))} + (1-\alpha)
\expect{\ALLOC(\toutcome'(\type))} \leq \intalloc''(\type)$ for all
$\type \in \typespace$. As a result, $\REV(\intalloc'')$ is at least
the revenue of $\toutcome''$, which is in turn equal to $\alpha
\REV(\intalloc) + (1-\alpha) \REV(\intalloc')$.
\end{proof}


We now give two examples for which the single-agent problem is
computationally tractable.  Both of these example are
multi-dimensional.  The first example is that of a standard multi-item
unit-demand preferences.  The second example that of a single-item
with a private budget.  For both of these problems the single-agent
problem can be expressed as a linear program with size polynomial in
the cardinality of the agent's type space.

\subsection{Quasi-linear Unit-demand Preferences}

There are $\numservice$ items available.  There is a finite type space
$\typespace \subset \posreals^\numservice$; the outcome space
$\outcomespace$ is the direct product between an assignment to the
agent of one of the $\numservice$ items, or none, and a required
payment.  $\outcomedistspace$ is the cross product of a probability
distribution over which item the agent receives and a probability
distribution over payments.  Without loss of generality for a
quasi-linear agent such a randomized outcome can be represented as
$\outcome =
(\mdalloc{\outcome}{1},\ldots,\mdalloc{\outcome}{\numservice},\mdprice{\outcome})$
where for $j \in [\numservice]$, $\mdalloc{\outcome}{j}$ is the
probability that the agent receives item $j$ and $\mdprice{\outcome}$
is the agent's required payment.

A single-agent mechanism assigns to each type an outcome as described
above.  An outcome rule specifies an outcome for any type $\type$ of
the agent as $\toutcome(\type) =
(\mdalloc{\toutcome}{1}(\type),\ldots,\mdalloc{\toutcome}{\numservice}(\type),\mdprice{\toutcome}(\type))$.
This gives $\numservice+1$ non-negative real valued variables for each of
$|\typespace|$ types.  The following linear program, which is a simple
adaptation of one from \citet{BCKW-10} to include the feasibility
constraint given by $\talloc$, solves for the optimal single-agent
mechanism:
\begin{align*}
\max: & \quad \sum\nolimits_{\type \in \typespace} \dens(\type) \mdprice{\outcome}(\type) & \\
\hbox{s.t. }&\quad\!\sum\nolimits_j \mdalloc{\toutcome}{j}(\type) \leq \intalloc(\type) & \forall \type \in \typespace \\
            & \quad \sum\nolimits_j \mdval{\type}{j} \mdalloc{\toutcome}{j}(\type) - \mdprice{\toutcome}(\type) \geq \sum\nolimits_j \mdval{\type}{j} \mdalloc{\toutcome}{j}(\type') - \mdprice{\toutcome}(\type') & \forall \type,\type' \in \typespace\\
            & \quad \sum\nolimits_j \mdval{\type}{j} \mdalloc{\toutcome}{j}(\type) - \mdprice{\toutcome}(\type) \geq 0 & \forall \type \in \typespace.
\end{align*}
%
The optimal outcome rule from this program is $\toutcome^* = \RULE(\talloc)$ and its performance is $\REV(\talloc) = \expect[\type \sim \dens]{\mdprice{\toutcome^*}(\type)}$.

\begin{proposition}
The single-agent $\numservice$-item unit-demand problem can be solved
in polynomial time in $\numservice$ and $|\typespace|$.
\end{proposition}


\subsection{Private budget preferences.}

There is a single item available.  The agent has a private value for
this item and a private budget, i.e., $\typespace \subset
\posreals^2$; we will denote by $\bugval{\type}$ and $\bugbug{\type}$
this value and budget respectively.  The outcome space is
$\outcomespace = \{0,1\} \times \reals$ where for $\outcome
\in \outcomespace$ the first coordinate $\bugalloc{\outcome}$ denotes
whether the agent receives the item or not and the second coordinate
$\bugprice{\outcome}$ denotes her payment.  The agent's utility
is 
\[\util(\type,\outcome) =
\begin{cases}
\bugval{\type} \bugalloc{\outcome} - \bugprice{\outcome} & \text{if $\bugprice{\outcome} \leq \bugbug{\type}$, and }\\
-\infty & \text{otherwise.} 
\end{cases}
\] 
\autoref{claim:private-budget} below implies that when optimizing over
distributions on outcomes we can restrict attention to $[0,1] \times
[0,1] \times \posreals \subset \outcomedistspace$ where the first
coordinate denotes the probability that the agent receives the item,
the second coordinate denotes the probability that the agent makes a
non-zero payment, and the third coordinate denotes the non-zero
payment made.

\begin{claim}
\label{claim:private-budget}
Any incentive compatible and individually rational outcome rule can
be converted into an outcome rule above with the same expected
revenue.
\end{claim}

As a sketch of the argument to show this claim, note that if an agent
with type $\type$ receives randomized outcome $\outcome$ she is just
as happy to receive the item with the same probability and pay her
budget with probability equal to her previous expected payment divided
by her budget.  Such a payment is budget feasible and has the same
expectation as before.  Furthermore, this transformation only increases
the maximum payment that any agent makes which means that the relevant
incentive compatibility constraints are only fewer.  Importantly, the
only incentive constraints necessary are ones that prevent types with
higher budgets from reporting types with lower budgets.

A single-agent mechanism assigns to each type an outcome as described
above.  We denote the distribution over outcomes for $\type$ by
$\toutcome(\type) =
(\bugalloc{\outcome}(\type),\bugprob{\outcome}(\type),\bugbug{\type})$
where only the first two coordinates are free variables.  This gives
two non-negative real valued variables for each of $|\typespace|$
types.  The following linear program solves for the optimal
single-agent mechanism:
\begin{align*}
\max: & \quad \sum\nolimits_{\type \in \typespace} \dens(\type) \bugbug{\type} \bugprob{\outcome}(\type) & \\
\hbox{s.t. }&\quad \bugalloc{\outcome}(\type) \leq \intalloc(\type) & \forall \type \in \typespace \\
            & \quad \bugval{\type} \bugalloc{\outcome}(\type) - \bugbug{\type}\bugprob{\outcome}(\type) \geq \bugval{\type} \bugalloc{\outcome}(\type') - \bugbug{\type'}\bugprob{\outcome}(\type') & \forall \type,\type' \in \typespace \text{ with $\bugbug{\type'} \leq \bugbug{\type}$}\\
            & \quad \bugval{\type} \bugalloc{\outcome}(\type) - \bugbug{\type}\bugprob{\outcome}(\type) \geq 0 & \forall \type \in \typespace\\
            & \quad \bugprob{\outcome}(\type) \leq 1 & \forall \type \in \typespace.
\end{align*}
%
The optimal outcome rule from this program is $\toutcome^* = \RULE(\talloc)$ and its performance is $\REV(\talloc) = \expect[\type \sim \dens]{\bugbug{\type}\bugprob{\toutcome^*}(\type)}$.


\begin{proposition}
The single-agent private budget problem can be solved in polynomial
time in $|\typespace|$.
\end{proposition}
