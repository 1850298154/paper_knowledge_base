%\section{Mechanism Design via Reduced Forms}
\section{Multi- to Single-agent Reductions}
\label{sec:alg}%

%%
%% review of notation.
%%
An ex post allocation rule $\epallocs$ takes as its input a profile of
types $\Types=(\Type_1,\ldots, \Type_n)$ of the agents, and indicates
by $\epalloc_i(\types)$ a set of at most $k$ winners.  Agent $i$'s type
$\type_i \in \typespace_i$ is drawn independently at random from
distribution $\dens_i \in \distover{\typespace_i}$.  An ex post
allocation rule implements an interim allocation rule $\InAlloc_i
: \TypeSpace_i \to [0,1]$, for agent~$i$, if the probability of winning
for agent $i$ conditioned on her type $\Type_i \in \TypeSpace_i$ is
exactly $\InAlloc_i(\Type_i)$, where the probability is taken over the
random types other agents and the random choices of the allocation
rule.  A profile of interim allocation rules
$\InAllocs=(\InAlloc_1,\ldots, \InAlloc_n)$ is feasible if and only if
it can be implemented by some ex post allocation rule. $\InAllocSpace$
denotes the space of all feasible profiles of interim allocation
rules.

The optimal performance (e.g., revenue) of the single-agent problem
with allocation constraint given by $\talloc$ is denoted
$\REV(\talloc)$.  The outcome rule corresponding to this optimal
revenue is $\RULE(\talloc)$.  Given any feasible interim allocation
rule $\intallocs \in \InAllocSpace$ we would like to construct an
auction with revenue $\sum\agind \REV(\talloc\agind)$.  We need to be
careful because $\RULE(\intalloc\agind)$, by definition, is only
required to have allocation rules \emph{upper bounded}
by~$\intalloc\agind$ (see \eqref{eq:rule-rev-def} in
Section~\ref{sec:prelim}), while the ex post allocation
rule~$\epalloc\agind$ implements $\intalloc\agind$ exactly, and hence
we may need to scale down~$\epalloc\agind$ accordingly.  This is
defined formally as follows.

\begin{definition}
An optimal auction $\epoutcomes^*$ for feasible interim allocation rule $\intallocs$ (with corresponding ex post allocation rule $\epallocs$) is defined as follows on $\types$.  For agent $\agent$:
\begin{enumerate}
\item Let $\intoutcome^*\agind = \RULE(\intalloc\agind)$ be the optimal outcome rule for allocation constraint $\intalloc\agind$.
\item Let $\intalloc^*\agind = \expect{\ALLOC(\intoutcome^*\agind)}$
  be the allocation rule corresponding to outcome rule $\intoutcome^*\agind$.
\item If $\epalloc\agind(\types) = 1$, output
\[
\epoutcome^*\agind(\types) \sim
\begin{cases}
 \distribution{\intoutcome^*\agind(\type\agind) \given \ALLOC(\intoutcome^*\agind(\type\agind)) = 1}  & \text{w.p.~$\intalloc^*\agind(\type\agind)/\intalloc\agind(\type\agind)$, and}\\
\distribution{\intoutcome^*\agind(\type\agind) \given \ALLOC(\intoutcome^*\agind(\type\agind)) = 0} &\text{otherwise.}
\end{cases}
\]
\item Otherwise (when $\epalloc\agind(\types) = 0$), output
$\epoutcome^*\agind(\types) \sim \distribution{\intoutcome^*\agind(\type\agind) \given \ALLOC(\intoutcome^*\agind(\type\agind)) = 0}.$
\end{enumerate}
\end{definition}

\begin{proposition}
\label{prop:implementation}
For any feasible interim allocation rule $\intallocs
\in \InAllocSpace$, the optimal auction for this rule has expected
revenue $\sum_i \REV(\intalloc\agind)$.
\end{proposition}

\begin{proof}
The ex post outcome rule $\epoutcomes^*$ of the auction, by
construction, induces interim outcome rule $\intoutcomes^*$ for which
the revenue is as desired.
\end{proof}

The optimal multi-agent auction is the solution to optimizing the
cumulative revenue of individual single-agent problems subject to the
joint interim feasibility constraint given by $\intallocs
\in \InAllocSpace$.

\begin{proposition}
\label{claim:outcome-impl}
The optimal revenue is given by the convex program
\begin{align}
\max_{\intallocs \in \InAllocSpace}: \sum\nolimits_{\agent} \REV\agind(\intalloc\agind). \tag{CP} \label{eq:CP}
\end{align}
\end{proposition}

\begin{proof}
This is a convex program as $\REV(\cdot)$ is concave and
$\InAllocSpace$ is convex (convex combinations of feasible interim
allocation rules are feasible).  By \autoref{prop:implementation} this
revenue is attainable; therefore, it is optimal.
\end{proof}


%\begin{theorem}
%\label{thm:reduction}
%For service constrained environments where agents' types are drawn
%independently and $k$ is~$1$, the problem of optimal mechanism design
%can be reduced in polynomial time to single-agent problems of
%optimizing the same objective subject to an interim allocation rule
%constraint.
%\end{theorem}



% In this section, we present techniques to design mechanisms via reduced forms for independent bidders.  We will assume
% indepedence of bidders throughout the section.
%
% Many mechanism design problems can be written as linear programs.  For example, for optimal auction design, we can assign variables to respresent allocations
% and payments for each type vector $\types = (\type_1, \ldots, \type_n)$, and the objective function, incentive
% compatibility constraints, individual rationality constraint and feasibility constraints can all be expressed in linear forms.  Both the number
% of variables and the number of constraints, however, grow exponential in the number of bidders, and solving such an LP
% is intractable.
%
% Our technique starts with the observation that, in the design of Bayesian truthful mechanisms for independent bidders,
% interaction among bidders is largely through their interim allocation rules, which can be much more succinctly
% representible.  Indeed, by the independence assumption, both incentive compatibility and individual rationality
% constraints are local to individual bidders, while the feasibility constraints are the only ones requiring information
% from more than one bidder's allocation information.  Therefore, the fact that even feasibility constraints can also be
% expressed in terms of interim allocation rules, as shown in Section~\ref{sec:border}, leads to the possibility of
% designing mechanisms via interim allocations alone, a.k.a.\@ via reduced forms of the mechanism.
%
% To make this approach conceptually clearer, we will enclose the local computation of individual bidders by concave functions
% on interim allocations alone, and effectively reduce multi-bidder mechanism design problems to those with only one bidder.
% As an example, we write out the following convex program for the problem of revenue maximization in service constrained
% environment:
%
% \begin{align*}
%     & \text{maximize:}      \qquad  \sum_{\agent = 1}^{n} \rho_\agent (\Inter \alloc_\agent) & \notag \\
%     & \forall S_1 \subseteq T_1, \cdots, \forall S_n \subseteq T_n: &\qquad \sum_{i=1}^n \sum_{t_i\in S_i} \Inter{x}_i(t_i) f_i(t_i)
%         \le \E_{t \sim \Dist}\left[\min(\#\{i | t_i \in S_i\}, k)\right] \tag{MRM$_k$}
% %     & \forall \agent \in [n], \forall \type \in \typespace_\agent:
% %                                         & & \sum_{\service \in \servicespace} \Inter\alloc_{\agent,
% % \type}^{\service} \leq \sum_{\service \in \servicespace} \\
% % %                                            \tag{$\alpha_{it}^{i}$}\label{eq:alphai}
% %     & \forall \agent i, \forall \type, \type' \in \typespace_i:
% %                                         & & \sum_{\service \in \servicespace} \Inter\alloc_{\agent,
% % \type}^{\service}
% %                                             \tag{$\alpha_{it}^{i'}$}\label{eq:alpha} \\
% %     &
% %                                         & & z_{01}^{0} \le 1
% %                                             \tag{$\alpha_{01}^{0}$}\label{eq:alpha0} \\
% %     & \forall i,i'\in [n]\cup\{0\}, i' < i,\forall t \in T_i, \forall t' \in T_{i'}:
% %                                         & & y_{it}^{i't'} \le q_{it} z_{i't'}^{i-1}
% %                                             \tag{$\lambda_{it}^{i't'}$}\label{eq:lambda} \\
% %     & \forall i\in [n], \forall t \in T_i:
% %                                         & & z_{it}^{n} \le q_{it}w_{it}
% %                                             \tag{$\beta_{it}$}\label{eq:beta} \\
% %     &
% %                                         & & y_{it}^{i't'} \ge 0, z_{it}^{i'} \ge 0
% \end{align*}
% where $\rho_\agent(\Inter \alloc_\agent)$ is the maximum revenue by any truthful allocation~$\alloc'_\agent$ and payment rule
% such that $\alloc_\agent(\type_\agent) \leq \Inter \alloc_\agent(\type_\agent)$ for all $\type_\agent \in \typespace_\agent$.
%

% Please note that, even though the number of constraints in the above program is exponential, the ellipsoid method enables us to solve it efficiently as long as we can give efficient \emph{separation oracles} which, given any tentative solution, outputs a violated constraint whenever there is one.  The problem therefore boils down to the following two questions, solutions to which immediately give rise to efficient algorithms to compute optimal mechanisms:
% all constraints except those enforcing feasibility are expressible by interim allocation rules and payments and can be written separately for each bidder, and we have only polynomially many of them.  As we have shown in Section~\ref{sec:border}, the feasibility constraints can also be expressed in terms of interim allocation rules, although there is an exponential number of them.  The ellipsoid method enables us to solve such linear programs as long as we can give efficient \emph{separation oracles} which, given any tentative solution, outputs a violated constraint whenever there is one.  The problem therefore boils down to the following two questions, solutions to which immediately give rise to efficient algorithms to compute optimal mechanisms: \footnote{Please see \autoref{sec:LP} for more elaboration on the LP.}


% \begin{enumerate}[{(}A{)}]
% \item
% \label{prob:A}
% \emph{Separation Oracle}:
% Given a set of interim allocation rules, can we efficiently find a constraint in \eqref{eq:MRM_k} that is violated,
% whenever there is one?
%
% \item
% \label{prob:B}
% \emph{Interim to ex-post conversion}:
% Given a distribution~$\Dist$ on the type spaces and a feasible set of interim allocation defined on it, do we have an efficient
% oracle which, given a type vector drawn from~$\Dist$, outputs an ex-post allocation such that the interim allocation rules are correctly implemented?
% \end{enumerate}
%
% We remark that the second question is meaningful only when one asks for such an oracle, since an explicit description of
% an ex-post allocation rule takes exponential space and time in general.
%
% In the remainder of this section, we present efficient algorithmic solutions to the above questions for independent
% bidders.  These amount to efficient algorithms for general mechanism design problems as long as the objective function
% is separable and each bidder's part can be expressed by a concave function of her interim allocation rule.  We present the main theorems for the particular case of service
% constraint environments here.
%
%
% \begin{theorem}
% \label{thm:main-sym}
% For service constraint environments which can serve at most $k$ of $n$ i.i.d.\@ bidders, where the common type space
% is~$\typespace$, optimal mechanisms can be computed in time polynomial in $n$ and $|\typespace|$.
% \end{theorem}
%
% \begin{theorem}
% \label{thm:main-assym}
% For service constraint environments which can serve at most one of $n$ independent bidders, where bidder~$\agent$ can assume a type from a type
% space~$\typespace_\agent$, an optimal Bayesian truthful mechanism can be computed in time polynomial in $n$ and $\sum_i |\typespace_\agent|$.
% \end{theorem}
%
% \subsection{Separation Oracles}
% \label{sec:sep-oracle}
% In Section~\ref{sec:MRM'} we showed that, when bidders are independent, the feasibility constraints have local structures
% which allow us to check only a much smaller set of constraints.  Here we make more careful use of these properties and
% show that a proper ordering of all individual types of bidders allows us to check only linearly many constraints to find
% a violated one if any, for the case of independent bidders and $k=1$.
%
% Recall that, when $k$ is~$1$, the set of constraints we need to check is
% \begin{align}
%     \forall S_1 \subseteq T_1, \cdots, \forall S_n \subseteq T_n: &\qquad \sum_{i=1}^n \sum_{t_i\in S_i} \Inter{x}_i(t_i) f_i(t_i)
%         \le 1-\prod_{i=1}^n (1-f_i(S_i)) \tag{MRM$_1$} \label{eq:MRM_1}
% \end{align}
%
% \begin{algorithm}
% \label{alg:sep-oracle}
% \textbf{Input:} A set of interim allocation rules $\Inter{x}_1,\cdots, \Inter{x}_n$.\\
% \textbf{Output:} $S_1,\cdots, S_n$, for which \eqref{eq:MRM_1} is violated (if any). \\
% \begin{algorithmic}[1]
%     \STATE For each $i$, let $T_i=\{\Tp_i^1, \Tp_i^2, \cdots\}$ be a relabeling of the types in decreasing order of
%     $\Inter{x}_i(\cdot)$.
%     \STATE For every $i\in [n]$, $j\in[|T_i|]$, let $f_i^j = f_i(\Tp_i^j)$, and $F_i^j = \sum_{r=1}^j f_i^j$.
%     \STATE For each type $\Tp_i^j$ define a weight $w(\Tp_i^j)=(1-F_i^{j-1})\cdot\Inter{x}_i(\Tp_i^j)$.
%     \STATE Make a list $L$ of all types in type spaces of all agents and sort it in decreasing order of $w(\cdot)$.
%     \STATE Set $S_i \leftarrow \emptyset$, for all $i \in [n]$.
%     \WHILE{$L \neq \emptyset$}
%         \STATE Let $\Tp_i^j$ denote the first element of the current list $L$.
%         \STATE Remove $\Tp_i^j$ from $L$ and add it to $S_i$.
%         \STATE Check \eqref{eq:MRM_1} for $S_1,\cdots, S_n$, and if violated, return $S_1,\cdots, S_n$.
%     \ENDWHILE
% \end{algorithmic}
% \caption{\textsc{CheckFeasibility}$(\Inter{x}_1,\cdots, \Inter{x}_n)$} \label{alg:sep}
% \end{algorithm}
%
% \begin{theorem}
% For $k=1$, algorithm \ref{alg:sep} can check the feasibility of any given set of interim allocation rules $\Inter{x}_1,\cdots,
% \Inter{x}_n$, and if infeasible, it always finds $S_1,\cdots, S_n$ for which \eqref{eq:MRM_1} is violated. Furthermore, this
% algorithm runs in time $O(N \log N)$, where $N=\sum_{i=1}^n |T_i|$ is the size of the input to the algorithm.
% \end{theorem}
% \begin{proof}
% We need to show that if $\Inter{x}_1,\cdots, \Inter{x}_n$ are infeasible, then the above algorithm always finds $S_1,\cdots, S_n$
% that violate the inequality \eqref{eq:MRM_1}. We prove this by contradiction. Suppose the algorithm does not find any violation.
% It is easy to see that the interim allocations are infeasible iff the maximum value of the following function is strictly
% positive.
% \begin{align*}
%     H(S_1,\cdots, S_n) &= \sum_{i=1}^n \sum_{t_i\in S_i} \Inter{x}_i(t_i) f_i(t_i)-1+\prod_{i=1}^n(1-f_i(S_i))
% \end{align*}
% Let $S^*_1 \subset T_1,\cdots, S^*_n \subset T_n$ be a maximizer of $H$ and if there are multiple maximizers, take the one in
% which each $S^*_i$ is of maximal size. We show that there exists a point during the running of the algorithm where for all $i$,
% $S_i=S^*_i$, which would be a contradiction. During the running of the algorithm, consider the first time\footnote{Since at the
% end of the algorithm $S_i=T_i$ for all $i$, we can always find such a first time.} that $S^*_i \subseteq S_i$ for all $i\in [n]$.
% We show that it must be $S_i=S^*_i$, so the algorithm must have indeed checked the \eqref{eq:MRM_1} for $S^*_1,\cdots, S^*_n$.
% The proof is again by contradiction. Let $i'$ be the index of the set $S_{i'}$ that was last updated, and let $\Tp_{i'}^{j'}$
% denote the element that was last added to it. It is easy to see\footnote{That is because each one of $S_{i''}$ and $S^*_{i''}$
% consists of a proper prefix of the sequence of types $\Tp_{i''}^1, \Tp_{i''}^2, \cdots$} that $S_{i'}=S^*_{i'}$. Suppose there is
% some $i''$ such that $S_{i''}\neq S^*_{i''}$. Choose $\Tp_{i''}^{j''} \in S_{i''}-S^*_{i''}$ with maximum weight. We show that
% adding $\Tp_{i''}^{j''}$ to $S^*_{i''}$ may only increase $H$ which would contradict the optimally or the maximality of $S^*_1,
% \cdots, S^*_n$. Define
% \begin{align*}
%     \Delta''    &= H(S^*_1, \cdots, S^*_{i''}\cup\{\Tp_{i''}^{j''}\}, \cdots, S^*_n)-H(S^*_1, \cdots, S^*_n) \\
%                 &= \Inter{x}_{i''}(\Tp_{i''}^{j''})f_{i''}(\Tp_{i''}^{j''})
%                     -\frac{\prod_{i=1}^n(1-f_i(S^*_i))}{(1-f_{i''}(S^*_{i''}))} f_{i''}(\Tp_{i''}^{j''}) \\
%                 &= \left(\Inter{x}_{i''}(\Tp_{i''}^{j''})(1-f_{i''}(S^*_{i''}))-\prod_{i=1}^n(1-f_i(S^*_i))\right)
%                     \cdot \frac{f_{i''}(\Tp_{i''}^{j''})}{1-f_{i''}(S^*_{i''})} \\
%                 &= \left(w(\Tp_{i''}^{j''})-\prod_{i=1}^n(1-f_i(S^*_i))\right)
%                     \cdot \frac{f_{i''}^{j''}}{1-F_{i''}^{j''-1}} \tag{$\Delta''$} \label{eq:Delta''}
% \end{align*}
% The last equation follows\footnote{That is because each one of $S_{i''}$ and $S^*_{i''}$ consists of a proper prefix of the
% sequence of types $\Tp_{i''}^1, \Tp_{i''}^2, \cdots$, and $\Tp_{i''}^{j''}$ was the element with maximum weight from
% $S_{i''}-S^*_{i''}$.} from $f_{i''}(S^*_{i''})=F_{i''}^{j''-1}$ and the definition of $w(\cdot)$. Next, define $\Delta'$ to be
% the amount of change in $H$ by removing $\Tp_{i'}^{j'}$ from $S^*_{i'}$. Using a similar argument as above we can get
% \begin{align*}
%     \Delta'     &= H(S^*_1, \cdots, S^*_n)-H(S^*_1, \cdots, S^*_{i'}-\{\Tp_{i'}^{j'}\}, \cdots, S^*_n) \\
%                 &= \left(w(\Tp_{i'}^{j'})-\left(\prod_{i=1}^n(1-f_i(S^*_i))\right)
%                     \frac{(1-f_{i'}(S^*_{i'})-f_{i'}(\Tp_{i'}^{j'}))}{(1-f_{i'}(S^*_{i'}))}\right)
%                     \cdot \frac{f_{i'}^{j'}}{1-F_{i'}^{j'-1}} \\
%                 &\le \left(w(\Tp_{i'}^{j'})-\prod_{i=1}^n(1-f_i(S^*_i))\right)
%                     \cdot \frac{f_{i'}^{j'}}{1-F_{i'}^{j'-1}}
% \end{align*}
% Observe that by optimality of  $S^*_1, \cdots, S^*_n$, $\Delta'$ must be non-negative, which implies that the inside of the big
% parenthesis in the last equation should be non-negative. On the other hand, since the algorithm must have removed
% $\Tp_{i''}^{j''}$ from the list $L$ prior to $\Tp_{i'}^{j'}$, it must be that $w(\Tp_{i''}^{j''}) \ge w(\Tp_{i'}^{j'})$. This
% implies that the inside of the big parenthesis of equation \eqref{eq:Delta''} must also be non-negative which proves that
% $\Delta'' \ge 0$. That completes the proof.
% \end{proof}




% \subsection{From Interim Allocations to Ex-post Allocations}
% \label{sec:int2expost}
% This subsection presents an algorithmic solution to Question~\ref{prob:B} presented at the beginning of the section for
% the case when $k$ is~$1$.  To
% be more formal, given a distribution~$\Dist$ of types and interim allocation rules $\Inter{x}_1, \ldots, \Inter{x}_n$
% defined on it, we present an efficient oracle which takes as its input a profile of types $\type \in \typespace$ and
% outputs a winner~$\agent$ with probability~$x_\agent(\type)$, such that, when $\type$ is drawn according to~$\Dist$, the
% expected probability of bidder~$\agent$ with type~$\type_\agent$ is exactly $\Inter{x}_\agent(\type_\agent)$.
%
% The presentation of the algorithm will be facilitated by the following definition, which will be instrumental in later
% sections as well.
%
% \newcommand{\DPST}{DPST}
% \begin{definition}[Distribution Preserving Stochastic Transformation (DPST)]
% \label{def:smap}%
% A pair of functions $(\pi_i, \mu_i)$, where $\pi_i,\mu_i : T_i \times T_i \to [0,1]$ is called a \emph{``stochastic
% transformation''} for agent $i$, iff for all $\Tp \in T_i$, $\sum_{\Tp' \in T_i} \pi_i(\Tp', \Tp) = 1$. A stochastic
% transformation can be applied to agent $i$ by replacing agent $i$ with a proxy that does the following. If the actual type
% reported by agent $i$ is $t_i$, the proxy instead reports a type $t'_i=\Pi_i(t_i)$ where $\Pi_i(t_i)$ is a random function that
% returns each $\Tp' \in T_i$ with probability $\pi_i(\Tp', t_i)$. If the proxy is chosen as a winner, then the proxy announces
% agent $i$ as a winner with probability $\mu_i(t'_i, t_i)$, otherwise agent $i$ is not a winner. Furthermore, $(\pi_i, \mu_i)$ is
% called \emph{``distribution preserving''} iff for all $\Tp' \in T_i$, $\sum_{\Tp \in T_i} \pi_i(\Tp', \Tp) f_i(\Tp) = f_i(\Tp')$,
% i.e., the the distribution of the types reported by the proxy is the same as the distribution of types of the actual agent $i$.
% We use the notation $(\pi_i, \mu_i) \times \Inter{x}_i$ to denote the new interim allocation rule that results from applying
% $(\pi_i, \mu_i)$ to $\Inter{x}_i$.
% \end{definition}
%
% The oracle makes use of a stochastic transition table $\Pi : U
% \times U \to [0,1]$ where $U = \cup_{i=0}^n T_i$ and $T_0=\{\Tp_0^1\}$ is the type space of a dummy agent $0$\footnote{Agent $0$
% wins only when there is no winner among the other agents, so that we can assume that there is always a winner.}. In particular,
% we assume that the types of different agents are distinct so $U$ has a distinct element for each type of each agent. $\Pi$ is
% computed using a linear program as explained later. The oracle works by visiting the agents one by one in a fixed order, randomly
% transferring a winning token among the agents with probabilities specified by $\Pi$ based on the types reported by the agents.
% The agent who holds the token at the end is chosen as the winner.
%
% \begin{algorithm}
% \textbf{Input:} A profile of types $t \in T$, a stochastic transition table $\Pi : U  \times U \to [0,1]$.\\
% \textbf{Output:} The index of the winner.
% \begin{algorithmic}[1]
%     \STATE Imagine a dummy agent $0$ and tentatively give him the winning token, also let $\Tp^* \leftarrow \Tp_0^1$.
%     \FOR{$i'=1$ to $n$}
%         \STATE Choose $Z$ uniformly at random from $[0,1]$.
%         \IF{$Z \le \Pi(\Tp^*, t_{i'})$}
%             \STATE Transfer the token to agent $i'$ and set $\Tp^* \leftarrow t_{i'}$.
%         \ENDIF
%     \ENDFOR
%     \RETURN The agent currently holding the token, or no winner if $\Tp^* = \Tp_0^1$.
% \end{algorithmic}
% \caption{\textsc{SequentialAllocation}$(t, \Pi)$ \label{alg:seq_alloc}}
% \end{algorithm}
%
% \begin{figure}
% \center
% \includegraphics[width=.95\textwidth]{fig_seq_alloc}
% \caption{The network used for computing $\Pi$. In this instance, there are three agents, with each agent $i$ having a type space
% $T_i=\{\Tp_i^1, \Tp_i^2\}$. All nodes in the same row correspond to the same type. The head nodes are solid, and the shadow nodes
% are hollow. The solid edges have a limited capacity while the dashed edges have infinite capacity. The capacities are shown only
% for some of the edges. The flow going from  $\Tp_{i,i'}^{j}$ to $\Tp_{i',i'}^{j'}$ corresponds to the ex-ante probability of
% $\Tp_{i'}^{j'}$ taking the token from  $\Tp_{i}^{j}$. The flow going from $\Tp_{i,i'}^{j}$ to $\Tp_{i,i'+1}^{j}$ corresponds to
% the ex-ante probability of  $\Tp_{i}^{j}$ still having the token after the sequential allocation algorithm has visited agent
% $i'$. \label{fig:seq_alloc}}
% \end{figure}
%
% The stochastic transition table $\Pi$ can be computed by solving a non-standard directed maximum flow problem in which some of
% the edges have dynamic capacities. \autoref{fig:seq_alloc} depicts this network for an instance with three agents, each one
% having two possible types. The network has one row corresponding to each type of each agent, and one column corresponding to each
% agent. The columns are in the order in which the sequential allocation algorithm visits the agents.  The network is constructed
% as follows. The network has a source node $s$, a sink node $s'$, and for each type $\Tp_i^j \in U$ and each $i' \in i\cdots n$,
% there is a node $\Tp_{i,i'}^j$ in the row corresponding to type $\Tp_i^j$ and in column $i'$. Each $\Tp_{i,i'}^j$ has an outgoing
% edge with infinite capacity going to $\Tp_{i,i'+1}^j$, except that for $i'=n$ this edge goes to a sink node $s'$ and has a
% limited capacity of $\Inter{x}_i(\Tp_i^j)f_i(\Tp_i^j)$ (except for the edge $(\Tp_{0,n}^1,s')$ which still has infinite
% capacity). For each edge $(u,v)$, we denote its capacity by $\capacity(u,v)$ and its flow by $\flow(u,v)$.
% $\flow(\Tp_{i,i'}^j,\Tp_{i,i'+1}^j)$ can be interpreted as the ex-ante probability that agent $i$ has type $\Tp_i^j$ and is also
% holding the token after the oracle has visited agent $i'$. To simplify the notation, we assume that each $\Tp_{i,n+1}^j$ is an
% alias for the sink node $s'$, and $\Tp_{0,0}^1$ is an alias for the source node $s$. Each node $\Tp_{i,i}^j$ is called the
% \emph{``head node''} and each one of $\Tp_{i,i+1}^j, \cdots, \Tp_{i,n}^j$ is called a \emph{``shadow node''}.
%
% Every shadow node $\Tp_{i,i'}^j$ of agent $i$ has an outgoing edge to each head node of agent $i'$, i.e., $\Tp_{i,i'}^j$ has one
% edge to each $\Tp_{i',i'}^{j'}$ for each $j' \in [|T_{i'}|]$. The edge $(\Tp_{i,i'}^j, \Tp_{i',i'}^{j'})$ has a dynamic capacity
% of $\flow(\Tp_{i,i'-1}^{j},\Tp_{i,i'}^{j}) f_{i'}(\Tp_{i'}^{j'})$. Observe that $\flow(\Tp_{i,i'}^j, \Tp_{i',i'}^{j'})$ can be
% interpreted as the ex-ante probability of the following event: agent $i$ having a type $\Tp_i^j$, and holding the token after the
% oracle has visited the agent $i'-1$, and agent $i'$ having a type $\Tp_{i'}^{j'}$, and the token being transferred from $i$ to
% $i'$. We solve the following flow problem in this network: we push one unit of flow into $\Tp_{0,1}^1$ and maximize the total
% flow going to the sink through the edges other than $(\Tp_{0,n}^1, s')$. This can be achieved by solving the following linear
% program.
%
% \begin{align*}
%     & \text{maximize:}                  & & \quad \sum_{i=1}^{n} \sum_{j=1}^{|T_i|} \flow(\Tp_{i,n}^j, s') && \tag{LP$_{seq}$} \label{p:seq_alloc} \\
%     & \forall \Tp_{i'}^{j'} \in U-\{\Tp_0^1\}:
%                                         & & \flow(\Tp_{i',i'}^{j'}, \Tp_{i',i'+1}^{j'}) = \sum_{i=0}^{i'-1} \sum_{j=1}^{|T_{i}|} \flow(\Tp_{i,i'}^{j},
%                                         \Tp_{i',i'}^{j'})\\
%     & \forall \Tp_i^j \in U, \forall i'\in [n], i' > i:
%                                         & & \flow(\Tp_{i,i'}^j, \Tp_{i,i'+1}^j) = \flow(\Tp_{i,i'-1}^j, \Tp_{i,i'}^j)-\sum_{j'=1}^{|T_{i'}|}
%                                         \flow(\Tp_{i,i'}^j,\Tp_{i',i'}^{j'})\\
%     & \forall \Tp_{i'}^{j'}, \Tp_i^j \in U, i'>i:
%                                         & & \flow(\Tp_{i,i'}^{j}, \Tp_{i',i'}^{j'}) \le \flow(\Tp_{i,i'-1}^{j}, \Tp_{i,i'}^{j}) f_{i'}(\Tp_{i'}^{j'}) \\
%     & \forall \Tp_i^j \in U-\{\Tp_0^1\}:
%                                         & & \flow(\Tp_{i,n}^j, s') \le \Inter{x}_i(\Tp_i^j) f_i(\Tp_i^j) \\
%     &
%                                         & & \flow(s,\Tp_0^1) = 1 \\
%     &
%                                         & & \flow(\cdot, \cdot) \ge 0
% \end{align*}
%
% To simplify the notation we define the following aliases.
% \begin{itemize}
% \item $\sflow(\Tp_i^j,\Tp_{i'}^{j'}) =\sflow(\Tp_{i,i'}^j,\Tp_{i',i'}^{j'})$.
% It is the ex-ante probability of the following event: agent $i$ having type $\Tp_i^j$, and also holding the winning token when
% the sequential allocation algorithm visits agent $i'$, and agent $i'$ having type $\Tp_{i'}^{j'}$, and taking the winning token
% from agent $i$.
%
% \item $\ssflow{i'}(\Tp_i^j) = \flow(\Tp_{i,i'}^j, \Tp_{i,i'+1}^j)$.
% It is the ex-ante probability of the following event: agent $i$ having type $\Tp_{i}^{j}$, and also holding the winning token
% after the sequential allocation algorithm has visited agent $i'$.
% \end{itemize}
% We also define the \emph{``residual capacity''} from $\Tp_i^j$  to $\Tp_{i'}^{j'}$ as follows.
% \begin{align*}
%     \srcapacity(\Tp_i^j, \Tp_{i'}^{j'})=
%         \begin{cases}
%             \flow(\Tp_{i,i'-1}^{j},\Tp_{i,i'}^{j}) f_{i'}(\Tp_{i'}^{j'})-\flow(\Tp_{i,i'}^j,\Tp_{i',i'}^{j'})   & i < i' \\
%             \flow(\Tp_{i',i}^{j'}, \Tp_{i,i}^{j})                                                               & i > i' \\
%             0                                                                                           & \text{otherwise}
%         \end{cases}
% \end{align*}
% Next, We will prove the following theorem.
%
% \begin{theorem}
% \label{thm:seq_alloc}%
% The interim allocation rules $\Inter{x}_1,\cdots, \Inter{x}_n$ are feasible iff the optimal value of \eqref{p:seq_alloc} is
% exactly $\sum_{i=1}^n \sum_{j=1}^{|T_i|} \Inter{x}_i(\Tp_i^j)f_i(\Tp_i^j)$. Furthermore, if feasible, the interim allocation
% rules can be implemented by the sequential allocation algorithm \ref{alg:seq_alloc} using the following stochastic transition
% table.
% \begin{align}
%     \forall \Tp_i^j , \Tp_{i'}^{j'} \in U, i<i': \qquad
%         \Pi(\Tp_i^j, \Tp_{i'}^{j'})&= \frac{\sflow(\Tp_i^j, \Tp_{i'}^{j'})}{\ssflow{i'-1}(\Tp_i^j) f_{i'}(\Tp_{i'}^{j'})} \tag{$\Pi$} \label{eq:Pi}
% \end{align}
% \end{theorem}
%
% \begin{proof}
% First, we show that if the optimal objective value of the \eqref{p:seq_alloc} is  $\sum_{i=1}^n \sum_{j=1}^{|T_i|}
% \Inter{x}_i(\Tp_i^j)f_i(\Tp_i^j)$, then the algorithm \ref{alg:seq_alloc} with the above definition of $\Pi$ guarantees that the
% expected probability of winning for agent $i$ conditioned on having a type $\Tp_i^j$ is exactly $\Inter{x}_i(\Tp_i^j)$. Observe
% that, in the algorithm \ref{alg:seq_alloc} after visiting agent $i'$, $\ssflow{i'}(\Tp_{i}^j)$ is exactly the ex-ante probability
% that agent $i$ has type $\Tp_i^j$ and is also holding the winning token, for every $i \le i'$ (this can be trivially verified
% from the constraints of the \eqref{p:seq_alloc} and by induction on $i'$). Now observe that the only way to achieve the mentioned
% objective value is iff $\ssflow{n}(\Tp_{i}^j)=\Inter{x}_i(\Tp_i^j)f_i(\Tp_i^j)$ for all $\Tp_i^j \in U-\{\Tp_0^1\}$. By combining
% the previous two observation, the claim follows.
%
%
% Next, we prove the opposite direction. The proof is by contradiction. Suppose the optimal value of the \eqref{p:seq_alloc} is
% less than $\sum_{i=1}^n \sum_{j=1}^{|T_i|} \Inter{x}_i(\Tp_i^j)f_i(\Tp_i^j)$. We prove that the interim allocations  must be
% infeasible. Let $U_+ \subseteq U$ be the set of types that require a non-zero probability of winning, i.e., define
% \begin{align*}
%     U_+ &= \{\Tp_i^j \in U | \Inter{x}_i(\Tp_i^j) > 0 \text{ or } \Tp_i^j=\Tp_0^1 \}
% \end{align*}
% Suppose for every $\Tp_i^j \in U-U_+$ we add the constraint $\ssflow{i}(\Tp_i^j)=0$ to the LP, which is equivalent to the
% following.
% \begin{align*}
%     \flow(\Tp_{i,i}^j, \Tp_{i,i+1}^j) &= 0
% \end{align*}
% Effectively, the new constraints exclude from the LP the nodes/edges corresponding to types that require a zero probability of
% winning. Note that adding new constraints may only decrease the optimal objective value of the LP.
%
% We say that a type $\Tp_{i^*}^{j^*} \in U_+$ is \emph{``augmentable''} iff there exists a sequence of types
% $\Tp_{i_0}^{j_0}=\Tp_0^1,\Tp_{i_1}^{j_1},\cdots, \Tp_{i_m}^{j_m}=\Tp_{i^*}^{j^*}$, such that for every $\ell \in [m]$,
% $\srcapacity(\Tp_{i_{\ell-1}}^{j_{\ell-1}}, \Tp_{i_{\ell}}^{j_\ell}) > 0$ and $\Tp_{i_{\ell-1}}^{j_{\ell-1}} \in U_+$ and
% $\ssflow{n}(\Tp_{0}^1) > 0$. Furthermore, we say that a type $\Tp_{i^*}^{j^*} \in U_+-\{\Tp_0^1\}$ is \emph{``unsatisfied''} iff
% $\ssflow{n}(\Tp_{i^*}^{j^*}) < \Inter{x}_{i^*}(\Tp_{i^*}^{j^*})f_{i^*}(\Tp_{i^*}^{j^*})$. Let $A^+ \subseteq U_+$ denote the set
% of all types that are augmentable, and let $A^- \subseteq U_+$ denote the set of types that are unsatisfied. We prove the claim
% by showing that each one of the following statements imply the next one.
% \begin{enumerate}[{(}I{)}]
% \item \label{it:stm1}%
% The optimal objective value of \eqref{p:seq_alloc} is less than $\sum_{i=1}^n \sum_{j=1}^{|T_i|}
% \Inter{x}_i(\Tp_i^j)f_i(\Tp_i^j)$.
%
% \item \label{it:stm2}%
% There exist unsatisfied type(s) and they are not augmentable, i.e., $A^- \neq \emptyset$ and $A^+ \cap A^- = \emptyset$.
%
%
% \item \label{it:stm3}%
% The \eqref{eq:MRM_1} is violated for $S_1,\cdots, S_n$ where $S_i=(U_+-A^+) \cap T_i$, so the interim allocations are infeasible.
% \end{enumerate}
%
% We first show that \ref{it:stm1} implies \ref{it:stm2}. Clearly if the optimal objective value of the LP is less than
% $\sum_{i=1}^n \sum_{j=1}^{|T_i|} \Inter{x}_i(\Tp_i^j)f_i(\Tp_i^j)$, then there must be at least one unsatisfied type, so $A^-
% \neq \emptyset$. Next, we show that if $A^+ \cap A^- \neq \emptyset$, then the objective value of the LP can be improved, so it
% must be that $A^+ \cap A^- = \emptyset$. Suppose $A^+ \cap A^- \neq \emptyset$. Choose $\Tp_{i^*}^{j^*} \in A^+ \cap A^-$ that
% requires the shortest sequence of augmentations. Let $\Tp_{i_0}^{j_0}=\Tp_0^1,\cdots, \Tp_{i_m}^{j_m}=\Tp_{i^*}^{j^*}$ denote
% this sequence. We define the operation $\Reroute(\Tp_i^j, \Tp_{i'}^{j'}, \epsilon)$ (see algorithm \ref{alg:reroute} and
% \autoref{fig:reroute}) that has the effect of decreasing $\ssflow{n}(\Tp_{i}^{j})$ by $\epsilon$ while increasing
% $\ssflow{n}(\Tp_{i'}^{j'})$ by $\epsilon$ by rerouting the flow in a feasible way as long as $\epsilon$ is small enough. The
% objective value of the LP can be improved by augmenting the type $\Tp_{i^*}^{j^*}$ by applying
% $\Reroute(\Tp_{i_{\ell-1}}^{j_{\ell-1}}, \Tp_{i_\ell}^{j_\ell}, \epsilon)$ for each $\ell \in [m]$ and for a small enough
% $\epsilon > 0$. From \autoref{lem:reroute} we can conclude that choosing $\epsilon$ as
% \begin{align*}
%     \epsilon &= \min\left(\Inter{x}_{i_m}(\Tp_{i_m}^{j_m}) f_{i_m}(\Tp_{i_m}^{j_m})-\ssflow{n}(\Tp_{i_m}^{j_m}),
%         \min_{\ell \in [m]} \left(\srcapacity(\Tp_{i_{\ell-1}}^{j_{\ell-1}}, \Tp_{i_{\ell}}^{j_\ell})
%         \ssflow{n}(\Tp_{i_{\ell-1}}^{j_{\ell-1}})\right)\right)
% \end{align*}
% guarantees that the LP constraints are not violated after the sequence of augmentations while the objective function is improved
% by $\epsilon$. Note that $\epsilon > 0$ because the first term in the outer $\min$ is positive\footnote{That is because
% $\Tp_{i_m}^{j_m}$ is unsatisfied.}, $\srcapacity(\Tp_{i_{\ell-1}}^{j_{\ell-1}}, \Tp_{i_{\ell}}^{j_\ell})
% > 0$, and $\ssflow{n}(\Tp_{i_{\ell-1}}^{j_{\ell-1}}) > 0$. Note that if $\ssflow{n}(\Tp_{i_{\ell-1}}^{j_{\ell-1}}) = 0$, then
% $\Tp_{i_{\ell-1}}^{j_{\ell-1}}$ would have been an augmentable unsatisfied\footnote{That is because
% $\Tp_{i_{\ell-1}}^{j_{\ell-1}} \in U_+$, so if $\ssflow{n}(\Tp_{i_{\ell-1}}^{j_{\ell-1}}) = 0$, then
% $\ssflow{n}(\Tp_{i_{\ell-1}}^{j_{\ell-1}})<
% \Inter{x}_{i_{\ell-1}}(\Tp_{i_{\ell-1}}^{j_{\ell-1}})f_{i_{\ell-1}}(\Tp_{i_{\ell-1}}^{j_{\ell-1}})$, which means
% $\Tp_{i_{\ell-1}}^{j_{\ell-1}}$ must be unsatisfied.} type with a shorter sequence of augmentations than $\Tp_{i_m}^{j_m}$ which
% would have contradicted $\Tp_{i_m}^{j_m}$ being such a type with the shortest sequence of augmentations. So the objective
% function can be improved by some $\epsilon > 0$ which contradicts the optimality of the LP solution, therefore it must be that
% $A^+ \cap A^- = \emptyset$.
%
% Next, we show that \ref{it:stm2} implies \ref{it:stm3}. Suppose $A^- \neq \emptyset$ and $A^+ \cap A^- = \emptyset$. We prove
% that \eqref{eq:MRM_1} is violated for $S_1,\cdots, S_n$ where $S_i=(U_+-A^+) \cap T_i$. We will show that, in algorithm
% \ref{alg:seq_alloc}, by using the stochastic transition table $\Pi$ defined earlier, if there is at least one agent whose type is
% in $U_+-A^+$, then the winner must also be from $U_+-A^+$. But then the fact that there are some unsatisfied types $A^- \subset
% U_+$ and that $A^- \cap A^+ = \emptyset$ implies that $A^- \subset U_+-A^+$. But that means the total expected probability  of
% winning for the types in $U_+-A^+$ is less than the probability that there is at least one agent whose type is from $U_+-A^+$
% which contradicts the \eqref{eq:MRM_1} condition for $S_1,\cdots, S_n$ where $S_i=(U_+-A^+) \cap T_i$. Pick any $\Tp_i^j\not \in
% U_+-A^+$ any $\Tp_{i'}^{j'} \in U_+-A^+$. If $\Tp_{i}^{j} \not \in U_+$, then an agent with type $\Tp_{i}^{j}$ can never be
% holding the winning token. On the other hand, if $\Tp_{i}^{j} \in U_+$, then $\srcapacity(\Tp_i^j,\Tp_{i'}^{j'}) = 0$, otherwise
% $\Tp_{i'}^{j'}$ would have been augmentable. The fact that $\srcapacity(\Tp_i^j,\Tp_{i'}^{j'}) = 0$ implies that, if $i < i'$,
% then $\Pi(\Tp_i^j, \Tp_{i'}^{j'})=1$, and if $i > i'$, then $\Pi(\Tp_{i'}^{j'},\Tp_i^j)=0$, which implies that $\Tp_{i}^{j}$
% cannot be a winner if $\Tp_{i'}^{j'}$ is present. That completes the proof.
% \end{proof}
%
%
%
% \begin{algorithm}[h]
% \textbf{Input:} A source type $\Tp_i^j$, a destination type $\Tp_{i'}^{j'}$ where $i \neq i'$, and  $\epsilon \in [0,1]$.\\
% \textbf{Output:} Modify an existing flow corresponding to \eqref{p:seq_alloc} to reroute an $\epsilon$ amount of flow of the edge
% $(\Tp_{i,n}^{j}, s')$ to the edge $(\Tp_{i',n}^{j'}, s')$.
% \begin{algorithmic}[1]
%     \STATE $\rho \leftarrow \epsilon/\ssflow{n}(\Tp_{i}^{j})$.
%     \IF{$i < i'$}
%         \STATE Increase $\sflow(\Tp_{i}^{j}, \Tp_{i'}^{j'})$ by $\rho\cdot \ssflow{i'}(\Tp_{i}^{j})$.
%     \ELSE
%         \STATE Decrease $\sflow(\Tp_{i'}^{j'},\Tp_{i}^{j})$ by $\rho\cdot \ssflow{i}(\Tp_{i}^{j})$.
%     \ENDIF
%
%     \FOR{$i''=\max(i,i')$ to $n$}
%         \STATE Move a $\rho$-fraction of $\ssflow{i''}(\Tp_{i}^{j})$ to $\ssflow{i''}(\Tp_{i'}^{j'})$, i.e., increase
%         $\ssflow{i''}(\Tp_{i'}^{j'})$ by $\rho\cdot\ssflow{i''}(\Tp_{i}^{j})$ and then decrease $\ssflow{i''}(\Tp_{i}^{j})$ by
%         the same amount.
%     \ENDFOR
%     \FOR{$i''=\max(i,i')+1$ to $n$}
%         \FOR{$j''=1$ to $|T_{i''}|$}
%             \STATE Move a $\rho$-fraction of $\sflow(\Tp_{i}^{j}, \Tp_{i''}^{j''})$ to  $\sflow(\Tp_{i'}^{j'}, \Tp_{i''}^{j''})$, i.e., increase
%              $\sflow(\Tp_{i'}^{j'}, \Tp_{i''}^{j''})$ by $\rho\cdot\sflow(\Tp_{i}^{j}, \Tp_{i''}^{j''})$ and then decrease $\sflow(\Tp_{i}^{j}, \Tp_{i''}^{j''})$
%              by the same amount.
%         \ENDFOR
%     \ENDFOR
% \end{algorithmic}
% \caption{$\Reroute(\Tp_i^j,\Tp_{i'}^{j'}, \epsilon)$ \label{alg:reroute}}
% \end{algorithm}
%
% \begin{figure}[h]
% \center
% \includegraphics[width=.95\textwidth]{fig_seq_alloc_reroute}
% \caption{The changes made by applying $\Reroute(\Tp_0^1, \Tp_1^2, \epsilon)$. The flow is increased along the green edges and
% decreased along the red edges. The amount of change in indicated for each green and each red edge
% ($\rho=\epsilon/\ssflow{n}(\Tp_0^1)$). The flow along all other edges stay intact. The operation has the effect of rerouting
% $\epsilon$ amount of flow of the edge $(\Tp_{0,n}^1,s')$ to the edge $(\Tp_{1,n}^2,s')$. \label{fig:reroute}}
% \end{figure}
%
% %Next we explain the operation $\Reroute(\Tp_{i'}^{j'}, \Tp_i^j, \epsilon)$ as defined in algorithm \ref{alg:reroute}.
%
% \begin{lemma}
% \label{lem:reroute}%
% The operation $\Reroute(\Tp_i^j, \Tp_{i'}^{j'}, \epsilon)$, as defined in algorithm \ref{alg:reroute}, modifies an existing flow
% assignment (corresponding to \eqref{p:seq_alloc}) to decrease $\ssflow{n}(\Tp_{i}^{j})$ by $\epsilon$ and to increase
% $\ssflow{n}(\Tp_{i'}^{j'})$ by $\epsilon$ without affecting $\ssflow{n}(\Tp_{i''}^{j''})$ for any other type $\Tp_{i''}^{j''}
% \not \in \{\Tp_{i}^{j}, \Tp_{i'}^{j'}\}$. Furthermore, the modified flow will be feasible (except potentially with respect to
% capacity constraints on the edges going to $s'$) if the initial flow is feasible (except potentially with respect to capacity
% constraints on the edges going to $s'$) and
% \begin{align*}
%     \epsilon &\le \srcapacity(\Tp_{i}^{j},\Tp_{i'}^{j'}) \ssflow{n}(\Tp_{i}^{j})
% \end{align*}
% \end{lemma}
% \begin{proof}
% The proof follows from the algorithm.
% \end{proof}


% \subsection{Symmetric Agents}
% \label{sec:symmetric}
% When bidders are drawn i.i.d.\@ from the same type space~$\typespace$, the problem has more structure, which renders
% simpler and more intuitive solutions to the two questions posed at the beginning of \autoref{sec:contextual}.  A first
% observation is that, for i.i.d.\@ bidders, there exists an optimal mechanism whose interim allocation rules are
% symmetric across bidders.  Therefore, we may restrict our attention to such interim allocation rules.  The ranking
% used in \autoref{alg:sep-oracle} comes to be dictated by the interim allocation alone, and the conversion of interim
% allocation to ex-post allocation rules can be roughly seen as an algorithm applying Birkhoff-von Neumann-Rado
% decomposition to a vector by another one majorizing it.  Due to the discreteness of the type space, extra care need
% be taken during this process, and we present an inductive procedure accomplishing this decomposition.
%
% The fact that any interim allocation rule $\Inter{x}^*_i$ can be converted to any other dominated interim allocation rule
% $\Inter{x}_i$ without affecting the other agents has the following important implication for symmetric agents.
%
% \begin{theorem}
% \label{thm:smap_sym}%
% When agents are symmetric, any set of interim allocation rules $\Inter{x}_1, \cdots, \Inter{x}_n$ that are symmetric (i.e.
% $\Inter{x}_i = \Inter{x}_1$ for all $i \in [n]$) is feasible iff the following condition holds. Furthermore, if feasible, a
% corresponding ex-post allocation rules $x$ can be constructed in time $O(|T_1|^3)$.
% \begin{align*}
%     \forall q\in[0,1]:  \qquad \NInter{X}_i(q) &= \frac{g_k(q,\cdots, q)}{n} \tag{MRM$_k^{sm}$} \label{eq:MRM_k_sm}
% \end{align*}
% \end{theorem}
% \begin{proof}
% Note that \eqref{eq:MRM_k_sm} is a special case of \eqref{eq:MRM'_k} so it is necessary. We will show that it is also sufficient.
% We prove the theorem by explicitly constructing a symmetric ex-post allocation rule $x^*$ such that the corresponding interim
% allocation rules $\Inter{x}^*_i$ dominate $\Inter{x}_i$. By \autoref{thm:smap_comp}, a \DPST{} $(\pi_i, \mu_i)$ can be computed
% to convert $\Inter{x}^*_i$ to the the desired interim allocation $\Inter{x}_i$ and because of symmetry the same \DPST{} should
% work for all agents. Let $T_i = \{\Tp_i^1, \Tp_i^2, \cdots\}$ denote a relabeling of types in decreasing order of $\Inter{x}_i$
% and let $F_i^j = \sum_{r=1}^{j} f_i(\Tp_i^r)$. Suppose the vector of types reported by the agents is $t = (\Tp_1^{j_1},\cdots,
% \Tp_n^{j_n})$, so that $j_1, \cdots, j_n$ are the indices of the types reported by the agents. Define $x^*$ to be the following
% allocation rule. Choose the $k$ agents who have the lowest indices as the winners, breaking ties uniformly at random. To complete
% the proof, we need to show that the resulting interim allocations $\Inter{x}^*_i$ dominate the $\Inter{x}_i$. Let
% $\NInter{X}^*_i$ denote the resulting cumulative normalized interim allocation rule. For any $\bar{j} \in [|T_i|]$,
% $\NInter{X}^*_i(F_i^{\bar{j}})$ is the expected probability that agent $i$ has a type with index at most ${\bar{j}}$ and also
% wins, so $n\cdot\NInter{X}^*_i(F_i^{\bar{j}})$ is the expected number of winners whose type indices are at most ${\bar{j}}$,
% which is equal to the expected number of agents, up to $k$, whose types have index at most ${\bar{j}}$, i.e.,
% \begin{align*}
%     n\cdot\NInter{X}^*_i(F_i^{\bar{j}}) &= \E_{j_1,\cdots,j_n}[\min(k, |\{i | j_i \le {\bar{j}}\}|)] \\
%                                         &= g_k(F_i^{\bar{j}},\cdots, F_i^{\bar{j}})
% \intertext{on the other hand from \eqref{eq:MRM_k_sm} we can argue that}
%     n\cdot\NInter{X}_i(F_i^{\bar{j}})   &\le g_k(F_i^{\bar{j}},\cdots, F_i^{\bar{j}})
% \end{align*}
% So $\NInter{X}_i(q) \le \NInter{X}^*_i(q)$ for all $q \in \{F_i^{\bar{j}} | \bar{j} \in [|T_i|]\}$. Since $\NInter{X}^*_i$ is
% concave and $\NInter{X}_i$ is piece-wise linear and its derivative changes only at $q \in \{F_i^{\bar{j}} | \bar{j} \in
% [|T_i|]\}$, it must be that $\NInter{X}_i(q) \le \NInter{X}^*_i(q)$ for all $q\in [0,1]$. That means $\Inter{x}^*_i$ dominates
% $\Inter{x}_i$, which completes the proof.
% \end{proof}
%
% \begin{corollary}
% \label{cor:sep}%
% When agents are symmetric, the condition \eqref{eq:MRM_k_sm} only needs to be checked at the points where the derivative of
% $\NInter{X}_i$ changes. So the condition can be verified in $O(|T_i| \log |T_i|)$ time\footnote{The types have to be sorted in
% decreasing order of $\Inter{x}_i$ which takes $O(|T_i| \log |T_i|)$ time.}.
% \end{corollary}
%
