\section{Related work}\label{background} 
Task allocation is a well-studied problem, posing ongoing challenges in various computing environments \cite{Stavrinides2019, Genez2020, Jayanetti2022, Kanbar2022, Kritikakou2022, Peixoto2022, Mo2023}.
However, previous related research efforts do not consider the edge/hub/cloud architecture, nor all of the parameters investigated in this work. This is demonstrated in \cref{table:comparison}, which summarizes our qualitative comparison with relevant state-of-the-art approaches. 
The comparison is made with respect to the objectives and parameters considered in this work, the applicability of each approach to applications comprising multiple tasks with precedence relationships among them (i.e., applications with a task flow graph structure), as well as the optimality of the solution provided by each method.
An overview of the related literature, as well as a comparison with our preliminary research, are provided in the remainder of this section.


\begin{table*}[!ht]
\centering
\caption{Qualitative comparison of this work with relevant research efforts.}
\label{table:comparison}
\footnotesize
\resizebox{0.85\textwidth}{!}{
    \begin{tabular}{@{\extracolsep{4pt}}lcccccccccc@{}} 
        \toprule
        \multirow{3}{*}{Reference} & \multicolumn{2}{c}{Objectives} & \multicolumn{6}{c}{Considered Parameters} & \multirow{2}{*}{Task Flow} & \multirow{2}{*}{Optimal}\\
         \cline{2-3}   \cline{4-9} 
        & Latency & Energy & Comp. & Comp. & Comm. &  Comm. &  \multirow{2}{*}{Memory} & \multirow{2}{*}{Storage} & \multirow{2}{*}{Graph} & \multirow{2}{*}{Solution}\\
        & Min. & Min. & Latency & Energy & Latency & Energy & & & & \\
        
        \hline
        %-- Latency Minimization References
        %                               Latency         Energy       Comp.          Comp.        Comm.        Comm.        Memory        Storage       TFG           Optimal Solution
        \cite{Alfakih2021}              & \checkmark    & -           & \checkmark  & -           & -          & -          & \checkmark  & \checkmark & -          & -           \\
        \cite{Guevara2022}              & \checkmark    & -           & \checkmark  & -           & \checkmark & -          & \checkmark  & \checkmark & \checkmark & -           \\
        \cite{Weikert2022}              & \checkmark    & -           & \checkmark  & -           & \checkmark & \checkmark & \checkmark  & -          & \checkmark & -           \\
        \cite{Lai2022}                  & \checkmark    & -           & \checkmark  & -           & \checkmark & -          & \checkmark  & \checkmark & -          & -           \\
        \cite{Barijough2019}            & \checkmark    & -           & \checkmark   & -          & \checkmark & \checkmark & -           & -          & \checkmark & \checkmark  \\
        \cite{Tang2022}                 & \checkmark    & -           & \checkmark   & -          & \checkmark & -          & -           & \checkmark & -          & \checkmark  \\
        \cite{Kuang2021}                & \checkmark    & -           & \checkmark   & \checkmark & \checkmark & \checkmark & -           & -          & -          & -           \\
        
        %-- Energy Minimization References
        %                               Latency         Energy       Comp.          Comp.        Comm.        Comm.        Memory      Storage         TFG           Optimal Solution                  
        \cite{Avgeris2022}              & -             & \checkmark  & \checkmark  & \checkmark  &\checkmark & -           & -           & -          & -          & \checkmark \\
        \cite{Khalil2018}               & -             & \checkmark  & -           & \checkmark  & -         & \checkmark  & -           & -          & -          & -          \\
        \cite{Kritikakou2023}           & -             & \checkmark  & \checkmark  & \checkmark  & -         & -           & -           & -          & \checkmark & -          \\
        \cite{Hu2020}                   & -             & \checkmark & \checkmark   & \checkmark & \checkmark & \checkmark & -          & -            & -          & -          \\
        \cite{Azizi2022}                & -             & \checkmark & \checkmark   & \checkmark & \checkmark & -          & -          & -            & -          & -          \\
        \cite{Li2022}                   & -             & \checkmark & \checkmark   & \checkmark & \checkmark & \checkmark & -          & -            & -          & -          \\

        %-- Latency and Energy Minimization References
        %                               Latency         Energy       Comp.          Comp.        Comm.        Comm.        Memory      Storage         TFG          Optimal Solution          
        \cite{Zhang2021}                & \checkmark    & \checkmark & \checkmark   & \checkmark & \checkmark & \checkmark & -          & -            & -          & -          \\
        \cite{Dinh2017}                 & \checkmark    & \checkmark & \checkmark   & \checkmark & \checkmark & \checkmark & -          & -            & -          & -          \\        
        \cite{Tong2023}                 & \checkmark    & \checkmark & \checkmark   & \checkmark & \checkmark & \checkmark & -          & -            & -          & -          \\

        
        This work & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark  & \checkmark \\
        \bottomrule
    \end{tabular}
}
%\vspace{-3mm}
\end{table*}



\subsection{Latency minimization}
A number of works on task allocation in edge computing and multi-tier environments have a primary focus on latency minimization.
For instance, Alfakih et al. \cite{Alfakih2021} explore the minimization of the computational latency of task execution in an edge computing system, based on an accelerated particle swarm optimization algorithm combined with a dynamic programming approach.
Guevara et al. \cite{Guevara2022} present a reinforcement learning-based resource allocation technique for minimizing the total execution time of tasks in a fog-cloud environment.
On the other hand, Weikert et al. \cite{Weikert2022} propose an algorithm for task allocation in an IoT platform, aiming to optimize the overall latency.
Furthermore, Lai et al. \cite{Lai2022} propose an online Lyapunov optimization-based method to tackle the problem of allocating user tasks in an edge computing environment, utilizing a stochastic approach. 
Barijough et al. \cite{Barijough2019} introduce a technique for allocating real-time streaming applications under latency and quality constraints.  
Tang et al. \cite{Tang2022} propose a framework for managing the physical resources of the edge and cloud layers, so that the response time is minimized and the system throughput is improved.
Moreover, Kuang et al. \cite{Kuang2021} present an iterative algorithm based on Lagrangian dual decomposition in order to minimize latency in an edge computing system. 


\subsection{Energy consumption minimization}
Several studies are focused on task allocation strategies aiming to reduce the total energy consumption.
Specifically, Avgeris et al. \cite{Avgeris2022} propose a resource allocation technique based on mixed integer linear programming in order to minimize the energy consumption of edge servers.
Within this context, Khalil et al. \cite{Khalil2018} present a framework for energy-efficient task allocation in an IoT environment, utilizing evolutionary-based meta-heuristics. 
Cui et al. \cite{Kritikakou2023} propose a heuristic algorithm for minimizing the total energy consumption of a platform comprising homogeneous processors, utilizing dynamic voltage and frequency scaling (DVFS).  
On the other hand, Hu et al. \cite{Hu2020} introduce a game-theoretic approach for task allocation in an edge computing environment to minimize the system energy consumption within an acceptable delay range.
Similarly, Azizi et al. \cite{Azizi2022} propose two priority-aware semi-greedy algorithms for allocating  IoT tasks in a heterogeneous fog platform, so that the total energy consumption is optimized, while meeting the deadline of each task.
Furthermore, Li et al. \cite{Li2022} examine a two-stage iterative algorithm, in which the resource allocation problem is decomposed into two sub-problems to obtain a suboptimal solution. 




\subsection{Latency and energy consumption minimization}
On the other hand, certain related works consider both optimization objectives, the minimization of latency and energy consumption.
For instance, Zhang et al. \cite{Zhang2021} present a game theory-based scheme for task allocation in a UAV-assisted edge computing environment. The goal of the proposed approach is to minimize the weighted latency and energy consumption of the system, considering resource allocation constraints.
Dinh et al. \cite{Dinh2017} propose a semi-definite relaxation-based optimization framework for allocating tasks in an edge architecture. The particular framework aims to minimize the total latency of the tasks, as well as the total energy consumption of the system.
On the other hand, Tong et al. \cite{Tong2023} present a latency and energy-aware Stackelberg game-based task allocation strategy, considering an edge device with limited computational resources.


\subsection{Our approach vs. state-of-the-art}
Overall, none of the aforementioned research efforts considers the specific edge/hub/cloud architecture examined in this work. 
Furthermore, some approaches do not take into account the energy required for the execution of the tasks \cite{Alfakih2021, Guevara2022, Weikert2022, Lai2022, Barijough2019, Tang2022} or the energy consumed for inter-task communication \cite{Alfakih2021, Guevara2022, Lai2022, Tang2022, Avgeris2022, Kritikakou2023, Azizi2022}. 
The majority of the related studies consider devices with unlimited resources, such as memory \cite{Barijough2019, Tang2022, Kuang2021, Avgeris2022, Khalil2018, Kritikakou2023, Hu2020, Azizi2022, Li2022} and storage \cite{Weikert2022, Barijough2019, Kuang2021, Avgeris2022, Khalil2018, Kritikakou2023, Hu2020, Azizi2022, Li2022}, an assumption that is not realistic, especially in the case of resource-limited devices at the edge of the network.     
Moreover, several approaches are only applicable to single-task applications \cite{Alfakih2021, Lai2022, Tang2022, Kuang2021, Avgeris2022, Khalil2018, Hu2020, Azizi2022, Li2022} or cannot provide an optimal solution to each of the objectives considered in this work \cite{Alfakih2021, Guevara2022, Weikert2022, Lai2022, Kuang2021, Khalil2018, Kritikakou2023, Hu2020, Azizi2022, Li2022}.

Related studies that are closer to ours \cite{Zhang2021, Dinh2017, Tong2023}, even though they consider both the latency and energy aspects of the problem, do not take into account the memory and storage limitations of the devices. Furthermore, they cannot be applied to applications with precedence relationships among their tasks, and can only provide suboptimal solutions.
Hence, our proposed approach aims to fill these gaps, by incorporating all of the important parameters that characterize an edge/hub/cloud environment, providing an optimal allocation for a task flow graph. 


\begin{figure*}[t]
    \centering
    \includegraphics[width=.85\textwidth]{coins_journal_tfg_to_etfg_v6.1.1.pdf}
    \caption{Overview of proposed optimization framework. The task flow graph transformation, including the encapsulated energy model, is described in \cref{extended,subsec:energyModel}. The formulation of the optimization problem is presented in \cref{subsec:optimization}.}
    \label{flow}
    %\vspace{-3mm}
\end{figure*}


\subsection{Comparison with our preliminary research}
The foundational concepts of this work were first presented in a preliminary form in \cite{Kouloumpris2019}.
Below, we outline the main differences and contributions of the current study with respect to our preliminary research:
\begin{enumerate}
    \item We streamlined and enhanced the mathematical representation of all aspects of the proposed approach, from the description of the task flow graph transformation to the modeling of the optimization problem.
    
    \item We extended our optimization framework to consider a new objective for the minimization of overall energy consumption (in addition to the latency objective), based on an improved energy model.
     
    \item We developed suitable synthetic benchmarks to further validate and evaluate the efficiency and scalability of our framework, by extending our transformation method to randomly generated task flow graphs.
    
    \item We conducted extensive experimentation with alternative configurations of different devices, for both the real-world use-case scenario and the synthetic benchmarks.  
\end{enumerate}
