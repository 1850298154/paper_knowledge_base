
\documentclass{article} % For LaTeX2e
\usepackage{iclr2021_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{listings}       % code listings
\usepackage{xcolor}         % code listings colors
\usepackage{graphicx}       % image scaling
\graphicspath{ {./figures/} }
\usepackage[noend, boxruled, linesnumbered] {algorithm2e}
\usepackage{wrapfig}
\usepackage{changepage}
\usepackage{multirow}
\usepackage{hyperref}       % hyperlinks
\usepackage{relsize}

\renewcommand*{\UrlFont}{\ttfamily\smaller[0]\relax}


\title{End-to-End Egospheric Spatial Memory}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{%
  Daniel Lenton $^1$, Stephen James $^1$, Ronald Clark $^2$, Andrew J. Davison $^1$ \\
  $^1$ Dyson Robotics Lab, $^2$ Department of Computing, Imperial College London \\
  \texttt{\{djl11,slj12,ronald.clark,a.davison\}@ic.ac.uk} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Spatial memory, or the ability to remember and recall specific locations and objects, is central to autonomous agents' ability to carry out tasks in real environments. However, most existing artificial memory modules are not very adept at storing spatial information. We propose a parameter-free module, Egospheric Spatial Memory (ESM), which encodes the memory in an ego-sphere around the agent, enabling expressive 3D representations. ESM can be trained end-to-end via either imitation or reinforcement learning, and improves both training efficiency and final performance against other memory baselines on both drone and manipulator visuomotor control tasks. The explicit egocentric geometry also enables us to seamlessly combine the learned controller with other non-learned modalities, such as local obstacle avoidance. We further show applications to semantic segmentation on the ScanNet dataset, where ESM naturally combines image-level and map-level inference modalities. Through our broad set of experiments, we show that ESM provides a general computation graph for embodied spatial reasoning, and the module forms a bridge between real-time mapping systems and differentiable memory architectures. Implementation at: \url{https://github.com/ivy-dl/memory}.
\end{abstract}

\input{sections/1_intro}
\input{sections/2_related_work}
\input{sections/3_method}
\input{sections/4_experiments}
\input{sections/5_conclusion}

\bibliography{ref}
\bibliographystyle{iclr2021_conference}

\input{sections/6_appendix}

\end{document}