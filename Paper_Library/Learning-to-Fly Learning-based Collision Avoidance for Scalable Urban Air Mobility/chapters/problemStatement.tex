\section{Problem formulation: Collision Avoidance} \label{sec:CA}

%Corresponding to the UAS trajectories generated in the previous section is \textit{robustness tube} in which the UAS can fly within and still satisfy the STL specification. An example of this is shown in Fig. \ref{fig:dronetube}.

While flying their planned trajectories (from the previous section), two UAS that are within communication range share a look-ahead of their trajectories and check for a potential collision at any time step $k$ in this look-ahead horizon of $N$ time steps.
We assume the UAS can communicate with each other in a manner that allows for enough advance notice for avoiding collisions, e.g. using 5G technology. 
The details of this are beyond the scope of this paper.
%Then they check if there is a potential collisio

%When the UAS are within communication range, they share their planned trajectories with each other and check if there is a conflict or a potential collision in a look-ahead horizon along the planned trajectories. 

\begin{mydef}
	\label{def:msep}
	\textbf{2-UAS Conflict}: Two UAS, with discrete-time positions $\mathbf{p}_1$ and $\mathbf{p}_2$ are said to be in \textit{conflict} at time step $k$ if $||p_{1,k}-p_{2,k}||_\infty < \delta$, where $\delta$ is a predefined minimum separation distance\footnote{A more general polyhedral constraint of the form $H(p_{1,k}-p_{2,k})< g$ can be used for defining the conflict without loss of generality.}. Here, $p_{j,k}$ represents the position of UAS $j$ at time step $k$. 
\end{mydef}

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=0.35\textwidth,trim={6cm 0cm 7.5cm 3cm},clip]{figures/DroneTube.pdf}
	\end{center}
	\vspace{-10pt}
	\caption{\small Discrete time trajectories of two UAS, and their associated robustness tubes (see def. \ref{def:robustnesstube}) in gray and purple. The trajectories satisfy a reach-avoid specification, see example \ref{ex:reach_avoid_exmp}. $\text{Unsafe}$ set is in red and the $\text{Goal}$ set is in green.}
	\label{fig:dronetube}
	\vspace{-10pt}
\end{figure}


\begin{mydef}
	\label{def:robustnesstube}
	\textbf{Robustness tube}: Given an STL formula $\varphi$ and a discrete-time position trajectory $\mathbf{p}_j$ that satisfies $\varphi$ (with associated robustness $\rho$), the (discrete) \textit{robustness tube} around $\mathbf{p}_j$ is given by $\mathbf{P}_j = \mathbf{p}_j\oplus \mathbb{B}_{\rho_{\varphi}}$. We say the \textit{radius} of this tube is $\rho$ (in the inf-norm sense). Here $\mathbb{B}_\rho$ is a 3D cube with sides $2\rho$ and $\oplus$ is the Minkowski sum operation.
\end{mydef}
See an example of the robustness tube in Figure~\ref{fig:dronetube}. 
%Given a discrete-time trajectory $\mathbf{p}$, we now formally define 
%the \textit{robustness tube} (also see Figure~\ref{fig:dronetube}) 
%around the trajectory.

%\begin{mydef}
%	\label{def:robustnesstube}
%	\textbf{Robustness tube}: The (discrete) robustness tube of UAS $j$ with a position trajectory $\mathbf{p}_j$ (with associated robustness $\rho$) is given by $\mathbf{P}_j = p_{j,k} \oplus \mathbb{B}_{\rho_{\varphi}} \, \forall k$. We say the \textit{radius} of this tube is $\rho$. Here $\mathbb{B}_\rho$ is a 3D cube with sides $2\rho$ and $\oplus$ is the Minkowski sum operation.
%	
%	% is given by the union of hyper-cubes, centered around $p_k, \, \forall k \in \{0,\dotsc,N \}$ (where the duration of the trajectory is $N$-time steps), with sides of length $2\rho$. We refer to $2\rho$ as the \textit{width} of the robustness tube. Formally the robustness tube is a sequence of $N+1$ hypercubes in the position space $\mathbf{P}|P_k =  (p_k \oplus \mathbb{B}_\rho) \, \forall k=\{0,\dotsc,N\}$.
%	%$\mathbf{P} = p[k] \oplus \rho \, \forall k$. We say the \textit{width} of %this tube is $\rho$.
%\end{mydef}

\textbf{Note}: As long as a UAS stays within its robustness tube, it will satisfy the STL specification $\varphi$ for the which the trajectory was generated for (see Corollary \ref{cor:rob_tube}). 

The following assumption now relates the minimum allowable radius $\rho$ of the robustness tube to the minimum allowable separation $\delta$ between two UAS.
%We focus on the case where the drones have a \textit{robustness}, $\rho$, of at least $\delta/2$.

\begin{myass}
	\label{assumption1}
	For each of the two UAS in conflict, the radius of the robustness tube is greater than $\delta/2$, i.e. $\min (\rho_1,\rho_2) \geq \delta/2$ where $\rho_1$ and $\rho_2$ are the robustness of UAS 1 and 2, respectively.
\end{myass}
This assumption defines the case where the radius of the robustness tube is just wide enough to have two UAS placed along opposing edges (of a cube at the same time step) and still achieve the minimum separation between them. We assume that all the trajectories generated by the independent planning have sufficient robustness to satisfy this assumption (see Sec. \ref{sec:problem_planning}).
Now we define the problem of collision avoidance with satisfaction of STL specifications:
% such that the STL specifications of each UAS are still satisfied:
%This assumption allows us to place two drones on opposing edges of a cube of side $2\delta$ and have them not be in conflict. 
%In the case where the robustness tube of either drones is not wide enough, we resort to solving a joint (and non-convex) optimization that is beyond the scope of this document.
\begin{myprob}
	\label{prob:deconfliction}
	Given two planned $N$-step UAS trajectories $\mathbf{p}_1$ and $\mathbf{p}_2$ that have a conflict, the collision avoidance problem is to find a new sequence of positions $\mathbf{p}_1'$ and $\mathbf{p}_2'$ that meet the following conditions:
	\begin{subequations}
		\begin{align}
		||p_{1,k}'-p_{2,k}'|| &\geq \delta \, \forall k = 0,\dotsc,N \label{eq:msep}\\
		p_{j,k}' &\in \mathbf{P}_j \, \forall j=1,2, \, \forall k = 0,\dotsc,N \label{eq:intube}
		\end{align}
	\end{subequations}
\end{myprob}
%Here $\mathbf{P}_j$ is the robustness tube for UAS $j$. 
This implies that we need a new trajectory for each UAS such that they achieve minimum separation distance and also stay within the robustness tube around their originally planned trajectories (see Corollary \ref{cor:rob_tube}). 

%Given two length-$(N+1)$ drone trajectories $\mathbf{p}_1$ and $\mathbf{p}_2$, 
%and conflict times $0\leq k_1,k_2,\dotsc,k_C\leq N-1$ at which the drones are in conflict
%\[|\mathbf{p_1}[k_i]-\mathbf{p_2}[k_i]| \leq \delta\]
%our task is to develop a control algorithm such that there are no conflicts in the $N$-step horizon while the new trajectories $\mathbf{p}_1'$ and $\mathbf{p}_2'$ remain inside their respective robustness tubes $\mathbf{P}_1$ and $\mathbf{P}_2$.  

%\begin{myprob}
%\label{prob:deconflict}
%The control problem is to find
%\begin{equation}
%\begin{split}
%\mathbf{u}_1' \in U^{N-1},  \, \mathbf{u}_2' \in U^{N-1} \, &\text{s.t.}, \\
%||p_1'[k]-p_2'[k]|| \geq \delta \, &\forall k = 0,\dotsc,N \\
%p_j'[k] \in \mathbf{P}_j \, &\forall j=1,2, \, \forall k = 0,\dotsc,N \\
%\text{subject to the dynamics of the drones}
%\end{split}
%\end{equation}
%\end{myprob}

%here $U$ is the set of feasible control actions for either drone (assumed the same w.l.o.g) and $\mathbf{u}' = u[0]',\dotsc,u[N-1]'$ are the control actions over the $N$-step horizon. The new trajectory $p'$ is a function of the new control actions $u'$.

\subsection{Convex constraints for collision avoidance}

Let $z_k$ be the difference in UAS positions at time step $k$. For two UAS not to be in conflict, we need 
\begin{equation}
\label{eq:noconf}
z_k = p_{1,k} - p_{2,k}  \not \in \mathbb{B}_\delta \, \forall k
\end{equation}
%\text{or,} \, C(x_1[k]-x_2[k]) &\not \in \mathbb{C}_\delta
%where $\mathbf{C}_\delta$ is a inf-norm box with side $\delta$. 
This is a non-convex constraint. For a computationally tractable controller formulation which solves problem \ref{prob:deconfliction}, we define convex constraints that when satisfied imply eq. \eqref{eq:noconf}. 
%\footnote{KJ: We don't use $z_k$ anywhere else but here. Do we need it?}

The $3$D cube $\mathbb{B}_\delta$ can be defined by a set of linear inequality constraints of the form $\widetilde{H}^i z \leq \widetilde{g}^i \, \forall i=1,\dotsc,6$.%\footnote{One inequality per each face of the 3D cube.}. 
Eq.~\eqref{eq:noconf} is satisfied when $\exists i \, | \widetilde{H}^i z > \widetilde{g}_i$. Let $H = -\widetilde{H}$ and $g = -\widetilde{g}$, then for any $i \in \{1,\dotsc,6\}$, 
\begin{equation}
\label{eq:pickaside}
H^i(p_{1,k}-p_{2,k}) < {g}^i \Rightarrow (p_{1,k}-p_{2,k}) \not \in \mathbb{B}_\delta 
\end{equation}

Intuitively, picking one $i$ at time step $k$ results in a configuration (in position space) where the two UAS are separated in one of two ways along one of three axis of motion\footnote{Two ways along one of three axis defines $6$ options, $i\in\{1,\ldots,6\}$.}, e.g. at a time step $k$ if we select $i|H^i=\begin{bmatrix}0& 0& 1\end{bmatrix},\, g^i = -\delta$, it implies than UAS 2 flies over UAS 1 by $\delta$ m, and so on.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section{CA-MPC: Control for Collision Avoidance}
%\label{sec:CA_control}



\section{Centralized solution: MILP formulation}
\label{sec:subsec_milp}

Let the dynamics of either UAS\footnote{For simplicity we assume both 
	UAS have identical dynamics associated with multi-rotor robots, 
	however our approach would work otherwise.} be of the form $x_{k+1} = Ax_k + Bu_k$. The states 
$x_k \in \mathbb{R}^6$ here are the positions and velocities in the 
3D space, or $x_k = [p_k,\,v_k]^T$ (here 
$p$ and $v$ are the positions and velocities in the 3D space). The 
inputs $u_k \in \mathbb{R}^3$ are the thrust, roll and pitch of the 
UAS. The matrices $A$ and $B$ can be obtained through linearization 
of the UAS dynamics around hover and discretization in time \cite{PantAMNDM15_Anytime}. 
Let $C$ be the observation matrix such that $p_k=Cx_k$. 

For $N$ steps into the future with a conflict, solving the following receding horizon MILP over the variables of the two UAS would result in new trajectories $\mathbf{p}_1', \, \mathbf{p}_2'$ that satisfy the minimum separation requirement \eqref{eq:noconf}. 
%In case there is indeed a violation of the mutual separation requirement in the $N$ step future, solving the following receding horizon MILP over the variables of the two UAS would result in new trajectories $\mathbf{p}_1', \, \mathbf{p}_2'$ that would not violate the mutual separation requirement of \eqref{eq:noconf}. 
Let $\mathbf{x}_j \in \mathbb{R}^{6(N+1)}$ be the pre-planned full state trajectories, $\mathbf{x}_j' \in \mathbb{R}^{6(N+1)}$ the new full state trajectories and $\mathbf{u}_j' \in \mathbb{R}^{3N}$ the new controls to be computed for the two UAS ($j=1,\,2$). 
Let $\mathbf{b} \in \{0,1\}^{6(N+1)}$ be binary decision variables, and $M$ is a large positive number, then the MILP problem is defined as:
\begin{equation}
\label{eq:CentralMILP}
\resizebox{.442\textwidth}{!}{%
	$
	\begin{aligned}
	\min_{\mathbf{u}_1', \, \mathbf{u}_2', \, \mathbf{b} |\mathbf{x}_1,\, \mathbf{x}_2} &L(\mathbf{x}_1', \, \mathbf{u}_1', \, \mathbf{x}_2', \, \mathbf{u}_2') \\
	x_{j,0}' &= x_{j,0} \, \forall j \in \{1,2\} \\
	x_{j,k+1}' &= Ax_{j,k}' + Bu_{j,k}' \, \forall k \in \{0,\dotsc,N-1\} , \, \forall j \in \{1,2\}\\
	Cx'_{j,k} &\in P_{j,k} \, \forall k \in \{0,\dotsc,N\} , \, \forall j \in \{1,2\}\\
	H^{i}C(x_{1,k}'\!-\!x_{2,k}') &\leq {g}_{i} \!+\! M(1\!-b_{i,k}\!) \, \forall k \in \{0,\dotsc\!,N\}, \forall i \in \{1,\dotsc,\!6\} \\
	\sum_{i=1}^6 b^i_{k} &\geq 1 \, \forall k \in \{0,\dotsc,N\} \\
	u_{j,k}' &\in U \, \forall k \in \{0,\dotsc,N\} , \, \forall j\in \{1,2\}\\
	x_{j,k}' &\in X \, \forall k \in \{0,\dotsc,N+1\}, \forall j\in \{1,2\}
	\end{aligned}$%
}
\end{equation}
Here $b^i_k$ encodes action $i=1,\dotsc,6$ taken for avoiding a collision at time step $k$ which corresponds to a particular side of the cube $\mathbb{B}_\delta$.
A solution (when it exists) to this MILP results in new 
trajectories that avoid collisions and stay within their respective robustness tubes of the original trajectories. 
However, this method relies on solving for a pair of UAS in a centralized manner. 
Also, it introduces $6$ times as many variables (and constraints) as the time horizon of the optimization, which could make the MILP computationally intractable for a real-time implementation. % (which we show in later sections). 
Therefore, we develop a decentralized approach in the following sections.

%The focus now will be on developing an alternative solution that solves the problem in a distributed manner through the two UAS communicating, and each UAS (cooperatively) solving a convex optimization-based control problem over its own variables.


\section{Decentralized solution: Learning-to-Fly}
\label{sec:CA_MPC}

The distributed and co-operative collision avoidance MPC scheme of Section \ref{sec:ca_mpc} with the conflict resolution algorithm described in Section \ref{sec:learning_supervised} form the online collision avoidance scheme, \textit{Learning-to-Fly} (L2F), our main contribution.

%\subsection{Cooperative distributed control for collision avoidance}
We assume that the two UAS can communicate their pre-planned $N$-step trajectories $\mathbf{p}_1,\, \mathbf{p}_2$ to each other (refer to Sec. \ref{sec:problem_planning}).
%(obtained by solving eq. \ref{eq:single_FbL})  
Instead of solving the centralized MILP, we want to solve problem \ref{prob:deconfliction} by following these steps: 


\begin{enumerate}
\item \textbf{Conflict resolution:} UAS 1 and 2 make a \textit{sequence of decisions}, $\mathbf{d}=(d_0,\ldots,d_N)$ to avoid collision. Each $d_k\in\{1,\ldots\,6\}$ 
represents a particular choice of $H$ and $g$ at time step $k$, see eq.~\ref{eq:pickaside}.
%represents a decision at time step $k$ on which $i$ to use from eq.~\eqref{eq:pickaside}. 
Section \ref{sec:learning_supervised} describes our proposed learning-based method for conflict resolution.
%----------------------------------------
\item \textbf{UAS 1 CA-MPC:} UAS 1 takes the conflict resolution sequence $\mathbf{d}$ from step 1 and solves a convex optimization to try to deconflict while assuming UAS 2 maintains its original trajectory. After the optimization the new trajectory for UAS 1 is sent to UAS 2.
%----------------------------------------
\item \textbf{UAS 2 CA-MPC:} (If needed) UAS 2 takes the same conflict resolution sequence $\mathbf{d}$ from step 1 and solves a convex optimization to try to avoid UAS 1's new trajectory. 
Section~\ref{sec:ca_mpc} provides more details on CA-MPC steps 2 and 3.
\end{enumerate}

%\ypcomment{shorten and get rid}

The overall algorithm is shown in Alg. \ref{alg:l2f}. 
The visualization of the above steps is presented in Fig.~\ref{fig:concept}.
Such decentralized approach differs from the centralized MILP approach, where both the binary decision variables and continuous control variables for each UAS are decided concurrently. 
%The decision sequence from conflict resolution is used to generate new trajectories as described in the next section. 


\subsection{Distributed and co-operative collision avoidance MPC}
\label{sec:ca_mpc}
%As before, let $x_{1,k}, x_{2,k}$ represent the states of the UASs at time step $k$ according to the pre-planned (conflicting) trajectories $\mathbf{x}_1$, $\mathbf{x}_2$.
%\textbf{CA-MPC optimization for UAS $j$:}
Each UAS $j\in\{1,2\}$ solves the following Collision Avoidance MPC optimization\footnote{Enforcing the separation constraint at each time step can lead to a restrictive formulation, especially in cases where the two UAS are only briefly close to each other. This does however give us an optimization with a structure that does not change over time, and can avoid collisions in cases where the UAS could run across each other more than once in quick succession (e.g. \url{https://tinyurl.com/uex7722}), which is something ACAS-Xu was not designed for.}:

%<<<<<<< HEAD
%Alg. \ref{alg:l2f}, for each UAS $j$, solves the following collision avoidance MPC\footnote{enforcing the separation constraint at each time step can lead to a restrictive formulation, especially in cases where the two UAS are only briefly close to each other. This does however give us an optimization with a structure that does not change over time, and can avoid collisions in cases where the UAS could run across each other more than once in quick succession (e.g. \url{https://youtu.be/M4bqiR7poRI}), which is something ACAS-Xu was not designed for.}:

%\textbf{$\text{CA-MPC}_j(x_j,x_{avoid}, P_j, d, prty_j)$}:
%=======
\textbf{$\text{CA-MPC}_j(\mathbf{x}_j,\, \mathbf{x}_{avoid},\, P_j,\ \mathbf{d},\, prty_j)$}:
%>>>>>>> 68d93b18f46dd7a9dd16874ca25552cef67eeffc
%Given
%Let $x'$ and $u'$ be the new states and inputs for UAS 1 to be optimized:
\begin{equation}
\label{eq:campc}
\resizebox{.44\textwidth}{!}{
	$
	\begin{aligned}
	& \min_{\mathbf{u}_j',\mathbf{\lambda}_j|\mathbf{x}_j,\mathbf{x}_{avoid}} \sum_k \lambda_{j,k} \\
	x_{j,0}' &= x_{j,0} \\
	x_{j,k+1}' &= Ax_{j,k}' + Bu_{j,k}' \, \forall k=\{0,\dotsc,N-1\} \\
	Cx_{j,k}' &\in P_{j,k} \, \forall k=\{0,\dotsc,N\} \\
	prty_j \!\cdot\! H^{d_k}C(x_{avoid,k}\!-x_{j,k}') &\leq g^{d_k} \!+\! \lambda_{j,k}\, \forall k=\{0,\dotsc,N\} \\
	\lambda_{j,k} &\geq 0\, \forall k=\{0,\dotsc,N\} \\
	u_{j,k}' &\in U\, \forall k=\{0,\dotsc,N \} \\
	x_{j,k}' &\in X \, \forall k \in \{0,\dotsc,N+1\}
	\end{aligned}
	$
}
\end{equation}
where, $\mathbf{x}_j$ is the pre-planned trajectory of UAS $j$, $\mathbf{x}_{avoid}$ is the pre-planned trajectory  from which UAS $j$ must attain a minimum separation, $prty_j \in \{-1, +1\}$ is the priority of UAS $j$ w.r.t the other UAS in conflict.
The decision sequence $\mathbf{d}$ is represented as $H^{d_k},\, g^{d_k}$. 
This MPC optimization tries to find a new trajectory $\mathbf{x}_j'$ for the UAS $j$ that minimizes the slack variables $\lambda_{j,k}$ that correspond to violations in the minimum separation constraint $\eqref{eq:pickaside}$ w.r.t the pre-planned trajectory $\mathbf{x}_{avoid}$ of the UAS in conflict. 
The constraints in \eqref{eq:campc} ensure that UAS $j$ respects its dynamics, input constraints, and state constraints to stay inside the robustness tube. %w.r.t its pre-planned trajectory.
An objective of $0$ implies that UAS $j$'s new trajectory satisfies the minimum separation between the two UAS, see eq.~\eqref{eq:pickaside}.
%Alg. $\ref{alg:l2f}$ proceeds a

\textbf{CA-MPC optimization for UAS 1:}
UAS 1, with lower priority, $prty_1 = -1$, first attempts to resolve the conflict for the given sequence of decisions $\mathbf{d}$.
%\begin{align}
%(\mathbf{x_1'}, \mathbf{u}_1', \mathbf{\lambda}_1)&=\textbf{CA-MPC}_1(\mathbf{x}_1,\mathbf{x}_2, P_1, d, -1)
%\label{eq:drone1mpc}
%\end{align}
An objective of $0$ implies that UAS 1 alone can satisfy the minimum separation between the two UAS. 
%Otherwise, additional maneuvers by UAS 2 are needed.
Otherwise, UAS 1 alone could not create separation and UAS 2 now needs to maneuver as well.

\textbf{CA-MPC optimization for UAS 2:}
If UAS 1 is unsuccessful at collision avoidance, UAS 1 communicates its current revised trajectory $\mathbf{x}_1'$ to UAS 2, with $prty_2 = +1$.
UAS 2 then creates a new trajectory $\mathbf{x}_2'$ 
(w.r.t the same decision sequence $\mathbf{d}$).
%\begin{align}
%(\mathbf{x}_2', \mathbf{u}_2', \mathbf{\lambda}_2)&=\textbf{CA-MPC}_2(\mathbf{x}_2,\mathbf{x}_1', P_2, d, +1)
%\label{eq:drone2mpc}
%\end{align}


Alg. \ref{alg:l2f} is designed to be computationally lighter than the 
MILP approach (see Section~\ref{sec:subsec_milp}), but unlike the MILP it is not complete. 
%In Section \ref{sec:experiments}, through extensive simulations we show that with comparable performance the L2F approach is considerably faster than MILP.
In Section \ref{sec:experiments}, through extensive simulations we show that the L2F approach demonstrates a significant improvement in runtime while  maintaining comparable performance in terms of separation. 

%\begin{algorithm}
%	\KwData{Pre-planned trajectories $x_1, x_2$, robustness tubes}
%	\KwResult{Sequence of control signals $u_1'$, $u_2'$ for the two UASs}
%	%\While{Not done}{
%	%Pick $\text{present}$ maneuver \\
%	Get $\mathbf{d}$ from conflict resolution 
%	
%	UAS 1 solves optimization \eqref{eq:campc} \\
%	$(x_1', u_1', \lambda_1)=\textbf{CA-MPC}_1(x_2, P_1, d, -1)$
%	
%	\eIf{$\sum_k \lambda_{1,k} = 0$}
%	{\textbf{Done}: UAS 1 alone has created separation
%	}
%	{
%		UAS 1 transmits solution $x_1'$ to UAS 2\\
%		UAS 2 solves optimization of \eqref{eq:campc} \\
%		(x_2', u_2', \lambda_2)=\textbf{CA-MPC}_2(x_1', P_2, d, +1)
%		
%		\eIf{$\sum_k \lambda_{2,k} = 0$}{\textbf{Done:} UAS 2 has created 
%			separation }
%		{\eIf{$||p_{1,k}'-p_{2,k}'|| \geq \delta \, \forall k = 0,\dotsc,N$}
%			{\textbf{Done}: UAS 1 alone has created separation}
%			{\textbf{Not done}: UAS still violate eq. \ref{eq:msep}}}
%	}
%
%	Apply control signals $u_1'$, $u_2'$ if \textbf{Done}; else \textbf{Fail}.
%	%} %end while
%	\caption{Learning-to-Fly: Decentralized and cooperative collision avoidance for two UAS. Also see fig. \ref{fig:concept}.}
%	\label{alg:l2f}
%\end{algorithm}


%Otherwise, additional maneuvers by UAS 2 are needed.

%
%\textbf{CA-MPC optimization for UAS 1:}
%Let $x_{1,k}'$ and $u_{1,k}'$ be the new states and inputs for UAS 1 to be optimized:
%\begin{equation}
%{\small
%\vspace{-10pt}
%\label{eq:drone1mpc}
%\begin{split}
%& \min_{\mathbf{u_1'},\mathbf{\lambda_1}|\mathbf{x_1},\, \mathbf{x_2}} \sum_k \lambda_{1,k} \\
%x_{1,0}' &= x_{1,0} \\
%x_{1,k+1}' &= Ax_{1,k}' + Bu_{1,k}' \, \forall k=\{0,\dotsc,N\} \\
%Cx_{1,k}' &\in P_{1,k} \, \forall k=\{0,\dotsc,N\} \\
%H^{d_k}(x_{1,k}'-x_{2,k}) &\leq g^{d_k} + \lambda_{1,k}\, \forall k=\{0,\dotsc,N+1 \} \\
%\lambda_{1,k} &\geq 0\, \forall k=\{0,\dotsc,N \\
%u_{1,k}' &\in U\, \forall k=\{0,\dotsc,N \} \\
%x_{1,k}' &\in X \, \forall k \in \{0,\dotsc,N+1\}
%\end{split}
%}
%\end{equation}

%This MPC optimization tries to find a trajectory for UAS 1 that minimize the slack variables $\lambda_{1,k}$ that correspond to violations in the minimum separation constraint w.r.t the pre-planned trajectory of UAS 2. 
%The constraints are meant to ensure that UAS 1 respects its dynamics, input constraints, and state constraints to stay inside the robustness tube w.r.t its pre-planned trajectory.
%An objective of $0$ implies that UAS 1's maneuvers alone can satisfy the minimum separation between the two UASs. 
%Otherwise, additional maneuvers by UAS 2 are needed.
%If the objective is greater than 0, UAS 1 alone could not create separation and UAS 2 now needs to maneuver as well.
%
%\textbf{CA-MPC optimization for UAS 2:}
%If UAS 1 is unsuccessful at collision avoidance, UAS 2 creates a new trajectory based off of UAS 1's new trajectory $\mathbf{x_1'}$ (w.r.t the same de-confliction decisions $H^{d_k},g^{d_k}$ of UAS 1).
%
%\begin{equation}
%\label{eq:drone2mpc}
%{\small
%\begin{split}
%& \min_{\mathbf{u_2'},\mathbf{\lambda_2}|\mathbf{x_1'},\, \mathbf{x_2}} \sum_k \lambda_{2,k} \\
%x_{2,0}' &= x_{2,0} \\
%x_{2,k+1}' &= Ax_{2,k}' + Bu_{2,k}' \, \forall k=\{0,\dotsc,N\} \\
%Cx_{2,k}' &\in {P}_{2,k} \, \forall k=\{0,\dotsc,N\} \\
%H^{d_k}(x_{1,k}'-x_{2,k}') &\leq g^{d_k} + \lambda_{2,k}\, \forall k=\{0,\dotsc,N+1 \} \\
%\lambda_{2,k} &\geq 0\, \forall k=\{0,\dotsc,N \}\\
%u_{2,k}' &\in U\, \forall k=\{0,\dotsc,N \} \\
%x_{2,k}' &\in X \, \forall k \in \{0,\dotsc,N+1\}
%\end{split}}
%\end{equation}
%An objective of zero means the 2 UASs have cooperatively created new trajectories that do not conflict. 
%The overall algorithm for Learning-to-Fly is presented in the Alg. \ref{alg:l2f}. 
%Alg. \ref{alg:l2f} is designed to be computationally lighter than the 
%MILP approach (see Section~\ref{sec:subsec_milp}), but unlike the MILP it is not complete. 
%In Section \ref{sec:experiments} through extensive simulations we show that with comparable performance the L2F approach is considerably faster than MILP.

\begin{algorithm}
	\KwData{Pre-planned trajectories, robustness tubes}
	\KwResult{Sequence of control signals $\mathbf{u}_1'$, $\mathbf{u}_2'$ for the two UAS}
	%\While{Not done}{
	%Pick $\text{present}$ maneuver \\
	Get $\mathbf{d}$ from conflict resolution 
	
	UAS 1 solves CA-MPC optimization \eqref{eq:campc}:\\
	$(\mathbf{x}_1', \mathbf{u}_1', \mathbf{\lambda}_1)=\textbf{CA-MPC}_1(\mathbf{x}_1,\mathbf{x}_2, P_1, \mathbf{d}, -1)$ 
	
	\eIf{$\sum_k \lambda_{1,k} = 0$}
	{\textbf{Done}: UAS 1 alone has created separation; Set $\mathbf{u}_2'=\mathbf{u}_2$
	}
	{ UAS 1 transmits solution to UAS 2
		
		UAS 2 solves CA-MPC optimization \eqref{eq:campc}: \\
		$(\mathbf{x}_2', \mathbf{u}_2', \mathbf{\lambda}_2)=\textbf{CA-MPC}_2(\mathbf{x}_2,\mathbf{x}_1', P_2, d, +1)$
		
		\eIf{$\sum_k \lambda_{2,k} = 0$}{\textbf{Done:} UAS 2 has created 
			separation }
		{\eIf{$||p_{1,k}'-p_{2,k}'|| \geq \delta \, \forall k = 0,\dotsc,N$}
			{\textbf{Done}: UAS 1 and UAS 2 created separation}
			{\textbf{Not done}: UAS still violate eq. \ref{eq:msep}}}
	}
	
	Apply control signals $\mathbf{u}_1'$, $\mathbf{u}_2'$ if \textbf{Done}; else \textbf{Fail}.
	%} %end while
	\caption{Learning-to-Fly: Decentralized and cooperative collision avoidance for two UAS. Also see fig. \ref{fig:concept}.}
	\label{alg:l2f}
	
\end{algorithm}
The solution of CA-MPC can be defined as follows:
\begin{definition}[Zero-slack solution]
	\label{def:zero_slack}
	The solution of the CA-MPC optimization \eqref{eq:campc}, is called the \textit{zero-slack solution} if for a given decision sequence $\mathbf{d}$ either
	
	1) there exists an optimal solution of \eqref{eq:campc} such that  $\sum_k\lambda_{1,k}=0$ or
	
	2) problem \eqref{eq:campc} is feasible with $\sum_k\lambda_{1,k}>0$ and there exists an optimal solution of \eqref{eq:campc} such that  $\sum_k\lambda_{2,k}=0$.
\end{definition}

The two following theorems make important connections between feasible solutions for MILP and CA-MPC formulations.
%, existence of feasible solutions and satisfaction of the mutual separation requirement. 
They are the consequence of the construction of CA-MPC optimizations. We omit the proofs for brevity.


\begin{theorem}[Sufficient condition for CA]
	\label{th:CAMPC_success}
	Zero-slack solution of \eqref{eq:campc}
	implies that the resulting trajectories for two UAS are non-conflicting and within the robustness tubes of the initial trajectories\footnote{Theorem~\ref{th:CAMPC_success} formulates a conservative result as \eqref{eq:pickaside} is a convex under approximation of the originally non-convex collision avoidance constraint \eqref{eq:noconf}. Indeed, non-zero slack $\exists k| \lambda_{2,k}>0$ does not necessarily imply the violation of the mutual separation requirement \eqref{eq:msep}. The control signals $u_1',u_2'$ computed by alg. \ref{alg:l2f} can therefore in some instances still create separation between drones even when the conditions of Theorem \ref{th:CAMPC_success} are not satisfied.}.
\end{theorem}

%Theorem~\ref{th:CAMPC_success} formulates a conservative result. Indeed, if $\exists k| 
%\lambda_{2,k}>0$, it does not necessarily imply that the separation 
%requirement \eqref{eq:msep} is violated.

%This could happen because at the time step $k$ the separation between the two UAS is achieved through some other relative position configurations ($i$ in eq. \ref{eq:pickaside}) compared to the one that is used as a constraint in the optimization. At the time steps $k$ where the robustness tubes of the two UAS are themselves more than $\delta$m apart, having a $\lambda_{2,k}>0$ cannot result in a violation of eq. \ref{eq:msep}. Fig. \ref{fig:slackbad} shows a couple of such examples.



%\ypcomment{no} On the other hand, if the objective is greater than 0, the de-confliction maneuvers $H_{i[k]},g_{i[k]}$ were chosen poorly and the drones could not satisfy them \textbf{YP: Needs a proof that a central optimization would not be able to satisfy these constraints either}.

%Next, we take the joint (across the two drones) collision avoidance constraint of \eqref{eq:pickaside} and turn it into constraints on the controls of the individual drones:



%\begin{equation}
%\begin{split}
%&H_i z[k] \leq g_i  \\
%& \Rightarrow H_i(x_1[k]-x_2[k]) \leq g_i  \\
%%& \Rightarrow H_i x_1[k] - H_i x_2[k] \leq g_i  \\
%& \Rightarrow H_i (A^kx_1[0] + G \mathbf{u}_1) - H_i (A^k x_2[0] + G \mathbf{u}_2) \leq g_i  \\
%& \Rightarrow H_i G \mathbf{u}_1 - H_i G \mathbf{u}_2 \leq g_i - H_iA^k (x_1[0]-x_2[0])  \\
%& \text{or,} \, \bar{H}_i \mathbf{u}_1 - \bar{H}_i \mathbf{u}_2 \leq \bar{g}_i  \\
%& \text{or,} \, \bar{H}_i \mathbf{u}_1 - \bar{H}_i \mathbf{u}_2 \leq \lambda \bar{g}_i +(1-\lambda) \bar{g}_i \\
%& \text{or, strengthen this to}\, (\bar{H}_i \mathbf{u}_1 \leq \lambda \bar{g}_i \, \& \, -\bar{H}_i \mathbf{u}_2 \leq (1-\lambda) \bar{g}_i)\label{eq:nocoll}
%\end{split}
%\end{equation}

%Here, $G$ is the appropriate matrix from the system dynamics (for compactness). $\lambda \in [0,1]$ is a co-operation parameter that helps us distribute the joint constraint on collision avoidance to two independent constraints on the controls of the two drones.

%One candidate method for de-confliction would be to enforce such a constraint on all time steps $0,\dotsc,N$ in the horizon. The drawback is that this would require us to find the correct $i$, or de-confliction rule of Eq. \ref{eq:pickaside} for each time step $k$ in the horizon. This is not trivial as the reachability of the system dynamics could result in maneuvers not being feasible with the constraint of staying in the robustness tube. In the worst case, this could potentially require us to cycle through all $6^N$ combinations for collision avoidance in $\mathbb{R}^3$ (or try all sides of the $\mathbf{C}_\delta$ collision box at each time step in the horizon). This is outlined in the next section.

\input{chapters/feasMILPCAMPC}

\input{chapters/learning_supervised}


%
%\begin{figure}[tb]
%\includegraphics[width=0.49\textwidth]{OverallArchitecture.pdf}
%\caption{Overall planning and control architecture for the framework developed in this paper.}
%\label{fig:architecture}
%\end{figure}
%

%\subsection{A greedy algorithm for decision making:}
%For a horizon length of $N$ steps, there are $6^{N}$ possible selections for the deconfliction constraints $H_{i[k]}, \, g_{i[k]}$ (6 at each time step in the horizon). The centralized MILP formulation picks which constraint to use by activating the corresponding binary variable \eqref{eq:CentralMILP}. For the decentralized, cooperative MPC case, we need a decision making algorithm to pick these constraints as there are no binary variables in our formulations \eqref{eq:drone1mpc}, \eqref{eq:drone2mpc}. 
%
%
%\ypcomment{move to appendix}
%The following is a greedy approach to this:
%
%\begin{algorithm}
% \KwData{Pre-planned trajectories: $\mathbf{x_1}, \, \mathbf{x_2}$, a preset maneuver: $\text{preset} \in \{1,\dotsc,6\}$}
% \KwResult{$i[k]\, \forall k=\{0,\dotsc N+1\}$ for maneuvers $H_{i[k]},\, g_i[k]$}
% initialization k=0, no conflict at time step $k=0$\; \\
% \While{$k \leq N+1$}{
% \For{$i=\{1,\dotsc,6\}$}
% {$r_{i}[k] = g_i - H_i (x_1[k]-x_2[k])$
% }
% %$i[k] = \text{argmax}_i\, (g_i - H_i (x_1[k]-x_2[k]))$ \\
% \eIf{$\exists i|r_i[k] \geq 0 $}{
% $i[k] = \text{argmax}_i\, r_{i}[k]$
% }
% {i[k] = $\text{preset}$
% }
% k = k+1
%%  read current\;
%%  \eIf{understand}{
%%   go to next section\;
%%   current section becomes this one\;
%%   }{
%%   go back to the beginning of current section\;
%%  }
% }
% \caption{Greedy selection of deconfliction maneuvers}
% \label{alg:greedy}
%\end{algorithm}
%
%Algorithm \ref{alg:greedy}, for time steps $k$ such that there is no conflict, selects the direction (or side of the hypercube \eqref{eq:noconf}) where there is the most separation between the drones. For the time steps where there is a conflict, it picks a pre-defined maneuver. %the separation direction (or maneuver) for the last time step where there was no conflict.



