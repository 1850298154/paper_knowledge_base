\section{Combining Novelty and Fitness}
\label{sec:combination}

The results of the resource sharing experiments showed that although novelty search finds a broad diversity of behaviours, regions with high-fitness behaviours may never be explored. This issue has also been reported in other studies \citep{stan10a,cuccu11b}, and a common solution is to combine novelty search with fitness-based evolution (see Section~\ref{sec:ns_variants}). The combination is promising, because while novelty search promotes exploration of the behaviour space, fitness-based evolution exploits existing high fitness solutions. In this section, we study the application of \emph{progressive minimal criteria novelty search} (PMCNS) \citep{gomes12} and \emph{linear scalarization} \citep{cuccu11b} to the evolution of solutions for the resource sharing task. We compare the results obtained with PMCNS and with linear scalarization to the results obtained with pure novelty search and with fitness-based evolution.

\subsection{Progressive Minimal Criteria Novelty Search}

PMCNS~\citep{gomes12} is an extension of \emph{minimal criteria novelty search} (MCNS)~\citep{stan10a}. In MCNS, the exploration of the behaviour space is restricted by domain-dependent minimal criteria that evolved individuals must meet in order to be selected for reproduction. The objective of PMCNS is to take advantage of the restrictions on behaviour space exploration provided by MCNS, but without having to define fixed, domain-dependent criteria \emph{a priori}. In PMCNS, a dynamic fitness threshold is used as the minimal criterion: individuals with a fitness score above the threshold meet the criterion. The fitness threshold is progressively increased during the evolutionary process. The idea behind the increasing fitness criterion is to progressively restrict the search space to regions of the behaviour space with higher fitness scores, and thereby avoid that novelty search spends much or all effort on regions of the behaviour space with novel, but low fitness behaviours.

The minimal criterion starts at the theoretical minimum of the fitness score (typically zero), so all controllers initially meet the criterion. In each generation $g$, the new criterion $mc_{g}$ is based on the fitness score $v_{g}$ of the $P$-th percentile of the individuals in the current population, i.e., the fitness score below which $P$ percent of the individuals fall. The parameter $P$ controls the exigency of the minimal criterion (0 -- all individuals meet the criterion, 1 -- only the individual with the highest fitness meets the criterion). Only increases in the minimal criterion are allowed, and in order to smoothen the increase, the minimal criterion from the previous generation is used to determine the criterion for the current generation (Eq.~\ref{eq:pmcns1}). The score used for selection of each individual $i$ in the population is then calculated according to Eq.~\ref{eq:pmcns2}.

\begin{equation}
mc_{g} = mc_{g-1} + \mathrm{max}(0, (v_{g} - mc_{g-1}) \cdot S)
\label{eq:pmcns1}
\end{equation}

\begin{equation}
\mathrm{score}(i) =	
\begin{cases}
	nov_{i} & \text{if $f\!it_{i} \geq mc_{g}$}
	\\
	0 & \text{otherwise}
\end{cases}
\label{eq:pmcns2}
\end{equation}

The variables $nov_{i}$ and $f\!it_{i}$ are the novelty and fitness score of the individual $i$, respectively. The smoothening parameter $S$ controls the speed of the adaptation of the minimal criterion.

% the following is not true: (0 -- no changes at all, 1 -- the value from the previous generation is not considered).

\subsection{Linear Scalarization of Novelty and Fitness Scores}

\citet{cuccu11b} proposed a linear scalarization of novelty and fitness score, as an approach to sustain diversity while improving the performance of traditional fitness-based evolution. Each individual $i$ is evaluated to obtain both fitness score, $f\!it(i)$, and novelty score, $nov(i)$, which after being normalised (Eq.~\ref{eq:blendnorm}) are combined according to Eq.~\ref{eq:blend}.

\begin{equation}
\overline{f\!it}(i)=\frac{f\!it(i)-f\!it_{min}}{f\!it_{max}-f\!it_{min}}, \quad \overline{nov}(i)=\frac{nov(i)-nov_{min}}{nov_{max}-nov_{min}} \enspace ,
\label{eq:blendnorm}
\end{equation}

\begin{equation}
score(i)=(1-\rho)\cdot \overline{f\!it}(i)+\rho \cdot \overline{nov}(i) \enspace .
\label{eq:blend}
\end{equation}

The parameter $\rho$ controls the relative weight of fitness and novelty, and must be specified by the experimenter (usually through trial and error). $f\!it_{min}$ and $nov_{min}$ are respectively the lowest fitness and novelty scores in the current population, and $f\!it_{max}$ and $nov_{max}$ are the corresponding highest scores.

\subsection{Experimental Setup}

We used the experimental setup of the resource sharing task (see Section~\ref{sec:energy_setup}) for this set of experiments. The fitness function and the behaviour characterisations are also the same as we used previous experiments (see Section~\ref{sec:energy_functions}).

For PMCNS, we chose a percentile value of $P=0.50$ (values of 0.25, 0.50 and 0.75 were tested), which corresponds the median value of the fitness scores in the population, and a smoothening parameter of $S=0.25$, which corresponds to relatively slow increases in the minimal criterion value. For linear scalarization, the parameter $\rho$ was set to $\rho=0.75$ (values of 0.25, 0.50 and 0.75 were tested), which means that the score of each individual is composed of 75\% of the novelty score and 25\% of the fitness score. A discussion of the parameter values for linear scalarization and PMCNS can be found in \citep{cuccu11b} and in \citep{gomes12}, respectively.

\subsection{Results}

We ran experiments with both behaviour characterisations $\mathbf{b_{simple}}$ and $\mathbf{b_{extra}}$ to evaluate the performance of PMCNS and linear scalarization in behaviour spaces of different dimensionality. The resulting fitness trajectories are shown in Figure~\ref{fig:mix_fitness_trajectories}.

\begin{figure}[b]
\centering
\includegraphics[width=\textwidth]{pic/mix_performance.pdf}
\caption{Highest fitness scores obtained in the resource sharing task with fitness-based evolution (\emph{Fit}), and novelty-based evolutionary techniques with $\mathbf{b_{simple}}$ (\emph{PMCNS-s}, \emph{Scalarization-s}, \emph{NS-s}) and $\mathbf{b_{extra}}$ (\emph{PMCNS-e}, \emph{Scalarization-e}, \emph{NS-e}). Top: average fitness value of the highest scoring individual found so far at each generation. The values are averaged over 30 independent evolutionary runs for each method. Bottom: box-plots of the highest fitness score found in each evolutionary run, for each method. The whiskers extend to the lowest and the highest data point within 1.5 times the interquartile range. Outliers are indicated by circles.}
\label{fig:mix_fitness_trajectories}
\end{figure}

The results show that both PMCNS and linear scalarization are more effective than pure novelty search when using $\mathbf{b_{extra}}$ (Mann--Whitney U test, $p$-value~$<$~0.01), and achieve similar fitness scores when using $\mathbf{b_{simple}}$. With the $\mathbf{b_{extra}}$ characterisation, pure novelty search fails to reach high fitness scores, as evolution tends to focus the exploration on behaviour dimensions that are not directly relevant for solving the task. The results suggest that PMCNS and linear scalarization can overcome this issue, and that the inclusion of a fitness component in the selection criteria helps to guide the evolutionary process towards solutions with high fitness. It should also be noted that PMCNS and linear scalarization do not appear to be affected by the deceptiveness of the fitness function since they could consistently achieve high fitness scores.

% space exploration ns/blend/pmcns (simple)
\begin{figure}[b]
\centering
\includegraphics[width=\textwidth]{pic/mix_simple_exploration}
\caption{Behaviour space exploration for each variant of novelty search, with the $\mathbf{b_{simple}}$ characterisation, in all evolutionary runs. The $x$-axis is the average energy level of the robots still alive, the $y$-axis is the number of survivors. Each individual is mapped according to its behaviour. Darker zones indicate that there were more individuals evolved with the behaviour of that zone.}
\label{fig:space_exploration_simple}
\end{figure}

% space exploration ns/blend/pmcns (extra) 
\begin{figure}[b]
\centering
\includegraphics[width=\textwidth]{pic/mix_extra_exploration}
\caption{Kohonen maps representing the explored behaviour space with each variant of novelty search, with the $\mathbf{b_{extra}}$ characterisation. Each circle represents a behaviour pattern, depicted by the 4 slices of different colour. Each slice represents one component of the behaviour characterisation -- the bigger the slice, the greater the value of that component. The darker the background of a circle is, the more individuals were evolved with the corresponding behaviour. The behaviour patterns with higher fitness scores are indicated in the upper right corner of each map.}
\label{fig:space_exploration_extra}
\end{figure}

% behaviour space comparison ns vs mixes
Figure~\ref{fig:space_exploration_simple} and Figure~\ref{fig:space_exploration_extra} depict the behaviour space exploration with $\mathbf{b_{simple}}$ and $\mathbf{b_{extra}}$, respectively. An analysis of the behaviour space exploration shows that PMCNS and linear scalarization have a greater focus on regions associated with high fitness scores compared to pure novelty search. The coverage of the behaviour space was not negatively affected in PMCNS and linear scalarization. In fact, the two methods found the same broad range of behaviours as pure novelty search. The difference between pure novelty search and novelty search combined with fitness-based search is the amount of exploration done in each behaviour region: PMCNS and linear scalarization focused less on the low fitness behaviours (few or no robots surviving till the end of the simulation) and more on the high-fitness behaviours (high number of surviving robots). As a result, the PMCNS and linear scalarization could achieve solutions with significantly higher fitness scores than the best solutions evolved with pure novelty search.
