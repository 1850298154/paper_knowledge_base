\section{Introduction}

% ------ motivation & novelty search --------

Motivations for the use of evolutionary techniques to design control systems for robots are numerous~\citep{harvey93,nelson09}. In the swarm robotics domain in particular, the complexity stemming from the intricate dynamics required to produce self-organised behaviour complicates the hand-design of control systems. Artificial evolution, on the contrary, has been shown capable of exploiting the intricate dynamics and synthesise self-organised behaviours~(see for example \citealp{trianni06b,sperati08}). However, evolutionary robotics techniques have only been proven effective in relatively simple tasks~\citep{sprong11,doncieux11,brambilla12}. The lack of studies that report successful evolution of behaviours for complex tasks can be ascribed to the difficulties in configuring the evolutionary process such that adequate solutions are synthesised within a reasonable amount of time \citep{doncieux11}.

The most common approach in artificial evolution, and evolutionary robotics in particular, is to guide the evolutionary process towards a fixed objective \citep{nelson09} (henceforth referred to as \emph{fitness-based evolution}). The experimenter defines a fitness function that estimates the quality of candidate solutions with respect to a given task, and this fitness function is used to score the individuals in the population. While search based on the task objective may intuitively seem reasonable, it is associated with a number of issues of which \emph{deception} is one of the most prominent~\citep{whitley91,jones95}. Deception is a challenging issue in evolutionary computation which occurs when the fitness function misguides the evolutionary process \citep{stan11a}, potentially causing evolution to converge to local optima. As the complexity of a task or a system increases, it becomes more difficult to craft an appropriate fitness function, and fitness-based evolution becomes more vulnerable to deception \citep{zaera96}.

Novelty search \citep{stan11a} is a distinctive evolutionary approach which rewards solutions based solely on their behavioural novelty. In fitness-based evolution, the objective is typically static, and the evaluations of individuals are independent of one another. In novelty search, on the other hand, individuals are evaluated by a dynamic measure that scores candidate solutions based on how different they are from solutions evaluated so far, with respect to their behaviour. Due to the absence of a static objective, novelty search is unaffected by premature convergence. \citet{mouret09} showed that the novelty-based paradigm can also be effective in bootstrapping evolution. Novelty search has proven capable of finding a broad diversity of solutions to a given problem \citep{stan11b} and solutions with lower neural network complexity than fitness-based evolution \citep{stan11a}. Novelty search has been successfully applied to many domains, including non-collective evolutionary robotics~(for examples, see \citealp{krcah10,stan11a,mouret11}).

In this paper, we propose and study the application of novelty search to the evolution of neural controllers for swarm robotics systems. Our motivation is the high level of complexity associated with swarm robotics, which stems from the intricate dynamics between many interacting units. The high level of complexity has the tendency to generate deceptive fitness landscapes~\citep{whitley91}, and novelty search has been shown to be unaffected by deception~\citep{stan11a}. To evaluate novelty search in the swarm robotics domain, we conduct several experiments. We use two different tasks in our study: (i)~an aggregation task, and (ii)~a resource sharing task. The former is a task commonly used in the field of evolutionary swarm robotics. The latter is a more challenging task in which the swarm must coordinate to ensure that each member has periodic and exclusive access to a charging station. In all experiments, we establish comparisons between novelty search and traditional fitness-based evolution. One of the key components in novelty search is the \emph{novelty measure} that quantifies the novelty of each solution. It is based on a \emph{behaviour characterisation} (usually a real-valued vector) that corresponds to an approximate representation of the individual's actual behaviour. The behaviour characterisation is typically domain-dependent and task-dependent. We study different approaches to the definition of behaviour characterisations for swarm robotics tasks. Our characterisations capture the macroscopic swarm-level behaviour and thus are independent of the swarm size. In the aggregation task, we evaluate characterisations composed of behavioural features sampled at regular intervals. In the resource sharing task, we go on to show that simple characterisations that summarise an entire simulation are, in fact, sufficient for novelty search to find good solutions.

One issue that can arise in novelty search is that a significant part of the effort may be spent exploring novel but unfruitful regions of the behaviour space \citep{stan10a,cuccu11b}. A number of methods that combine the exploratory nature of novelty search with the exploitatory nature of fitness-based evolution have been proposed to address this issue \citep{stan10a,cuccu11b,mouret11,gomes12}. We explore the potential of two such methods, namely \emph{progressive minimal criteria novelty search}~\citep{gomes12} and \emph{linear scalarization} of novelty and fitness objectives~\citep{cuccu11b}. 

The paper is organised as follows: in Section~\ref{sec:related_work}, we discuss related work, present the current challenges in evolutionary robotics, and introduce the novelty search algorithm. In Section~\ref{sec:aggregation}, we use novelty search to evolve aggregation behaviours. We experiment with three behaviour characterisations, and study how each one affects the behavioural diversity and the performance of novelty search. In Section~\ref{sec:sharing}, we experiment with a more challenging resource sharing task. We find that some behaviour characterisations open the search space too much and thereby reduce the effectiveness of novelty search. In Section~\ref{sec:combination}, we show how the problem of vast behaviour spaces can be mitigated by combining novelty search with fitness-based evolution. We conclude in Section~\ref{sec:conclusion} with a summary of the contributions of the paper and with a discussion of ongoing work.

\section{Related Work}
\label{sec:related_work}

In this section, we first discuss swarm robotics and evolutionary robotics, and the main challenges associated with these fields. We then present novelty search and how it can overcome some of these challenges. We go on to review recently proposed variants of novelty search. We conclude the section with a description of NEAT, the neuroevolution method used in our experiments.

\subsection{Swarm Robotics}

The field of swarm robotics, as well as the more general field of swarm intelligence~\citep{BonDorThe99:book}, take inspiration from the observation of social insects. In a swarm intelligence system, be it natural such as an ant colony, or artificial such as a large-scale decentralised multirobot system, relatively simple units rely on self-organisation to display collectively intelligent behaviour. As such, swarm robotics is an auspicious approach to the decentralised coordination of large numbers of robots~\citep{sahin05a}. An extensive survey of the modelling of swarm robotics systems and the problems that have been addressed can be found in \citep{brambilla12,sahin07}. Self-organisation in multirobot systems has, however, proven difficult to design by hand. Manually designing the control for the individual units of a swarm requires the decomposition of the macroscopic swarm behaviour into microscopic behavioural rules \citep{trianni06b}. Such decomposition includes discovering the relevant interactions between the individual robots, and between the robots and the environment, which will ultimately lead to the emergence of global self-organised behaviour. Unfortunately, there is no general method for decomposing a desired global behaviour into the rules that govern each individual. System designers therefore typically take inspiration from biological swarm systems or rely on manual trial and error.

\subsection{Evolutionary Robotics}

Evolutionary robotics is a field concerned with the application of evolutionary computation to the synthesis of robotic systems. Evolutionary robotics is an alternative for the design of control for swarm robotics systems, because the application of evolutionary computation eliminates the need for manual decomposition of the desired macroscopic behaviour. Artificial evolution essentially performs an iterative trial and error process in which candidate solutions are evaluated according to their swarm-level behaviour. Macroscopic performance evaluation is thus used to guide the evolutionary process towards the objective. Several swarm robotics tasks have been solved with evolutionary approaches, such as coordinated motion~\citep{baldassarre07}, foraging~\citep{liu07}, aggregation~\citep{trianni03}, hole avoidance~\citep{trianni06a}, aerial vehicles communication \citep{hauert09}, categorisation~\citep{ampatzis08}, group transport~\citep{gross08}, and social learning \citep{pini08}. 

Traditional evolutionary approaches are, however, prone to suffer from a number of issues \citep{doncieux11}. Deception~\citep{whitley91,jones95} is a challenging issue in evolutionary computation, because it can cause the evolutionary process to converge prematurely to local optima. Deception occurs when the fitness function creates a \emph{deceiving} fitness gradient. This typically happens when the fitness function fails to adequately reward the intermediated steps that are needed to achieve the global optimum. A related issue that can arise when applying evolutionary computation to complex tasks is the bootstrap problem \citep{gomez96,mouret09}. This problem occurs when the task is too demanding to exert significant selective pressure on the population during the early stages of evolution, as all of the individuals perform equally poorly. As a consequence, there is no fitness gradient and the evolutionary process starts to drift in an uninteresting region of the solution space.

One way to circumvent deception is through the use of techniques that maintain genotypic diversity in the population, such as fitness sharing~\citep{goldberg87b}, promotion of diversity based on the fitness score of the solutions~\citep{hu05,hutter06}, intermingling individuals of different genetic ages~\citep{hornby06,castelli11}, and minimisation of the age of the genotypes \citep{schmidt10}. However, the problem may ultimately be in the fitness function itself, not in the particular search algorithm. If the fitness function is actively misguiding the search, the evolutionary process may still fail, regardless of the amount of genotypic diversity present in the population. 

A distinct approach to address the issue of deception is through the use of coevolution. In competitive coevolution, individual fitness is evaluated through competition with other individuals in the population, rather than through an absolute fitness measure. Ideally, this creates an \emph{arms race} that leads to increasingly better solutions. This approach has been applied with success in some domains (e.g. \citet{chellapilla99}), but it is also associated with a number of issues that stem from the potentially counterproductive dynamics between the multiple co-evolving species, such as convergence to mediocre stable states \citep{watson01}. Other techniques to overcome deception and to bootstrap evolution rely on the decomposition of the objective into multiple sub-goals that each are easier to attain. These techniques include incremental evolution~\citep{gomez96}, fitness shaping~\citep{uchibe02}, and multi-objectivisation~\citep{deb01,knowles01}. A common drawback of these approaches is that task decomposition may not always be possible, and when it is, a significant amount of \emph{a priori} knowledge about the task is required to devise appropriate sub-tasks.

\subsection{Novelty Search}
\label{sec:ns}

% novelty search motivation
While the methods discussed above for mitigating deception might help the evolutionary process to avoid getting stuck in local optima, they leave the underlying problem untreated, namely that the fitness function itself might be misdirecting the search. With this issue in mind, a new evolutionary approach was recently proposed --- novelty search. In novelty search, the evolutionary process is based on the promotion of phenotypic (i.e., behavioural) diversity and innovation, contrasting with more common techniques that strive to maintain genotypic diversity. \citet{stan11a} used two deceptive robotics tasks to show how novelty search was able to find good solutions faster and more consistently than fitness-based evolution. Even though the objective was not directly pursued in any of their experiments, a solution was found more consistently through the exploration of the behaviour space. Successful applications of novelty search include the evolution of adaptive neural networks \citep{soltoggio09}; genetic programming \citep{stan10b}; evolution strategies \citep{cuccu11a}; body-brain co-evolution \citep{krcah10}; biped robot control \citep{stan11a}; and robot navigation in deceptive mazes \citep{stan08, mouret11}.

% novelty search implementation
Implementing novelty search requires little change to any evolutionary algorithm aside from replacing the fitness function with a domain-dependent novelty metric. This metric quantifies how different an individual is from the other, previously evaluated individuals with respect to behaviour. Previously seen behaviours are stored in an archive. The archive is initially empty, and new behaviours are added to it if they are significantly different from the ones already there, i.e., if their novelty score is above some threshold.

A novelty metric characterises how far an individual is from other individuals in the behaviour space. This metric depends on the sparseness at a given point in the behaviour space. A simple measure of sparseness at a point is the average distance to the $k$-nearest neighbours of that point, where $k$ is a fixed parameter empirically determined. The sparseness $\rho$ at point $x$ is given by:
\begin{equation}
\rho (x)=\frac{1}{k}\sum_{i=1}^{k}dist(x,\mu _{i}) \enspace ,
\end{equation}
where $\mu _{i}$ is the $i$th-nearest neighbour of $x$ with respect to the distance metric $dist$. Note that the computational cost of the nearest-neighbours calculation increases linearly with the size of the population and the size of the archive. However, it is possible to limit the size of the archive \citep{stan11a} and to use data structures such as KD-trees to reduce this cost. The function $dist$ is a measure of behavioural difference between two individuals in the search space. Candidates from sparse regions of the behaviour space thus tend to receive higher novelty scores, which results in an evolutionary process that strives to uniformly explore the behavioural space. Note that the novelty metric promotes behavioural diversity within the population at all times and therefore helps to avoid convergence to a single solution, which is common in fitness-based evolution.

The behaviour of each individual is typically characterised by a vector of real numbers. The behavioural distance $dist$ is then given by the distance between the corresponding characterisation vectors (the Euclidean distance is typically used). The experimenter should design the behaviour characterisation so that it captures behaviour aspects that are considered relevant to the problem or task. For example, in a maze navigation task \citep{stan11a} the behaviour characterisation was the trajectory of the robot through the maze. The design of the characterisation has direct implications on the effectiveness of novelty search. An excessively detailed characterisation can open the search space too much, and might cause the evolution to focus on regions of the behaviour space that are irrelevant for the task for which a solution is sought. On the other hand, an incomplete or inadequate characterisation can originate counterproductive \emph{conflation}. Conflation occurs because the mapping between observable behaviours and behaviour characterisations is typically not injective. As such, notably different behaviours can have similar behaviour characterisations, which can potentially hinder the evolution of novel solutions \citep{kistemaker11}.

Designing the behaviour characterisation often requires knowledge about which behaviour features are relevant for solving a task. However, unlike fitness shaping techniques, it is not necessary to understand exactly how these behaviour features affect fitness, or in which order the features must be evolved. Novelty search does not require a fitness gradient to guide evolution, which makes the approach applicable to some classes of problems that are difficult to solve using traditional fitness-based evolution \citep{kistemaker11}.

\subsection{Novelty Search Variants} \label{sec:ns_variants}

Several extensions of novelty search have been proposed to overcome the limitation of novelty search with respect to guiding evolution towards good solutions in vast behaviour spaces. These extensions are based on the combination of the exploratory character of novelty search with the exploitatory character of fitness-based evolution.

\citet{stan10a} proposed \emph{minimal criteria novelty search}~(MCNS), an extension of novelty search where individuals must meet some domain-dependent minimal criteria to be selected for reproduction. In \citep{stan10a}, the authors applied MCNS in two maze navigation tasks and demonstrated that MCNS evolved solutions more consistently than both novelty search and fitness-based evolution. Similar results were reported in \citep{kirkpatrick12}, using competitive coevolution and a different task. However, MCNS suffers from a number of drawbacks \citep{stan10a}. First, the choice of minimal criteria in a particular domain requires careful consideration and domain knowledge, since it adds significant restrictions to the search space. Constraining the search space too much can hinder the evolution of some types of solutions. Second, if no individuals are found that meet the minimal criteria, search is effectively random. In situations where an initial randomly generated population is unlikely to contain such individuals, it may therefore be necessary to seed MCNS with a genome specifically evolved to meet the criteria. And finally, if the minimal criteria are too stringent, it might be difficult to mutate apt individuals without violating the criteria, and thus many evaluations may be wasted.

In recent work \citep{gomes12}, we proposed an extension named \emph{progressive minimal criteria novelty search} (PMCNS), which overcomes the drawbacks of MCNS. In PMCNS, the respective benefits of novelty search and fitness-based evolution are combined by letting novelty search freely explore new regions of the behaviour space, as long as solutions meet a progressively stricter fitness criterion. PMCNS was found to outperform several other evolutionary algorithms, and to evolve higher scoring individuals while still maintaining behavioural diversity.

\citet{cuccu11b} proposed an alternative approach for combining novelty and fitness, where the score of each individual is based on a linear scalarization of the novelty score and the fitness score (henceforth referred to as \emph{linear scalarization}). They applied the approach to a deceptive box-pushing task, and found that linear scalarization outperformed both novelty search and fitness-based evolution. \citet{mouret11} proposed novelty-based multiobjectivisation, which is a Pareto-based multi-objective evolutionary algorithm. A novelty objective is added to the task objective in a multi-objective optimisation. The technique was applied to a deceptive maze navigation problem. Compared with pure novelty search, the use of multiobjectivisation only led to marginally better results. Other techniques for sustaining behavioural diversity in evolutionary robotics are reviewed in \citep{mouret12}.

\subsection{NEAT}
In our experiments, the controllers of the robots are time recurrent neural networks evolved by NEAT (short for NeuroEvolution of Augmenting Topologies) \citep{stan02}. NEAT is a widely used neuroevolution approach, and one of the most successful approaches developed to date. NEAT simultaneously optimises the weighting parameters and the structure of artificial neural networks. It begins the evolution with a population of small, simple networks and complexifies the network topology into diverse species over generations. This leads to the evolution of increasingly sophisticated behaviour. A key feature in NEAT is its distinctive approach to maintain a diversity of growing structures simultaneously. Unique historical markings are assigned to each new structural component. During crossover, genes with the same historical markings are aligned, producing valid offspring efficiently, without the need of complex topological comparisons. NEAT uses speciation and fitness sharing to protect new structural innovations. This reduces competition between networks with distinct topologies, providing time for the weights of new structures to be optimised. Networks are assigned to species based on the extent to which they share historical markings. Complexification is thus supported by both historical markings and speciation, allowing NEAT to establish high-level features early in evolution and then elaborate on them as the evolutionary process progresses. In effect, NEAT searches for a compact, appropriate network topology by incrementally complexifying existing structures.

It is important to note that both novelty search and NEAT strive to maintain diversity, but at different levels: whereas NEAT maintains \emph{genotypic} diversity, novelty search maintains \emph{phenotypic} diversity. Novelty search and NEAT thus complement one another and their combined use bears a number of advantages. In particular, the complexification mechanism of NEAT can introduce order in the exploration done by novelty search, with less complex behaviours being explored before progressing to more complex ones~\citep{stan11a}.
